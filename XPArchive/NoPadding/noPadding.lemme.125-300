INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
+_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 67758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 4, 125)            63750     
_________________________________________________________________
flatten_1 (Flatten)          (None, 500)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 8)                 4008      
=================================================================
Total params: 67,758
Trainable params: 67,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.2492 - acc: 0.8704 - val_loss: 0.4887 - val_acc: 0.9803
Epoch 2/15
 - 0s - loss: 0.3005 - acc: 0.9743 - val_loss: 0.1660 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1417 - acc: 0.9744 - val_loss: 0.1040 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.1019 - acc: 0.9755 - val_loss: 0.0835 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:07.690136
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_2 (Embedding)      (None, 4, 125)            1851375   
_________________________________________________________________
flatten_2 (Flatten)          (None, 500)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0619 - acc: 0.9850 - val_loss: 0.0319 - val_acc: 0.9888
Epoch 2/15
 - 6s - loss: 0.0247 - acc: 0.9901 - val_loss: 0.0301 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0306 - val_acc: 0.9890
Epoch 00003: early stopping
# Training time = 0:04:30.164022
# F-Score(Ordinary) = 0.256, Recall: 0.929, Precision: 0.149
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.584, Recall: 0.915, Precision: 0.429
# F-Score(id) = 0.069, Recall: 1.0, Precision: 0.036
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_3 (Embedding)      (None, 4, 125)            1851375   
_________________________________________________________________
flatten_3 (Flatten)          (None, 500)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0628 - acc: 0.9845 - val_loss: 0.0315 - val_acc: 0.9894
Epoch 2/15
 - 6s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0303 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0210 - acc: 0.9906 - val_loss: 0.0301 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:04:28.626545
# F-Score(Ordinary) = 0.438, Recall: 0.933, Precision: 0.286
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.434, Recall: 0.9, Precision: 0.286
# F-Score(id) = 0.64, Recall: 0.942, Precision: 0.485
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_4 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_4 (Embedding)      (None, 4, 125)            1851375   
_________________________________________________________________
flatten_4 (Flatten)          (None, 500)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0623 - acc: 0.9848 - val_loss: 0.0335 - val_acc: 0.9892
Epoch 2/15
 - 6s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0304 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0211 - acc: 0.9907 - val_loss: 0.0306 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:04:27.942263
# F-Score(Ordinary) = 0.388, Recall: 0.939, Precision: 0.245
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.585, Recall: 0.887, Precision: 0.437
# F-Score(id) = 0.425, Recall: 1.0, Precision: 0.269
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_5 (Embedding)      (None, 4, 125)            1851375   
_________________________________________________________________
flatten_5 (Flatten)          (None, 500)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0630 - acc: 0.9844 - val_loss: 0.0319 - val_acc: 0.9893
Epoch 2/15
 - 6s - loss: 0.0247 - acc: 0.9900 - val_loss: 0.0306 - val_acc: 0.9892
Epoch 3/15
 - 6s - loss: 0.0210 - acc: 0.9907 - val_loss: 0.0304 - val_acc: 0.9890
Epoch 00003: early stopping
# Training time = 0:04:26.336810
# F-Score(Ordinary) = 0.357, Recall: 0.915, Precision: 0.222
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.508, Recall: 0.836, Precision: 0.365
# F-Score(id) = 0.417, Recall: 1.0, Precision: 0.263
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_6 (Embedding)      (None, 4, 125)            1851375   
_________________________________________________________________
flatten_6 (Flatten)          (None, 500)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0623 - acc: 0.9859 - val_loss: 0.0318 - val_acc: 0.9892
Epoch 2/15
 - 6s - loss: 0.0247 - acc: 0.9901 - val_loss: 0.0312 - val_acc: 0.9890
Epoch 3/15
 - 6s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0311 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:04:23.670809
# F-Score(Ordinary) = 0.215, Recall: 0.946, Precision: 0.121
# F-Score(lvc) = 0.318, Recall: 1.0, Precision: 0.189
# F-Score(ireflv) = 0.303, Recall: 0.885, Precision: 0.183
# F-Score(id) = 0.035, Recall: 1.0, Precision: 0.018
********************
********************
# XP = Lemma(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 81308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_7 (Embedding)      (None, 4, 150)            76500     
_________________________________________________________________
flatten_7 (Flatten)          (None, 600)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 8)                 4808      
=================================================================
Total params: 81,308
Trainable params: 81,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.1943 - acc: 0.8978 - val_loss: 0.4237 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.2599 - acc: 0.9744 - val_loss: 0.1459 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1286 - acc: 0.9747 - val_loss: 0.0975 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.0957 - acc: 0.9759 - val_loss: 0.0799 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:01.480234
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 2226458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_8 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_8 (Embedding)      (None, 4, 150)            2221650   
_________________________________________________________________
flatten_8 (Flatten)          (None, 600)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 8)                 4808      
=================================================================
Total params: 2,226,458
Trainable params: 2,226,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0605 - acc: 0.9845 - val_loss: 0.0319 - val_acc: 0.9889
Epoch 2/15
 - 6s - loss: 0.0247 - acc: 0.9901 - val_loss: 0.0301 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0307 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:04:05.574150
# F-Score(Ordinary) = 0.26, Recall: 0.943, Precision: 0.151
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.579, Recall: 0.93, Precision: 0.421
# F-Score(id) = 0.069, Recall: 1.0, Precision: 0.036
********************
********************
# XP = Lemma(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 2226458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_9 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_9 (Embedding)      (None, 4, 150)            2221650   
_________________________________________________________________
flatten_9 (Flatten)          (None, 600)               0         
_________________________________________________________________
dense_9 (Dense)              (None, 8)                 4808      
=================================================================
Total params: 2,226,458
Trainable params: 2,226,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0597 - acc: 0.9862 - val_loss: 0.0314 - val_acc: 0.9892
Epoch 2/15
 - 6s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0300 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0210 - acc: 0.9906 - val_loss: 0.0300 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:04:26.234124
# F-Score(Ordinary) = 0.459, Recall: 0.937, Precision: 0.304
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.462, Recall: 0.907, Precision: 0.31
# F-Score(id) = 0.656, Recall: 0.944, Precision: 0.503
********************
********************
# XP = Lemma(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 2226458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_10 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_10 (Embedding)     (None, 4, 150)            2221650   
_________________________________________________________________
flatten_10 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 2,226,458
Trainable params: 2,226,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0602 - acc: 0.9854 - val_loss: 0.0338 - val_acc: 0.9891
Epoch 2/15
 - 6s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0302 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0306 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:04:25.806172
# F-Score(Ordinary) = 0.388, Recall: 0.939, Precision: 0.245
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.585, Recall: 0.887, Precision: 0.437
# F-Score(id) = 0.425, Recall: 1.0, Precision: 0.269
********************
********************
# XP = Lemma(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 2226458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_11 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_11 (Embedding)     (None, 4, 150)            2221650   
_________________________________________________________________
flatten_11 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 2,226,458
Trainable params: 2,226,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0602 - acc: 0.9862 - val_loss: 0.0319 - val_acc: 0.9892
Epoch 2/15
 - 6s - loss: 0.0246 - acc: 0.9900 - val_loss: 0.0310 - val_acc: 0.9891
Epoch 3/15
 - 6s - loss: 0.0210 - acc: 0.9907 - val_loss: 0.0307 - val_acc: 0.9890
Epoch 00003: early stopping
# Training time = 0:04:28.054456
# F-Score(Ordinary) = 0.376, Recall: 0.928, Precision: 0.236
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.551, Recall: 0.864, Precision: 0.405
# F-Score(id) = 0.425, Recall: 1.0, Precision: 0.269
********************
********************
# XP = Lemma(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 2226458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_12 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_12 (Embedding)     (None, 4, 150)            2221650   
_________________________________________________________________
flatten_12 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 2,226,458
Trainable params: 2,226,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0601 - acc: 0.9860 - val_loss: 0.0319 - val_acc: 0.9891
Epoch 2/15
 - 6s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0316 - val_acc: 0.9888
Epoch 3/15
 - 6s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0312 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:04:25.984478
# F-Score(Ordinary) = 0.211, Recall: 0.945, Precision: 0.119
# F-Score(lvc) = 0.256, Recall: 1.0, Precision: 0.147
# F-Score(ireflv) = 0.367, Recall: 0.906, Precision: 0.23
# F-Score(id) = 0.024, Recall: 1.0, Precision: 0.012
********************
********************
# XP = Lemma(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 94858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_13 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_13 (Embedding)     (None, 4, 175)            89250     
_________________________________________________________________
flatten_13 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_13 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 94,858
Trainable params: 94,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.1044 - acc: 0.7997 - val_loss: 0.3621 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.2258 - acc: 0.9745 - val_loss: 0.1316 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1188 - acc: 0.9751 - val_loss: 0.0921 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.0895 - acc: 0.9772 - val_loss: 0.0764 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:01.496300
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 2597533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_14 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_14 (Embedding)     (None, 4, 175)            2591925   
_________________________________________________________________
flatten_14 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 2,597,533
Trainable params: 2,597,533
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0579 - acc: 0.9861 - val_loss: 0.0319 - val_acc: 0.9889
Epoch 2/15
 - 7s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0304 - val_acc: 0.9894
Epoch 3/15
 - 7s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0310 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:04:20.645761
# F-Score(Ordinary) = 0.27, Recall: 0.932, Precision: 0.158
# F-Score(lvc) = 0.081, Recall: 1.0, Precision: 0.042
# F-Score(ireflv) = 0.599, Recall: 0.918, Precision: 0.444
# F-Score(id) = 0.08, Recall: 1.0, Precision: 0.042
********************
********************
# XP = Lemma(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 2597533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_15 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_15 (Embedding)     (None, 4, 175)            2591925   
_________________________________________________________________
flatten_15 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_15 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 2,597,533
Trainable params: 2,597,533
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0582 - acc: 0.9856 - val_loss: 0.0316 - val_acc: 0.9892
Epoch 2/15
 - 7s - loss: 0.0244 - acc: 0.9901 - val_loss: 0.0302 - val_acc: 0.9894
Epoch 3/15
 - 7s - loss: 0.0210 - acc: 0.9906 - val_loss: 0.0301 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:04:13.083327
# F-Score(Ordinary) = 0.467, Recall: 0.932, Precision: 0.311
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.494, Recall: 0.896, Precision: 0.341
# F-Score(id) = 0.651, Recall: 0.943, Precision: 0.497
********************
********************
# XP = Lemma(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 2597533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_16 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_16 (Embedding)     (None, 4, 175)            2591925   
_________________________________________________________________
flatten_16 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 2,597,533
Trainable params: 2,597,533
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0582 - acc: 0.9864 - val_loss: 0.0339 - val_acc: 0.9891
Epoch 2/15
 - 7s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0303 - val_acc: 0.9894
Epoch 3/15
 - 7s - loss: 0.0210 - acc: 0.9907 - val_loss: 0.0306 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:04:17.338106
# F-Score(Ordinary) = 0.394, Recall: 0.94, Precision: 0.249
# F-Score(lvc) = 0.081, Recall: 1.0, Precision: 0.042
# F-Score(ireflv) = 0.6, Recall: 0.891, Precision: 0.452
# F-Score(id) = 0.432, Recall: 1.0, Precision: 0.275
********************
********************
# XP = Lemma(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 2597533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_17 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_17 (Embedding)     (None, 4, 175)            2591925   
_________________________________________________________________
flatten_17 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_17 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 2,597,533
Trainable params: 2,597,533
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0585 - acc: 0.9853 - val_loss: 0.0319 - val_acc: 0.9893
Epoch 2/15
 - 7s - loss: 0.0246 - acc: 0.9900 - val_loss: 0.0310 - val_acc: 0.9892
Epoch 3/15
 - 7s - loss: 0.0210 - acc: 0.9907 - val_loss: 0.0308 - val_acc: 0.9889
Epoch 00003: early stopping
# Training time = 0:04:07.243241
# F-Score(Ordinary) = 0.385, Recall: 0.93, Precision: 0.243
# F-Score(lvc) = 0.081, Recall: 1.0, Precision: 0.042
# F-Score(ireflv) = 0.582, Recall: 0.873, Precision: 0.437
# F-Score(id) = 0.425, Recall: 1.0, Precision: 0.269
********************
********************
# XP = Lemma(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 2597533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_18 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_18 (Embedding)     (None, 4, 175)            2591925   
_________________________________________________________________
flatten_18 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 2,597,533
Trainable params: 2,597,533
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0583 - acc: 0.9862 - val_loss: 0.0320 - val_acc: 0.9891
Epoch 2/15
 - 7s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0317 - val_acc: 0.9888
Epoch 3/15
 - 7s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0312 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:04:02.898410
# F-Score(Ordinary) = 0.215, Recall: 0.93, Precision: 0.121
# F-Score(lvc) = 0.286, Recall: 0.96, Precision: 0.168
# F-Score(ireflv) = 0.325, Recall: 0.893, Precision: 0.198
# F-Score(id) = 0.047, Recall: 1.0, Precision: 0.024
********************
********************
# XP = Lemma(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 108408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_19 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_19 (Embedding)     (None, 4, 200)            102000    
_________________________________________________________________
flatten_19 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_19 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 108,408
Trainable params: 108,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.0565 - acc: 0.8676 - val_loss: 0.3259 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.2055 - acc: 0.9744 - val_loss: 0.1220 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1120 - acc: 0.9751 - val_loss: 0.0878 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.0852 - acc: 0.9781 - val_loss: 0.0738 - val_acc: 0.9783
Epoch 00004: early stopping
# Training time = 0:00:01.490709
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 2968608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_20 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_20 (Embedding)     (None, 4, 200)            2962200   
_________________________________________________________________
flatten_20 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 2,968,608
Trainable params: 2,968,608
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0569 - acc: 0.9851 - val_loss: 0.0320 - val_acc: 0.9889
Epoch 2/15
 - 8s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0304 - val_acc: 0.9893
Epoch 3/15
 - 8s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0310 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:04:16.384444
# F-Score(Ordinary) = 0.29, Recall: 0.926, Precision: 0.172
# F-Score(lvc) = 0.081, Recall: 1.0, Precision: 0.042
# F-Score(ireflv) = 0.618, Recall: 0.908, Precision: 0.468
# F-Score(id) = 0.113, Recall: 1.0, Precision: 0.06
********************
********************
# XP = Lemma(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 2968608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_21 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_21 (Embedding)     (None, 4, 200)            2962200   
_________________________________________________________________
flatten_21 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_21 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 2,968,608
Trainable params: 2,968,608
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0572 - acc: 0.9851 - val_loss: 0.0318 - val_acc: 0.9892
Epoch 2/15
 - 8s - loss: 0.0244 - acc: 0.9901 - val_loss: 0.0303 - val_acc: 0.9895
Epoch 3/15
 - 8s - loss: 0.0210 - acc: 0.9906 - val_loss: 0.0302 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:55.322487
# F-Score(Ordinary) = 0.464, Recall: 0.931, Precision: 0.309
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.511, Recall: 0.9, Precision: 0.357
# F-Score(id) = 0.646, Recall: 0.943, Precision: 0.491
********************
********************
# XP = Lemma(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 2968608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_22 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_22 (Embedding)     (None, 4, 200)            2962200   
_________________________________________________________________
flatten_22 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_22 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 2,968,608
Trainable params: 2,968,608
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0566 - acc: 0.9863 - val_loss: 0.0339 - val_acc: 0.9891
Epoch 2/15
 - 8s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0303 - val_acc: 0.9895
Epoch 3/15
 - 8s - loss: 0.0210 - acc: 0.9907 - val_loss: 0.0305 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:04:06.283762
# F-Score(Ordinary) = 0.385, Recall: 0.938, Precision: 0.243
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.593, Recall: 0.889, Precision: 0.444
# F-Score(id) = 0.425, Recall: 1.0, Precision: 0.269
********************
********************
# XP = Lemma(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 2968608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_23 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_23 (Embedding)     (None, 4, 200)            2962200   
_________________________________________________________________
flatten_23 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_23 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 2,968,608
Trainable params: 2,968,608
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0567 - acc: 0.9858 - val_loss: 0.0320 - val_acc: 0.9892
Epoch 2/15
 - 8s - loss: 0.0246 - acc: 0.9900 - val_loss: 0.0313 - val_acc: 0.9890
Epoch 3/15
 - 8s - loss: 0.0211 - acc: 0.9908 - val_loss: 0.0311 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:04:12.372132
# F-Score(Ordinary) = 0.39, Recall: 0.923, Precision: 0.247
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.564, Recall: 0.855, Precision: 0.421
# F-Score(id) = 0.439, Recall: 1.0, Precision: 0.281
********************
********************
# XP = Lemma(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 2968608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_24 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_24 (Embedding)     (None, 4, 200)            2962200   
_________________________________________________________________
flatten_24 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_24 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 2,968,608
Trainable params: 2,968,608
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0571 - acc: 0.9856 - val_loss: 0.0319 - val_acc: 0.9891
Epoch 2/15
 - 8s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0319 - val_acc: 0.9887
Epoch 3/15
 - 8s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0313 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:04:03.140869
# F-Score(Ordinary) = 0.211, Recall: 0.929, Precision: 0.119
# F-Score(lvc) = 0.265, Recall: 0.957, Precision: 0.154
# F-Score(ireflv) = 0.346, Recall: 0.9, Precision: 0.214
# F-Score(id) = 0.035, Recall: 1.0, Precision: 0.018
********************
********************
# XP = Lemma(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 121958
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_25 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_25 (Embedding)     (None, 4, 225)            114750    
_________________________________________________________________
flatten_25 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_25 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 121,958
Trainable params: 121,958
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.0205 - acc: 0.8429 - val_loss: 0.2929 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.1892 - acc: 0.9744 - val_loss: 0.1138 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1072 - acc: 0.9754 - val_loss: 0.0834 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.0823 - acc: 0.9786 - val_loss: 0.0706 - val_acc: 0.9793
Epoch 5/15
 - 0s - loss: 0.0677 - acc: 0.9817 - val_loss: 0.0633 - val_acc: 0.9843
Epoch 00005: early stopping
# Training time = 0:00:01.585170
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 3339683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_26 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_26 (Embedding)     (None, 4, 225)            3332475   
_________________________________________________________________
flatten_26 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_26 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 3,339,683
Trainable params: 3,339,683
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0553 - acc: 0.9865 - val_loss: 0.0320 - val_acc: 0.9889
Epoch 2/15
 - 8s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0304 - val_acc: 0.9895
Epoch 3/15
 - 8s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0309 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:52.747657
# F-Score(Ordinary) = 0.286, Recall: 0.925, Precision: 0.169
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.618, Recall: 0.908, Precision: 0.468
# F-Score(id) = 0.113, Recall: 1.0, Precision: 0.06
********************
********************
# XP = Lemma(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 3339683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_27 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_27 (Embedding)     (None, 4, 225)            3332475   
_________________________________________________________________
flatten_27 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_27 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 3,339,683
Trainable params: 3,339,683
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0557 - acc: 0.9865 - val_loss: 0.0321 - val_acc: 0.9892
Epoch 2/15
 - 8s - loss: 0.0244 - acc: 0.9901 - val_loss: 0.0304 - val_acc: 0.9894
Epoch 3/15
 - 8s - loss: 0.0210 - acc: 0.9906 - val_loss: 0.0302 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:04:41.557269
# F-Score(Ordinary) = 0.469, Recall: 0.932, Precision: 0.314
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.511, Recall: 0.9, Precision: 0.357
# F-Score(id) = 0.656, Recall: 0.944, Precision: 0.503
********************
********************
# XP = Lemma(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 3339683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_28 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_28 (Embedding)     (None, 4, 225)            3332475   
_________________________________________________________________
flatten_28 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_28 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 3,339,683
Trainable params: 3,339,683
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0557 - acc: 0.9864 - val_loss: 0.0343 - val_acc: 0.9891
Epoch 2/15
 - 8s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0305 - val_acc: 0.9894
Epoch 3/15
 - 8s - loss: 0.0211 - acc: 0.9907 - val_loss: 0.0306 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:04:39.023892
# F-Score(Ordinary) = 0.38, Recall: 0.937, Precision: 0.238
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.578, Recall: 0.885, Precision: 0.429
# F-Score(id) = 0.425, Recall: 1.0, Precision: 0.269
********************
********************
# XP = Lemma(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 3339683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_29 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_29 (Embedding)     (None, 4, 225)            3332475   
_________________________________________________________________
flatten_29 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_29 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 3,339,683
Trainable params: 3,339,683
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0561 - acc: 0.9853 - val_loss: 0.0320 - val_acc: 0.9892
Epoch 2/15
 - 8s - loss: 0.0246 - acc: 0.9900 - val_loss: 0.0314 - val_acc: 0.9890
Epoch 3/15
 - 8s - loss: 0.0211 - acc: 0.9908 - val_loss: 0.0312 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:01.963670
# F-Score(Ordinary) = 0.407, Recall: 0.927, Precision: 0.261
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.579, Recall: 0.859, Precision: 0.437
# F-Score(id) = 0.454, Recall: 1.0, Precision: 0.293
********************
********************
# XP = Lemma(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 3339683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_30 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_30 (Embedding)     (None, 4, 225)            3332475   
_________________________________________________________________
flatten_30 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_30 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 3,339,683
Trainable params: 3,339,683
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0552 - acc: 0.9867 - val_loss: 0.0321 - val_acc: 0.9888
Epoch 2/15
 - 8s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0320 - val_acc: 0.9887
Epoch 3/15
 - 8s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0313 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:04:20.110875
# F-Score(Ordinary) = 0.211, Recall: 0.929, Precision: 0.119
# F-Score(lvc) = 0.255, Recall: 0.955, Precision: 0.147
# F-Score(ireflv) = 0.357, Recall: 0.903, Precision: 0.222
# F-Score(id) = 0.035, Recall: 1.0, Precision: 0.018
********************
********************
# XP = Lemma(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 135508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_31 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_31 (Embedding)     (None, 4, 250)            127500    
_________________________________________________________________
flatten_31 (Flatten)         (None, 1000)              0         
_________________________________________________________________
dense_31 (Dense)             (None, 8)                 8008      
=================================================================
Total params: 135,508
Trainable params: 135,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.0026 - acc: 0.8669 - val_loss: 0.2950 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.1882 - acc: 0.9745 - val_loss: 0.1135 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1051 - acc: 0.9752 - val_loss: 0.0835 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.0802 - acc: 0.9792 - val_loss: 0.0709 - val_acc: 0.9793
Epoch 5/15
 - 0s - loss: 0.0656 - acc: 0.9815 - val_loss: 0.0636 - val_acc: 0.9823
Epoch 00005: early stopping
# Training time = 0:00:01.617918
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 3710758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_32 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_32 (Embedding)     (None, 4, 250)            3702750   
_________________________________________________________________
flatten_32 (Flatten)         (None, 1000)              0         
_________________________________________________________________
dense_32 (Dense)             (None, 8)                 8008      
=================================================================
Total params: 3,710,758
Trainable params: 3,710,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0546 - acc: 0.9861 - val_loss: 0.0320 - val_acc: 0.9890
Epoch 2/15
 - 9s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0305 - val_acc: 0.9894
Epoch 3/15
 - 9s - loss: 0.0211 - acc: 0.9907 - val_loss: 0.0310 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:04:15.311197
# F-Score(Ordinary) = 0.28, Recall: 0.923, Precision: 0.165
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.618, Recall: 0.908, Precision: 0.468
# F-Score(id) = 0.091, Recall: 1.0, Precision: 0.048
********************
********************
# XP = Lemma(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 3710758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_33 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_33 (Embedding)     (None, 4, 250)            3702750   
_________________________________________________________________
flatten_33 (Flatten)         (None, 1000)              0         
_________________________________________________________________
dense_33 (Dense)             (None, 8)                 8008      
=================================================================
Total params: 3,710,758
Trainable params: 3,710,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0549 - acc: 0.9854 - val_loss: 0.0322 - val_acc: 0.9892
Epoch 2/15
 - 9s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0306 - val_acc: 0.9895
Epoch 3/15
 - 9s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0304 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:04:03.774847
# F-Score(Ordinary) = 0.463, Recall: 0.925, Precision: 0.309
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.508, Recall: 0.882, Precision: 0.357
# F-Score(id) = 0.64, Recall: 0.942, Precision: 0.485
********************
********************
# XP = Lemma(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 3710758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_34 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_34 (Embedding)     (None, 4, 250)            3702750   
_________________________________________________________________
flatten_34 (Flatten)         (None, 1000)              0         
_________________________________________________________________
dense_34 (Dense)             (None, 8)                 8008      
=================================================================
Total params: 3,710,758
Trainable params: 3,710,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0546 - acc: 0.9863 - val_loss: 0.0343 - val_acc: 0.9891
Epoch 2/15
 - 9s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0308 - val_acc: 0.9895
Epoch 3/15
 - 9s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0309 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:04:29.461305
# F-Score(Ordinary) = 0.388, Recall: 0.939, Precision: 0.245
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.585, Recall: 0.887, Precision: 0.437
# F-Score(id) = 0.439, Recall: 1.0, Precision: 0.281
********************
********************
# XP = Lemma(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 3710758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_35 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_35 (Embedding)     (None, 4, 250)            3702750   
_________________________________________________________________
flatten_35 (Flatten)         (None, 1000)              0         
_________________________________________________________________
dense_35 (Dense)             (None, 8)                 8008      
=================================================================
Total params: 3,710,758
Trainable params: 3,710,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0547 - acc: 0.9863 - val_loss: 0.0320 - val_acc: 0.9891
Epoch 2/15
 - 9s - loss: 0.0246 - acc: 0.9900 - val_loss: 0.0315 - val_acc: 0.9890
Epoch 3/15
 - 9s - loss: 0.0211 - acc: 0.9907 - val_loss: 0.0314 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:04:18.219679
# F-Score(Ordinary) = 0.404, Recall: 0.926, Precision: 0.259
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.571, Recall: 0.857, Precision: 0.429
# F-Score(id) = 0.461, Recall: 1.0, Precision: 0.299
********************
********************
# XP = Lemma(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 3710758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_36 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_36 (Embedding)     (None, 4, 250)            3702750   
_________________________________________________________________
flatten_36 (Flatten)         (None, 1000)              0         
_________________________________________________________________
dense_36 (Dense)             (None, 8)                 8008      
=================================================================
Total params: 3,710,758
Trainable params: 3,710,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0548 - acc: 0.9856 - val_loss: 0.0322 - val_acc: 0.9888
Epoch 2/15
 - 9s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0323 - val_acc: 0.9886
Epoch 3/15
 - 9s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0314 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:04:28.758884
# F-Score(Ordinary) = 0.189, Recall: 0.92, Precision: 0.105
# F-Score(lvc) = 0.2, Recall: 0.941, Precision: 0.112
# F-Score(ireflv) = 0.346, Recall: 0.9, Precision: 0.214
# F-Score(id) = 0.035, Recall: 1.0, Precision: 0.018
********************
********************
# XP = Lemma(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 149058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_37 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_37 (Embedding)     (None, 4, 275)            140250    
_________________________________________________________________
flatten_37 (Flatten)         (None, 1100)              0         
_________________________________________________________________
dense_37 (Dense)             (None, 8)                 8808      
=================================================================
Total params: 149,058
Trainable params: 149,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 0.9202 - acc: 0.8772 - val_loss: 0.2400 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.1651 - acc: 0.9746 - val_loss: 0.1036 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.0995 - acc: 0.9754 - val_loss: 0.0783 - val_acc: 0.9793
Epoch 00003: early stopping
# Training time = 0:00:01.428338
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 4081833
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_38 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_38 (Embedding)     (None, 4, 275)            4073025   
_________________________________________________________________
flatten_38 (Flatten)         (None, 1100)              0         
_________________________________________________________________
dense_38 (Dense)             (None, 8)                 8808      
=================================================================
Total params: 4,081,833
Trainable params: 4,081,833
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0540 - acc: 0.9865 - val_loss: 0.0322 - val_acc: 0.9889
Epoch 2/15
 - 10s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0305 - val_acc: 0.9894
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0310 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:04:46.194202
# F-Score(Ordinary) = 0.286, Recall: 0.925, Precision: 0.169
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.625, Recall: 0.909, Precision: 0.476
# F-Score(id) = 0.102, Recall: 1.0, Precision: 0.054
********************
********************
# XP = Lemma(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 4081833
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_39 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_39 (Embedding)     (None, 4, 275)            4073025   
_________________________________________________________________
flatten_39 (Flatten)         (None, 1100)              0         
_________________________________________________________________
dense_39 (Dense)             (None, 8)                 8808      
=================================================================
Total params: 4,081,833
Trainable params: 4,081,833
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0539 - acc: 0.9865 - val_loss: 0.0324 - val_acc: 0.9892
Epoch 2/15
 - 10s - loss: 0.0244 - acc: 0.9901 - val_loss: 0.0305 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0302 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:04:16.730510
# F-Score(Ordinary) = 0.468, Recall: 0.926, Precision: 0.314
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.517, Recall: 0.885, Precision: 0.365
# F-Score(id) = 0.656, Recall: 0.944, Precision: 0.503
********************
********************
# XP = Lemma(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 4081833
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_40 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_40 (Embedding)     (None, 4, 275)            4073025   
_________________________________________________________________
flatten_40 (Flatten)         (None, 1100)              0         
_________________________________________________________________
dense_40 (Dense)             (None, 8)                 8808      
=================================================================
Total params: 4,081,833
Trainable params: 4,081,833
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0539 - acc: 0.9866 - val_loss: 0.0343 - val_acc: 0.9891
Epoch 2/15
 - 10s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0307 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0307 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:04:26.935839
# F-Score(Ordinary) = 0.38, Recall: 0.937, Precision: 0.238
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.585, Recall: 0.887, Precision: 0.437
# F-Score(id) = 0.417, Recall: 1.0, Precision: 0.263
********************
********************
# XP = Lemma(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 4081833
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_41 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_41 (Embedding)     (None, 4, 275)            4073025   
_________________________________________________________________
flatten_41 (Flatten)         (None, 1100)              0         
_________________________________________________________________
dense_41 (Dense)             (None, 8)                 8808      
=================================================================
Total params: 4,081,833
Trainable params: 4,081,833
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0541 - acc: 0.9857 - val_loss: 0.0322 - val_acc: 0.9893
Epoch 2/15
 - 10s - loss: 0.0247 - acc: 0.9900 - val_loss: 0.0318 - val_acc: 0.9890
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0317 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:04:34.314432
# F-Score(Ordinary) = 0.421, Recall: 0.93, Precision: 0.272
# F-Score(lvc) = 0.155, Recall: 1.0, Precision: 0.084
# F-Score(ireflv) = 0.586, Recall: 0.862, Precision: 0.444
# F-Score(id) = 0.468, Recall: 1.0, Precision: 0.305
********************
********************
# XP = Lemma(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 4081833
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_42 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_42 (Embedding)     (None, 4, 275)            4073025   
_________________________________________________________________
flatten_42 (Flatten)         (None, 1100)              0         
_________________________________________________________________
dense_42 (Dense)             (None, 8)                 8808      
=================================================================
Total params: 4,081,833
Trainable params: 4,081,833
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0532 - acc: 0.9867 - val_loss: 0.0323 - val_acc: 0.9889
Epoch 2/15
 - 10s - loss: 0.0247 - acc: 0.9900 - val_loss: 0.0325 - val_acc: 0.9886
Epoch 3/15
 - 10s - loss: 0.0214 - acc: 0.9906 - val_loss: 0.0315 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:04:02.870686
# F-Score(Ordinary) = 0.193, Recall: 0.94, Precision: 0.108
# F-Score(lvc) = 0.201, Recall: 1.0, Precision: 0.112
# F-Score(ireflv) = 0.346, Recall: 0.9, Precision: 0.214
# F-Score(id) = 0.047, Recall: 1.0, Precision: 0.024
********************
********************
# XP = Lemma(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 162608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_43 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_43 (Embedding)     (None, 4, 300)            153000    
_________________________________________________________________
flatten_43 (Flatten)         (None, 1200)              0         
_________________________________________________________________
dense_43 (Dense)             (None, 8)                 9608      
=================================================================
Total params: 162,608
Trainable params: 162,608
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 0.9029 - acc: 0.8988 - val_loss: 0.2302 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.1583 - acc: 0.9744 - val_loss: 0.0999 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.0958 - acc: 0.9760 - val_loss: 0.0762 - val_acc: 0.9803
Epoch 00003: early stopping
# Training time = 0:00:01.456576
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 4452908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_44 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_44 (Embedding)     (None, 4, 300)            4443300   
_________________________________________________________________
flatten_44 (Flatten)         (None, 1200)              0         
_________________________________________________________________
dense_44 (Dense)             (None, 8)                 9608      
=================================================================
Total params: 4,452,908
Trainable params: 4,452,908
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0529 - acc: 0.9856 - val_loss: 0.0321 - val_acc: 0.9890
Epoch 2/15
 - 10s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0304 - val_acc: 0.9894
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0309 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:04:00.103245
# F-Score(Ordinary) = 0.293, Recall: 0.927, Precision: 0.174
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.625, Recall: 0.909, Precision: 0.476
# F-Score(id) = 0.124, Recall: 1.0, Precision: 0.066
********************
********************
# XP = Lemma(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 4452908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_45 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_45 (Embedding)     (None, 4, 300)            4443300   
_________________________________________________________________
flatten_45 (Flatten)         (None, 1200)              0         
_________________________________________________________________
dense_45 (Dense)             (None, 8)                 9608      
=================================================================
Total params: 4,452,908
Trainable params: 4,452,908
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0531 - acc: 0.9868 - val_loss: 0.0325 - val_acc: 0.9891
Epoch 2/15
 - 10s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0305 - val_acc: 0.9896
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0301 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:54.359148
# F-Score(Ordinary) = 0.475, Recall: 0.939, Precision: 0.318
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.528, Recall: 0.904, Precision: 0.373
# F-Score(id) = 0.659, Recall: 0.955, Precision: 0.503
********************
********************
# XP = Lemma(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 4452908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_46 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_46 (Embedding)     (None, 4, 300)            4443300   
_________________________________________________________________
flatten_46 (Flatten)         (None, 1200)              0         
_________________________________________________________________
dense_46 (Dense)             (None, 8)                 9608      
=================================================================
Total params: 4,452,908
Trainable params: 4,452,908
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0532 - acc: 0.9859 - val_loss: 0.0344 - val_acc: 0.9891
Epoch 2/15
 - 10s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0307 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0308 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:03:56.815215
# F-Score(Ordinary) = 0.38, Recall: 0.937, Precision: 0.238
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.593, Recall: 0.889, Precision: 0.444
# F-Score(id) = 0.417, Recall: 1.0, Precision: 0.263
********************
********************
# XP = Lemma(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 4452908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_47 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_47 (Embedding)     (None, 4, 300)            4443300   
_________________________________________________________________
flatten_47 (Flatten)         (None, 1200)              0         
_________________________________________________________________
dense_47 (Dense)             (None, 8)                 9608      
=================================================================
Total params: 4,452,908
Trainable params: 4,452,908
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0535 - acc: 0.9856 - val_loss: 0.0322 - val_acc: 0.9892
Epoch 2/15
 - 10s - loss: 0.0247 - acc: 0.9901 - val_loss: 0.0317 - val_acc: 0.9890
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9908 - val_loss: 0.0314 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:49.901811
# F-Score(Ordinary) = 0.415, Recall: 0.921, Precision: 0.268
# F-Score(lvc) = 0.143, Recall: 1.0, Precision: 0.077
# F-Score(ireflv) = 0.576, Recall: 0.846, Precision: 0.437
# F-Score(id) = 0.468, Recall: 1.0, Precision: 0.305
********************
********************
# XP = Lemma(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 4452908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_48 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_48 (Embedding)     (None, 4, 300)            4443300   
_________________________________________________________________
flatten_48 (Flatten)         (None, 1200)              0         
_________________________________________________________________
dense_48 (Dense)             (None, 8)                 9608      
=================================================================
Total params: 4,452,908
Trainable params: 4,452,908
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0532 - acc: 0.9867 - val_loss: 0.0323 - val_acc: 0.9888
Epoch 2/15
 - 10s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0326 - val_acc: 0.9886
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0315 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:04:00.890789
# F-Score(Ordinary) = 0.215, Recall: 0.93, Precision: 0.121
# F-Score(lvc) = 0.211, Recall: 0.944, Precision: 0.119
# F-Score(ireflv) = 0.407, Recall: 0.917, Precision: 0.262
# F-Score(id) = 0.035, Recall: 1.0, Precision: 0.018
********************
