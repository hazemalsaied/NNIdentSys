INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
+_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
Train enabled
# Seed = 0
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 431633
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 12, 25)            429225    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 431,633
Trainable params: 431,633
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 297
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0767 - acc: 0.9786 - val_loss: 0.0328 - val_acc: 0.9875
Epoch 2/15
 - 6s - loss: 0.0242 - acc: 0.9894 - val_loss: 0.0326 - val_acc: 0.9884
Epoch 3/15
 - 6s - loss: 0.0203 - acc: 0.9907 - val_loss: 0.0339 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0289 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0195 - acc: 0.9907
Epoch 3/3
 - 1s - loss: 0.0163 - acc: 0.9922
# Training time = 0:05:37.167197!
# F-Score(Ordinary) = 0.339, Recall: 0.588, Precision: 0.238
# F-Score(lvc) = 0.172, Recall: 0.7, Precision: 0.098
# F-Score(ireflv) = 0.016, Recall: 0.333, Precision: 0.008
# F-Score(id) = 0.536, Recall: 0.558, Precision: 0.515
********************
# Seed = 1
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 431183
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_2 (Embedding)      (None, 12, 25)            428775    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 431,183
Trainable params: 431,183
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0785 - acc: 0.9792 - val_loss: 0.0329 - val_acc: 0.9874
Epoch 2/15
 - 6s - loss: 0.0241 - acc: 0.9895 - val_loss: 0.0316 - val_acc: 0.9884
Epoch 3/15
 - 6s - loss: 0.0202 - acc: 0.9906 - val_loss: 0.0328 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0283 - acc: 0.9884
Epoch 2/3
 - 1s - loss: 0.0196 - acc: 0.9910
Epoch 3/3
 - 1s - loss: 0.0162 - acc: 0.9923
# Training time = 0:05:11.356518!
# F-Score(Ordinary) = 0.47, Recall: 0.649, Precision: 0.368
# F-Score(lvc) = 0.287, Recall: 0.806, Precision: 0.175
# F-Score(ireflv) = 0.693, Recall: 0.788, Precision: 0.619
# F-Score(id) = 0.393, Recall: 0.475, Precision: 0.335
********************
# Seed = 2
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 431333
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_3 (Embedding)      (None, 12, 25)            428925    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 431,333
Trainable params: 431,333
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 427
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0791 - acc: 0.9814 - val_loss: 0.0334 - val_acc: 0.9875
Epoch 2/15
 - 6s - loss: 0.0244 - acc: 0.9894 - val_loss: 0.0319 - val_acc: 0.9882
Epoch 3/15
 - 6s - loss: 0.0203 - acc: 0.9908 - val_loss: 0.0330 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0284 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0191 - acc: 0.9912
Epoch 3/3
 - 1s - loss: 0.0160 - acc: 0.9926
# Training time = 0:05:14.678685!
# F-Score(Ordinary) = 0.516, Recall: 0.573, Precision: 0.469
# F-Score(lvc) = 0.365, Recall: 0.667, Precision: 0.252
# F-Score(ireflv) = 0.675, Recall: 0.711, Precision: 0.643
# F-Score(id) = 0.476, Recall: 0.447, Precision: 0.509
********************
# Seed = 3
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 431733
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_4 (Embedding)      (None, 12, 25)            429325    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 431,733
Trainable params: 431,733
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 433
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0802 - acc: 0.9788 - val_loss: 0.0331 - val_acc: 0.9875
Epoch 2/15
 - 6s - loss: 0.0245 - acc: 0.9894 - val_loss: 0.0321 - val_acc: 0.9881
Epoch 3/15
 - 6s - loss: 0.0204 - acc: 0.9907 - val_loss: 0.0332 - val_acc: 0.9880
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0292 - acc: 0.9882
Epoch 2/3
 - 1s - loss: 0.0197 - acc: 0.9911
Epoch 3/3
 - 1s - loss: 0.0164 - acc: 0.9921
# Training time = 0:05:14.857288!
# F-Score(Ordinary) = 0.393, Recall: 0.651, Precision: 0.281
# F-Score(lvc) = 0.436, Recall: 0.598, Precision: 0.343
# F-Score(ireflv) = 0.031, Recall: 0.667, Precision: 0.016
# F-Score(id) = 0.509, Recall: 0.663, Precision: 0.413
********************
# Seed = 4
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 431583
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_5 (Embedding)      (None, 12, 25)            429175    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 431,583
Trainable params: 431,583
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 295
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0789 - acc: 0.9801 - val_loss: 0.0345 - val_acc: 0.9871
Epoch 2/15
 - 6s - loss: 0.0245 - acc: 0.9892 - val_loss: 0.0333 - val_acc: 0.9881
Epoch 3/15
 - 6s - loss: 0.0205 - acc: 0.9906 - val_loss: 0.0354 - val_acc: 0.9879
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0289 - acc: 0.9885
Epoch 2/3
 - 1s - loss: 0.0196 - acc: 0.9911
Epoch 3/3
 - 1s - loss: 0.0163 - acc: 0.9923
# Training time = 0:04:50.054342!
# F-Score(Ordinary) = 0.161, Recall: 0.656, Precision: 0.092
# F-Score(lvc) = 0.115, Recall: 0.692, Precision: 0.063
# F-Score(id) = 0.288, Recall: 0.646, Precision: 0.186
********************
# Seed = 5
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 432083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_6 (Embedding)      (None, 12, 25)            429675    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 432,083
Trainable params: 432,083
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 450
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0786 - acc: 0.9794 - val_loss: 0.0337 - val_acc: 0.9874
Epoch 2/15
 - 6s - loss: 0.0241 - acc: 0.9895 - val_loss: 0.0319 - val_acc: 0.9881
Epoch 3/15
 - 6s - loss: 0.0202 - acc: 0.9908 - val_loss: 0.0335 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0289 - acc: 0.9883
Epoch 2/3
 - 1s - loss: 0.0196 - acc: 0.9911
Epoch 3/3
 - 1s - loss: 0.0162 - acc: 0.9921
# Training time = 0:04:54.717036!
# F-Score(Ordinary) = 0.427, Recall: 0.715, Precision: 0.304
# F-Score(lvc) = 0.435, Recall: 0.703, Precision: 0.315
# F-Score(ireflv) = 0.701, Recall: 0.771, Precision: 0.643
# F-Score(id) = 0.054, Recall: 0.294, Precision: 0.03
********************
# Seed = 6
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 432233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_7 (Embedding)      (None, 12, 25)            429825    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 432,233
Trainable params: 432,233
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 483
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0795 - acc: 0.9805 - val_loss: 0.0361 - val_acc: 0.9867
Epoch 2/15
 - 6s - loss: 0.0244 - acc: 0.9895 - val_loss: 0.0319 - val_acc: 0.9881
Epoch 3/15
 - 6s - loss: 0.0204 - acc: 0.9906 - val_loss: 0.0333 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0285 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0191 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0161 - acc: 0.9923
# Training time = 0:05:05.457930!
# F-Score(Ordinary) = 0.385, Recall: 0.578, Precision: 0.288
# F-Score(lvc) = 0.425, Recall: 0.652, Precision: 0.315
# F-Score(ireflv) = 0.031, Recall: 0.5, Precision: 0.016
# F-Score(id) = 0.481, Recall: 0.517, Precision: 0.449
********************
# Seed = 7
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 431958
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_8 (Embedding)      (None, 12, 25)            429550    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 431,958
Trainable params: 431,958
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 419
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0803 - acc: 0.9799 - val_loss: 0.0328 - val_acc: 0.9874
Epoch 2/15
 - 6s - loss: 0.0241 - acc: 0.9896 - val_loss: 0.0328 - val_acc: 0.9882
Epoch 3/15
 - 6s - loss: 0.0202 - acc: 0.9909 - val_loss: 0.0341 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0282 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0192 - acc: 0.9910
Epoch 3/3
 - 1s - loss: 0.0160 - acc: 0.9923
# Training time = 0:05:13.918792!
# F-Score(Ordinary) = 0.364, Recall: 0.474, Precision: 0.295
# F-Score(lvc) = 0.4, Recall: 0.702, Precision: 0.28
# F-Score(ireflv) = 0.06, Recall: 0.571, Precision: 0.032
# F-Score(id) = 0.427, Recall: 0.385, Precision: 0.479
********************
# Seed = 8
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 431633
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_9 (Embedding)      (None, 12, 25)            429225    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 431,633
Trainable params: 431,633
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 263
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0778 - acc: 0.9818 - val_loss: 0.0344 - val_acc: 0.9872
Epoch 2/15
 - 6s - loss: 0.0243 - acc: 0.9894 - val_loss: 0.0329 - val_acc: 0.9883
Epoch 3/15
 - 6s - loss: 0.0204 - acc: 0.9906 - val_loss: 0.0338 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0287 - acc: 0.9883
Epoch 2/3
 - 1s - loss: 0.0194 - acc: 0.9912
Epoch 3/3
 - 1s - loss: 0.0163 - acc: 0.9922
# Training time = 0:05:09.670346!
# F-Score(Ordinary) = 0.324, Recall: 0.638, Precision: 0.217
# F-Score(lvc) = 0.207, Recall: 0.81, Precision: 0.119
# F-Score(id) = 0.522, Recall: 0.602, Precision: 0.461
********************
# Seed = 9
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 432058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_10 (Embedding)     (None, 12, 25)            429650    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 432,058
Trainable params: 432,058
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 150
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0780 - acc: 0.9797 - val_loss: 0.0340 - val_acc: 0.9873
Epoch 2/15
 - 6s - loss: 0.0244 - acc: 0.9893 - val_loss: 0.0329 - val_acc: 0.9880
Epoch 3/15
 - 6s - loss: 0.0204 - acc: 0.9907 - val_loss: 0.0329 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0286 - acc: 0.9883
Epoch 2/3
 - 1s - loss: 0.0195 - acc: 0.9910
Epoch 3/3
 - 1s - loss: 0.0164 - acc: 0.9920
# Training time = 0:05:14.420216!
# F-Score(Ordinary) = 0.4, Recall: 0.72, Precision: 0.277
# F-Score(lvc) = 0.271, Recall: 0.706, Precision: 0.168
# F-Score(ireflv) = 0.716, Recall: 0.783, Precision: 0.659
# F-Score(id) = 0.133, Recall: 0.464, Precision: 0.078
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 863258
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_11 (Embedding)     (None, 12, 50)            858450    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 863,258
Trainable params: 863,258
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 297
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0644 - acc: 0.9820 - val_loss: 0.0326 - val_acc: 0.9877
Epoch 2/15
 - 6s - loss: 0.0230 - acc: 0.9899 - val_loss: 0.0332 - val_acc: 0.9884
Epoch 3/15
 - 6s - loss: 0.0196 - acc: 0.9910 - val_loss: 0.0347 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0285 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0179 - acc: 0.9914
Epoch 3/3
 - 1s - loss: 0.0149 - acc: 0.9930
# Training time = 0:04:59.930280!
# F-Score(Ordinary) = 0.283, Recall: 0.473, Precision: 0.201
# F-Score(lvc) = 0.027, Recall: 0.5, Precision: 0.014
# F-Score(id) = 0.481, Recall: 0.462, Precision: 0.503
********************
# Seed = 1
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 862358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_12 (Embedding)     (None, 12, 50)            857550    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 862,358
Trainable params: 862,358
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0658 - acc: 0.9804 - val_loss: 0.0326 - val_acc: 0.9877
Epoch 2/15
 - 6s - loss: 0.0230 - acc: 0.9898 - val_loss: 0.0324 - val_acc: 0.9883
Epoch 3/15
 - 6s - loss: 0.0195 - acc: 0.9908 - val_loss: 0.0337 - val_acc: 0.9887
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0281 - acc: 0.9885
Epoch 2/3
 - 1s - loss: 0.0183 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0148 - acc: 0.9927
# Training time = 0:05:15.021944!
# F-Score(Ordinary) = 0.471, Recall: 0.633, Precision: 0.375
# F-Score(lvc) = 0.226, Recall: 0.76, Precision: 0.133
# F-Score(ireflv) = 0.7, Recall: 0.748, Precision: 0.659
# F-Score(id) = 0.407, Recall: 0.48, Precision: 0.353
********************
# Seed = 2
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 862658
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_13 (Embedding)     (None, 12, 50)            857850    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 862,658
Trainable params: 862,658
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 427
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0648 - acc: 0.9843 - val_loss: 0.0328 - val_acc: 0.9879
Epoch 2/15
 - 6s - loss: 0.0232 - acc: 0.9899 - val_loss: 0.0323 - val_acc: 0.9881
Epoch 3/15
 - 6s - loss: 0.0197 - acc: 0.9911 - val_loss: 0.0337 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0282 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9918
Epoch 3/3
 - 1s - loss: 0.0147 - acc: 0.9929
# Training time = 0:05:13.365195!
# F-Score(Ordinary) = 0.446, Recall: 0.52, Precision: 0.391
# F-Score(lvc) = 0.253, Recall: 0.71, Precision: 0.154
# F-Score(ireflv) = 0.653, Recall: 0.681, Precision: 0.627
# F-Score(id) = 0.395, Recall: 0.379, Precision: 0.413
********************
# Seed = 3
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 863458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_14 (Embedding)     (None, 12, 50)            858650    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 863,458
Trainable params: 863,458
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 433
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0649 - acc: 0.9814 - val_loss: 0.0324 - val_acc: 0.9879
Epoch 2/15
 - 6s - loss: 0.0231 - acc: 0.9899 - val_loss: 0.0327 - val_acc: 0.9881
Epoch 3/15
 - 6s - loss: 0.0195 - acc: 0.9911 - val_loss: 0.0332 - val_acc: 0.9880
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0286 - acc: 0.9884
Epoch 2/3
 - 1s - loss: 0.0181 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0150 - acc: 0.9926
# Training time = 0:04:48.540227!
# F-Score(Ordinary) = 0.434, Recall: 0.533, Precision: 0.366
# F-Score(lvc) = 0.448, Recall: 0.551, Precision: 0.378
# F-Score(ireflv) = 0.219, Recall: 0.8, Precision: 0.127
# F-Score(id) = 0.499, Recall: 0.478, Precision: 0.521
********************
# Seed = 4
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 863158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_15 (Embedding)     (None, 12, 50)            858350    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 863,158
Trainable params: 863,158
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 295
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0652 - acc: 0.9822 - val_loss: 0.0338 - val_acc: 0.9873
Epoch 2/15
 - 6s - loss: 0.0232 - acc: 0.9897 - val_loss: 0.0339 - val_acc: 0.9881
Epoch 3/15
 - 6s - loss: 0.0197 - acc: 0.9909 - val_loss: 0.0361 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0282 - acc: 0.9885
Epoch 2/3
 - 1s - loss: 0.0179 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0149 - acc: 0.9928
# Training time = 0:05:06.177951!
# F-Score(Ordinary) = 0.073, Recall: 0.607, Precision: 0.039
# F-Score(lvc) = 0.04, Recall: 0.5, Precision: 0.021
# F-Score(id) = 0.148, Recall: 0.636, Precision: 0.084
********************
# Seed = 5
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 864158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_16 (Embedding)     (None, 12, 50)            859350    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 864,158
Trainable params: 864,158
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 450
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0651 - acc: 0.9828 - val_loss: 0.0334 - val_acc: 0.9875
Epoch 2/15
 - 6s - loss: 0.0231 - acc: 0.9898 - val_loss: 0.0326 - val_acc: 0.9881
Epoch 3/15
 - 6s - loss: 0.0197 - acc: 0.9909 - val_loss: 0.0343 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0286 - acc: 0.9884
Epoch 2/3
 - 1s - loss: 0.0181 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0149 - acc: 0.9926
# Training time = 0:05:12.892346!
# F-Score(Ordinary) = 0.442, Recall: 0.711, Precision: 0.32
# F-Score(lvc) = 0.458, Recall: 0.69, Precision: 0.343
# F-Score(ireflv) = 0.693, Recall: 0.775, Precision: 0.627
# F-Score(id) = 0.105, Recall: 0.417, Precision: 0.06
********************
# Seed = 6
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 864458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_17 (Embedding)     (None, 12, 50)            859650    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 864,458
Trainable params: 864,458
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 483
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0659 - acc: 0.9807 - val_loss: 0.0360 - val_acc: 0.9867
Epoch 2/15
 - 6s - loss: 0.0231 - acc: 0.9900 - val_loss: 0.0323 - val_acc: 0.9883
Epoch 3/15
 - 6s - loss: 0.0197 - acc: 0.9910 - val_loss: 0.0339 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0282 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0176 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0148 - acc: 0.9928
# Training time = 0:05:13.176491!
# F-Score(Ordinary) = 0.381, Recall: 0.479, Precision: 0.316
# F-Score(lvc) = 0.447, Recall: 0.667, Precision: 0.336
# F-Score(id) = 0.46, Recall: 0.407, Precision: 0.527
********************
# Seed = 7
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 863908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_18 (Embedding)     (None, 12, 50)            859100    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 863,908
Trainable params: 863,908
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 419
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0641 - acc: 0.9830 - val_loss: 0.0330 - val_acc: 0.9876
Epoch 2/15
 - 6s - loss: 0.0230 - acc: 0.9900 - val_loss: 0.0336 - val_acc: 0.9881
Epoch 3/15
 - 6s - loss: 0.0195 - acc: 0.9910 - val_loss: 0.0346 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0279 - acc: 0.9889
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0148 - acc: 0.9927
# Training time = 0:05:13.548662!
# F-Score(Ordinary) = 0.327, Recall: 0.341, Precision: 0.314
# F-Score(lvc) = 0.416, Recall: 0.712, Precision: 0.294
# F-Score(id) = 0.358, Recall: 0.266, Precision: 0.545
********************
# Seed = 8
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 863258
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_19 (Embedding)     (None, 12, 50)            858450    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 863,258
Trainable params: 863,258
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 263
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0650 - acc: 0.9836 - val_loss: 0.0361 - val_acc: 0.9869
Epoch 2/15
 - 6s - loss: 0.0232 - acc: 0.9899 - val_loss: 0.0338 - val_acc: 0.9882
Epoch 3/15
 - 6s - loss: 0.0198 - acc: 0.9908 - val_loss: 0.0344 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0283 - acc: 0.9885
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0150 - acc: 0.9926
# Training time = 0:05:10.648568!
# F-Score(Ordinary) = 0.277, Recall: 0.529, Precision: 0.188
# F-Score(lvc) = 0.079, Recall: 0.667, Precision: 0.042
# F-Score(id) = 0.479, Recall: 0.514, Precision: 0.449
********************
# Seed = 9
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 864108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_20 (Embedding)     (None, 12, 50)            859300    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 864,108
Trainable params: 864,108
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 150
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0656 - acc: 0.9834 - val_loss: 0.0346 - val_acc: 0.9876
Epoch 2/15
 - 6s - loss: 0.0231 - acc: 0.9899 - val_loss: 0.0332 - val_acc: 0.9881
Epoch 3/15
 - 6s - loss: 0.0196 - acc: 0.9910 - val_loss: 0.0330 - val_acc: 0.9887
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0279 - acc: 0.9885
Epoch 2/3
 - 1s - loss: 0.0177 - acc: 0.9919
Epoch 3/3
 - 1s - loss: 0.0149 - acc: 0.9926
# Training time = 0:04:41.987561!
# F-Score(Ordinary) = 0.421, Recall: 0.633, Precision: 0.316
# F-Score(lvc) = 0.354, Recall: 0.694, Precision: 0.238
# F-Score(ireflv) = 0.725, Recall: 0.763, Precision: 0.69
# F-Score(id) = 0.135, Recall: 0.273, Precision: 0.09
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1294883
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_21 (Embedding)     (None, 12, 75)            1287675   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 1,294,883
Trainable params: 1,294,883
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 297
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0582 - acc: 0.9836 - val_loss: 0.0329 - val_acc: 0.9878
Epoch 2/15
 - 6s - loss: 0.0226 - acc: 0.9900 - val_loss: 0.0338 - val_acc: 0.9882
Epoch 3/15
 - 6s - loss: 0.0193 - acc: 0.9911 - val_loss: 0.0348 - val_acc: 0.9882
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0281 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0172 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0142 - acc: 0.9931
# Training time = 0:04:56.517503!
# F-Score(Ordinary) = 0.272, Recall: 0.421, Precision: 0.201
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(id) = 0.46, Recall: 0.415, Precision: 0.515
********************
# Seed = 1
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1293533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_22 (Embedding)     (None, 12, 75)            1286325   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 1,293,533
Trainable params: 1,293,533
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0588 - acc: 0.9847 - val_loss: 0.0326 - val_acc: 0.9878
Epoch 2/15
 - 6s - loss: 0.0227 - acc: 0.9900 - val_loss: 0.0328 - val_acc: 0.9884
Epoch 3/15
 - 6s - loss: 0.0195 - acc: 0.9910 - val_loss: 0.0343 - val_acc: 0.9887
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0279 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0179 - acc: 0.9914
Epoch 3/3
 - 1s - loss: 0.0144 - acc: 0.9927
# Training time = 0:05:15.034644!
# F-Score(Ordinary) = 0.466, Recall: 0.587, Precision: 0.387
# F-Score(lvc) = 0.229, Recall: 0.826, Precision: 0.133
# F-Score(ireflv) = 0.686, Recall: 0.726, Precision: 0.651
# F-Score(id) = 0.414, Recall: 0.434, Precision: 0.395
********************
# Seed = 2
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1293983
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_23 (Embedding)     (None, 12, 75)            1286775   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 1,293,983
Trainable params: 1,293,983
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 427
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0591 - acc: 0.9846 - val_loss: 0.0326 - val_acc: 0.9881
Epoch 2/15
 - 6s - loss: 0.0228 - acc: 0.9900 - val_loss: 0.0323 - val_acc: 0.9884
Epoch 3/15
 - 6s - loss: 0.0194 - acc: 0.9912 - val_loss: 0.0336 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0279 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0171 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0142 - acc: 0.9930
# Training time = 0:04:34.518368!
# F-Score(Ordinary) = 0.476, Recall: 0.612, Precision: 0.389
# F-Score(lvc) = 0.253, Recall: 0.71, Precision: 0.154
# F-Score(ireflv) = 0.658, Recall: 0.693, Precision: 0.627
# F-Score(id) = 0.447, Recall: 0.504, Precision: 0.401
********************
# Seed = 3
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1295183
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_24 (Embedding)     (None, 12, 75)            1287975   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 1,295,183
Trainable params: 1,295,183
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 433
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0585 - acc: 0.9838 - val_loss: 0.0326 - val_acc: 0.9879
Epoch 2/15
 - 6s - loss: 0.0228 - acc: 0.9901 - val_loss: 0.0337 - val_acc: 0.9880
Epoch 3/15
 - 6s - loss: 0.0194 - acc: 0.9911 - val_loss: 0.0338 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0286 - acc: 0.9884
Epoch 2/3
 - 1s - loss: 0.0174 - acc: 0.9919
Epoch 3/3
 - 1s - loss: 0.0145 - acc: 0.9928
# Training time = 0:05:12.422380!
# F-Score(Ordinary) = 0.429, Recall: 0.484, Precision: 0.384
# F-Score(lvc) = 0.449, Recall: 0.539, Precision: 0.385
# F-Score(ireflv) = 0.299, Recall: 0.821, Precision: 0.183
# F-Score(id) = 0.453, Recall: 0.401, Precision: 0.521
********************
# Seed = 4
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1294733
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_25 (Embedding)     (None, 12, 75)            1287525   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 1,294,733
Trainable params: 1,294,733
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 295
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0584 - acc: 0.9849 - val_loss: 0.0333 - val_acc: 0.9876
Epoch 2/15
 - 6s - loss: 0.0228 - acc: 0.9899 - val_loss: 0.0342 - val_acc: 0.9879
Epoch 3/15
 - 6s - loss: 0.0196 - acc: 0.9910 - val_loss: 0.0364 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0280 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0171 - acc: 0.9920
Epoch 3/3
 - 1s - loss: 0.0143 - acc: 0.9929
# Training time = 0:05:13.786935!
# F-Score(Ordinary) = 0.031, Recall: 0.636, Precision: 0.016
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(id) = 0.068, Recall: 0.6, Precision: 0.036
********************
# Seed = 5
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1296233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_26 (Embedding)     (None, 12, 75)            1289025   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 1,296,233
Trainable params: 1,296,233
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 450
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0588 - acc: 0.9836 - val_loss: 0.0330 - val_acc: 0.9877
Epoch 2/15
 - 6s - loss: 0.0227 - acc: 0.9900 - val_loss: 0.0333 - val_acc: 0.9882
Epoch 3/15
 - 6s - loss: 0.0194 - acc: 0.9910 - val_loss: 0.0348 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0283 - acc: 0.9884
Epoch 2/3
 - 1s - loss: 0.0174 - acc: 0.9918
Epoch 3/3
 - 1s - loss: 0.0143 - acc: 0.9928
# Training time = 0:05:12.811204!
# F-Score(Ordinary) = 0.429, Recall: 0.667, Precision: 0.316
# F-Score(lvc) = 0.458, Recall: 0.69, Precision: 0.343
# F-Score(ireflv) = 0.693, Recall: 0.775, Precision: 0.627
# F-Score(id) = 0.08, Recall: 0.235, Precision: 0.048
********************
# Seed = 6
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1296683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_27 (Embedding)     (None, 12, 75)            1289475   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 1,296,683
Trainable params: 1,296,683
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 483
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0596 - acc: 0.9840 - val_loss: 0.0356 - val_acc: 0.9868
Epoch 2/15
 - 6s - loss: 0.0227 - acc: 0.9902 - val_loss: 0.0327 - val_acc: 0.9884
Epoch 3/15
 - 6s - loss: 0.0195 - acc: 0.9910 - val_loss: 0.0342 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0280 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0169 - acc: 0.9923
Epoch 3/3
 - 1s - loss: 0.0142 - acc: 0.9928
# Training time = 0:04:48.136435!
# F-Score(Ordinary) = 0.341, Recall: 0.353, Precision: 0.33
# F-Score(lvc) = 0.466, Recall: 0.65, Precision: 0.364
# F-Score(id) = 0.356, Recall: 0.268, Precision: 0.527
********************
# Seed = 7
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1295858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_28 (Embedding)     (None, 12, 75)            1288650   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 1,295,858
Trainable params: 1,295,858
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 419
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0588 - acc: 0.9844 - val_loss: 0.0334 - val_acc: 0.9876
Epoch 2/15
 - 6s - loss: 0.0228 - acc: 0.9901 - val_loss: 0.0345 - val_acc: 0.9879
Epoch 3/15
 - 6s - loss: 0.0194 - acc: 0.9911 - val_loss: 0.0349 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0278 - acc: 0.9889
Epoch 2/3
 - 1s - loss: 0.0172 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0143 - acc: 0.9928
# Training time = 0:05:01.640767!
# F-Score(Ordinary) = 0.275, Recall: 0.245, Precision: 0.314
# F-Score(lvc) = 0.424, Recall: 0.717, Precision: 0.301
# F-Score(id) = 0.27, Recall: 0.18, Precision: 0.539
********************
# Seed = 8
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1294883
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_29 (Embedding)     (None, 12, 75)            1287675   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 1,294,883
Trainable params: 1,294,883
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 263
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0587 - acc: 0.9840 - val_loss: 0.0370 - val_acc: 0.9866
Epoch 2/15
 - 6s - loss: 0.0228 - acc: 0.9900 - val_loss: 0.0339 - val_acc: 0.9883
Epoch 3/15
 - 6s - loss: 0.0195 - acc: 0.9910 - val_loss: 0.0346 - val_acc: 0.9887
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0281 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0170 - acc: 0.9920
Epoch 3/3
 - 1s - loss: 0.0143 - acc: 0.9929
# Training time = 0:05:02.701766!
# F-Score(Ordinary) = 0.267, Recall: 0.554, Precision: 0.176
# F-Score(lvc) = 0.067, Recall: 0.833, Precision: 0.035
# F-Score(id) = 0.473, Recall: 0.534, Precision: 0.425
********************
# Seed = 9
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1296158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_30 (Embedding)     (None, 12, 75)            1288950   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 1,296,158
Trainable params: 1,296,158
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 150
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0573 - acc: 0.9829 - val_loss: 0.0360 - val_acc: 0.9874
Epoch 2/15
 - 6s - loss: 0.0226 - acc: 0.9900 - val_loss: 0.0340 - val_acc: 0.9882
Epoch 3/15
 - 6s - loss: 0.0194 - acc: 0.9911 - val_loss: 0.0334 - val_acc: 0.9887
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0278 - acc: 0.9885
Epoch 2/3
 - 1s - loss: 0.0171 - acc: 0.9920
Epoch 3/3
 - 1s - loss: 0.0143 - acc: 0.9928
# Training time = 0:05:14.348426!
# F-Score(Ordinary) = 0.429, Recall: 0.648, Precision: 0.32
# F-Score(lvc) = 0.349, Recall: 0.717, Precision: 0.231
# F-Score(ireflv) = 0.717, Recall: 0.754, Precision: 0.683
# F-Score(id) = 0.17, Recall: 0.339, Precision: 0.114
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1726508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_31 (Embedding)     (None, 12, 100)           1716900   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,726,508
Trainable params: 1,726,508
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 297
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0543 - acc: 0.9849 - val_loss: 0.0334 - val_acc: 0.9877
Epoch 2/15
 - 6s - loss: 0.0226 - acc: 0.9901 - val_loss: 0.0341 - val_acc: 0.9881
Epoch 3/15
 - 6s - loss: 0.0193 - acc: 0.9911 - val_loss: 0.0351 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0282 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0169 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0140 - acc: 0.9933
# Training time = 0:05:14.418873!
# F-Score(Ordinary) = 0.27, Recall: 0.42, Precision: 0.199
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(id) = 0.456, Recall: 0.413, Precision: 0.509
********************
# Seed = 1
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1724708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_32 (Embedding)     (None, 12, 100)           1715100   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,724,708
Trainable params: 1,724,708
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0544 - acc: 0.9850 - val_loss: 0.0328 - val_acc: 0.9878
Epoch 2/15
 - 6s - loss: 0.0226 - acc: 0.9901 - val_loss: 0.0330 - val_acc: 0.9885
Epoch 3/15
 - 6s - loss: 0.0193 - acc: 0.9910 - val_loss: 0.0342 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0276 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0174 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0141 - acc: 0.9928
# Training time = 0:05:14.916037!
# F-Score(Ordinary) = 0.472, Recall: 0.589, Precision: 0.394
# F-Score(lvc) = 0.259, Recall: 0.815, Precision: 0.154
# F-Score(ireflv) = 0.686, Recall: 0.726, Precision: 0.651
# F-Score(id) = 0.408, Recall: 0.428, Precision: 0.389
********************
# Seed = 2
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1725308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_33 (Embedding)     (None, 12, 100)           1715700   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,725,308
Trainable params: 1,725,308
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 427
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0550 - acc: 0.9846 - val_loss: 0.0329 - val_acc: 0.9881
Epoch 2/15
 - 6s - loss: 0.0225 - acc: 0.9901 - val_loss: 0.0328 - val_acc: 0.9884
Epoch 3/15
 - 6s - loss: 0.0192 - acc: 0.9913 - val_loss: 0.0340 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0278 - acc: 0.9889
Epoch 2/3
 - 1s - loss: 0.0167 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0139 - acc: 0.9930
# Training time = 0:05:13.165009!
# F-Score(Ordinary) = 0.446, Recall: 0.55, Precision: 0.375
# F-Score(lvc) = 0.226, Recall: 0.76, Precision: 0.133
# F-Score(ireflv) = 0.675, Recall: 0.721, Precision: 0.635
# F-Score(id) = 0.383, Recall: 0.389, Precision: 0.377
********************
# Seed = 3
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1726908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_34 (Embedding)     (None, 12, 100)           1717300   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,726,908
Trainable params: 1,726,908
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 433
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0543 - acc: 0.9838 - val_loss: 0.0327 - val_acc: 0.9879
Epoch 2/15
 - 6s - loss: 0.0227 - acc: 0.9901 - val_loss: 0.0340 - val_acc: 0.9880
Epoch 3/15
 - 6s - loss: 0.0192 - acc: 0.9912 - val_loss: 0.0337 - val_acc: 0.9880
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0283 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0170 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0141 - acc: 0.9928
# Training time = 0:04:35.662776!
# F-Score(Ordinary) = 0.386, Recall: 0.38, Precision: 0.391
# F-Score(lvc) = 0.423, Recall: 0.459, Precision: 0.392
# F-Score(ireflv) = 0.304, Recall: 0.75, Precision: 0.19
# F-Score(id) = 0.38, Recall: 0.297, Precision: 0.527
********************
# Seed = 4
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1726308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_35 (Embedding)     (None, 12, 100)           1716700   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,726,308
Trainable params: 1,726,308
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 295
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0552 - acc: 0.9850 - val_loss: 0.0333 - val_acc: 0.9877
Epoch 2/15
 - 6s - loss: 0.0227 - acc: 0.9900 - val_loss: 0.0347 - val_acc: 0.9879
Epoch 3/15
 - 6s - loss: 0.0194 - acc: 0.9911 - val_loss: 0.0365 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0278 - acc: 0.9885
Epoch 2/3
 - 1s - loss: 0.0167 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0140 - acc: 0.9931
# Training time = 0:05:20.750627!
# F-Score(Ordinary) = 0.035, Recall: 0.5, Precision: 0.018
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(id) = 0.077, Recall: 0.467, Precision: 0.042
********************
# Seed = 5
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1728308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_36 (Embedding)     (None, 12, 100)           1718700   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,728,308
Trainable params: 1,728,308
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 450
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0552 - acc: 0.9845 - val_loss: 0.0326 - val_acc: 0.9877
Epoch 2/15
 - 6s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0340 - val_acc: 0.9881
Epoch 3/15
 - 6s - loss: 0.0194 - acc: 0.9910 - val_loss: 0.0351 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0283 - acc: 0.9884
Epoch 2/3
 - 1s - loss: 0.0171 - acc: 0.9920
Epoch 3/3
 - 1s - loss: 0.0141 - acc: 0.9928
# Training time = 0:05:16.971388!
# F-Score(Ordinary) = 0.439, Recall: 0.658, Precision: 0.33
# F-Score(lvc) = 0.455, Recall: 0.649, Precision: 0.35
# F-Score(ireflv) = 0.71, Recall: 0.781, Precision: 0.651
# F-Score(id) = 0.098, Recall: 0.27, Precision: 0.06
********************
# Seed = 6
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1728908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_37 (Embedding)     (None, 12, 100)           1719300   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,728,908
Trainable params: 1,728,908
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 483
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0552 - acc: 0.9829 - val_loss: 0.0355 - val_acc: 0.9869
Epoch 2/15
 - 6s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0326 - val_acc: 0.9885
Epoch 3/15
 - 6s - loss: 0.0193 - acc: 0.9911 - val_loss: 0.0342 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0277 - acc: 0.9889
Epoch 2/3
 - 1s - loss: 0.0164 - acc: 0.9924
Epoch 3/3
 - 1s - loss: 0.0139 - acc: 0.9928
# Training time = 0:04:59.420633!
# F-Score(Ordinary) = 0.279, Recall: 0.243, Precision: 0.327
# F-Score(lvc) = 0.462, Recall: 0.654, Precision: 0.357
# F-Score(id) = 0.26, Recall: 0.172, Precision: 0.527
********************
# Seed = 7
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1727808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_38 (Embedding)     (None, 12, 100)           1718200   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,727,808
Trainable params: 1,727,808
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 419
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0544 - acc: 0.9843 - val_loss: 0.0334 - val_acc: 0.9877
Epoch 2/15
 - 6s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0346 - val_acc: 0.9880
Epoch 3/15
 - 6s - loss: 0.0192 - acc: 0.9912 - val_loss: 0.0348 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0275 - acc: 0.9889
Epoch 2/3
 - 1s - loss: 0.0167 - acc: 0.9919
Epoch 3/3
 - 1s - loss: 0.0140 - acc: 0.9929
# Training time = 0:04:55.294230!
# F-Score(Ordinary) = 0.29, Recall: 0.259, Precision: 0.33
# F-Score(lvc) = 0.454, Recall: 0.734, Precision: 0.329
# F-Score(ireflv) = 0.016, Recall: 1.0, Precision: 0.008
# F-Score(id) = 0.28, Recall: 0.188, Precision: 0.551
********************
# Seed = 8
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1726508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_39 (Embedding)     (None, 12, 100)           1716900   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,726,508
Trainable params: 1,726,508
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 263
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0548 - acc: 0.9837 - val_loss: 0.0377 - val_acc: 0.9862
Epoch 2/15
 - 6s - loss: 0.0227 - acc: 0.9902 - val_loss: 0.0344 - val_acc: 0.9882
Epoch 3/15
 - 6s - loss: 0.0194 - acc: 0.9910 - val_loss: 0.0346 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0278 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0165 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0139 - acc: 0.9929
# Training time = 0:05:12.550733!
# F-Score(Ordinary) = 0.223, Recall: 0.411, Precision: 0.153
# F-Score(lvc) = 0.041, Recall: 0.75, Precision: 0.021
# F-Score(id) = 0.387, Recall: 0.396, Precision: 0.377
********************
# Seed = 9
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1728208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_40 (Embedding)     (None, 12, 100)           1718600   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,728,208
Trainable params: 1,728,208
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 150
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0550 - acc: 0.9848 - val_loss: 0.0372 - val_acc: 0.9871
Epoch 2/15
 - 6s - loss: 0.0226 - acc: 0.9901 - val_loss: 0.0346 - val_acc: 0.9881
Epoch 3/15
 - 6s - loss: 0.0194 - acc: 0.9911 - val_loss: 0.0337 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0277 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0167 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0141 - acc: 0.9929
# Training time = 0:05:15.142261!
# F-Score(Ordinary) = 0.432, Recall: 0.576, Precision: 0.346
# F-Score(lvc) = 0.379, Recall: 0.766, Precision: 0.252
# F-Score(ireflv) = 0.739, Recall: 0.786, Precision: 0.698
# F-Score(id) = 0.185, Recall: 0.243, Precision: 0.15
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2158133
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_41 (Embedding)     (None, 12, 125)           2146125   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 2,158,133
Trainable params: 2,158,133
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 297
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0516 - acc: 0.9852 - val_loss: 0.0337 - val_acc: 0.9877
Epoch 2/15
 - 7s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0346 - val_acc: 0.9880
Epoch 3/15
 - 7s - loss: 0.0193 - acc: 0.9913 - val_loss: 0.0357 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0282 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0167 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0138 - acc: 0.9933
# Training time = 0:05:03.600030!
# F-Score(Ordinary) = 0.267, Recall: 0.449, Precision: 0.19
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(id) = 0.467, Recall: 0.446, Precision: 0.491
********************
# Seed = 1
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2155883
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_42 (Embedding)     (None, 12, 125)           2143875   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 2,155,883
Trainable params: 2,155,883
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0526 - acc: 0.9839 - val_loss: 0.0329 - val_acc: 0.9879
Epoch 2/15
 - 7s - loss: 0.0226 - acc: 0.9901 - val_loss: 0.0329 - val_acc: 0.9884
Epoch 3/15
 - 7s - loss: 0.0193 - acc: 0.9911 - val_loss: 0.0338 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0275 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0172 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0139 - acc: 0.9929
# Training time = 0:05:15.983106!
# F-Score(Ordinary) = 0.487, Recall: 0.605, Precision: 0.407
# F-Score(lvc) = 0.237, Recall: 0.769, Precision: 0.14
# F-Score(ireflv) = 0.684, Recall: 0.741, Precision: 0.635
# F-Score(id) = 0.459, Recall: 0.469, Precision: 0.449
********************
# Seed = 2
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2156633
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_43 (Embedding)     (None, 12, 125)           2144625   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 2,156,633
Trainable params: 2,156,633
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 427
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0520 - acc: 0.9843 - val_loss: 0.0335 - val_acc: 0.9880
Epoch 2/15
 - 7s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0331 - val_acc: 0.9883
Epoch 3/15
 - 7s - loss: 0.0192 - acc: 0.9913 - val_loss: 0.0341 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0276 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0164 - acc: 0.9922
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9930
# Training time = 0:05:08.739616!
# F-Score(Ordinary) = 0.44, Recall: 0.514, Precision: 0.384
# F-Score(lvc) = 0.214, Recall: 0.72, Precision: 0.126
# F-Score(ireflv) = 0.678, Recall: 0.717, Precision: 0.643
# F-Score(id) = 0.382, Recall: 0.36, Precision: 0.407
********************
# Seed = 3
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2158633
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_44 (Embedding)     (None, 12, 125)           2146625   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 2,158,633
Trainable params: 2,158,633
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 433
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0526 - acc: 0.9841 - val_loss: 0.0333 - val_acc: 0.9878
Epoch 2/15
 - 7s - loss: 0.0227 - acc: 0.9902 - val_loss: 0.0345 - val_acc: 0.9879
Epoch 3/15
 - 7s - loss: 0.0193 - acc: 0.9912 - val_loss: 0.0339 - val_acc: 0.9880
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0284 - acc: 0.9885
Epoch 2/3
 - 1s - loss: 0.0168 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0140 - acc: 0.9928
# Training time = 0:04:48.855909!
# F-Score(Ordinary) = 0.352, Recall: 0.317, Precision: 0.396
# F-Score(lvc) = 0.444, Recall: 0.524, Precision: 0.385
# F-Score(ireflv) = 0.314, Recall: 0.758, Precision: 0.198
# F-Score(id) = 0.314, Recall: 0.221, Precision: 0.539
********************
# Seed = 4
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2157883
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_45 (Embedding)     (None, 12, 125)           2145875   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 2,157,883
Trainable params: 2,157,883
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 295
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0519 - acc: 0.9849 - val_loss: 0.0334 - val_acc: 0.9877
Epoch 2/15
 - 7s - loss: 0.0227 - acc: 0.9901 - val_loss: 0.0354 - val_acc: 0.9880
Epoch 3/15
 - 7s - loss: 0.0195 - acc: 0.9911 - val_loss: 0.0368 - val_acc: 0.9880
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0279 - acc: 0.9885
Epoch 2/3
 - 1s - loss: 0.0165 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0138 - acc: 0.9930
# Training time = 0:05:13.885566!
# F-Score(Ordinary) = 0.023, Recall: 0.714, Precision: 0.011
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(id) = 0.046, Recall: 0.667, Precision: 0.024
********************
# Seed = 5
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2160383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_46 (Embedding)     (None, 12, 125)           2148375   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 2,160,383
Trainable params: 2,160,383
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 450
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0525 - acc: 0.9848 - val_loss: 0.0326 - val_acc: 0.9877
Epoch 2/15
 - 7s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0342 - val_acc: 0.9881
Epoch 3/15
 - 7s - loss: 0.0192 - acc: 0.9911 - val_loss: 0.0347 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0280 - acc: 0.9885
Epoch 2/3
 - 1s - loss: 0.0168 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0138 - acc: 0.9929
# Training time = 0:05:14.855304!
# F-Score(Ordinary) = 0.442, Recall: 0.711, Precision: 0.32
# F-Score(lvc) = 0.459, Recall: 0.667, Precision: 0.35
# F-Score(ireflv) = 0.702, Recall: 0.798, Precision: 0.627
# F-Score(id) = 0.095, Recall: 0.391, Precision: 0.054
********************
# Seed = 6
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2161133
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_47 (Embedding)     (None, 12, 125)           2149125   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 2,161,133
Trainable params: 2,161,133
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 483
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0524 - acc: 0.9841 - val_loss: 0.0357 - val_acc: 0.9869
Epoch 2/15
 - 7s - loss: 0.0225 - acc: 0.9903 - val_loss: 0.0330 - val_acc: 0.9884
Epoch 3/15
 - 7s - loss: 0.0193 - acc: 0.9911 - val_loss: 0.0342 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0276 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0161 - acc: 0.9925
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9928
# Training time = 0:05:15.555366!
# F-Score(Ordinary) = 0.292, Recall: 0.267, Precision: 0.323
# F-Score(lvc) = 0.466, Recall: 0.65, Precision: 0.364
# F-Score(id) = 0.28, Recall: 0.192, Precision: 0.515
********************
# Seed = 7
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2159758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_48 (Embedding)     (None, 12, 125)           2147750   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 2,159,758
Trainable params: 2,159,758
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 419
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0528 - acc: 0.9850 - val_loss: 0.0336 - val_acc: 0.9877
Epoch 2/15
 - 7s - loss: 0.0225 - acc: 0.9903 - val_loss: 0.0351 - val_acc: 0.9878
Epoch 3/15
 - 7s - loss: 0.0192 - acc: 0.9913 - val_loss: 0.0349 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0274 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0166 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0138 - acc: 0.9929
# Training time = 0:04:54.118276!
# F-Score(Ordinary) = 0.273, Recall: 0.233, Precision: 0.33
# F-Score(lvc) = 0.462, Recall: 0.738, Precision: 0.336
# F-Score(ireflv) = 0.016, Recall: 1.0, Precision: 0.008
# F-Score(id) = 0.253, Recall: 0.165, Precision: 0.545
********************
# Seed = 8
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2158133
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_49 (Embedding)     (None, 12, 125)           2146125   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 2,158,133
Trainable params: 2,158,133
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 263
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0523 - acc: 0.9850 - val_loss: 0.0375 - val_acc: 0.9863
Epoch 2/15
 - 7s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0341 - val_acc: 0.9883
Epoch 3/15
 - 7s - loss: 0.0193 - acc: 0.9911 - val_loss: 0.0344 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0276 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0162 - acc: 0.9922
Epoch 3/3
 - 1s - loss: 0.0137 - acc: 0.9930
# Training time = 0:05:28.881345!
# F-Score(Ordinary) = 0.221, Recall: 0.477, Precision: 0.144
# F-Score(lvc) = 0.027, Recall: 0.667, Precision: 0.014
# F-Score(id) = 0.412, Recall: 0.473, Precision: 0.365
********************
# Seed = 9
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2160258
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_50 (Embedding)     (None, 12, 125)           2148250   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 2,160,258
Trainable params: 2,160,258
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 150
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0518 - acc: 0.9841 - val_loss: 0.0383 - val_acc: 0.9871
Epoch 2/15
 - 7s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0348 - val_acc: 0.9881
Epoch 3/15
 - 7s - loss: 0.0193 - acc: 0.9912 - val_loss: 0.0337 - val_acc: 0.9887
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0275 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0165 - acc: 0.9922
Epoch 3/3
 - 1s - loss: 0.0138 - acc: 0.9930
# Training time = 0:05:09.256689!
# F-Score(Ordinary) = 0.425, Recall: 0.592, Precision: 0.332
# F-Score(lvc) = 0.335, Recall: 0.738, Precision: 0.217
# F-Score(ireflv) = 0.739, Recall: 0.786, Precision: 0.698
# F-Score(id) = 0.194, Recall: 0.275, Precision: 0.15
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2589758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_51 (Embedding)     (None, 12, 150)           2575350   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 2,589,758
Trainable params: 2,589,758
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 297
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0505 - acc: 0.9837 - val_loss: 0.0339 - val_acc: 0.9878
Epoch 2/15
 - 8s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0344 - val_acc: 0.9881
Epoch 3/15
 - 8s - loss: 0.0191 - acc: 0.9913 - val_loss: 0.0353 - val_acc: 0.9880
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0277 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0163 - acc: 0.9919
Epoch 3/3
 - 1s - loss: 0.0135 - acc: 0.9932
# Training time = 0:05:05.512117!
# F-Score(Ordinary) = 0.25, Recall: 0.341, Precision: 0.197
# F-Score(id) = 0.411, Recall: 0.341, Precision: 0.515
********************
# Seed = 1
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2587058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_52 (Embedding)     (None, 12, 150)           2572650   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 2,587,058
Trainable params: 2,587,058
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0507 - acc: 0.9851 - val_loss: 0.0331 - val_acc: 0.9879
Epoch 2/15
 - 8s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0329 - val_acc: 0.9884
Epoch 3/15
 - 8s - loss: 0.0191 - acc: 0.9911 - val_loss: 0.0339 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0273 - acc: 0.9889
Epoch 2/3
 - 1s - loss: 0.0170 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0138 - acc: 0.9928
# Training time = 0:05:19.512520!
# F-Score(Ordinary) = 0.476, Recall: 0.625, Precision: 0.384
# F-Score(lvc) = 0.24, Recall: 0.833, Precision: 0.14
# F-Score(ireflv) = 0.693, Recall: 0.775, Precision: 0.627
# F-Score(id) = 0.432, Recall: 0.469, Precision: 0.401
********************
# Seed = 2
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2587958
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_53 (Embedding)     (None, 12, 150)           2573550   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 2,587,958
Trainable params: 2,587,958
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 427
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0509 - acc: 0.9849 - val_loss: 0.0337 - val_acc: 0.9879
Epoch 2/15
 - 8s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0332 - val_acc: 0.9883
Epoch 3/15
 - 8s - loss: 0.0191 - acc: 0.9914 - val_loss: 0.0341 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0277 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0163 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0135 - acc: 0.9931
# Training time = 0:04:55.484875!
# F-Score(Ordinary) = 0.448, Recall: 0.562, Precision: 0.373
# F-Score(lvc) = 0.149, Recall: 0.667, Precision: 0.084
# F-Score(ireflv) = 0.669, Recall: 0.718, Precision: 0.627
# F-Score(id) = 0.432, Recall: 0.438, Precision: 0.425
********************
# Seed = 3
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2590358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_54 (Embedding)     (None, 12, 150)           2575950   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 2,590,358
Trainable params: 2,590,358
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 433
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0502 - acc: 0.9852 - val_loss: 0.0333 - val_acc: 0.9877
Epoch 2/15
 - 8s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0346 - val_acc: 0.9881
Epoch 3/15
 - 8s - loss: 0.0191 - acc: 0.9913 - val_loss: 0.0341 - val_acc: 0.9880
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0284 - acc: 0.9884
Epoch 2/3
 - 1s - loss: 0.0167 - acc: 0.9920
Epoch 3/3
 - 1s - loss: 0.0139 - acc: 0.9928
# Training time = 0:05:18.918221!
# F-Score(Ordinary) = 0.361, Recall: 0.324, Precision: 0.407
# F-Score(lvc) = 0.451, Recall: 0.509, Precision: 0.406
# F-Score(ireflv) = 0.318, Recall: 0.806, Precision: 0.198
# F-Score(id) = 0.318, Recall: 0.225, Precision: 0.545
********************
# Seed = 4
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2589458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_55 (Embedding)     (None, 12, 150)           2575050   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 2,589,458
Trainable params: 2,589,458
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 295
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0503 - acc: 0.9850 - val_loss: 0.0333 - val_acc: 0.9877
Epoch 2/15
 - 8s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0354 - val_acc: 0.9879
Epoch 3/15
 - 8s - loss: 0.0193 - acc: 0.9912 - val_loss: 0.0365 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0277 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0163 - acc: 0.9920
Epoch 3/3
 - 1s - loss: 0.0137 - acc: 0.9931
# Training time = 0:05:24.408123!
# F-Score(Ordinary) = 0.014, Recall: 0.6, Precision: 0.007
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(id) = 0.023, Recall: 0.5, Precision: 0.012
********************
# Seed = 5
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2592458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_56 (Embedding)     (None, 12, 150)           2578050   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 2,592,458
Trainable params: 2,592,458
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 450
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0505 - acc: 0.9851 - val_loss: 0.0325 - val_acc: 0.9880
Epoch 2/15
 - 8s - loss: 0.0225 - acc: 0.9903 - val_loss: 0.0345 - val_acc: 0.9880
Epoch 3/15
 - 8s - loss: 0.0192 - acc: 0.9911 - val_loss: 0.0349 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0280 - acc: 0.9884
Epoch 2/3
 - 1s - loss: 0.0166 - acc: 0.9922
Epoch 3/3
 - 1s - loss: 0.0137 - acc: 0.9929
# Training time = 0:04:53.676841!
# F-Score(Ordinary) = 0.449, Recall: 0.702, Precision: 0.33
# F-Score(lvc) = 0.472, Recall: 0.699, Precision: 0.357
# F-Score(ireflv) = 0.711, Recall: 0.794, Precision: 0.643
# F-Score(id) = 0.102, Recall: 0.333, Precision: 0.06
********************
# Seed = 6
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2593358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_57 (Embedding)     (None, 12, 150)           2578950   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 2,593,358
Trainable params: 2,593,358
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 483
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0505 - acc: 0.9850 - val_loss: 0.0357 - val_acc: 0.9867
Epoch 2/15
 - 8s - loss: 0.0224 - acc: 0.9903 - val_loss: 0.0328 - val_acc: 0.9886
Epoch 3/15
 - 8s - loss: 0.0192 - acc: 0.9911 - val_loss: 0.0344 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0276 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0160 - acc: 0.9925
Epoch 3/3
 - 1s - loss: 0.0135 - acc: 0.9928
# Training time = 0:04:52.937840!
# F-Score(Ordinary) = 0.292, Recall: 0.27, Precision: 0.318
# F-Score(lvc) = 0.466, Recall: 0.607, Precision: 0.378
# F-Score(id) = 0.277, Recall: 0.193, Precision: 0.491
********************
# Seed = 7
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2591708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_58 (Embedding)     (None, 12, 150)           2577300   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 2,591,708
Trainable params: 2,591,708
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 419
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0506 - acc: 0.9853 - val_loss: 0.0339 - val_acc: 0.9878
Epoch 2/15
 - 8s - loss: 0.0224 - acc: 0.9904 - val_loss: 0.0352 - val_acc: 0.9878
Epoch 3/15
 - 8s - loss: 0.0190 - acc: 0.9912 - val_loss: 0.0349 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0273 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0164 - acc: 0.9920
Epoch 3/3
 - 1s - loss: 0.0137 - acc: 0.9928
# Training time = 0:05:12.824790!
# F-Score(Ordinary) = 0.253, Recall: 0.205, Precision: 0.33
# F-Score(lvc) = 0.443, Recall: 0.75, Precision: 0.315
# F-Score(ireflv) = 0.062, Recall: 1.0, Precision: 0.032
# F-Score(id) = 0.224, Recall: 0.141, Precision: 0.539
********************
# Seed = 8
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2589758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_59 (Embedding)     (None, 12, 150)           2575350   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 2,589,758
Trainable params: 2,589,758
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 263
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0507 - acc: 0.9845 - val_loss: 0.0373 - val_acc: 0.9865
Epoch 2/15
 - 8s - loss: 0.0227 - acc: 0.9902 - val_loss: 0.0346 - val_acc: 0.9882
Epoch 3/15
 - 8s - loss: 0.0194 - acc: 0.9911 - val_loss: 0.0348 - val_acc: 0.9887
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0277 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0161 - acc: 0.9922
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9929
# Training time = 0:04:35.960537!
# F-Score(Ordinary) = 0.221, Recall: 0.433, Precision: 0.149
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(id) = 0.395, Recall: 0.422, Precision: 0.371
********************
# Seed = 9
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2592308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_60 (Embedding)     (None, 12, 150)           2577900   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 2,592,308
Trainable params: 2,592,308
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 150
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0501 - acc: 0.9853 - val_loss: 0.0388 - val_acc: 0.9870
Epoch 2/15
 - 8s - loss: 0.0227 - acc: 0.9901 - val_loss: 0.0351 - val_acc: 0.9881
Epoch 3/15
 - 8s - loss: 0.0193 - acc: 0.9912 - val_loss: 0.0337 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0274 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0163 - acc: 0.9922
Epoch 3/3
 - 1s - loss: 0.0137 - acc: 0.9930
# Training time = 0:04:50.657640!
# F-Score(Ordinary) = 0.444, Recall: 0.628, Precision: 0.343
# F-Score(lvc) = 0.316, Recall: 0.824, Precision: 0.196
# F-Score(ireflv) = 0.746, Recall: 0.8, Precision: 0.698
# F-Score(id) = 0.26, Recall: 0.358, Precision: 0.204
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3021383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_61 (Embedding)     (None, 12, 175)           3004575   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 3,021,383
Trainable params: 3,021,383
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 297
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0490 - acc: 0.9853 - val_loss: 0.0344 - val_acc: 0.9877
Epoch 2/15
 - 9s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0344 - val_acc: 0.9881
Epoch 3/15
 - 9s - loss: 0.0191 - acc: 0.9912 - val_loss: 0.0355 - val_acc: 0.9882
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0278 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0163 - acc: 0.9919
Epoch 3/3
 - 1s - loss: 0.0135 - acc: 0.9932
# Training time = 0:05:15.443281!
# F-Score(Ordinary) = 0.255, Recall: 0.363, Precision: 0.197
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(id) = 0.422, Recall: 0.36, Precision: 0.509
********************
# Seed = 1
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3018233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_62 (Embedding)     (None, 12, 175)           3001425   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 3,018,233
Trainable params: 3,018,233
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0494 - acc: 0.9858 - val_loss: 0.0331 - val_acc: 0.9879
Epoch 2/15
 - 9s - loss: 0.0224 - acc: 0.9901 - val_loss: 0.0328 - val_acc: 0.9885
Epoch 3/15
 - 9s - loss: 0.0189 - acc: 0.9912 - val_loss: 0.0338 - val_acc: 0.9887
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0270 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0168 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9928
# Training time = 0:05:19.769244!
# F-Score(Ordinary) = 0.464, Recall: 0.613, Precision: 0.373
# F-Score(lvc) = 0.217, Recall: 0.783, Precision: 0.126
# F-Score(ireflv) = 0.704, Recall: 0.779, Precision: 0.643
# F-Score(id) = 0.405, Recall: 0.446, Precision: 0.371
********************
# Seed = 2
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3019283
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_63 (Embedding)     (None, 12, 175)           3002475   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 3,019,283
Trainable params: 3,019,283
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 427
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0494 - acc: 0.9848 - val_loss: 0.0337 - val_acc: 0.9879
Epoch 2/15
 - 9s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0328 - val_acc: 0.9884
Epoch 3/15
 - 9s - loss: 0.0190 - acc: 0.9914 - val_loss: 0.0337 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0274 - acc: 0.9889
Epoch 2/3
 - 1s - loss: 0.0161 - acc: 0.9923
Epoch 3/3
 - 1s - loss: 0.0134 - acc: 0.9931
# Training time = 0:05:05.500742!
# F-Score(Ordinary) = 0.46, Recall: 0.573, Precision: 0.384
# F-Score(lvc) = 0.172, Recall: 0.7, Precision: 0.098
# F-Score(ireflv) = 0.689, Recall: 0.743, Precision: 0.643
# F-Score(id) = 0.435, Recall: 0.439, Precision: 0.431
********************
# Seed = 3
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3022083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_64 (Embedding)     (None, 12, 175)           3005275   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 3,022,083
Trainable params: 3,022,083
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 433
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0490 - acc: 0.9852 - val_loss: 0.0335 - val_acc: 0.9878
Epoch 2/15
 - 9s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0347 - val_acc: 0.9880
Epoch 3/15
 - 9s - loss: 0.0191 - acc: 0.9912 - val_loss: 0.0340 - val_acc: 0.9880
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0282 - acc: 0.9885
Epoch 2/3
 - 1s - loss: 0.0165 - acc: 0.9922
Epoch 3/3
 - 1s - loss: 0.0138 - acc: 0.9929
# Training time = 0:05:24.701066!
# F-Score(Ordinary) = 0.32, Recall: 0.267, Precision: 0.398
# F-Score(lvc) = 0.409, Recall: 0.446, Precision: 0.378
# F-Score(ireflv) = 0.306, Recall: 0.774, Precision: 0.19
# F-Score(id) = 0.279, Recall: 0.186, Precision: 0.557
********************
# Seed = 4
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3021033
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_65 (Embedding)     (None, 12, 175)           3004225   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 3,021,033
Trainable params: 3,021,033
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 295
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0489 - acc: 0.9850 - val_loss: 0.0337 - val_acc: 0.9877
Epoch 2/15
 - 9s - loss: 0.0226 - acc: 0.9901 - val_loss: 0.0351 - val_acc: 0.9880
Epoch 3/15
 - 9s - loss: 0.0192 - acc: 0.9912 - val_loss: 0.0362 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0274 - acc: 0.9884
Epoch 2/3
 - 1s - loss: 0.0162 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0135 - acc: 0.9931
# Training time = 0:05:24.519085!
# F-Score(Ordinary) = 0.049, Recall: 0.733, Precision: 0.025
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(id) = 0.11, Recall: 0.714, Precision: 0.06
********************
# Seed = 5
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3024533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_66 (Embedding)     (None, 12, 175)           3007725   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 3,024,533
Trainable params: 3,024,533
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 450
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0489 - acc: 0.9855 - val_loss: 0.0326 - val_acc: 0.9880
Epoch 2/15
 - 9s - loss: 0.0224 - acc: 0.9903 - val_loss: 0.0345 - val_acc: 0.9880
Epoch 3/15
 - 9s - loss: 0.0191 - acc: 0.9911 - val_loss: 0.0346 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0278 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0165 - acc: 0.9922
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9929
# Training time = 0:05:09.585762!
# F-Score(Ordinary) = 0.447, Recall: 0.684, Precision: 0.332
# F-Score(lvc) = 0.469, Recall: 0.714, Precision: 0.35
# F-Score(ireflv) = 0.702, Recall: 0.784, Precision: 0.635
# F-Score(id) = 0.126, Recall: 0.325, Precision: 0.078
********************
# Seed = 6
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3025583
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_67 (Embedding)     (None, 12, 175)           3008775   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 3,025,583
Trainable params: 3,025,583
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 483
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0488 - acc: 0.9851 - val_loss: 0.0359 - val_acc: 0.9868
Epoch 2/15
 - 9s - loss: 0.0225 - acc: 0.9903 - val_loss: 0.0329 - val_acc: 0.9885
Epoch 3/15
 - 9s - loss: 0.0191 - acc: 0.9911 - val_loss: 0.0342 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0275 - acc: 0.9889
Epoch 2/3
 - 1s - loss: 0.0159 - acc: 0.9925
Epoch 3/3
 - 1s - loss: 0.0135 - acc: 0.9928
# Training time = 0:05:20.807882!
# F-Score(Ordinary) = 0.252, Recall: 0.211, Precision: 0.311
# F-Score(lvc) = 0.47, Recall: 0.621, Precision: 0.378
# F-Score(id) = 0.219, Recall: 0.142, Precision: 0.473
********************
# Seed = 7
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3023658
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_68 (Embedding)     (None, 12, 175)           3006850   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 3,023,658
Trainable params: 3,023,658
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 419
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0492 - acc: 0.9856 - val_loss: 0.0342 - val_acc: 0.9877
Epoch 2/15
 - 9s - loss: 0.0225 - acc: 0.9904 - val_loss: 0.0352 - val_acc: 0.9879
Epoch 3/15
 - 9s - loss: 0.0191 - acc: 0.9913 - val_loss: 0.0346 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0272 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0163 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9929
# Training time = 0:05:29.151426!
# F-Score(Ordinary) = 0.233, Recall: 0.182, Precision: 0.323
# F-Score(lvc) = 0.435, Recall: 0.703, Precision: 0.315
# F-Score(ireflv) = 0.016, Recall: 1.0, Precision: 0.008
# F-Score(id) = 0.205, Recall: 0.127, Precision: 0.539
********************
# Seed = 8
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3021383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_69 (Embedding)     (None, 12, 175)           3004575   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 3,021,383
Trainable params: 3,021,383
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 263
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0489 - acc: 0.9860 - val_loss: 0.0374 - val_acc: 0.9866
Epoch 2/15
 - 9s - loss: 0.0226 - acc: 0.9903 - val_loss: 0.0345 - val_acc: 0.9881
Epoch 3/15
 - 9s - loss: 0.0193 - acc: 0.9911 - val_loss: 0.0347 - val_acc: 0.9887
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0277 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0160 - acc: 0.9923
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9930
# Training time = 0:05:28.798929!
# F-Score(Ordinary) = 0.219, Recall: 0.385, Precision: 0.153
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(id) = 0.379, Recall: 0.374, Precision: 0.383
********************
# Seed = 9
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3024358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_70 (Embedding)     (None, 12, 175)           3007550   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 3,024,358
Trainable params: 3,024,358
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 150
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0482 - acc: 0.9858 - val_loss: 0.0391 - val_acc: 0.9870
Epoch 2/15
 - 9s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0348 - val_acc: 0.9882
Epoch 3/15
 - 9s - loss: 0.0190 - acc: 0.9912 - val_loss: 0.0337 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0274 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0162 - acc: 0.9922
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9930
# Training time = 0:05:39.745475!
# F-Score(Ordinary) = 0.423, Recall: 0.642, Precision: 0.316
# F-Score(lvc) = 0.257, Recall: 0.786, Precision: 0.154
# F-Score(ireflv) = 0.736, Recall: 0.779, Precision: 0.698
# F-Score(id) = 0.224, Recall: 0.365, Precision: 0.162
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3453008
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_71 (Embedding)     (None, 12, 200)           3433800   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 3,453,008
Trainable params: 3,453,008
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 297
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0481 - acc: 0.9854 - val_loss: 0.0347 - val_acc: 0.9877
Epoch 2/15
 - 9s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0344 - val_acc: 0.9881
Epoch 3/15
 - 9s - loss: 0.0191 - acc: 0.9913 - val_loss: 0.0353 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0277 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0162 - acc: 0.9919
Epoch 3/3
 - 1s - loss: 0.0134 - acc: 0.9932
# Training time = 0:05:04.501953!
# F-Score(Ordinary) = 0.263, Recall: 0.396, Precision: 0.197
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(id) = 0.444, Recall: 0.394, Precision: 0.509
********************
# Seed = 1
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3449408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_72 (Embedding)     (None, 12, 200)           3430200   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 3,449,408
Trainable params: 3,449,408
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0482 - acc: 0.9859 - val_loss: 0.0333 - val_acc: 0.9879
Epoch 2/15
 - 9s - loss: 0.0224 - acc: 0.9901 - val_loss: 0.0328 - val_acc: 0.9886
Epoch 3/15
 - 9s - loss: 0.0190 - acc: 0.9911 - val_loss: 0.0338 - val_acc: 0.9887
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0271 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0169 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0137 - acc: 0.9928
# Training time = 0:04:52.557951!
# F-Score(Ordinary) = 0.452, Recall: 0.59, Precision: 0.366
# F-Score(lvc) = 0.196, Recall: 0.8, Precision: 0.112
# F-Score(ireflv) = 0.701, Recall: 0.771, Precision: 0.643
# F-Score(id) = 0.396, Recall: 0.425, Precision: 0.371
********************
# Seed = 2
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3450608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_73 (Embedding)     (None, 12, 200)           3431400   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 3,450,608
Trainable params: 3,450,608
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 427
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0483 - acc: 0.9857 - val_loss: 0.0338 - val_acc: 0.9881
Epoch 2/15
 - 10s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0329 - val_acc: 0.9885
Epoch 3/15
 - 10s - loss: 0.0190 - acc: 0.9913 - val_loss: 0.0339 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0276 - acc: 0.9889
Epoch 2/3
 - 1s - loss: 0.0161 - acc: 0.9923
Epoch 3/3
 - 1s - loss: 0.0134 - acc: 0.9930
# Training time = 0:05:27.207995!
# F-Score(Ordinary) = 0.453, Recall: 0.593, Precision: 0.366
# F-Score(lvc) = 0.139, Recall: 0.733, Precision: 0.077
# F-Score(ireflv) = 0.695, Recall: 0.757, Precision: 0.643
# F-Score(id) = 0.432, Recall: 0.459, Precision: 0.407
********************
# Seed = 3
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3453808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_74 (Embedding)     (None, 12, 200)           3434600   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 3,453,808
Trainable params: 3,453,808
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 433
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0484 - acc: 0.9855 - val_loss: 0.0338 - val_acc: 0.9877
Epoch 2/15
 - 9s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0346 - val_acc: 0.9881
Epoch 3/15
 - 9s - loss: 0.0190 - acc: 0.9913 - val_loss: 0.0338 - val_acc: 0.9880
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0280 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0164 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0137 - acc: 0.9930
# Training time = 0:04:47.169090!
# F-Score(Ordinary) = 0.31, Recall: 0.255, Precision: 0.394
# F-Score(lvc) = 0.39, Recall: 0.419, Precision: 0.364
# F-Score(ireflv) = 0.306, Recall: 0.774, Precision: 0.19
# F-Score(id) = 0.271, Recall: 0.179, Precision: 0.557
********************
# Seed = 4
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3452608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_75 (Embedding)     (None, 12, 200)           3433400   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 3,452,608
Trainable params: 3,452,608
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 295
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0484 - acc: 0.9857 - val_loss: 0.0337 - val_acc: 0.9877
Epoch 2/15
 - 10s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0351 - val_acc: 0.9880
Epoch 3/15
 - 10s - loss: 0.0191 - acc: 0.9912 - val_loss: 0.0359 - val_acc: 0.9882
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0274 - acc: 0.9885
Epoch 2/3
 - 1s - loss: 0.0162 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0135 - acc: 0.9931
# Training time = 0:05:34.054498!
# F-Score(Ordinary) = 0.031, Recall: 0.5, Precision: 0.016
# F-Score(id) = 0.077, Recall: 0.5, Precision: 0.042
********************
# Seed = 5
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3456608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_76 (Embedding)     (None, 12, 200)           3437400   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 3,456,608
Trainable params: 3,456,608
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 450
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0482 - acc: 0.9847 - val_loss: 0.0329 - val_acc: 0.9881
Epoch 2/15
 - 9s - loss: 0.0225 - acc: 0.9903 - val_loss: 0.0349 - val_acc: 0.9880
Epoch 3/15
 - 9s - loss: 0.0191 - acc: 0.9912 - val_loss: 0.0349 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0279 - acc: 0.9885
Epoch 2/3
 - 1s - loss: 0.0165 - acc: 0.9922
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9929
# Training time = 0:04:48.730067!
# F-Score(Ordinary) = 0.457, Recall: 0.701, Precision: 0.339
# F-Score(lvc) = 0.491, Recall: 0.726, Precision: 0.371
# F-Score(ireflv) = 0.711, Recall: 0.794, Precision: 0.643
# F-Score(id) = 0.118, Recall: 0.333, Precision: 0.072
********************
# Seed = 6
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3457808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_77 (Embedding)     (None, 12, 200)           3438600   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 3,457,808
Trainable params: 3,457,808
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 483
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0480 - acc: 0.9854 - val_loss: 0.0361 - val_acc: 0.9868
Epoch 2/15
 - 10s - loss: 0.0226 - acc: 0.9903 - val_loss: 0.0331 - val_acc: 0.9884
Epoch 3/15
 - 10s - loss: 0.0192 - acc: 0.9911 - val_loss: 0.0345 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0277 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0158 - acc: 0.9926
Epoch 3/3
 - 1s - loss: 0.0134 - acc: 0.9928
# Training time = 0:06:30.179614!
# F-Score(Ordinary) = 0.277, Recall: 0.252, Precision: 0.307
# F-Score(lvc) = 0.445, Recall: 0.593, Precision: 0.357
# F-Score(id) = 0.261, Recall: 0.18, Precision: 0.479
********************
# Seed = 7
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3455608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_78 (Embedding)     (None, 12, 200)           3436400   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 3,455,608
Trainable params: 3,455,608
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 419
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0482 - acc: 0.9856 - val_loss: 0.0347 - val_acc: 0.9876
Epoch 2/15
 - 9s - loss: 0.0226 - acc: 0.9904 - val_loss: 0.0353 - val_acc: 0.9879
Epoch 3/15
 - 9s - loss: 0.0190 - acc: 0.9913 - val_loss: 0.0349 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0272 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0162 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9929
# Training time = 0:05:19.966802!
# F-Score(Ordinary) = 0.2, Recall: 0.144, Precision: 0.327
# F-Score(lvc) = 0.449, Recall: 0.742, Precision: 0.322
# F-Score(ireflv) = 0.016, Recall: 1.0, Precision: 0.008
# F-Score(id) = 0.166, Recall: 0.098, Precision: 0.545
********************
# Seed = 8
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3453008
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_79 (Embedding)     (None, 12, 200)           3433800   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 3,453,008
Trainable params: 3,453,008
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 263
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0484 - acc: 0.9856 - val_loss: 0.0372 - val_acc: 0.9866
Epoch 2/15
 - 9s - loss: 0.0225 - acc: 0.9903 - val_loss: 0.0343 - val_acc: 0.9883
Epoch 3/15
 - 9s - loss: 0.0191 - acc: 0.9911 - val_loss: 0.0346 - val_acc: 0.9887
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0275 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0160 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0135 - acc: 0.9929
# Training time = 0:05:08.852433!
# F-Score(Ordinary) = 0.223, Recall: 0.393, Precision: 0.156
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(id) = 0.386, Recall: 0.382, Precision: 0.389
********************
# Seed = 9
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3456408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_80 (Embedding)     (None, 12, 200)           3437200   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 3,456,408
Trainable params: 3,456,408
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 150
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0473 - acc: 0.9852 - val_loss: 0.0396 - val_acc: 0.9870
Epoch 2/15
 - 9s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0351 - val_acc: 0.9882
Epoch 3/15
 - 9s - loss: 0.0191 - acc: 0.9913 - val_loss: 0.0340 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0275 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0162 - acc: 0.9922
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9930
# Training time = 0:05:46.772984!
# F-Score(Ordinary) = 0.435, Recall: 0.665, Precision: 0.323
# F-Score(lvc) = 0.262, Recall: 0.88, Precision: 0.154
# F-Score(ireflv) = 0.729, Recall: 0.782, Precision: 0.683
# F-Score(id) = 0.27, Recall: 0.429, Precision: 0.198
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3884633
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_81 (Embedding)     (None, 12, 225)           3863025   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 3,884,633
Trainable params: 3,884,633
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 297
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0471 - acc: 0.9848 - val_loss: 0.0347 - val_acc: 0.9878
Epoch 2/15
 - 10s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0343 - val_acc: 0.9883
Epoch 3/15
 - 11s - loss: 0.0190 - acc: 0.9913 - val_loss: 0.0355 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0277 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0161 - acc: 0.9918
Epoch 3/3
 - 1s - loss: 0.0133 - acc: 0.9931
# Training time = 0:05:19.682379!
# F-Score(Ordinary) = 0.237, Recall: 0.298, Precision: 0.197
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(id) = 0.374, Recall: 0.295, Precision: 0.509
********************
# Seed = 1
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3880583
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_82 (Embedding)     (None, 12, 225)           3858975   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 3,880,583
Trainable params: 3,880,583
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0471 - acc: 0.9862 - val_loss: 0.0336 - val_acc: 0.9879
Epoch 2/15
 - 11s - loss: 0.0227 - acc: 0.9902 - val_loss: 0.0329 - val_acc: 0.9885
Epoch 3/15
 - 11s - loss: 0.0192 - acc: 0.9911 - val_loss: 0.0338 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0271 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0169 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0137 - acc: 0.9928
# Training time = 0:05:46.024945!
# F-Score(Ordinary) = 0.462, Recall: 0.606, Precision: 0.373
# F-Score(lvc) = 0.186, Recall: 0.833, Precision: 0.105
# F-Score(ireflv) = 0.687, Recall: 0.772, Precision: 0.619
# F-Score(id) = 0.429, Recall: 0.453, Precision: 0.407
********************
# Seed = 2
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3881933
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_83 (Embedding)     (None, 12, 225)           3860325   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 3,881,933
Trainable params: 3,881,933
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 427
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0474 - acc: 0.9851 - val_loss: 0.0345 - val_acc: 0.9880
Epoch 2/15
 - 10s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0332 - val_acc: 0.9884
Epoch 3/15
 - 10s - loss: 0.0190 - acc: 0.9914 - val_loss: 0.0340 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0277 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0161 - acc: 0.9922
Epoch 3/3
 - 1s - loss: 0.0134 - acc: 0.9931
# Training time = 0:05:06.599591!
# F-Score(Ordinary) = 0.455, Recall: 0.607, Precision: 0.364
# F-Score(lvc) = 0.161, Recall: 0.722, Precision: 0.091
# F-Score(ireflv) = 0.698, Recall: 0.764, Precision: 0.643
# F-Score(id) = 0.426, Recall: 0.471, Precision: 0.389
********************
# Seed = 3
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3885533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_84 (Embedding)     (None, 12, 225)           3863925   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 3,885,533
Trainable params: 3,885,533
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 433
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0473 - acc: 0.9857 - val_loss: 0.0341 - val_acc: 0.9877
Epoch 2/15
 - 10s - loss: 0.0227 - acc: 0.9902 - val_loss: 0.0348 - val_acc: 0.9881
Epoch 3/15
 - 10s - loss: 0.0190 - acc: 0.9913 - val_loss: 0.0340 - val_acc: 0.9880
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0282 - acc: 0.9884
Epoch 2/3
 - 1s - loss: 0.0164 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0137 - acc: 0.9930
# Training time = 0:05:33.337554!
# F-Score(Ordinary) = 0.3, Recall: 0.241, Precision: 0.398
# F-Score(lvc) = 0.406, Recall: 0.439, Precision: 0.378
# F-Score(ireflv) = 0.308, Recall: 0.8, Precision: 0.19
# F-Score(id) = 0.253, Recall: 0.163, Precision: 0.557
********************
# Seed = 4
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3884183
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_85 (Embedding)     (None, 12, 225)           3862575   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 3,884,183
Trainable params: 3,884,183
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 295
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0476 - acc: 0.9856 - val_loss: 0.0344 - val_acc: 0.9877
Epoch 2/15
 - 10s - loss: 0.0227 - acc: 0.9902 - val_loss: 0.0353 - val_acc: 0.9879
Epoch 3/15
 - 10s - loss: 0.0191 - acc: 0.9912 - val_loss: 0.0361 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0276 - acc: 0.9884
Epoch 2/3
 - 1s - loss: 0.0161 - acc: 0.9920
Epoch 3/3
 - 1s - loss: 0.0134 - acc: 0.9932
# Training time = 0:04:59.667959!
# F-Score(Ordinary) = 0.049, Recall: 0.733, Precision: 0.025
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(id) = 0.1, Recall: 0.692, Precision: 0.054
********************
# Seed = 5
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3888683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_86 (Embedding)     (None, 12, 225)           3867075   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 3,888,683
Trainable params: 3,888,683
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 450
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0472 - acc: 0.9850 - val_loss: 0.0330 - val_acc: 0.9880
Epoch 2/15
 - 11s - loss: 0.0226 - acc: 0.9903 - val_loss: 0.0354 - val_acc: 0.9881
Epoch 3/15
 - 11s - loss: 0.0192 - acc: 0.9912 - val_loss: 0.0352 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0280 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0165 - acc: 0.9923
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9929
# Training time = 0:05:22.852487!
# F-Score(Ordinary) = 0.475, Recall: 0.693, Precision: 0.362
# F-Score(lvc) = 0.493, Recall: 0.688, Precision: 0.385
# F-Score(ireflv) = 0.719, Recall: 0.804, Precision: 0.651
# F-Score(id) = 0.178, Recall: 0.413, Precision: 0.114
********************
# Seed = 6
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3890033
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_87 (Embedding)     (None, 12, 225)           3868425   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 3,890,033
Trainable params: 3,890,033
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 483
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0471 - acc: 0.9857 - val_loss: 0.0361 - val_acc: 0.9868
Epoch 2/15
 - 11s - loss: 0.0225 - acc: 0.9904 - val_loss: 0.0327 - val_acc: 0.9886
Epoch 3/15
 - 11s - loss: 0.0191 - acc: 0.9912 - val_loss: 0.0343 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0275 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0157 - acc: 0.9926
Epoch 3/3
 - 1s - loss: 0.0133 - acc: 0.9928
# Training time = 0:05:31.401386!
# F-Score(Ordinary) = 0.216, Recall: 0.167, Precision: 0.307
# F-Score(lvc) = 0.454, Recall: 0.605, Precision: 0.364
# F-Score(ireflv) = 0.016, Recall: 0.333, Precision: 0.008
# F-Score(id) = 0.177, Recall: 0.109, Precision: 0.467
********************
# Seed = 7
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3887558
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_88 (Embedding)     (None, 12, 225)           3865950   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 3,887,558
Trainable params: 3,887,558
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 419
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0474 - acc: 0.9857 - val_loss: 0.0351 - val_acc: 0.9876
Epoch 2/15
 - 10s - loss: 0.0227 - acc: 0.9903 - val_loss: 0.0354 - val_acc: 0.9879
Epoch 3/15
 - 10s - loss: 0.0191 - acc: 0.9913 - val_loss: 0.0349 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0272 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0162 - acc: 0.9919
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9929
# Training time = 0:04:58.459353!
# F-Score(Ordinary) = 0.208, Recall: 0.153, Precision: 0.323
# F-Score(lvc) = 0.429, Recall: 0.71, Precision: 0.308
# F-Score(ireflv) = 0.047, Recall: 1.0, Precision: 0.024
# F-Score(id) = 0.176, Recall: 0.105, Precision: 0.539
********************
# Seed = 8
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3884633
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_89 (Embedding)     (None, 12, 225)           3863025   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 3,884,633
Trainable params: 3,884,633
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 263
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0472 - acc: 0.9848 - val_loss: 0.0371 - val_acc: 0.9865
Epoch 2/15
 - 10s - loss: 0.0225 - acc: 0.9903 - val_loss: 0.0344 - val_acc: 0.9883
Epoch 3/15
 - 10s - loss: 0.0191 - acc: 0.9912 - val_loss: 0.0347 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0276 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0158 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0134 - acc: 0.9930
# Training time = 0:05:22.395300!
# F-Score(Ordinary) = 0.21, Recall: 0.342, Precision: 0.151
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(id) = 0.358, Recall: 0.335, Precision: 0.383
********************
# Seed = 9
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3888458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_90 (Embedding)     (None, 12, 225)           3866850   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 3,888,458
Trainable params: 3,888,458
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 150
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0468 - acc: 0.9858 - val_loss: 0.0395 - val_acc: 0.9871
Epoch 2/15
 - 10s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0351 - val_acc: 0.9882
Epoch 3/15
 - 10s - loss: 0.0190 - acc: 0.9912 - val_loss: 0.0341 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0275 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0161 - acc: 0.9923
Epoch 3/3
 - 1s - loss: 0.0135 - acc: 0.9931
# Training time = 0:05:09.127259!
# F-Score(Ordinary) = 0.425, Recall: 0.621, Precision: 0.323
# F-Score(lvc) = 0.25, Recall: 0.84, Precision: 0.147
# F-Score(ireflv) = 0.728, Recall: 0.77, Precision: 0.69
# F-Score(id) = 0.258, Recall: 0.371, Precision: 0.198
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4316258
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_91 (Embedding)     (None, 12, 250)           4292250   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 4,316,258
Trainable params: 4,316,258
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 297
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0464 - acc: 0.9856 - val_loss: 0.0350 - val_acc: 0.9879
Epoch 2/15
 - 11s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0345 - val_acc: 0.9881
Epoch 3/15
 - 11s - loss: 0.0190 - acc: 0.9913 - val_loss: 0.0358 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0279 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0162 - acc: 0.9919
Epoch 3/3
 - 1s - loss: 0.0134 - acc: 0.9932
# Training time = 0:05:28.689003!
# F-Score(Ordinary) = 0.251, Recall: 0.371, Precision: 0.19
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(id) = 0.416, Recall: 0.365, Precision: 0.485
********************
# Seed = 1
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4311758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_92 (Embedding)     (None, 12, 250)           4287750   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 4,311,758
Trainable params: 4,311,758
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0459 - acc: 0.9855 - val_loss: 0.0336 - val_acc: 0.9879
Epoch 2/15
 - 11s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0329 - val_acc: 0.9885
Epoch 3/15
 - 11s - loss: 0.0190 - acc: 0.9911 - val_loss: 0.0337 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0271 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0169 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9928
# Training time = 0:05:28.526657!
# F-Score(Ordinary) = 0.46, Recall: 0.612, Precision: 0.368
# F-Score(lvc) = 0.186, Recall: 0.833, Precision: 0.105
# F-Score(ireflv) = 0.713, Recall: 0.788, Precision: 0.651
# F-Score(id) = 0.409, Recall: 0.447, Precision: 0.377
********************
# Seed = 2
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4313258
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_93 (Embedding)     (None, 12, 250)           4289250   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 4,313,258
Trainable params: 4,313,258
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 427
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0463 - acc: 0.9856 - val_loss: 0.0345 - val_acc: 0.9879
Epoch 2/15
 - 11s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0332 - val_acc: 0.9884
Epoch 3/15
 - 11s - loss: 0.0190 - acc: 0.9914 - val_loss: 0.0340 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0276 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0160 - acc: 0.9922
Epoch 3/3
 - 1s - loss: 0.0133 - acc: 0.9930
# Training time = 0:05:12.876728!
# F-Score(Ordinary) = 0.449, Recall: 0.627, Precision: 0.35
# F-Score(lvc) = 0.139, Recall: 0.733, Precision: 0.077
# F-Score(ireflv) = 0.696, Recall: 0.782, Precision: 0.627
# F-Score(id) = 0.427, Recall: 0.492, Precision: 0.377
********************
# Seed = 3
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4317258
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_94 (Embedding)     (None, 12, 250)           4293250   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 4,317,258
Trainable params: 4,317,258
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 433
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0465 - acc: 0.9860 - val_loss: 0.0341 - val_acc: 0.9877
Epoch 2/15
 - 11s - loss: 0.0227 - acc: 0.9903 - val_loss: 0.0349 - val_acc: 0.9881
Epoch 3/15
 - 11s - loss: 0.0191 - acc: 0.9913 - val_loss: 0.0341 - val_acc: 0.9879
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0283 - acc: 0.9884
Epoch 2/3
 - 1s - loss: 0.0163 - acc: 0.9922
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9930
# Training time = 0:04:57.526825!
# F-Score(Ordinary) = 0.28, Recall: 0.216, Precision: 0.398
# F-Score(lvc) = 0.423, Recall: 0.47, Precision: 0.385
# F-Score(ireflv) = 0.288, Recall: 0.815, Precision: 0.175
# F-Score(id) = 0.227, Recall: 0.142, Precision: 0.563
********************
# Seed = 4
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4315758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_95 (Embedding)     (None, 12, 250)           4291750   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 4,315,758
Trainable params: 4,315,758
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 295
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0461 - acc: 0.9853 - val_loss: 0.0343 - val_acc: 0.9877
Epoch 2/15
 - 11s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0352 - val_acc: 0.9880
Epoch 3/15
 - 11s - loss: 0.0190 - acc: 0.9913 - val_loss: 0.0359 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0276 - acc: 0.9883
Epoch 2/3
 - 1s - loss: 0.0161 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0134 - acc: 0.9932
# Training time = 0:05:52.483926!
# F-Score(Ordinary) = 0.04, Recall: 0.643, Precision: 0.021
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(id) = 0.078, Recall: 0.583, Precision: 0.042
********************
# Seed = 5
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4320758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_96 (Embedding)     (None, 12, 250)           4296750   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 4,320,758
Trainable params: 4,320,758
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 450
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0461 - acc: 0.9851 - val_loss: 0.0330 - val_acc: 0.9879
Epoch 2/15
 - 11s - loss: 0.0225 - acc: 0.9903 - val_loss: 0.0350 - val_acc: 0.9881
Epoch 3/15
 - 11s - loss: 0.0191 - acc: 0.9912 - val_loss: 0.0349 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0278 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0164 - acc: 0.9923
Epoch 3/3
 - 1s - loss: 0.0135 - acc: 0.9930
# Training time = 0:05:03.947033!
# F-Score(Ordinary) = 0.475, Recall: 0.709, Precision: 0.357
# F-Score(lvc) = 0.491, Recall: 0.679, Precision: 0.385
# F-Score(ireflv) = 0.714, Recall: 0.802, Precision: 0.643
# F-Score(id) = 0.166, Recall: 0.447, Precision: 0.102
********************
# Seed = 6
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4322258
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_97 (Embedding)     (None, 12, 250)           4298250   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 4,322,258
Trainable params: 4,322,258
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 483
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0464 - acc: 0.9850 - val_loss: 0.0363 - val_acc: 0.9867
Epoch 2/15
 - 11s - loss: 0.0225 - acc: 0.9903 - val_loss: 0.0328 - val_acc: 0.9886
Epoch 3/15
 - 11s - loss: 0.0191 - acc: 0.9912 - val_loss: 0.0344 - val_acc: 0.9882
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0276 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0158 - acc: 0.9924
Epoch 3/3
 - 1s - loss: 0.0134 - acc: 0.9928
# Training time = 0:04:43.974292!
# F-Score(Ordinary) = 0.197, Recall: 0.147, Precision: 0.297
# F-Score(lvc) = 0.446, Recall: 0.578, Precision: 0.364
# F-Score(ireflv) = 0.016, Recall: 0.5, Precision: 0.008
# F-Score(id) = 0.155, Recall: 0.094, Precision: 0.443
********************
# Seed = 7
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4319508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_98 (Embedding)     (None, 12, 250)           4295500   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 4,319,508
Trainable params: 4,319,508
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 419
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0463 - acc: 0.9860 - val_loss: 0.0356 - val_acc: 0.9875
Epoch 2/15
 - 11s - loss: 0.0227 - acc: 0.9904 - val_loss: 0.0354 - val_acc: 0.9879
Epoch 3/15
 - 11s - loss: 0.0191 - acc: 0.9913 - val_loss: 0.0349 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0271 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0161 - acc: 0.9920
Epoch 3/3
 - 1s - loss: 0.0135 - acc: 0.9928
# Training time = 0:04:37.412373!
# F-Score(Ordinary) = 0.195, Recall: 0.138, Precision: 0.33
# F-Score(lvc) = 0.425, Recall: 0.688, Precision: 0.308
# F-Score(ireflv) = 0.076, Recall: 0.833, Precision: 0.04
# F-Score(id) = 0.158, Recall: 0.093, Precision: 0.539
********************
# Seed = 8
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4316258
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_99 (Embedding)     (None, 12, 250)           4292250   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 4,316,258
Trainable params: 4,316,258
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 263
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0465 - acc: 0.9856 - val_loss: 0.0369 - val_acc: 0.9867
Epoch 2/15
 - 11s - loss: 0.0227 - acc: 0.9903 - val_loss: 0.0345 - val_acc: 0.9882
Epoch 3/15
 - 11s - loss: 0.0193 - acc: 0.9911 - val_loss: 0.0351 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0278 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0159 - acc: 0.9922
Epoch 3/3
 - 1s - loss: 0.0135 - acc: 0.9930
# Training time = 0:05:06.316353!
# F-Score(Ordinary) = 0.215, Recall: 0.42, Precision: 0.144
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(id) = 0.387, Recall: 0.412, Precision: 0.365
********************
# Seed = 9
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4320508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_100 (Embedding)    (None, 12, 250)           4296500   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 4,320,508
Trainable params: 4,320,508
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 150
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0464 - acc: 0.9859 - val_loss: 0.0398 - val_acc: 0.9871
Epoch 2/15
 - 11s - loss: 0.0228 - acc: 0.9902 - val_loss: 0.0354 - val_acc: 0.9883
Epoch 3/15
 - 11s - loss: 0.0193 - acc: 0.9912 - val_loss: 0.0342 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0276 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0161 - acc: 0.9924
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9931
# Training time = 0:04:48.194631!
# F-Score(Ordinary) = 0.457, Recall: 0.65, Precision: 0.352
# F-Score(lvc) = 0.35, Recall: 0.8, Precision: 0.224
# F-Score(ireflv) = 0.723, Recall: 0.78, Precision: 0.675
# F-Score(id) = 0.29, Recall: 0.42, Precision: 0.222
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4747883
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_101 (Embedding)    (None, 12, 275)           4721475   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 4,747,883
Trainable params: 4,747,883
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 297
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0459 - acc: 0.9853 - val_loss: 0.0353 - val_acc: 0.9878
Epoch 2/15
 - 12s - loss: 0.0227 - acc: 0.9903 - val_loss: 0.0345 - val_acc: 0.9882
Epoch 3/15
 - 12s - loss: 0.0190 - acc: 0.9913 - val_loss: 0.0357 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0280 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0162 - acc: 0.9919
Epoch 3/3
 - 1s - loss: 0.0133 - acc: 0.9931
# Training time = 0:05:24.499540!
# F-Score(Ordinary) = 0.236, Recall: 0.333, Precision: 0.183
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(id) = 0.39, Recall: 0.332, Precision: 0.473
********************
# Seed = 1
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4742933
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_102 (Embedding)    (None, 12, 275)           4716525   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 4,742,933
Trainable params: 4,742,933
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0455 - acc: 0.9860 - val_loss: 0.0334 - val_acc: 0.9880
Epoch 2/15
 - 12s - loss: 0.0224 - acc: 0.9902 - val_loss: 0.0327 - val_acc: 0.9885
Epoch 3/15
 - 12s - loss: 0.0189 - acc: 0.9911 - val_loss: 0.0334 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0271 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0169 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9928
# Training time = 0:05:14.141110!
# F-Score(Ordinary) = 0.447, Recall: 0.611, Precision: 0.352
# F-Score(lvc) = 0.165, Recall: 0.867, Precision: 0.091
# F-Score(ireflv) = 0.698, Recall: 0.764, Precision: 0.643
# F-Score(id) = 0.403, Recall: 0.458, Precision: 0.359
********************
# Seed = 2
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4744583
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_103 (Embedding)    (None, 12, 275)           4718175   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 4,744,583
Trainable params: 4,744,583
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 427
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0459 - acc: 0.9854 - val_loss: 0.0346 - val_acc: 0.9879
Epoch 2/15
 - 13s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0331 - val_acc: 0.9884
Epoch 3/15
 - 13s - loss: 0.0190 - acc: 0.9914 - val_loss: 0.0339 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0276 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0160 - acc: 0.9923
Epoch 3/3
 - 1s - loss: 0.0133 - acc: 0.9930
# Training time = 0:05:23.738322!
# F-Score(Ordinary) = 0.446, Recall: 0.62, Precision: 0.348
# F-Score(lvc) = 0.128, Recall: 0.769, Precision: 0.07
# F-Score(ireflv) = 0.699, Recall: 0.777, Precision: 0.635
# F-Score(id) = 0.419, Recall: 0.481, Precision: 0.371
********************
# Seed = 3
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4748983
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_104 (Embedding)    (None, 12, 275)           4722575   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 4,748,983
Trainable params: 4,748,983
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 433
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0458 - acc: 0.9855 - val_loss: 0.0343 - val_acc: 0.9878
Epoch 2/15
 - 12s - loss: 0.0227 - acc: 0.9903 - val_loss: 0.0349 - val_acc: 0.9880
Epoch 3/15
 - 12s - loss: 0.0190 - acc: 0.9913 - val_loss: 0.0343 - val_acc: 0.9879
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0284 - acc: 0.9883
Epoch 2/3
 - 1s - loss: 0.0164 - acc: 0.9920
Epoch 3/3
 - 1s - loss: 0.0137 - acc: 0.9930
# Training time = 0:05:37.054445!
# F-Score(Ordinary) = 0.289, Recall: 0.23, Precision: 0.391
# F-Score(lvc) = 0.409, Recall: 0.468, Precision: 0.364
# F-Score(ireflv) = 0.31, Recall: 0.828, Precision: 0.19
# F-Score(id) = 0.238, Recall: 0.152, Precision: 0.551
********************
# Seed = 4
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4747333
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_105 (Embedding)    (None, 12, 275)           4720925   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 4,747,333
Trainable params: 4,747,333
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 295
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0458 - acc: 0.9863 - val_loss: 0.0345 - val_acc: 0.9878
Epoch 2/15
 - 12s - loss: 0.0227 - acc: 0.9902 - val_loss: 0.0353 - val_acc: 0.9879
Epoch 3/15
 - 12s - loss: 0.0191 - acc: 0.9912 - val_loss: 0.0358 - val_acc: 0.9882
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0276 - acc: 0.9884
Epoch 2/3
 - 1s - loss: 0.0161 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0134 - acc: 0.9931
# Training time = 0:04:37.629278!
# F-Score(Ordinary) = 0.04, Recall: 0.75, Precision: 0.021
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(id) = 0.079, Recall: 0.7, Precision: 0.042
********************
# Seed = 5
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4752833
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_106 (Embedding)    (None, 12, 275)           4726425   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 4,752,833
Trainable params: 4,752,833
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 450
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0458 - acc: 0.9860 - val_loss: 0.0331 - val_acc: 0.9879
Epoch 2/15
 - 12s - loss: 0.0225 - acc: 0.9904 - val_loss: 0.0350 - val_acc: 0.9881
Epoch 3/15
 - 12s - loss: 0.0190 - acc: 0.9912 - val_loss: 0.0348 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0279 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0164 - acc: 0.9923
Epoch 3/3
 - 1s - loss: 0.0135 - acc: 0.9930
# Training time = 0:04:39.729752!
# F-Score(Ordinary) = 0.448, Recall: 0.671, Precision: 0.336
# F-Score(lvc) = 0.444, Recall: 0.658, Precision: 0.336
# F-Score(ireflv) = 0.714, Recall: 0.802, Precision: 0.643
# F-Score(id) = 0.142, Recall: 0.333, Precision: 0.09
********************
# Seed = 6
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4754483
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_107 (Embedding)    (None, 12, 275)           4728075   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 4,754,483
Trainable params: 4,754,483
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 483
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0462 - acc: 0.9855 - val_loss: 0.0365 - val_acc: 0.9869
Epoch 2/15
 - 12s - loss: 0.0226 - acc: 0.9903 - val_loss: 0.0329 - val_acc: 0.9886
Epoch 3/15
 - 12s - loss: 0.0191 - acc: 0.9912 - val_loss: 0.0343 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0276 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0157 - acc: 0.9924
Epoch 3/3
 - 1s - loss: 0.0133 - acc: 0.9929
# Training time = 0:05:39.137577!
# F-Score(Ordinary) = 0.22, Recall: 0.175, Precision: 0.297
# F-Score(lvc) = 0.444, Recall: 0.571, Precision: 0.364
# F-Score(ireflv) = 0.016, Recall: 0.333, Precision: 0.008
# F-Score(id) = 0.181, Recall: 0.114, Precision: 0.443
********************
# Seed = 7
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4751458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_108 (Embedding)    (None, 12, 275)           4725050   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 4,751,458
Trainable params: 4,751,458
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 419
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0463 - acc: 0.9859 - val_loss: 0.0357 - val_acc: 0.9877
Epoch 2/15
 - 12s - loss: 0.0226 - acc: 0.9904 - val_loss: 0.0350 - val_acc: 0.9879
Epoch 3/15
 - 12s - loss: 0.0190 - acc: 0.9913 - val_loss: 0.0348 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0271 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0161 - acc: 0.9919
Epoch 3/3
 - 1s - loss: 0.0135 - acc: 0.9928
# Training time = 0:04:53.677811!
# F-Score(Ordinary) = 0.223, Recall: 0.167, Precision: 0.336
# F-Score(lvc) = 0.438, Recall: 0.687, Precision: 0.322
# F-Score(ireflv) = 0.076, Recall: 0.833, Precision: 0.04
# F-Score(id) = 0.186, Recall: 0.112, Precision: 0.545
********************
# Seed = 8
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4747883
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_109 (Embedding)    (None, 12, 275)           4721475   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 4,747,883
Trainable params: 4,747,883
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 263
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0458 - acc: 0.9857 - val_loss: 0.0371 - val_acc: 0.9866
Epoch 2/15
 - 12s - loss: 0.0225 - acc: 0.9904 - val_loss: 0.0344 - val_acc: 0.9883
Epoch 3/15
 - 12s - loss: 0.0191 - acc: 0.9912 - val_loss: 0.0345 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0276 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0158 - acc: 0.9923
Epoch 3/3
 - 1s - loss: 0.0134 - acc: 0.9930
# Training time = 0:04:57.394167!
# F-Score(Ordinary) = 0.204, Recall: 0.363, Precision: 0.142
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(id) = 0.357, Recall: 0.355, Precision: 0.359
********************
# Seed = 9
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 4752558
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_110 (Embedding)    (None, 12, 275)           4726150   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 4,752,558
Trainable params: 4,752,558
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 150
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0458 - acc: 0.9849 - val_loss: 0.0397 - val_acc: 0.9873
Epoch 2/15
 - 13s - loss: 0.0228 - acc: 0.9903 - val_loss: 0.0354 - val_acc: 0.9882
Epoch 3/15
 - 13s - loss: 0.0191 - acc: 0.9912 - val_loss: 0.0342 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0275 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0160 - acc: 0.9923
Epoch 3/3
 - 1s - loss: 0.0135 - acc: 0.9930
# Training time = 0:04:43.609122!
# F-Score(Ordinary) = 0.404, Recall: 0.618, Precision: 0.3
# F-Score(lvc) = 0.185, Recall: 0.789, Precision: 0.105
# F-Score(ireflv) = 0.729, Recall: 0.782, Precision: 0.683
# F-Score(id) = 0.24, Recall: 0.361, Precision: 0.18
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 5179508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_111 (Embedding)    (None, 12, 300)           5150700   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 5,179,508
Trainable params: 5,179,508
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 297
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0449 - acc: 0.9856 - val_loss: 0.0354 - val_acc: 0.9879
Epoch 2/15
 - 13s - loss: 0.0227 - acc: 0.9903 - val_loss: 0.0344 - val_acc: 0.9883
Epoch 3/15
 - 13s - loss: 0.0190 - acc: 0.9913 - val_loss: 0.0356 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0278 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0161 - acc: 0.9919
Epoch 3/3
 - 1s - loss: 0.0133 - acc: 0.9931
# Training time = 0:05:01.007292!
# F-Score(Ordinary) = 0.249, Recall: 0.371, Precision: 0.188
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(id) = 0.42, Recall: 0.37, Precision: 0.485
********************
# Seed = 1
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 5174108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_112 (Embedding)    (None, 12, 300)           5145300   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 5,174,108
Trainable params: 5,174,108
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0450 - acc: 0.9853 - val_loss: 0.0337 - val_acc: 0.9880
Epoch 2/15
 - 13s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0331 - val_acc: 0.9885
Epoch 3/15
 - 13s - loss: 0.0191 - acc: 0.9912 - val_loss: 0.0338 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0273 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0169 - acc: 0.9914
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9928
# Training time = 0:04:50.041858!
# F-Score(Ordinary) = 0.454, Recall: 0.655, Precision: 0.348
# F-Score(lvc) = 0.154, Recall: 0.923, Precision: 0.084
# F-Score(ireflv) = 0.69, Recall: 0.767, Precision: 0.627
# F-Score(id) = 0.431, Recall: 0.526, Precision: 0.365
********************
# Seed = 2
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 5175908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_113 (Embedding)    (None, 12, 300)           5147100   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 5,175,908
Trainable params: 5,175,908
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 427
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0452 - acc: 0.9861 - val_loss: 0.0346 - val_acc: 0.9880
Epoch 2/15
 - 13s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0328 - val_acc: 0.9885
Epoch 3/15
 - 13s - loss: 0.0189 - acc: 0.9914 - val_loss: 0.0339 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0277 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0160 - acc: 0.9921
Epoch 3/3
 - 1s - loss: 0.0133 - acc: 0.9930
# Training time = 0:04:41.615896!
# F-Score(Ordinary) = 0.438, Recall: 0.605, Precision: 0.343
# F-Score(lvc) = 0.114, Recall: 0.6, Precision: 0.063
# F-Score(ireflv) = 0.687, Recall: 0.748, Precision: 0.635
# F-Score(id) = 0.416, Recall: 0.484, Precision: 0.365
********************
# Seed = 3
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 5180708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_114 (Embedding)    (None, 12, 300)           5151900   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 5,180,708
Trainable params: 5,180,708
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 433
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0454 - acc: 0.9851 - val_loss: 0.0341 - val_acc: 0.9878
Epoch 2/15
 - 13s - loss: 0.0226 - acc: 0.9903 - val_loss: 0.0348 - val_acc: 0.9881
Epoch 3/15
 - 13s - loss: 0.0190 - acc: 0.9913 - val_loss: 0.0341 - val_acc: 0.9879
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0283 - acc: 0.9883
Epoch 2/3
 - 1s - loss: 0.0162 - acc: 0.9920
Epoch 3/3
 - 1s - loss: 0.0136 - acc: 0.9930
# Training time = 0:05:58.590962!
# F-Score(Ordinary) = 0.255, Recall: 0.189, Precision: 0.391
# F-Score(lvc) = 0.394, Recall: 0.44, Precision: 0.357
# F-Score(ireflv) = 0.31, Recall: 0.828, Precision: 0.19
# F-Score(id) = 0.199, Recall: 0.121, Precision: 0.551
********************
# Seed = 4
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 5178908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_115 (Embedding)    (None, 12, 300)           5150100   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 5,178,908
Trainable params: 5,178,908
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 295
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0455 - acc: 0.9850 - val_loss: 0.0349 - val_acc: 0.9877
Epoch 2/15
 - 13s - loss: 0.0227 - acc: 0.9902 - val_loss: 0.0355 - val_acc: 0.9879
Epoch 3/15
 - 13s - loss: 0.0191 - acc: 0.9912 - val_loss: 0.0362 - val_acc: 0.9882
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0278 - acc: 0.9882
Epoch 2/3
 - 1s - loss: 0.0161 - acc: 0.9920
Epoch 3/3
 - 1s - loss: 0.0134 - acc: 0.9931
# Training time = 0:04:42.867677!
# F-Score(Ordinary) = 0.035, Recall: 0.571, Precision: 0.018
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(id) = 0.067, Recall: 0.5, Precision: 0.036
********************
# Seed = 5
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 5184908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_116 (Embedding)    (None, 12, 300)           5156100   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 5,184,908
Trainable params: 5,184,908
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 450
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0453 - acc: 0.9857 - val_loss: 0.0332 - val_acc: 0.9879
Epoch 2/15
 - 13s - loss: 0.0225 - acc: 0.9904 - val_loss: 0.0348 - val_acc: 0.9882
Epoch 3/15
 - 13s - loss: 0.0191 - acc: 0.9912 - val_loss: 0.0347 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0279 - acc: 0.9885
Epoch 2/3
 - 1s - loss: 0.0163 - acc: 0.9923
Epoch 3/3
 - 1s - loss: 0.0135 - acc: 0.9930
# Training time = 0:05:09.120006!
# F-Score(Ordinary) = 0.473, Recall: 0.711, Precision: 0.355
# F-Score(lvc) = 0.48, Recall: 0.679, Precision: 0.371
# F-Score(ireflv) = 0.717, Recall: 0.81, Precision: 0.643
# F-Score(id) = 0.174, Recall: 0.45, Precision: 0.108
********************
# Seed = 6
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 5186708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_117 (Embedding)    (None, 12, 300)           5157900   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 5,186,708
Trainable params: 5,186,708
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 483
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0456 - acc: 0.9859 - val_loss: 0.0364 - val_acc: 0.9869
Epoch 2/15
 - 13s - loss: 0.0225 - acc: 0.9903 - val_loss: 0.0326 - val_acc: 0.9886
Epoch 3/15
 - 13s - loss: 0.0191 - acc: 0.9912 - val_loss: 0.0343 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0277 - acc: 0.9885
Epoch 2/3
 - 1s - loss: 0.0157 - acc: 0.9925
Epoch 3/3
 - 1s - loss: 0.0133 - acc: 0.9929
# Training time = 0:04:42.029574!
# F-Score(Ordinary) = 0.209, Recall: 0.158, Precision: 0.307
# F-Score(lvc) = 0.458, Recall: 0.581, Precision: 0.378
# F-Score(id) = 0.167, Recall: 0.102, Precision: 0.461
********************
# Seed = 7
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 5183408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_118 (Embedding)    (None, 12, 300)           5154600   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 5,183,408
Trainable params: 5,183,408
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 419
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0457 - acc: 0.9858 - val_loss: 0.0357 - val_acc: 0.9876
Epoch 2/15
 - 13s - loss: 0.0227 - acc: 0.9904 - val_loss: 0.0352 - val_acc: 0.9879
Epoch 3/15
 - 13s - loss: 0.0191 - acc: 0.9913 - val_loss: 0.0349 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0272 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0161 - acc: 0.9920
Epoch 3/3
 - 1s - loss: 0.0135 - acc: 0.9929
# Training time = 0:05:20.737969!
# F-Score(Ordinary) = 0.209, Recall: 0.152, Precision: 0.334
# F-Score(lvc) = 0.437, Recall: 0.714, Precision: 0.315
# F-Score(ireflv) = 0.104, Recall: 0.778, Precision: 0.056
# F-Score(id) = 0.17, Recall: 0.101, Precision: 0.539
********************
# Seed = 8
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 5179508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_119 (Embedding)    (None, 12, 300)           5150700   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 5,179,508
Trainable params: 5,179,508
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 263
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0454 - acc: 0.9862 - val_loss: 0.0369 - val_acc: 0.9867
Epoch 2/15
 - 13s - loss: 0.0226 - acc: 0.9904 - val_loss: 0.0344 - val_acc: 0.9883
Epoch 3/15
 - 13s - loss: 0.0191 - acc: 0.9912 - val_loss: 0.0347 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0276 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0158 - acc: 0.9923
Epoch 3/3
 - 1s - loss: 0.0134 - acc: 0.9931
# Training time = 0:04:44.066904!
# F-Score(Ordinary) = 0.205, Recall: 0.34, Precision: 0.146
# F-Score(lvc) = 0.027, Recall: 0.667, Precision: 0.014
# F-Score(id) = 0.352, Recall: 0.335, Precision: 0.371
********************
# Seed = 9
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 5184608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_120 (Embedding)    (None, 12, 300)           5155800   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 5,184,608
Trainable params: 5,184,608
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 150
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0453 - acc: 0.9854 - val_loss: 0.0398 - val_acc: 0.9873
Epoch 2/15
 - 13s - loss: 0.0228 - acc: 0.9902 - val_loss: 0.0356 - val_acc: 0.9882
Epoch 3/15
 - 13s - loss: 0.0192 - acc: 0.9912 - val_loss: 0.0343 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0276 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0160 - acc: 0.9924
Epoch 3/3
 - 1s - loss: 0.0135 - acc: 0.9930
# Training time = 0:04:43.196719!
# F-Score(Ordinary) = 0.414, Recall: 0.609, Precision: 0.314
# F-Score(lvc) = 0.238, Recall: 0.8, Precision: 0.14
# F-Score(ireflv) = 0.726, Recall: 0.775, Precision: 0.683
# F-Score(id) = 0.242, Recall: 0.348, Precision: 0.186
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 316783
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_121 (Embedding)    (None, 12, 25)            314375    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 316,783
Trainable params: 316,783
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 107
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0764 - acc: 0.9794 - val_loss: 0.0309 - val_acc: 0.9881
Epoch 2/15
 - 6s - loss: 0.0251 - acc: 0.9892 - val_loss: 0.0298 - val_acc: 0.9887
Epoch 3/15
 - 6s - loss: 0.0218 - acc: 0.9903 - val_loss: 0.0298 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0264 - acc: 0.9893
Epoch 2/3
 - 1s - loss: 0.0203 - acc: 0.9907
Epoch 3/3
 - 1s - loss: 0.0180 - acc: 0.9916
# Training time = 0:04:15.137238!
# F-Score(Ordinary) = 0.28, Recall: 0.41, Precision: 0.213
# F-Score(lvc) = 0.079, Recall: 0.667, Precision: 0.042
# F-Score(ireflv) = 0.104, Recall: 0.875, Precision: 0.056
# F-Score(id) = 0.424, Recall: 0.381, Precision: 0.479
********************
# Seed = 1
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 316283
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_122 (Embedding)    (None, 12, 25)            313875    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 316,283
Trainable params: 316,283
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 409
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0777 - acc: 0.9813 - val_loss: 0.0312 - val_acc: 0.9881
Epoch 2/15
 - 6s - loss: 0.0252 - acc: 0.9891 - val_loss: 0.0288 - val_acc: 0.9887
Epoch 3/15
 - 6s - loss: 0.0220 - acc: 0.9902 - val_loss: 0.0292 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0266 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0210 - acc: 0.9907
Epoch 3/3
 - 1s - loss: 0.0181 - acc: 0.9916
# Training time = 0:04:51.089655!
# F-Score(Ordinary) = 0.514, Recall: 0.593, Precision: 0.453
# F-Score(lvc) = 0.294, Recall: 0.926, Precision: 0.175
# F-Score(ireflv) = 0.782, Recall: 0.83, Precision: 0.738
# F-Score(id) = 0.442, Recall: 0.41, Precision: 0.479
********************
# Seed = 2
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 316558
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_123 (Embedding)    (None, 12, 25)            314150    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 316,558
Trainable params: 316,558
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 110
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0778 - acc: 0.9806 - val_loss: 0.0318 - val_acc: 0.9881
Epoch 2/15
 - 6s - loss: 0.0252 - acc: 0.9893 - val_loss: 0.0291 - val_acc: 0.9889
Epoch 3/15
 - 6s - loss: 0.0220 - acc: 0.9903 - val_loss: 0.0294 - val_acc: 0.9887
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0266 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0203 - acc: 0.9908
Epoch 3/3
 - 1s - loss: 0.0178 - acc: 0.9917
# Training time = 0:04:19.216230!
# F-Score(Ordinary) = 0.461, Recall: 0.427, Precision: 0.501
# F-Score(lvc) = 0.389, Recall: 0.787, Precision: 0.259
# F-Score(ireflv) = 0.756, Recall: 0.708, Precision: 0.81
# F-Score(id) = 0.319, Recall: 0.242, Precision: 0.467
********************
# Seed = 3
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 316958
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_124 (Embedding)    (None, 12, 25)            314550    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 316,958
Trainable params: 316,958
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 171
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0773 - acc: 0.9824 - val_loss: 0.0306 - val_acc: 0.9884
Epoch 2/15
 - 6s - loss: 0.0253 - acc: 0.9892 - val_loss: 0.0296 - val_acc: 0.9887
Epoch 3/15
 - 6s - loss: 0.0220 - acc: 0.9903 - val_loss: 0.0299 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0271 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0207 - acc: 0.9909
Epoch 3/3
 - 1s - loss: 0.0182 - acc: 0.9915
# Training time = 0:04:14.005167!
# F-Score(Ordinary) = 0.375, Recall: 0.502, Precision: 0.3
# F-Score(lvc) = 0.453, Recall: 0.622, Precision: 0.357
# F-Score(ireflv) = 0.216, Recall: 0.727, Precision: 0.127
# F-Score(id) = 0.389, Recall: 0.401, Precision: 0.377
********************
# Seed = 4
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 316883
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_125 (Embedding)    (None, 12, 25)            314475    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 316,883
Trainable params: 316,883
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 152
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0782 - acc: 0.9816 - val_loss: 0.0321 - val_acc: 0.9879
Epoch 2/15
 - 6s - loss: 0.0253 - acc: 0.9891 - val_loss: 0.0302 - val_acc: 0.9889
Epoch 3/15
 - 6s - loss: 0.0220 - acc: 0.9902 - val_loss: 0.0309 - val_acc: 0.9886
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0265 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0204 - acc: 0.9909
Epoch 3/3
 - 1s - loss: 0.0180 - acc: 0.9917
# Training time = 0:05:01.020083!
# F-Score(Ordinary) = 0.099, Recall: 0.522, Precision: 0.055
# F-Score(lvc) = 0.08, Recall: 0.857, Precision: 0.042
# F-Score(id) = 0.175, Recall: 0.462, Precision: 0.108
********************
# Seed = 5
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 317208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_126 (Embedding)    (None, 12, 25)            314800    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 317,208
Trainable params: 317,208
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 266
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0765 - acc: 0.9828 - val_loss: 0.0315 - val_acc: 0.9880
Epoch 2/15
 - 6s - loss: 0.0249 - acc: 0.9893 - val_loss: 0.0289 - val_acc: 0.9892
Epoch 3/15
 - 6s - loss: 0.0218 - acc: 0.9902 - val_loss: 0.0301 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0269 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0205 - acc: 0.9905
Epoch 3/3
 - 1s - loss: 0.0178 - acc: 0.9915
# Training time = 0:04:37.437318!
# F-Score(Ordinary) = 0.417, Recall: 0.767, Precision: 0.286
# F-Score(lvc) = 0.356, Recall: 0.865, Precision: 0.224
# F-Score(ireflv) = 0.786, Recall: 0.874, Precision: 0.714
# F-Score(id) = 0.021, Recall: 0.087, Precision: 0.012
********************
# Seed = 6
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 317158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_127 (Embedding)    (None, 12, 25)            314750    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 317,158
Trainable params: 317,158
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 375
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0764 - acc: 0.9831 - val_loss: 0.0324 - val_acc: 0.9877
Epoch 2/15
 - 6s - loss: 0.0252 - acc: 0.9893 - val_loss: 0.0286 - val_acc: 0.9890
Epoch 3/15
 - 6s - loss: 0.0219 - acc: 0.9902 - val_loss: 0.0298 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0265 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0201 - acc: 0.9910
Epoch 3/3
 - 1s - loss: 0.0178 - acc: 0.9914
# Training time = 0:04:17.129165!
# F-Score(Ordinary) = 0.352, Recall: 0.477, Precision: 0.279
# F-Score(lvc) = 0.394, Recall: 0.709, Precision: 0.273
# F-Score(ireflv) = 0.061, Recall: 0.8, Precision: 0.032
# F-Score(id) = 0.43, Recall: 0.398, Precision: 0.467
********************
# Seed = 7
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 317183
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_128 (Embedding)    (None, 12, 25)            314775    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 317,183
Trainable params: 317,183
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 390
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0780 - acc: 0.9788 - val_loss: 0.0304 - val_acc: 0.9884
Epoch 2/15
 - 6s - loss: 0.0249 - acc: 0.9894 - val_loss: 0.0293 - val_acc: 0.9888
Epoch 3/15
 - 6s - loss: 0.0217 - acc: 0.9904 - val_loss: 0.0299 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0264 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0204 - acc: 0.9905
Epoch 3/3
 - 1s - loss: 0.0178 - acc: 0.9917
# Training time = 0:05:31.877551!
# F-Score(Ordinary) = 0.321, Recall: 0.387, Precision: 0.275
# F-Score(lvc) = 0.331, Recall: 0.789, Precision: 0.21
# F-Score(ireflv) = 0.047, Recall: 1.0, Precision: 0.024
# F-Score(id) = 0.39, Recall: 0.316, Precision: 0.509
********************
# Seed = 8
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 316633
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_129 (Embedding)    (None, 12, 25)            314225    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 316,633
Trainable params: 316,633
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 424
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0786 - acc: 0.9808 - val_loss: 0.0326 - val_acc: 0.9878
Epoch 2/15
 - 6s - loss: 0.0252 - acc: 0.9891 - val_loss: 0.0296 - val_acc: 0.9887
Epoch 3/15
 - 6s - loss: 0.0219 - acc: 0.9901 - val_loss: 0.0294 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0263 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0201 - acc: 0.9909
Epoch 3/3
 - 1s - loss: 0.0178 - acc: 0.9915
# Training time = 0:04:19.986049!
# F-Score(Ordinary) = 0.282, Recall: 0.446, Precision: 0.206
# F-Score(lvc) = 0.161, Recall: 0.722, Precision: 0.091
# F-Score(ireflv) = 0.031, Recall: 1.0, Precision: 0.016
# F-Score(id) = 0.43, Recall: 0.412, Precision: 0.449
********************
# Seed = 9
********************
# XP = Tokens(25) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 317433
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_130 (Embedding)    (None, 12, 25)            315025    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 300)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 2408      
=================================================================
Total params: 317,433
Trainable params: 317,433
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0786 - acc: 0.9814 - val_loss: 0.0322 - val_acc: 0.9876
Epoch 2/15
 - 6s - loss: 0.0252 - acc: 0.9891 - val_loss: 0.0292 - val_acc: 0.9890
Epoch 3/15
 - 6s - loss: 0.0219 - acc: 0.9903 - val_loss: 0.0294 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0263 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0201 - acc: 0.9908
Epoch 3/3
 - 1s - loss: 0.0179 - acc: 0.9917
# Training time = 0:04:19.880023!
# F-Score(Ordinary) = 0.475, Recall: 0.682, Precision: 0.364
# F-Score(lvc) = 0.371, Recall: 0.706, Precision: 0.252
# F-Score(ireflv) = 0.772, Recall: 0.752, Precision: 0.794
# F-Score(id) = 0.204, Recall: 0.449, Precision: 0.132
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 633558
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_131 (Embedding)    (None, 12, 50)            628750    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 633,558
Trainable params: 633,558
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 107
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0642 - acc: 0.9839 - val_loss: 0.0302 - val_acc: 0.9884
Epoch 2/15
 - 6s - loss: 0.0241 - acc: 0.9896 - val_loss: 0.0302 - val_acc: 0.9887
Epoch 3/15
 - 6s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0302 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0261 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0193 - acc: 0.9911
Epoch 3/3
 - 1s - loss: 0.0170 - acc: 0.9921
# Training time = 0:05:00.916413!
# F-Score(Ordinary) = 0.251, Recall: 0.389, Precision: 0.185
# F-Score(id) = 0.433, Recall: 0.391, Precision: 0.485
********************
# Seed = 1
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 632558
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_132 (Embedding)    (None, 12, 50)            627750    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 632,558
Trainable params: 632,558
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 409
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0635 - acc: 0.9813 - val_loss: 0.0303 - val_acc: 0.9886
Epoch 2/15
 - 6s - loss: 0.0241 - acc: 0.9896 - val_loss: 0.0289 - val_acc: 0.9889
Epoch 3/15
 - 6s - loss: 0.0213 - acc: 0.9904 - val_loss: 0.0293 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0262 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0199 - acc: 0.9908
Epoch 3/3
 - 1s - loss: 0.0169 - acc: 0.9921
# Training time = 0:04:45.652512!
# F-Score(Ordinary) = 0.483, Recall: 0.576, Precision: 0.416
# F-Score(lvc) = 0.185, Recall: 0.789, Precision: 0.105
# F-Score(ireflv) = 0.795, Recall: 0.841, Precision: 0.754
# F-Score(id) = 0.41, Recall: 0.391, Precision: 0.431
********************
# Seed = 2
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 633108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_133 (Embedding)    (None, 12, 50)            628300    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 633,108
Trainable params: 633,108
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 110
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0652 - acc: 0.9828 - val_loss: 0.0306 - val_acc: 0.9886
Epoch 2/15
 - 6s - loss: 0.0241 - acc: 0.9896 - val_loss: 0.0296 - val_acc: 0.9889
Epoch 3/15
 - 6s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0298 - val_acc: 0.9887
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0263 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0192 - acc: 0.9910
Epoch 3/3
 - 1s - loss: 0.0167 - acc: 0.9920
# Training time = 0:04:20.363406!
# F-Score(Ordinary) = 0.452, Recall: 0.449, Precision: 0.455
# F-Score(lvc) = 0.335, Recall: 0.833, Precision: 0.21
# F-Score(ireflv) = 0.764, Recall: 0.723, Precision: 0.81
# F-Score(id) = 0.3, Recall: 0.244, Precision: 0.389
********************
# Seed = 3
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 633908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_134 (Embedding)    (None, 12, 50)            629100    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 633,908
Trainable params: 633,908
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 171
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0637 - acc: 0.9844 - val_loss: 0.0291 - val_acc: 0.9890
Epoch 2/15
 - 6s - loss: 0.0240 - acc: 0.9897 - val_loss: 0.0298 - val_acc: 0.9886
Epoch 3/15
 - 6s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0301 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0266 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0195 - acc: 0.9912
Epoch 3/3
 - 1s - loss: 0.0170 - acc: 0.9918
# Training time = 0:04:41.682229!
# F-Score(Ordinary) = 0.426, Recall: 0.464, Precision: 0.394
# F-Score(lvc) = 0.434, Recall: 0.487, Precision: 0.392
# F-Score(ireflv) = 0.385, Recall: 0.886, Precision: 0.246
# F-Score(id) = 0.433, Recall: 0.38, Precision: 0.503
********************
# Seed = 4
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 633758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_135 (Embedding)    (None, 12, 50)            628950    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 633,758
Trainable params: 633,758
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 152
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0641 - acc: 0.9826 - val_loss: 0.0308 - val_acc: 0.9884
Epoch 2/15
 - 6s - loss: 0.0242 - acc: 0.9895 - val_loss: 0.0311 - val_acc: 0.9885
Epoch 3/15
 - 6s - loss: 0.0215 - acc: 0.9903 - val_loss: 0.0321 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0263 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0193 - acc: 0.9912
Epoch 3/3
 - 1s - loss: 0.0170 - acc: 0.9921
# Training time = 0:04:16.950483!
# F-Score(Ordinary) = 0.059, Recall: 0.341, Precision: 0.032
# F-Score(lvc) = 0.027, Recall: 0.667, Precision: 0.014
# F-Score(id) = 0.117, Recall: 0.316, Precision: 0.072
********************
# Seed = 5
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 634408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_136 (Embedding)    (None, 12, 50)            629600    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 634,408
Trainable params: 634,408
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 266
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0639 - acc: 0.9817 - val_loss: 0.0307 - val_acc: 0.9878
Epoch 2/15
 - 6s - loss: 0.0242 - acc: 0.9896 - val_loss: 0.0294 - val_acc: 0.9891
Epoch 3/15
 - 6s - loss: 0.0216 - acc: 0.9903 - val_loss: 0.0308 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0267 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0196 - acc: 0.9908
Epoch 3/3
 - 1s - loss: 0.0169 - acc: 0.9919
# Training time = 0:04:23.692098!
# F-Score(Ordinary) = 0.419, Recall: 0.751, Precision: 0.291
# F-Score(lvc) = 0.372, Recall: 0.778, Precision: 0.245
# F-Score(ireflv) = 0.765, Recall: 0.846, Precision: 0.698
# F-Score(id) = 0.032, Recall: 0.15, Precision: 0.018
********************
# Seed = 6
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 634308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_137 (Embedding)    (None, 12, 50)            629500    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 634,308
Trainable params: 634,308
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 375
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0641 - acc: 0.9836 - val_loss: 0.0309 - val_acc: 0.9882
Epoch 2/15
 - 6s - loss: 0.0241 - acc: 0.9897 - val_loss: 0.0286 - val_acc: 0.9890
Epoch 3/15
 - 6s - loss: 0.0214 - acc: 0.9904 - val_loss: 0.0301 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0262 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0191 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0169 - acc: 0.9918
# Training time = 0:04:26.499326!
# F-Score(Ordinary) = 0.322, Recall: 0.4, Precision: 0.27
# F-Score(lvc) = 0.4, Recall: 0.702, Precision: 0.28
# F-Score(id) = 0.38, Recall: 0.324, Precision: 0.461
********************
# Seed = 7
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 634358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_138 (Embedding)    (None, 12, 50)            629550    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 634,358
Trainable params: 634,358
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 390
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0630 - acc: 0.9827 - val_loss: 0.0298 - val_acc: 0.9886
Epoch 2/15
 - 6s - loss: 0.0240 - acc: 0.9897 - val_loss: 0.0294 - val_acc: 0.9888
Epoch 3/15
 - 6s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0301 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0261 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0193 - acc: 0.9907
Epoch 3/3
 - 1s - loss: 0.0168 - acc: 0.9921
# Training time = 0:04:48.922051!
# F-Score(Ordinary) = 0.304, Recall: 0.344, Precision: 0.272
# F-Score(lvc) = 0.359, Recall: 0.805, Precision: 0.231
# F-Score(id) = 0.36, Recall: 0.279, Precision: 0.509
********************
# Seed = 8
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 633258
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_139 (Embedding)    (None, 12, 50)            628450    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 633,258
Trainable params: 633,258
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 424
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0639 - acc: 0.9828 - val_loss: 0.0333 - val_acc: 0.9874
Epoch 2/15
 - 6s - loss: 0.0241 - acc: 0.9895 - val_loss: 0.0303 - val_acc: 0.9887
Epoch 3/15
 - 6s - loss: 0.0214 - acc: 0.9903 - val_loss: 0.0301 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0262 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0192 - acc: 0.9911
Epoch 3/3
 - 1s - loss: 0.0170 - acc: 0.9918
# Training time = 0:04:18.416445!
# F-Score(Ordinary) = 0.251, Recall: 0.388, Precision: 0.185
# F-Score(lvc) = 0.116, Recall: 0.75, Precision: 0.063
# F-Score(id) = 0.396, Recall: 0.365, Precision: 0.431
********************
# Seed = 9
********************
# XP = Tokens(50) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 634858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_140 (Embedding)    (None, 12, 50)            630050    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 600)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 4808      
=================================================================
Total params: 634,858
Trainable params: 634,858
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0628 - acc: 0.9844 - val_loss: 0.0320 - val_acc: 0.9880
Epoch 2/15
 - 6s - loss: 0.0240 - acc: 0.9895 - val_loss: 0.0292 - val_acc: 0.9891
Epoch 3/15
 - 6s - loss: 0.0213 - acc: 0.9904 - val_loss: 0.0295 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9893
Epoch 2/3
 - 1s - loss: 0.0191 - acc: 0.9912
Epoch 3/3
 - 1s - loss: 0.0169 - acc: 0.9919
# Training time = 0:05:01.832361!
# F-Score(Ordinary) = 0.468, Recall: 0.549, Precision: 0.407
# F-Score(lvc) = 0.43, Recall: 0.648, Precision: 0.322
# F-Score(ireflv) = 0.756, Recall: 0.708, Precision: 0.81
# F-Score(id) = 0.21, Recall: 0.266, Precision: 0.174
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 950333
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_141 (Embedding)    (None, 12, 75)            943125    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 950,333
Trainable params: 950,333
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 107
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0569 - acc: 0.9839 - val_loss: 0.0300 - val_acc: 0.9884
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9897 - val_loss: 0.0305 - val_acc: 0.9886
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0301 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0260 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0189 - acc: 0.9912
Epoch 3/3
 - 1s - loss: 0.0165 - acc: 0.9922
# Training time = 0:04:19.962517!
# F-Score(Ordinary) = 0.243, Recall: 0.371, Precision: 0.181
# F-Score(id) = 0.417, Recall: 0.373, Precision: 0.473
********************
# Seed = 1
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 948833
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_142 (Embedding)    (None, 12, 75)            941625    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 948,833
Trainable params: 948,833
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 409
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0569 - acc: 0.9852 - val_loss: 0.0303 - val_acc: 0.9887
Epoch 2/15
 - 7s - loss: 0.0237 - acc: 0.9896 - val_loss: 0.0289 - val_acc: 0.9889
Epoch 3/15
 - 7s - loss: 0.0212 - acc: 0.9904 - val_loss: 0.0295 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0261 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0196 - acc: 0.9908
Epoch 3/3
 - 1s - loss: 0.0165 - acc: 0.9921
# Training time = 0:04:21.275412!
# F-Score(Ordinary) = 0.47, Recall: 0.572, Precision: 0.398
# F-Score(lvc) = 0.188, Recall: 0.882, Precision: 0.105
# F-Score(ireflv) = 0.777, Recall: 0.81, Precision: 0.746
# F-Score(id) = 0.385, Recall: 0.38, Precision: 0.389
********************
# Seed = 2
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 949658
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_143 (Embedding)    (None, 12, 75)            942450    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 949,658
Trainable params: 949,658
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 110
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0587 - acc: 0.9833 - val_loss: 0.0306 - val_acc: 0.9887
Epoch 2/15
 - 7s - loss: 0.0239 - acc: 0.9898 - val_loss: 0.0299 - val_acc: 0.9889
Epoch 3/15
 - 7s - loss: 0.0214 - acc: 0.9906 - val_loss: 0.0300 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0261 - acc: 0.9893
Epoch 2/3
 - 1s - loss: 0.0188 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0163 - acc: 0.9923
# Training time = 0:04:17.181574!
# F-Score(Ordinary) = 0.457, Recall: 0.497, Precision: 0.423
# F-Score(lvc) = 0.272, Recall: 0.885, Precision: 0.161
# F-Score(ireflv) = 0.74, Recall: 0.713, Precision: 0.77
# F-Score(id) = 0.34, Recall: 0.305, Precision: 0.383
********************
# Seed = 3
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 950858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_144 (Embedding)    (None, 12, 75)            943650    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 950,858
Trainable params: 950,858
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 171
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0568 - acc: 0.9836 - val_loss: 0.0293 - val_acc: 0.9889
Epoch 2/15
 - 6s - loss: 0.0239 - acc: 0.9898 - val_loss: 0.0306 - val_acc: 0.9885
Epoch 3/15
 - 6s - loss: 0.0214 - acc: 0.9906 - val_loss: 0.0307 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0268 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0191 - acc: 0.9914
Epoch 3/3
 - 1s - loss: 0.0167 - acc: 0.9920
# Training time = 0:05:18.904805!
# F-Score(Ordinary) = 0.392, Recall: 0.362, Precision: 0.428
# F-Score(lvc) = 0.438, Recall: 0.496, Precision: 0.392
# F-Score(ireflv) = 0.505, Recall: 0.783, Precision: 0.373
# F-Score(id) = 0.321, Recall: 0.238, Precision: 0.491
********************
# Seed = 4
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 950633
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_145 (Embedding)    (None, 12, 75)            943425    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 950,633
Trainable params: 950,633
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 152
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0582 - acc: 0.9834 - val_loss: 0.0301 - val_acc: 0.9885
Epoch 2/15
 - 7s - loss: 0.0240 - acc: 0.9896 - val_loss: 0.0319 - val_acc: 0.9884
Epoch 3/15
 - 7s - loss: 0.0215 - acc: 0.9904 - val_loss: 0.0326 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0261 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0187 - acc: 0.9914
Epoch 3/3
 - 1s - loss: 0.0165 - acc: 0.9923
# Training time = 0:04:20.784254!
# F-Score(Ordinary) = 0.039, Recall: 0.346, Precision: 0.021
# F-Score(lvc) = 0.014, Recall: 0.5, Precision: 0.007
# F-Score(id) = 0.084, Recall: 0.333, Precision: 0.048
********************
# Seed = 5
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 951608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_146 (Embedding)    (None, 12, 75)            944400    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 951,608
Trainable params: 951,608
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 266
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0575 - acc: 0.9850 - val_loss: 0.0303 - val_acc: 0.9881
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9898 - val_loss: 0.0299 - val_acc: 0.9891
Epoch 3/15
 - 7s - loss: 0.0214 - acc: 0.9903 - val_loss: 0.0312 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0265 - acc: 0.9889
Epoch 2/3
 - 1s - loss: 0.0190 - acc: 0.9911
Epoch 3/3
 - 1s - loss: 0.0165 - acc: 0.9920
# Training time = 0:04:19.180608!
# F-Score(Ordinary) = 0.431, Recall: 0.714, Precision: 0.309
# F-Score(lvc) = 0.4, Recall: 0.75, Precision: 0.273
# F-Score(ireflv) = 0.763, Recall: 0.818, Precision: 0.714
# F-Score(id) = 0.041, Recall: 0.148, Precision: 0.024
********************
# Seed = 6
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 951458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_147 (Embedding)    (None, 12, 75)            944250    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 951,458
Trainable params: 951,458
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 375
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0588 - acc: 0.9838 - val_loss: 0.0305 - val_acc: 0.9882
Epoch 2/15
 - 7s - loss: 0.0239 - acc: 0.9897 - val_loss: 0.0289 - val_acc: 0.9891
Epoch 3/15
 - 7s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0303 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0261 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0187 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0164 - acc: 0.9922
# Training time = 0:04:19.297990!
# F-Score(Ordinary) = 0.298, Recall: 0.32, Precision: 0.279
# F-Score(lvc) = 0.44, Recall: 0.772, Precision: 0.308
# F-Score(id) = 0.314, Recall: 0.238, Precision: 0.461
********************
# Seed = 7
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 951533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_148 (Embedding)    (None, 12, 75)            944325    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 951,533
Trainable params: 951,533
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 390
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0575 - acc: 0.9852 - val_loss: 0.0294 - val_acc: 0.9888
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9898 - val_loss: 0.0300 - val_acc: 0.9888
Epoch 3/15
 - 7s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0304 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0261 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0189 - acc: 0.9911
Epoch 3/3
 - 1s - loss: 0.0164 - acc: 0.9921
# Training time = 0:04:29.768089!
# F-Score(Ordinary) = 0.296, Recall: 0.328, Precision: 0.27
# F-Score(lvc) = 0.385, Recall: 0.818, Precision: 0.252
# F-Score(id) = 0.335, Recall: 0.256, Precision: 0.485
********************
# Seed = 8
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 949883
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_149 (Embedding)    (None, 12, 75)            942675    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 949,883
Trainable params: 949,883
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 424
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0580 - acc: 0.9845 - val_loss: 0.0336 - val_acc: 0.9873
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9897 - val_loss: 0.0306 - val_acc: 0.9887
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9904 - val_loss: 0.0305 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0262 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0187 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0166 - acc: 0.9919
# Training time = 0:04:22.480341!
# F-Score(Ordinary) = 0.252, Recall: 0.393, Precision: 0.185
# F-Score(lvc) = 0.105, Recall: 0.8, Precision: 0.056
# F-Score(id) = 0.402, Recall: 0.372, Precision: 0.437
********************
# Seed = 9
********************
# XP = Tokens(75) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 952283
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_150 (Embedding)    (None, 12, 75)            945075    
_________________________________________________________________
tokenFlatten (Flatten)       (None, 900)               0         
_________________________________________________________________
output (Dense)               (None, 8)                 7208      
=================================================================
Total params: 952,283
Trainable params: 952,283
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0572 - acc: 0.9832 - val_loss: 0.0326 - val_acc: 0.9880
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9897 - val_loss: 0.0297 - val_acc: 0.9891
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9904 - val_loss: 0.0299 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0258 - acc: 0.9893
Epoch 2/3
 - 1s - loss: 0.0187 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0165 - acc: 0.9920
# Training time = 0:04:18.679057!
# F-Score(Ordinary) = 0.493, Recall: 0.551, Precision: 0.446
# F-Score(lvc) = 0.45, Recall: 0.653, Precision: 0.343
# F-Score(ireflv) = 0.765, Recall: 0.712, Precision: 0.825
# F-Score(id) = 0.273, Recall: 0.308, Precision: 0.246
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1267108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_151 (Embedding)    (None, 12, 100)           1257500   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,267,108
Trainable params: 1,267,108
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 107
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0539 - acc: 0.9833 - val_loss: 0.0302 - val_acc: 0.9884
Epoch 2/15
 - 7s - loss: 0.0237 - acc: 0.9898 - val_loss: 0.0307 - val_acc: 0.9888
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9907 - val_loss: 0.0302 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0186 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0162 - acc: 0.9923
# Training time = 0:04:19.554632!
# F-Score(Ordinary) = 0.254, Recall: 0.443, Precision: 0.178
# F-Score(id) = 0.456, Recall: 0.446, Precision: 0.467
********************
# Seed = 1
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1265108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_152 (Embedding)    (None, 12, 100)           1255500   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,265,108
Trainable params: 1,265,108
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 409
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0532 - acc: 0.9849 - val_loss: 0.0307 - val_acc: 0.9887
Epoch 2/15
 - 7s - loss: 0.0237 - acc: 0.9897 - val_loss: 0.0293 - val_acc: 0.9890
Epoch 3/15
 - 7s - loss: 0.0212 - acc: 0.9904 - val_loss: 0.0297 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0260 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0194 - acc: 0.9908
Epoch 3/3
 - 1s - loss: 0.0162 - acc: 0.9921
# Training time = 0:04:20.686111!
# F-Score(Ordinary) = 0.458, Recall: 0.548, Precision: 0.394
# F-Score(lvc) = 0.154, Recall: 0.923, Precision: 0.084
# F-Score(ireflv) = 0.768, Recall: 0.82, Precision: 0.722
# F-Score(id) = 0.387, Recall: 0.363, Precision: 0.413
********************
# Seed = 2
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1266208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_153 (Embedding)    (None, 12, 100)           1256600   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,266,208
Trainable params: 1,266,208
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 110
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0540 - acc: 0.9853 - val_loss: 0.0307 - val_acc: 0.9887
Epoch 2/15
 - 7s - loss: 0.0237 - acc: 0.9899 - val_loss: 0.0301 - val_acc: 0.9888
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0301 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9893
Epoch 2/3
 - 1s - loss: 0.0184 - acc: 0.9914
Epoch 3/3
 - 1s - loss: 0.0160 - acc: 0.9923
# Training time = 0:04:24.875187!
# F-Score(Ordinary) = 0.437, Recall: 0.447, Precision: 0.428
# F-Score(lvc) = 0.242, Recall: 0.909, Precision: 0.14
# F-Score(ireflv) = 0.748, Recall: 0.721, Precision: 0.778
# F-Score(id) = 0.323, Recall: 0.265, Precision: 0.413
********************
# Seed = 3
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1267808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_154 (Embedding)    (None, 12, 100)           1258200   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,267,808
Trainable params: 1,267,808
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 171
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0537 - acc: 0.9832 - val_loss: 0.0294 - val_acc: 0.9888
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9898 - val_loss: 0.0309 - val_acc: 0.9885
Epoch 3/15
 - 7s - loss: 0.0214 - acc: 0.9906 - val_loss: 0.0309 - val_acc: 0.9882
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0268 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0188 - acc: 0.9914
Epoch 3/3
 - 1s - loss: 0.0164 - acc: 0.9922
# Training time = 0:04:58.973400!
# F-Score(Ordinary) = 0.382, Recall: 0.34, Precision: 0.437
# F-Score(lvc) = 0.419, Recall: 0.47, Precision: 0.378
# F-Score(ireflv) = 0.558, Recall: 0.828, Precision: 0.421
# F-Score(id) = 0.298, Recall: 0.214, Precision: 0.491
********************
# Seed = 4
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1267508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_155 (Embedding)    (None, 12, 100)           1257900   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,267,508
Trainable params: 1,267,508
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 152
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0536 - acc: 0.9840 - val_loss: 0.0298 - val_acc: 0.9885
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9897 - val_loss: 0.0327 - val_acc: 0.9881
Epoch 3/15
 - 7s - loss: 0.0214 - acc: 0.9904 - val_loss: 0.0327 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0261 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0184 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0162 - acc: 0.9924
# Training time = 0:04:20.133801!
# F-Score(Ordinary) = 0.047, Recall: 0.393, Precision: 0.025
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(id) = 0.083, Recall: 0.32, Precision: 0.048
********************
# Seed = 5
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1268808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_156 (Embedding)    (None, 12, 100)           1259200   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,268,808
Trainable params: 1,268,808
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 266
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0537 - acc: 0.9854 - val_loss: 0.0298 - val_acc: 0.9883
Epoch 2/15
 - 7s - loss: 0.0236 - acc: 0.9898 - val_loss: 0.0299 - val_acc: 0.9891
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9904 - val_loss: 0.0310 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0263 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0187 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0161 - acc: 0.9921
# Training time = 0:04:19.301705!
# F-Score(Ordinary) = 0.412, Recall: 0.692, Precision: 0.293
# F-Score(lvc) = 0.385, Recall: 0.755, Precision: 0.259
# F-Score(ireflv) = 0.759, Recall: 0.83, Precision: 0.698
# F-Score(id) = 0.02, Recall: 0.067, Precision: 0.012
********************
# Seed = 6
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1268608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_157 (Embedding)    (None, 12, 100)           1259000   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,268,608
Trainable params: 1,268,608
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 375
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0538 - acc: 0.9851 - val_loss: 0.0302 - val_acc: 0.9883
Epoch 2/15
 - 7s - loss: 0.0237 - acc: 0.9899 - val_loss: 0.0290 - val_acc: 0.9891
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0304 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0260 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0183 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0161 - acc: 0.9921
# Training time = 0:04:22.609748!
# F-Score(Ordinary) = 0.279, Recall: 0.273, Precision: 0.286
# F-Score(lvc) = 0.456, Recall: 0.746, Precision: 0.329
# F-Score(id) = 0.274, Recall: 0.195, Precision: 0.461
********************
# Seed = 7
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1268708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_158 (Embedding)    (None, 12, 100)           1259100   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,268,708
Trainable params: 1,268,708
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 390
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0544 - acc: 0.9853 - val_loss: 0.0295 - val_acc: 0.9888
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9899 - val_loss: 0.0303 - val_acc: 0.9888
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0307 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0260 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0186 - acc: 0.9911
Epoch 3/3
 - 1s - loss: 0.0161 - acc: 0.9921
# Training time = 0:04:48.499503!
# F-Score(Ordinary) = 0.312, Recall: 0.361, Precision: 0.275
# F-Score(lvc) = 0.381, Recall: 0.783, Precision: 0.252
# F-Score(id) = 0.366, Recall: 0.29, Precision: 0.497
********************
# Seed = 8
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1266508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_159 (Embedding)    (None, 12, 100)           1256900   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,266,508
Trainable params: 1,266,508
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 424
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0538 - acc: 0.9854 - val_loss: 0.0340 - val_acc: 0.9872
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9897 - val_loss: 0.0308 - val_acc: 0.9889
Epoch 3/15
 - 7s - loss: 0.0214 - acc: 0.9904 - val_loss: 0.0309 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0262 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0185 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0164 - acc: 0.9921
# Training time = 0:05:30.463311!
# F-Score(Ordinary) = 0.238, Recall: 0.398, Precision: 0.169
# F-Score(lvc) = 0.093, Recall: 0.875, Precision: 0.049
# F-Score(id) = 0.388, Recall: 0.376, Precision: 0.401
********************
# Seed = 9
********************
# XP = Tokens(100) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1269708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_160 (Embedding)    (None, 12, 100)           1260100   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1200)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 9608      
=================================================================
Total params: 1,269,708
Trainable params: 1,269,708
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0533 - acc: 0.9839 - val_loss: 0.0333 - val_acc: 0.9880
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9897 - val_loss: 0.0301 - val_acc: 0.9891
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0301 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0258 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0184 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0163 - acc: 0.9920
# Training time = 0:04:22.193252!
# F-Score(Ordinary) = 0.489, Recall: 0.507, Precision: 0.471
# F-Score(lvc) = 0.466, Recall: 0.671, Precision: 0.357
# F-Score(ireflv) = 0.757, Recall: 0.705, Precision: 0.817
# F-Score(id) = 0.285, Recall: 0.272, Precision: 0.299
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1583883
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_161 (Embedding)    (None, 12, 125)           1571875   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 1,583,883
Trainable params: 1,583,883
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 107
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0510 - acc: 0.9852 - val_loss: 0.0302 - val_acc: 0.9883
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9898 - val_loss: 0.0308 - val_acc: 0.9888
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9907 - val_loss: 0.0302 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0258 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0184 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0160 - acc: 0.9922
# Training time = 0:04:23.723325!
# F-Score(Ordinary) = 0.272, Recall: 0.4, Precision: 0.206
# F-Score(id) = 0.459, Recall: 0.4, Precision: 0.539
********************
# Seed = 1
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1581383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_162 (Embedding)    (None, 12, 125)           1569375   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 1,581,383
Trainable params: 1,581,383
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 409
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0516 - acc: 0.9840 - val_loss: 0.0312 - val_acc: 0.9886
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9897 - val_loss: 0.0296 - val_acc: 0.9890
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0299 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0260 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0193 - acc: 0.9908
Epoch 3/3
 - 1s - loss: 0.0160 - acc: 0.9922
# Training time = 0:04:30.335723!
# F-Score(Ordinary) = 0.464, Recall: 0.548, Precision: 0.403
# F-Score(lvc) = 0.154, Recall: 0.923, Precision: 0.084
# F-Score(ireflv) = 0.773, Recall: 0.821, Precision: 0.73
# F-Score(id) = 0.397, Recall: 0.367, Precision: 0.431
********************
# Seed = 2
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1582758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_163 (Embedding)    (None, 12, 125)           1570750   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 1,582,758
Trainable params: 1,582,758
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 110
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0521 - acc: 0.9850 - val_loss: 0.0308 - val_acc: 0.9886
Epoch 2/15
 - 7s - loss: 0.0237 - acc: 0.9899 - val_loss: 0.0303 - val_acc: 0.9887
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0303 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9893
Epoch 2/3
 - 1s - loss: 0.0182 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0158 - acc: 0.9924
# Training time = 0:05:00.302361!
# F-Score(Ordinary) = 0.443, Recall: 0.459, Precision: 0.428
# F-Score(lvc) = 0.272, Recall: 0.885, Precision: 0.161
# F-Score(ireflv) = 0.728, Recall: 0.704, Precision: 0.754
# F-Score(id) = 0.329, Recall: 0.276, Precision: 0.407
********************
# Seed = 3
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1584758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_164 (Embedding)    (None, 12, 125)           1572750   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 1,584,758
Trainable params: 1,584,758
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 171
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0519 - acc: 0.9847 - val_loss: 0.0297 - val_acc: 0.9887
Epoch 2/15
 - 7s - loss: 0.0239 - acc: 0.9898 - val_loss: 0.0312 - val_acc: 0.9885
Epoch 3/15
 - 7s - loss: 0.0214 - acc: 0.9906 - val_loss: 0.0311 - val_acc: 0.9880
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0268 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0186 - acc: 0.9914
Epoch 3/3
 - 1s - loss: 0.0162 - acc: 0.9922
# Training time = 0:04:17.672574!
# F-Score(Ordinary) = 0.39, Recall: 0.338, Precision: 0.46
# F-Score(lvc) = 0.406, Recall: 0.449, Precision: 0.371
# F-Score(ireflv) = 0.631, Recall: 0.831, Precision: 0.508
# F-Score(id) = 0.293, Recall: 0.208, Precision: 0.497
********************
# Seed = 4
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1584383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_165 (Embedding)    (None, 12, 125)           1572375   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 1,584,383
Trainable params: 1,584,383
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 152
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0509 - acc: 0.9850 - val_loss: 0.0296 - val_acc: 0.9887
Epoch 2/15
 - 7s - loss: 0.0239 - acc: 0.9897 - val_loss: 0.0332 - val_acc: 0.9880
Epoch 3/15
 - 7s - loss: 0.0215 - acc: 0.9905 - val_loss: 0.0329 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0261 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0182 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0161 - acc: 0.9924
# Training time = 0:04:20.453037!
# F-Score(Ordinary) = 0.039, Recall: 0.429, Precision: 0.021
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(id) = 0.086, Recall: 0.4, Precision: 0.048
********************
# Seed = 5
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1586008
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_166 (Embedding)    (None, 12, 125)           1574000   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 1,586,008
Trainable params: 1,586,008
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 266
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0519 - acc: 0.9839 - val_loss: 0.0297 - val_acc: 0.9884
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9898 - val_loss: 0.0305 - val_acc: 0.9889
Epoch 3/15
 - 7s - loss: 0.0215 - acc: 0.9904 - val_loss: 0.0314 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0263 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0185 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0160 - acc: 0.9921
# Training time = 0:04:20.870753!
# F-Score(Ordinary) = 0.416, Recall: 0.67, Precision: 0.302
# F-Score(lvc) = 0.392, Recall: 0.696, Precision: 0.273
# F-Score(ireflv) = 0.766, Recall: 0.826, Precision: 0.714
# F-Score(id) = 0.02, Recall: 0.063, Precision: 0.012
********************
# Seed = 6
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1585758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_167 (Embedding)    (None, 12, 125)           1573750   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 1,585,758
Trainable params: 1,585,758
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 375
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0514 - acc: 0.9847 - val_loss: 0.0301 - val_acc: 0.9883
Epoch 2/15
 - 7s - loss: 0.0237 - acc: 0.9899 - val_loss: 0.0292 - val_acc: 0.9892
Epoch 3/15
 - 7s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0304 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0181 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0159 - acc: 0.9922
# Training time = 0:04:21.114046!
# F-Score(Ordinary) = 0.301, Recall: 0.312, Precision: 0.291
# F-Score(lvc) = 0.438, Recall: 0.759, Precision: 0.308
# F-Score(ireflv) = 0.016, Recall: 1.0, Precision: 0.008
# F-Score(id) = 0.315, Recall: 0.233, Precision: 0.485
********************
# Seed = 7
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1585883
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_168 (Embedding)    (None, 12, 125)           1573875   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 1,585,883
Trainable params: 1,585,883
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 390
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0512 - acc: 0.9856 - val_loss: 0.0295 - val_acc: 0.9887
Epoch 2/15
 - 7s - loss: 0.0237 - acc: 0.9899 - val_loss: 0.0307 - val_acc: 0.9886
Epoch 3/15
 - 7s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0309 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0260 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0184 - acc: 0.9912
Epoch 3/3
 - 1s - loss: 0.0159 - acc: 0.9921
# Training time = 0:05:21.744265!
# F-Score(Ordinary) = 0.294, Recall: 0.323, Precision: 0.27
# F-Score(lvc) = 0.366, Recall: 0.791, Precision: 0.238
# F-Score(id) = 0.339, Recall: 0.258, Precision: 0.497
********************
# Seed = 8
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1583133
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_169 (Embedding)    (None, 12, 125)           1571125   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 1,583,133
Trainable params: 1,583,133
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 424
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0511 - acc: 0.9856 - val_loss: 0.0344 - val_acc: 0.9872
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9897 - val_loss: 0.0310 - val_acc: 0.9889
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0309 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0260 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0182 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0161 - acc: 0.9922
# Training time = 0:04:16.869378!
# F-Score(Ordinary) = 0.238, Recall: 0.387, Precision: 0.172
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(id) = 0.393, Recall: 0.37, Precision: 0.419
********************
# Seed = 9
********************
# XP = Tokens(125) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1587133
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_170 (Embedding)    (None, 12, 125)           1575125   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1500)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 12008     
=================================================================
Total params: 1,587,133
Trainable params: 1,587,133
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0513 - acc: 0.9858 - val_loss: 0.0341 - val_acc: 0.9880
Epoch 2/15
 - 7s - loss: 0.0239 - acc: 0.9897 - val_loss: 0.0306 - val_acc: 0.9891
Epoch 3/15
 - 7s - loss: 0.0214 - acc: 0.9906 - val_loss: 0.0304 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0258 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0183 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0162 - acc: 0.9920
# Training time = 0:04:22.334470!
# F-Score(Ordinary) = 0.486, Recall: 0.494, Precision: 0.478
# F-Score(lvc) = 0.471, Recall: 0.667, Precision: 0.364
# F-Score(ireflv) = 0.769, Recall: 0.714, Precision: 0.833
# F-Score(id) = 0.285, Recall: 0.263, Precision: 0.311
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1900658
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_171 (Embedding)    (None, 12, 150)           1886250   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 1,900,658
Trainable params: 1,900,658
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 107
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0496 - acc: 0.9843 - val_loss: 0.0305 - val_acc: 0.9882
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9898 - val_loss: 0.0312 - val_acc: 0.9888
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9907 - val_loss: 0.0304 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0257 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0182 - acc: 0.9914
Epoch 3/3
 - 1s - loss: 0.0159 - acc: 0.9922
# Training time = 0:04:56.950050!
# F-Score(Ordinary) = 0.276, Recall: 0.44, Precision: 0.201
# F-Score(id) = 0.48, Recall: 0.44, Precision: 0.527
********************
# Seed = 1
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1897658
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_172 (Embedding)    (None, 12, 150)           1883250   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 1,897,658
Trainable params: 1,897,658
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 409
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0496 - acc: 0.9855 - val_loss: 0.0317 - val_acc: 0.9885
Epoch 2/15
 - 7s - loss: 0.0239 - acc: 0.9897 - val_loss: 0.0299 - val_acc: 0.9890
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0302 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0261 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0192 - acc: 0.9908
Epoch 3/3
 - 1s - loss: 0.0160 - acc: 0.9922
# Training time = 0:04:19.659982!
# F-Score(Ordinary) = 0.476, Recall: 0.559, Precision: 0.414
# F-Score(lvc) = 0.118, Recall: 0.9, Precision: 0.063
# F-Score(ireflv) = 0.768, Recall: 0.82, Precision: 0.722
# F-Score(id) = 0.438, Recall: 0.399, Precision: 0.485
********************
# Seed = 2
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1899308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_173 (Embedding)    (None, 12, 150)           1884900   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 1,899,308
Trainable params: 1,899,308
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 110
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0494 - acc: 0.9860 - val_loss: 0.0311 - val_acc: 0.9886
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9899 - val_loss: 0.0309 - val_acc: 0.9887
Epoch 3/15
 - 7s - loss: 0.0215 - acc: 0.9906 - val_loss: 0.0305 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0181 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9924
# Training time = 0:04:30.118831!
# F-Score(Ordinary) = 0.456, Recall: 0.514, Precision: 0.41
# F-Score(lvc) = 0.2, Recall: 0.941, Precision: 0.112
# F-Score(ireflv) = 0.749, Recall: 0.729, Precision: 0.77
# F-Score(id) = 0.362, Recall: 0.333, Precision: 0.395
********************
# Seed = 3
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1901708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_174 (Embedding)    (None, 12, 150)           1887300   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 1,901,708
Trainable params: 1,901,708
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 171
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0499 - acc: 0.9839 - val_loss: 0.0297 - val_acc: 0.9886
Epoch 2/15
 - 7s - loss: 0.0239 - acc: 0.9899 - val_loss: 0.0313 - val_acc: 0.9884
Epoch 3/15
 - 7s - loss: 0.0214 - acc: 0.9906 - val_loss: 0.0312 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0268 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0185 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0162 - acc: 0.9923
# Training time = 0:04:53.381283!
# F-Score(Ordinary) = 0.387, Recall: 0.325, Precision: 0.478
# F-Score(lvc) = 0.431, Recall: 0.515, Precision: 0.371
# F-Score(ireflv) = 0.685, Recall: 0.839, Precision: 0.579
# F-Score(id) = 0.264, Recall: 0.181, Precision: 0.491
********************
# Seed = 4
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1901258
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_175 (Embedding)    (None, 12, 150)           1886850   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 1,901,258
Trainable params: 1,901,258
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 152
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0496 - acc: 0.9855 - val_loss: 0.0297 - val_acc: 0.9887
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9897 - val_loss: 0.0334 - val_acc: 0.9881
Epoch 3/15
 - 7s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0330 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0261 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0181 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0160 - acc: 0.9924
# Training time = 0:05:02.741395!
# F-Score(Ordinary) = 0.027, Recall: 0.4, Precision: 0.014
# F-Score(id) = 0.066, Recall: 0.4, Precision: 0.036
********************
# Seed = 5
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1903208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_176 (Embedding)    (None, 12, 150)           1888800   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 1,903,208
Trainable params: 1,903,208
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 266
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0493 - acc: 0.9851 - val_loss: 0.0298 - val_acc: 0.9884
Epoch 2/15
 - 7s - loss: 0.0236 - acc: 0.9899 - val_loss: 0.0304 - val_acc: 0.9890
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9904 - val_loss: 0.0309 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0261 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0183 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0159 - acc: 0.9921
# Training time = 0:04:27.065274!
# F-Score(Ordinary) = 0.404, Recall: 0.701, Precision: 0.284
# F-Score(lvc) = 0.37, Recall: 0.761, Precision: 0.245
# F-Score(ireflv) = 0.754, Recall: 0.843, Precision: 0.683
# F-Score(id) = 0.02, Recall: 0.069, Precision: 0.012
********************
# Seed = 6
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1902908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_177 (Embedding)    (None, 12, 150)           1888500   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 1,902,908
Trainable params: 1,902,908
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 375
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0492 - acc: 0.9840 - val_loss: 0.0301 - val_acc: 0.9883
Epoch 2/15
 - 7s - loss: 0.0237 - acc: 0.9899 - val_loss: 0.0293 - val_acc: 0.9892
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0303 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0180 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0158 - acc: 0.9921
# Training time = 0:04:31.553174!
# F-Score(Ordinary) = 0.266, Recall: 0.25, Precision: 0.284
# F-Score(lvc) = 0.427, Recall: 0.698, Precision: 0.308
# F-Score(ireflv) = 0.016, Recall: 1.0, Precision: 0.008
# F-Score(id) = 0.26, Recall: 0.181, Precision: 0.467
********************
# Seed = 7
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1903058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_178 (Embedding)    (None, 12, 150)           1888650   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 1,903,058
Trainable params: 1,903,058
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 390
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0499 - acc: 0.9844 - val_loss: 0.0296 - val_acc: 0.9888
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9899 - val_loss: 0.0309 - val_acc: 0.9887
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9907 - val_loss: 0.0309 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0258 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0182 - acc: 0.9912
Epoch 3/3
 - 1s - loss: 0.0158 - acc: 0.9922
# Training time = 0:05:10.032453!
# F-Score(Ordinary) = 0.278, Recall: 0.29, Precision: 0.268
# F-Score(lvc) = 0.37, Recall: 0.761, Precision: 0.245
# F-Score(id) = 0.309, Recall: 0.226, Precision: 0.485
********************
# Seed = 8
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1899758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_179 (Embedding)    (None, 12, 150)           1885350   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 1,899,758
Trainable params: 1,899,758
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 424
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0495 - acc: 0.9848 - val_loss: 0.0345 - val_acc: 0.9872
Epoch 2/15
 - 7s - loss: 0.0238 - acc: 0.9898 - val_loss: 0.0310 - val_acc: 0.9891
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0309 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0180 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0160 - acc: 0.9921
# Training time = 0:04:29.414375!
# F-Score(Ordinary) = 0.229, Recall: 0.386, Precision: 0.162
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(id) = 0.391, Recall: 0.376, Precision: 0.407
********************
# Seed = 9
********************
# XP = Tokens(150) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 1904558
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_180 (Embedding)    (None, 12, 150)           1890150   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 1800)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 14408     
=================================================================
Total params: 1,904,558
Trainable params: 1,904,558
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0496 - acc: 0.9848 - val_loss: 0.0342 - val_acc: 0.9880
Epoch 2/15
 - 7s - loss: 0.0239 - acc: 0.9897 - val_loss: 0.0308 - val_acc: 0.9889
Epoch 3/15
 - 7s - loss: 0.0214 - acc: 0.9906 - val_loss: 0.0302 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0256 - acc: 0.9894
Epoch 2/3
 - 1s - loss: 0.0181 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0160 - acc: 0.9921
# Training time = 0:04:57.305575!
# F-Score(Ordinary) = 0.479, Recall: 0.487, Precision: 0.471
# F-Score(lvc) = 0.442, Recall: 0.649, Precision: 0.336
# F-Score(ireflv) = 0.755, Recall: 0.701, Precision: 0.817
# F-Score(id) = 0.298, Recall: 0.272, Precision: 0.329
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2217433
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_181 (Embedding)    (None, 12, 175)           2200625   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 2,217,433
Trainable params: 2,217,433
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 107
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0478 - acc: 0.9851 - val_loss: 0.0307 - val_acc: 0.9883
Epoch 2/15
 - 8s - loss: 0.0239 - acc: 0.9899 - val_loss: 0.0310 - val_acc: 0.9887
Epoch 3/15
 - 8s - loss: 0.0213 - acc: 0.9907 - val_loss: 0.0303 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0256 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0181 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0158 - acc: 0.9923
# Training time = 0:04:28.130440!
# F-Score(Ordinary) = 0.267, Recall: 0.407, Precision: 0.199
# F-Score(id) = 0.457, Recall: 0.407, Precision: 0.521
********************
# Seed = 1
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2213933
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_182 (Embedding)    (None, 12, 175)           2197125   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 2,213,933
Trainable params: 2,213,933
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 409
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0477 - acc: 0.9857 - val_loss: 0.0316 - val_acc: 0.9884
Epoch 2/15
 - 8s - loss: 0.0239 - acc: 0.9898 - val_loss: 0.0297 - val_acc: 0.9889
Epoch 3/15
 - 8s - loss: 0.0212 - acc: 0.9905 - val_loss: 0.0298 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0190 - acc: 0.9909
Epoch 3/3
 - 1s - loss: 0.0158 - acc: 0.9922
# Training time = 0:04:30.818913!
# F-Score(Ordinary) = 0.491, Recall: 0.597, Precision: 0.416
# F-Score(lvc) = 0.166, Recall: 0.929, Precision: 0.091
# F-Score(ireflv) = 0.768, Recall: 0.82, Precision: 0.722
# F-Score(id) = 0.45, Recall: 0.433, Precision: 0.467
********************
# Seed = 2
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2215858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_183 (Embedding)    (None, 12, 175)           2199050   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 2,215,858
Trainable params: 2,215,858
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 110
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0482 - acc: 0.9856 - val_loss: 0.0312 - val_acc: 0.9887
Epoch 2/15
 - 8s - loss: 0.0238 - acc: 0.9899 - val_loss: 0.0306 - val_acc: 0.9887
Epoch 3/15
 - 8s - loss: 0.0213 - acc: 0.9907 - val_loss: 0.0302 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0257 - acc: 0.9893
Epoch 2/3
 - 1s - loss: 0.0179 - acc: 0.9914
Epoch 3/3
 - 1s - loss: 0.0156 - acc: 0.9923
# Training time = 0:04:25.147695!
# F-Score(Ordinary) = 0.447, Recall: 0.48, Precision: 0.419
# F-Score(lvc) = 0.22, Recall: 0.857, Precision: 0.126
# F-Score(ireflv) = 0.738, Recall: 0.708, Precision: 0.77
# F-Score(id) = 0.349, Recall: 0.305, Precision: 0.407
********************
# Seed = 3
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2218658
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_184 (Embedding)    (None, 12, 175)           2201850   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 2,218,658
Trainable params: 2,218,658
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 171
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0482 - acc: 0.9856 - val_loss: 0.0301 - val_acc: 0.9885
Epoch 2/15
 - 8s - loss: 0.0239 - acc: 0.9899 - val_loss: 0.0311 - val_acc: 0.9886
Epoch 3/15
 - 8s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0308 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0265 - acc: 0.9889
Epoch 2/3
 - 1s - loss: 0.0184 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0160 - acc: 0.9922
# Training time = 0:06:23.586398!
# F-Score(Ordinary) = 0.374, Recall: 0.322, Precision: 0.446
# F-Score(lvc) = 0.393, Recall: 0.417, Precision: 0.371
# F-Score(ireflv) = 0.592, Recall: 0.829, Precision: 0.46
# F-Score(id) = 0.285, Recall: 0.201, Precision: 0.491
********************
# Seed = 4
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2218133
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_185 (Embedding)    (None, 12, 175)           2201325   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 2,218,133
Trainable params: 2,218,133
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 152
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0480 - acc: 0.9851 - val_loss: 0.0298 - val_acc: 0.9886
Epoch 2/15
 - 8s - loss: 0.0239 - acc: 0.9897 - val_loss: 0.0338 - val_acc: 0.9880
Epoch 3/15
 - 8s - loss: 0.0215 - acc: 0.9906 - val_loss: 0.0333 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0262 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0180 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0159 - acc: 0.9924
# Training time = 0:04:20.932557!
# F-Score(Ordinary) = 0.031, Recall: 0.412, Precision: 0.016
# F-Score(id) = 0.076, Recall: 0.412, Precision: 0.042
********************
# Seed = 5
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2220408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_186 (Embedding)    (None, 12, 175)           2203600   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 2,220,408
Trainable params: 2,220,408
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 266
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0482 - acc: 0.9850 - val_loss: 0.0300 - val_acc: 0.9883
Epoch 2/15
 - 8s - loss: 0.0238 - acc: 0.9899 - val_loss: 0.0309 - val_acc: 0.9889
Epoch 3/15
 - 8s - loss: 0.0215 - acc: 0.9905 - val_loss: 0.0314 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0263 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0183 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0158 - acc: 0.9922
# Training time = 0:04:25.560117!
# F-Score(Ordinary) = 0.413, Recall: 0.632, Precision: 0.307
# F-Score(lvc) = 0.402, Recall: 0.765, Precision: 0.273
# F-Score(ireflv) = 0.763, Recall: 0.818, Precision: 0.714
# F-Score(id) = 0.046, Recall: 0.098, Precision: 0.03
********************
# Seed = 6
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2220058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_187 (Embedding)    (None, 12, 175)           2203250   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 2,220,058
Trainable params: 2,220,058
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 375
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0483 - acc: 0.9845 - val_loss: 0.0301 - val_acc: 0.9884
Epoch 2/15
 - 8s - loss: 0.0238 - acc: 0.9899 - val_loss: 0.0293 - val_acc: 0.9890
Epoch 3/15
 - 8s - loss: 0.0214 - acc: 0.9906 - val_loss: 0.0302 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0258 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0156 - acc: 0.9922
# Training time = 0:04:27.822792!
# F-Score(Ordinary) = 0.235, Recall: 0.2, Precision: 0.286
# F-Score(lvc) = 0.453, Recall: 0.696, Precision: 0.336
# F-Score(ireflv) = 0.016, Recall: 1.0, Precision: 0.008
# F-Score(id) = 0.208, Recall: 0.135, Precision: 0.449
********************
# Seed = 7
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2220233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_188 (Embedding)    (None, 12, 175)           2203425   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 2,220,233
Trainable params: 2,220,233
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 390
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0477 - acc: 0.9862 - val_loss: 0.0297 - val_acc: 0.9887
Epoch 2/15
 - 8s - loss: 0.0238 - acc: 0.9899 - val_loss: 0.0312 - val_acc: 0.9887
Epoch 3/15
 - 8s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0310 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0258 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0181 - acc: 0.9911
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9921
# Training time = 0:04:22.386998!
# F-Score(Ordinary) = 0.292, Recall: 0.321, Precision: 0.268
# F-Score(lvc) = 0.357, Recall: 0.786, Precision: 0.231
# F-Score(id) = 0.339, Recall: 0.258, Precision: 0.497
********************
# Seed = 8
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2216383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_189 (Embedding)    (None, 12, 175)           2199575   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 2,216,383
Trainable params: 2,216,383
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 424
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0480 - acc: 0.9861 - val_loss: 0.0346 - val_acc: 0.9871
Epoch 2/15
 - 8s - loss: 0.0239 - acc: 0.9898 - val_loss: 0.0310 - val_acc: 0.9891
Epoch 3/15
 - 8s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0309 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0180 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0159 - acc: 0.9922
# Training time = 0:04:56.603456!
# F-Score(Ordinary) = 0.225, Recall: 0.366, Precision: 0.162
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(id) = 0.38, Recall: 0.356, Precision: 0.407
********************
# Seed = 9
********************
# XP = Tokens(175) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2221983
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_190 (Embedding)    (None, 12, 175)           2205175   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2100)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 16808     
=================================================================
Total params: 2,221,983
Trainable params: 2,221,983
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0479 - acc: 0.9857 - val_loss: 0.0346 - val_acc: 0.9881
Epoch 2/15
 - 8s - loss: 0.0238 - acc: 0.9898 - val_loss: 0.0308 - val_acc: 0.9889
Epoch 3/15
 - 8s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0303 - val_acc: 0.9893
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0257 - acc: 0.9893
Epoch 2/3
 - 1s - loss: 0.0179 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0158 - acc: 0.9921
# Training time = 0:04:19.753714!
# F-Score(Ordinary) = 0.483, Recall: 0.512, Precision: 0.458
# F-Score(lvc) = 0.433, Recall: 0.692, Precision: 0.315
# F-Score(ireflv) = 0.757, Recall: 0.705, Precision: 0.817
# F-Score(id) = 0.3, Recall: 0.289, Precision: 0.311
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2534208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_191 (Embedding)    (None, 12, 200)           2515000   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 2,534,208
Trainable params: 2,534,208
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 107
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0471 - acc: 0.9852 - val_loss: 0.0310 - val_acc: 0.9883
Epoch 2/15
 - 8s - loss: 0.0239 - acc: 0.9899 - val_loss: 0.0314 - val_acc: 0.9886
Epoch 3/15
 - 8s - loss: 0.0213 - acc: 0.9907 - val_loss: 0.0306 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0258 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0180 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9924
# Training time = 0:04:28.758256!
# F-Score(Ordinary) = 0.268, Recall: 0.39, Precision: 0.204
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(id) = 0.447, Recall: 0.388, Precision: 0.527
********************
# Seed = 1
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2530208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_192 (Embedding)    (None, 12, 200)           2511000   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 2,530,208
Trainable params: 2,530,208
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 409
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0474 - acc: 0.9856 - val_loss: 0.0321 - val_acc: 0.9886
Epoch 2/15
 - 8s - loss: 0.0240 - acc: 0.9898 - val_loss: 0.0302 - val_acc: 0.9890
Epoch 3/15
 - 8s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0301 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0261 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0191 - acc: 0.9908
Epoch 3/3
 - 1s - loss: 0.0158 - acc: 0.9921
# Training time = 0:04:50.621828!
# F-Score(Ordinary) = 0.489, Recall: 0.602, Precision: 0.412
# F-Score(lvc) = 0.129, Recall: 0.833, Precision: 0.07
# F-Score(ireflv) = 0.776, Recall: 0.849, Precision: 0.714
# F-Score(id) = 0.46, Recall: 0.442, Precision: 0.479
********************
# Seed = 2
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2532408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_193 (Embedding)    (None, 12, 200)           2513200   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 2,532,408
Trainable params: 2,532,408
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 110
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0470 - acc: 0.9860 - val_loss: 0.0314 - val_acc: 0.9887
Epoch 2/15
 - 8s - loss: 0.0238 - acc: 0.9900 - val_loss: 0.0308 - val_acc: 0.9887
Epoch 3/15
 - 8s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0304 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0257 - acc: 0.9894
Epoch 2/3
 - 1s - loss: 0.0179 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0155 - acc: 0.9923
# Training time = 0:04:22.425084!
# F-Score(Ordinary) = 0.444, Recall: 0.488, Precision: 0.407
# F-Score(lvc) = 0.211, Recall: 0.944, Precision: 0.119
# F-Score(ireflv) = 0.749, Recall: 0.729, Precision: 0.77
# F-Score(id) = 0.336, Recall: 0.299, Precision: 0.383
********************
# Seed = 3
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2535608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_194 (Embedding)    (None, 12, 200)           2516400   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 2,535,608
Trainable params: 2,535,608
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 171
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0469 - acc: 0.9860 - val_loss: 0.0304 - val_acc: 0.9885
Epoch 2/15
 - 8s - loss: 0.0240 - acc: 0.9898 - val_loss: 0.0316 - val_acc: 0.9885
Epoch 3/15
 - 8s - loss: 0.0214 - acc: 0.9906 - val_loss: 0.0314 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0267 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0183 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0159 - acc: 0.9923
# Training time = 0:04:25.765653!
# F-Score(Ordinary) = 0.361, Recall: 0.301, Precision: 0.451
# F-Score(lvc) = 0.384, Recall: 0.398, Precision: 0.371
# F-Score(ireflv) = 0.629, Recall: 0.873, Precision: 0.492
# F-Score(id) = 0.256, Recall: 0.175, Precision: 0.473
********************
# Seed = 4
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2535008
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_195 (Embedding)    (None, 12, 200)           2515800   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 2,535,008
Trainable params: 2,535,008
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 152
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0469 - acc: 0.9861 - val_loss: 0.0301 - val_acc: 0.9887
Epoch 2/15
 - 8s - loss: 0.0240 - acc: 0.9898 - val_loss: 0.0339 - val_acc: 0.9880
Epoch 3/15
 - 8s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0330 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0261 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0179 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0158 - acc: 0.9924
# Training time = 0:04:42.126038!
# F-Score(Ordinary) = 0.043, Recall: 0.345, Precision: 0.023
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(id) = 0.082, Recall: 0.296, Precision: 0.048
********************
# Seed = 5
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2537608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_196 (Embedding)    (None, 12, 200)           2518400   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 2,537,608
Trainable params: 2,537,608
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 266
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0469 - acc: 0.9858 - val_loss: 0.0299 - val_acc: 0.9884
Epoch 2/15
 - 8s - loss: 0.0238 - acc: 0.9899 - val_loss: 0.0308 - val_acc: 0.9890
Epoch 3/15
 - 8s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0312 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0261 - acc: 0.9889
Epoch 2/3
 - 1s - loss: 0.0182 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9922
# Training time = 0:04:24.628454!
# F-Score(Ordinary) = 0.409, Recall: 0.657, Precision: 0.297
# F-Score(lvc) = 0.387, Recall: 0.771, Precision: 0.259
# F-Score(ireflv) = 0.755, Recall: 0.822, Precision: 0.698
# F-Score(id) = 0.048, Recall: 0.116, Precision: 0.03
********************
# Seed = 6
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2537208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_197 (Embedding)    (None, 12, 200)           2518000   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 2,537,208
Trainable params: 2,537,208
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 375
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0470 - acc: 0.9860 - val_loss: 0.0304 - val_acc: 0.9883
Epoch 2/15
 - 8s - loss: 0.0238 - acc: 0.9899 - val_loss: 0.0293 - val_acc: 0.9891
Epoch 3/15
 - 8s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0303 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0258 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0156 - acc: 0.9922
# Training time = 0:04:32.875769!
# F-Score(Ordinary) = 0.226, Recall: 0.193, Precision: 0.272
# F-Score(lvc) = 0.425, Recall: 0.688, Precision: 0.308
# F-Score(ireflv) = 0.016, Recall: 0.5, Precision: 0.008
# F-Score(id) = 0.204, Recall: 0.133, Precision: 0.437
********************
# Seed = 7
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2537408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_198 (Embedding)    (None, 12, 200)           2518200   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 2,537,408
Trainable params: 2,537,408
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 390
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0474 - acc: 0.9853 - val_loss: 0.0297 - val_acc: 0.9888
Epoch 2/15
 - 8s - loss: 0.0240 - acc: 0.9900 - val_loss: 0.0315 - val_acc: 0.9886
Epoch 3/15
 - 8s - loss: 0.0213 - acc: 0.9907 - val_loss: 0.0312 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0181 - acc: 0.9911
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9922
# Training time = 0:04:57.262058!
# F-Score(Ordinary) = 0.27, Recall: 0.277, Precision: 0.263
# F-Score(lvc) = 0.363, Recall: 0.846, Precision: 0.231
# F-Score(id) = 0.302, Recall: 0.218, Precision: 0.491
********************
# Seed = 8
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2533008
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_199 (Embedding)    (None, 12, 200)           2513800   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 2,533,008
Trainable params: 2,533,008
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 424
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0467 - acc: 0.9853 - val_loss: 0.0347 - val_acc: 0.9871
Epoch 2/15
 - 8s - loss: 0.0239 - acc: 0.9898 - val_loss: 0.0312 - val_acc: 0.9889
Epoch 3/15
 - 8s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0309 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0260 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0179 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0159 - acc: 0.9922
# Training time = 0:04:24.596407!
# F-Score(Ordinary) = 0.228, Recall: 0.413, Precision: 0.158
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(id) = 0.399, Recall: 0.402, Precision: 0.395
********************
# Seed = 9
********************
# XP = Tokens(200) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2539408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_200 (Embedding)    (None, 12, 200)           2520200   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2400)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 19208     
=================================================================
Total params: 2,539,408
Trainable params: 2,539,408
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0467 - acc: 0.9864 - val_loss: 0.0345 - val_acc: 0.9881
Epoch 2/15
 - 8s - loss: 0.0239 - acc: 0.9898 - val_loss: 0.0308 - val_acc: 0.9889
Epoch 3/15
 - 8s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0302 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0256 - acc: 0.9894
Epoch 2/3
 - 1s - loss: 0.0179 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9923
# Training time = 0:04:38.092667!
# F-Score(Ordinary) = 0.484, Recall: 0.523, Precision: 0.451
# F-Score(lvc) = 0.412, Recall: 0.689, Precision: 0.294
# F-Score(ireflv) = 0.756, Recall: 0.708, Precision: 0.81
# F-Score(id) = 0.313, Recall: 0.308, Precision: 0.317
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2850983
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_201 (Embedding)    (None, 12, 225)           2829375   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 2,850,983
Trainable params: 2,850,983
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 107
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0463 - acc: 0.9856 - val_loss: 0.0311 - val_acc: 0.9881
Epoch 2/15
 - 9s - loss: 0.0240 - acc: 0.9898 - val_loss: 0.0312 - val_acc: 0.9887
Epoch 3/15
 - 9s - loss: 0.0213 - acc: 0.9907 - val_loss: 0.0304 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0257 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0180 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9925
# Training time = 0:05:02.657652!
# F-Score(Ordinary) = 0.263, Recall: 0.414, Precision: 0.192
# F-Score(id) = 0.454, Recall: 0.414, Precision: 0.503
********************
# Seed = 1
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2846483
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_202 (Embedding)    (None, 12, 225)           2824875   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 2,846,483
Trainable params: 2,846,483
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 409
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0461 - acc: 0.9861 - val_loss: 0.0318 - val_acc: 0.9885
Epoch 2/15
 - 9s - loss: 0.0240 - acc: 0.9898 - val_loss: 0.0299 - val_acc: 0.9889
Epoch 3/15
 - 9s - loss: 0.0212 - acc: 0.9905 - val_loss: 0.0300 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0189 - acc: 0.9909
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9921
# Training time = 0:04:28.648688!
# F-Score(Ordinary) = 0.491, Recall: 0.613, Precision: 0.41
# F-Score(lvc) = 0.141, Recall: 0.846, Precision: 0.077
# F-Score(ireflv) = 0.769, Recall: 0.833, Precision: 0.714
# F-Score(id) = 0.462, Recall: 0.456, Precision: 0.467
********************
# Seed = 2
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2848958
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_203 (Embedding)    (None, 12, 225)           2827350   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 2,848,958
Trainable params: 2,848,958
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 110
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0462 - acc: 0.9856 - val_loss: 0.0315 - val_acc: 0.9887
Epoch 2/15
 - 9s - loss: 0.0238 - acc: 0.9900 - val_loss: 0.0308 - val_acc: 0.9887
Epoch 3/15
 - 9s - loss: 0.0213 - acc: 0.9907 - val_loss: 0.0304 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0257 - acc: 0.9893
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0154 - acc: 0.9923
# Training time = 0:04:28.380671!
# F-Score(Ordinary) = 0.454, Recall: 0.509, Precision: 0.41
# F-Score(lvc) = 0.211, Recall: 0.944, Precision: 0.119
# F-Score(ireflv) = 0.728, Recall: 0.704, Precision: 0.754
# F-Score(id) = 0.366, Recall: 0.337, Precision: 0.401
********************
# Seed = 3
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2852558
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_204 (Embedding)    (None, 12, 225)           2830950   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 2,852,558
Trainable params: 2,852,558
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 171
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0459 - acc: 0.9862 - val_loss: 0.0307 - val_acc: 0.9885
Epoch 2/15
 - 9s - loss: 0.0240 - acc: 0.9898 - val_loss: 0.0317 - val_acc: 0.9885
Epoch 3/15
 - 9s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0313 - val_acc: 0.9880
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0267 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0183 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0159 - acc: 0.9923
# Training time = 0:04:24.702395!
# F-Score(Ordinary) = 0.352, Recall: 0.29, Precision: 0.446
# F-Score(lvc) = 0.388, Recall: 0.425, Precision: 0.357
# F-Score(ireflv) = 0.622, Recall: 0.871, Precision: 0.484
# F-Score(id) = 0.25, Recall: 0.168, Precision: 0.485
********************
# Seed = 4
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2851883
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_205 (Embedding)    (None, 12, 225)           2830275   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 2,851,883
Trainable params: 2,851,883
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 152
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0461 - acc: 0.9854 - val_loss: 0.0301 - val_acc: 0.9888
Epoch 2/15
 - 9s - loss: 0.0240 - acc: 0.9898 - val_loss: 0.0340 - val_acc: 0.9880
Epoch 3/15
 - 9s - loss: 0.0215 - acc: 0.9906 - val_loss: 0.0331 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0261 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9924
# Training time = 0:04:30.059149!
# F-Score(Ordinary) = 0.039, Recall: 0.409, Precision: 0.021
# F-Score(lvc) = 0.014, Recall: 0.5, Precision: 0.007
# F-Score(id) = 0.086, Recall: 0.4, Precision: 0.048
********************
# Seed = 5
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2854808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_206 (Embedding)    (None, 12, 225)           2833200   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 2,854,808
Trainable params: 2,854,808
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 266
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0459 - acc: 0.9858 - val_loss: 0.0302 - val_acc: 0.9883
Epoch 2/15
 - 9s - loss: 0.0239 - acc: 0.9899 - val_loss: 0.0311 - val_acc: 0.9889
Epoch 3/15
 - 9s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0314 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0263 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0182 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9922
# Training time = 0:04:29.018823!
# F-Score(Ordinary) = 0.413, Recall: 0.653, Precision: 0.302
# F-Score(lvc) = 0.381, Recall: 0.725, Precision: 0.259
# F-Score(ireflv) = 0.766, Recall: 0.826, Precision: 0.714
# F-Score(id) = 0.048, Recall: 0.119, Precision: 0.03
********************
# Seed = 6
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2854358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_207 (Embedding)    (None, 12, 225)           2832750   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 2,854,358
Trainable params: 2,854,358
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 375
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0459 - acc: 0.9858 - val_loss: 0.0304 - val_acc: 0.9884
Epoch 2/15
 - 9s - loss: 0.0238 - acc: 0.9899 - val_loss: 0.0294 - val_acc: 0.9890
Epoch 3/15
 - 9s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0303 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0177 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0155 - acc: 0.9923
# Training time = 0:04:29.567072!
# F-Score(Ordinary) = 0.229, Recall: 0.192, Precision: 0.284
# F-Score(lvc) = 0.444, Recall: 0.658, Precision: 0.336
# F-Score(ireflv) = 0.016, Recall: 1.0, Precision: 0.008
# F-Score(id) = 0.2, Recall: 0.129, Precision: 0.443
********************
# Seed = 7
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2854583
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_208 (Embedding)    (None, 12, 225)           2832975   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 2,854,583
Trainable params: 2,854,583
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 390
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0462 - acc: 0.9862 - val_loss: 0.0298 - val_acc: 0.9886
Epoch 2/15
 - 9s - loss: 0.0240 - acc: 0.9900 - val_loss: 0.0314 - val_acc: 0.9888
Epoch 3/15
 - 9s - loss: 0.0213 - acc: 0.9907 - val_loss: 0.0310 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0181 - acc: 0.9912
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9922
# Training time = 0:04:26.249535!
# F-Score(Ordinary) = 0.274, Recall: 0.281, Precision: 0.268
# F-Score(lvc) = 0.374, Recall: 0.795, Precision: 0.245
# F-Score(id) = 0.304, Recall: 0.22, Precision: 0.491
********************
# Seed = 8
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2849633
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_209 (Embedding)    (None, 12, 225)           2828025   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 2,849,633
Trainable params: 2,849,633
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 424
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0459 - acc: 0.9858 - val_loss: 0.0346 - val_acc: 0.9871
Epoch 2/15
 - 9s - loss: 0.0239 - acc: 0.9898 - val_loss: 0.0314 - val_acc: 0.9889
Epoch 3/15
 - 9s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0309 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0179 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0158 - acc: 0.9922
# Training time = 0:04:27.517437!
# F-Score(Ordinary) = 0.218, Recall: 0.332, Precision: 0.162
# F-Score(lvc) = 0.041, Recall: 0.6, Precision: 0.021
# F-Score(id) = 0.362, Recall: 0.325, Precision: 0.407
********************
# Seed = 9
********************
# XP = Tokens(225) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 2856833
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_210 (Embedding)    (None, 12, 225)           2835225   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 2700)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 21608     
=================================================================
Total params: 2,856,833
Trainable params: 2,856,833
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0459 - acc: 0.9860 - val_loss: 0.0345 - val_acc: 0.9881
Epoch 2/15
 - 9s - loss: 0.0239 - acc: 0.9898 - val_loss: 0.0308 - val_acc: 0.9889
Epoch 3/15
 - 9s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0301 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0255 - acc: 0.9894
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9923
# Training time = 0:04:30.821684!
# F-Score(Ordinary) = 0.494, Recall: 0.533, Precision: 0.46
# F-Score(lvc) = 0.414, Recall: 0.7, Precision: 0.294
# F-Score(ireflv) = 0.757, Recall: 0.705, Precision: 0.817
# F-Score(id) = 0.325, Recall: 0.322, Precision: 0.329
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3167758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_211 (Embedding)    (None, 12, 250)           3143750   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 3,167,758
Trainable params: 3,167,758
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 107
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0453 - acc: 0.9859 - val_loss: 0.0311 - val_acc: 0.9881
Epoch 2/15
 - 10s - loss: 0.0239 - acc: 0.9898 - val_loss: 0.0313 - val_acc: 0.9887
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9908 - val_loss: 0.0304 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0256 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0155 - acc: 0.9926
# Training time = 0:04:43.210557!
# F-Score(Ordinary) = 0.264, Recall: 0.383, Precision: 0.201
# F-Score(ireflv) = 0.016, Recall: 1.0, Precision: 0.008
# F-Score(id) = 0.439, Recall: 0.38, Precision: 0.521
********************
# Seed = 1
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3162758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_212 (Embedding)    (None, 12, 250)           3138750   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 3,162,758
Trainable params: 3,162,758
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 409
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0456 - acc: 0.9859 - val_loss: 0.0320 - val_acc: 0.9886
Epoch 2/15
 - 10s - loss: 0.0241 - acc: 0.9898 - val_loss: 0.0303 - val_acc: 0.9889
Epoch 3/15
 - 10s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0302 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0261 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0190 - acc: 0.9909
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9922
# Training time = 0:04:28.968429!
# F-Score(Ordinary) = 0.489, Recall: 0.607, Precision: 0.41
# F-Score(lvc) = 0.105, Recall: 0.8, Precision: 0.056
# F-Score(ireflv) = 0.781, Recall: 0.85, Precision: 0.722
# F-Score(id) = 0.464, Recall: 0.449, Precision: 0.479
********************
# Seed = 2
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3165508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_213 (Embedding)    (None, 12, 250)           3141500   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 3,165,508
Trainable params: 3,165,508
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 110
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0457 - acc: 0.9861 - val_loss: 0.0317 - val_acc: 0.9886
Epoch 2/15
 - 9s - loss: 0.0239 - acc: 0.9900 - val_loss: 0.0309 - val_acc: 0.9887
Epoch 3/15
 - 9s - loss: 0.0213 - acc: 0.9907 - val_loss: 0.0304 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0258 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0154 - acc: 0.9923
# Training time = 0:04:33.500737!
# F-Score(Ordinary) = 0.461, Recall: 0.51, Precision: 0.421
# F-Score(lvc) = 0.232, Recall: 0.905, Precision: 0.133
# F-Score(ireflv) = 0.737, Recall: 0.7, Precision: 0.778
# F-Score(id) = 0.365, Recall: 0.335, Precision: 0.401
********************
# Seed = 3
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3169508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_214 (Embedding)    (None, 12, 250)           3145500   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 3,169,508
Trainable params: 3,169,508
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 171
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0452 - acc: 0.9853 - val_loss: 0.0305 - val_acc: 0.9884
Epoch 2/15
 - 10s - loss: 0.0241 - acc: 0.9899 - val_loss: 0.0317 - val_acc: 0.9885
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0313 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0266 - acc: 0.9887
Epoch 2/3
 - 1s - loss: 0.0182 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0158 - acc: 0.9922
# Training time = 0:04:26.631370!
# F-Score(Ordinary) = 0.355, Recall: 0.306, Precision: 0.421
# F-Score(lvc) = 0.375, Recall: 0.395, Precision: 0.357
# F-Score(ireflv) = 0.541, Recall: 0.891, Precision: 0.389
# F-Score(id) = 0.277, Recall: 0.194, Precision: 0.485
********************
# Seed = 4
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3168758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_215 (Embedding)    (None, 12, 250)           3144750   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 3,168,758
Trainable params: 3,168,758
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 152
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0454 - acc: 0.9857 - val_loss: 0.0302 - val_acc: 0.9888
Epoch 2/15
 - 10s - loss: 0.0240 - acc: 0.9898 - val_loss: 0.0336 - val_acc: 0.9880
Epoch 3/15
 - 10s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0329 - val_acc: 0.9883
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0262 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9924
# Training time = 0:04:26.185016!
# F-Score(Ordinary) = 0.047, Recall: 0.407, Precision: 0.025
# F-Score(lvc) = 0.027, Recall: 0.667, Precision: 0.014
# F-Score(id) = 0.094, Recall: 0.375, Precision: 0.054
********************
# Seed = 5
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3172008
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_216 (Embedding)    (None, 12, 250)           3148000   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 3,172,008
Trainable params: 3,172,008
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 266
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0453 - acc: 0.9862 - val_loss: 0.0303 - val_acc: 0.9884
Epoch 2/15
 - 10s - loss: 0.0239 - acc: 0.9899 - val_loss: 0.0311 - val_acc: 0.9890
Epoch 3/15
 - 10s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0315 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0263 - acc: 0.9889
Epoch 2/3
 - 1s - loss: 0.0181 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9921
# Training time = 0:04:35.274821!
# F-Score(Ordinary) = 0.424, Recall: 0.675, Precision: 0.309
# F-Score(lvc) = 0.387, Recall: 0.771, Precision: 0.259
# F-Score(ireflv) = 0.771, Recall: 0.827, Precision: 0.722
# F-Score(id) = 0.067, Recall: 0.167, Precision: 0.042
********************
# Seed = 6
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3171508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_217 (Embedding)    (None, 12, 250)           3147500   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 3,171,508
Trainable params: 3,171,508
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 375
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0451 - acc: 0.9862 - val_loss: 0.0305 - val_acc: 0.9884
Epoch 2/15
 - 10s - loss: 0.0240 - acc: 0.9899 - val_loss: 0.0295 - val_acc: 0.9891
Epoch 3/15
 - 10s - loss: 0.0214 - acc: 0.9906 - val_loss: 0.0304 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0260 - acc: 0.9889
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0156 - acc: 0.9923
# Training time = 0:04:31.337483!
# F-Score(Ordinary) = 0.212, Recall: 0.168, Precision: 0.286
# F-Score(lvc) = 0.444, Recall: 0.719, Precision: 0.322
# F-Score(ireflv) = 0.016, Recall: 1.0, Precision: 0.008
# F-Score(id) = 0.182, Recall: 0.114, Precision: 0.461
********************
# Seed = 7
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3171758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_218 (Embedding)    (None, 12, 250)           3147750   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 3,171,758
Trainable params: 3,171,758
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 390
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0451 - acc: 0.9866 - val_loss: 0.0298 - val_acc: 0.9886
Epoch 2/15
 - 10s - loss: 0.0240 - acc: 0.9900 - val_loss: 0.0314 - val_acc: 0.9889
Epoch 3/15
 - 10s - loss: 0.0213 - acc: 0.9907 - val_loss: 0.0312 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0180 - acc: 0.9912
Epoch 3/3
 - 1s - loss: 0.0156 - acc: 0.9923
# Training time = 0:04:30.201563!
# F-Score(Ordinary) = 0.266, Recall: 0.272, Precision: 0.261
# F-Score(lvc) = 0.37, Recall: 0.829, Precision: 0.238
# F-Score(id) = 0.294, Recall: 0.212, Precision: 0.479
********************
# Seed = 8
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3166258
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_219 (Embedding)    (None, 12, 250)           3142250   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 3,166,258
Trainable params: 3,166,258
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 424
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0452 - acc: 0.9864 - val_loss: 0.0346 - val_acc: 0.9872
Epoch 2/15
 - 9s - loss: 0.0240 - acc: 0.9898 - val_loss: 0.0315 - val_acc: 0.9889
Epoch 3/15
 - 9s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0312 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0260 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0158 - acc: 0.9922
# Training time = 0:04:30.830910!
# F-Score(Ordinary) = 0.215, Recall: 0.375, Precision: 0.151
# F-Score(lvc) = 0.014, Recall: 0.333, Precision: 0.007
# F-Score(id) = 0.382, Recall: 0.376, Precision: 0.389
********************
# Seed = 9
********************
# XP = Tokens(250) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3174258
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_220 (Embedding)    (None, 12, 250)           3150250   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3000)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 24008     
=================================================================
Total params: 3,174,258
Trainable params: 3,174,258
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0456 - acc: 0.9859 - val_loss: 0.0346 - val_acc: 0.9882
Epoch 2/15
 - 9s - loss: 0.0240 - acc: 0.9898 - val_loss: 0.0310 - val_acc: 0.9889
Epoch 3/15
 - 9s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0303 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0257 - acc: 0.9893
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9923
# Training time = 0:04:31.029383!
# F-Score(Ordinary) = 0.485, Recall: 0.518, Precision: 0.455
# F-Score(lvc) = 0.4, Recall: 0.661, Precision: 0.287
# F-Score(ireflv) = 0.766, Recall: 0.709, Precision: 0.833
# F-Score(id) = 0.311, Recall: 0.305, Precision: 0.317
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3484533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_221 (Embedding)    (None, 12, 275)           3458125   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 3,484,533
Trainable params: 3,484,533
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 107
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0450 - acc: 0.9850 - val_loss: 0.0313 - val_acc: 0.9881
Epoch 2/15
 - 10s - loss: 0.0241 - acc: 0.9899 - val_loss: 0.0315 - val_acc: 0.9887
Epoch 3/15
 - 10s - loss: 0.0213 - acc: 0.9908 - val_loss: 0.0307 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0258 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0180 - acc: 0.9914
Epoch 3/3
 - 1s - loss: 0.0156 - acc: 0.9927
# Training time = 0:04:41.497334!
# F-Score(Ordinary) = 0.251, Recall: 0.411, Precision: 0.181
# F-Score(id) = 0.44, Recall: 0.411, Precision: 0.473
********************
# Seed = 1
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3479033
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_222 (Embedding)    (None, 12, 275)           3452625   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 3,479,033
Trainable params: 3,479,033
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 409
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0447 - acc: 0.9862 - val_loss: 0.0321 - val_acc: 0.9885
Epoch 2/15
 - 10s - loss: 0.0241 - acc: 0.9898 - val_loss: 0.0302 - val_acc: 0.9889
Epoch 3/15
 - 10s - loss: 0.0213 - acc: 0.9904 - val_loss: 0.0302 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0261 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0190 - acc: 0.9909
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9922
# Training time = 0:04:34.244650!
# F-Score(Ordinary) = 0.479, Recall: 0.582, Precision: 0.407
# F-Score(lvc) = 0.117, Recall: 0.818, Precision: 0.063
# F-Score(ireflv) = 0.784, Recall: 0.858, Precision: 0.722
# F-Score(id) = 0.438, Recall: 0.413, Precision: 0.467
********************
# Seed = 2
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3482058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_223 (Embedding)    (None, 12, 275)           3455650   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 3,482,058
Trainable params: 3,482,058
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 110
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0448 - acc: 0.9854 - val_loss: 0.0318 - val_acc: 0.9886
Epoch 2/15
 - 10s - loss: 0.0238 - acc: 0.9900 - val_loss: 0.0305 - val_acc: 0.9889
Epoch 3/15
 - 10s - loss: 0.0211 - acc: 0.9907 - val_loss: 0.0304 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0257 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0177 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0153 - acc: 0.9924
# Training time = 0:04:49.428606!
# F-Score(Ordinary) = 0.454, Recall: 0.492, Precision: 0.421
# F-Score(lvc) = 0.222, Recall: 0.947, Precision: 0.126
# F-Score(ireflv) = 0.727, Recall: 0.688, Precision: 0.77
# F-Score(id) = 0.362, Recall: 0.322, Precision: 0.413
********************
# Seed = 3
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3486458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_224 (Embedding)    (None, 12, 275)           3460050   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 3,486,458
Trainable params: 3,486,458
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 171
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0447 - acc: 0.9861 - val_loss: 0.0309 - val_acc: 0.9883
Epoch 2/15
 - 10s - loss: 0.0241 - acc: 0.9899 - val_loss: 0.0317 - val_acc: 0.9886
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0313 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0266 - acc: 0.9885
Epoch 2/3
 - 1s - loss: 0.0182 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9923
# Training time = 0:04:37.113272!
# F-Score(Ordinary) = 0.345, Recall: 0.297, Precision: 0.412
# F-Score(lvc) = 0.374, Recall: 0.385, Precision: 0.364
# F-Score(ireflv) = 0.491, Recall: 0.878, Precision: 0.341
# F-Score(id) = 0.278, Recall: 0.194, Precision: 0.491
********************
# Seed = 4
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3485633
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_225 (Embedding)    (None, 12, 275)           3459225   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 3,485,633
Trainable params: 3,485,633
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 152
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0446 - acc: 0.9862 - val_loss: 0.0306 - val_acc: 0.9888
Epoch 2/15
 - 10s - loss: 0.0241 - acc: 0.9898 - val_loss: 0.0342 - val_acc: 0.9878
Epoch 3/15
 - 10s - loss: 0.0215 - acc: 0.9906 - val_loss: 0.0333 - val_acc: 0.9884
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0263 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9914
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9924
# Training time = 0:04:31.401611!
# F-Score(Ordinary) = 0.048, Recall: 0.44, Precision: 0.025
# F-Score(lvc) = 0.027, Recall: 0.667, Precision: 0.014
# F-Score(id) = 0.095, Recall: 0.409, Precision: 0.054
********************
# Seed = 5
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3489208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_226 (Embedding)    (None, 12, 275)           3462800   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 3,489,208
Trainable params: 3,489,208
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 266
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0451 - acc: 0.9863 - val_loss: 0.0303 - val_acc: 0.9884
Epoch 2/15
 - 10s - loss: 0.0241 - acc: 0.9898 - val_loss: 0.0313 - val_acc: 0.9889
Epoch 3/15
 - 10s - loss: 0.0215 - acc: 0.9905 - val_loss: 0.0317 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0265 - acc: 0.9889
Epoch 2/3
 - 1s - loss: 0.0182 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9922
# Training time = 0:04:30.083600!
# F-Score(Ordinary) = 0.424, Recall: 0.656, Precision: 0.314
# F-Score(lvc) = 0.383, Recall: 0.74, Precision: 0.259
# F-Score(ireflv) = 0.773, Recall: 0.821, Precision: 0.73
# F-Score(id) = 0.075, Recall: 0.17, Precision: 0.048
********************
# Seed = 6
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3488658
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_227 (Embedding)    (None, 12, 275)           3462250   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 3,488,658
Trainable params: 3,488,658
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 375
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0449 - acc: 0.9859 - val_loss: 0.0306 - val_acc: 0.9884
Epoch 2/15
 - 10s - loss: 0.0239 - acc: 0.9899 - val_loss: 0.0294 - val_acc: 0.9891
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0303 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0177 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0154 - acc: 0.9922
# Training time = 0:04:28.516631!
# F-Score(Ordinary) = 0.19, Recall: 0.146, Precision: 0.27
# F-Score(lvc) = 0.421, Recall: 0.634, Precision: 0.315
# F-Score(id) = 0.159, Recall: 0.098, Precision: 0.431
********************
# Seed = 7
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3488933
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_228 (Embedding)    (None, 12, 275)           3462525   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 3,488,933
Trainable params: 3,488,933
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 390
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0450 - acc: 0.9853 - val_loss: 0.0299 - val_acc: 0.9887
Epoch 2/15
 - 10s - loss: 0.0240 - acc: 0.9900 - val_loss: 0.0313 - val_acc: 0.9888
Epoch 3/15
 - 10s - loss: 0.0213 - acc: 0.9907 - val_loss: 0.0311 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0179 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0155 - acc: 0.9922
# Training time = 0:04:33.600907!
# F-Score(Ordinary) = 0.278, Recall: 0.289, Precision: 0.268
# F-Score(lvc) = 0.394, Recall: 0.822, Precision: 0.259
# F-Score(id) = 0.304, Recall: 0.223, Precision: 0.479
********************
# Seed = 8
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3482883
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_229 (Embedding)    (None, 12, 275)           3456475   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 3,482,883
Trainable params: 3,482,883
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 424
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0448 - acc: 0.9855 - val_loss: 0.0347 - val_acc: 0.9872
Epoch 2/15
 - 10s - loss: 0.0240 - acc: 0.9898 - val_loss: 0.0316 - val_acc: 0.9889
Epoch 3/15
 - 10s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0313 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0260 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0177 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9921
# Training time = 0:04:33.107842!
# F-Score(Ordinary) = 0.218, Recall: 0.366, Precision: 0.156
# F-Score(lvc) = 0.027, Recall: 0.667, Precision: 0.014
# F-Score(id) = 0.377, Recall: 0.361, Precision: 0.395
********************
# Seed = 9
********************
# XP = Tokens(275) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3491683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_230 (Embedding)    (None, 12, 275)           3465275   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3300)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 26408     
=================================================================
Total params: 3,491,683
Trainable params: 3,491,683
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0447 - acc: 0.9854 - val_loss: 0.0346 - val_acc: 0.9882
Epoch 2/15
 - 11s - loss: 0.0240 - acc: 0.9898 - val_loss: 0.0308 - val_acc: 0.9889
Epoch 3/15
 - 11s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0303 - val_acc: 0.9893
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0257 - acc: 0.9893
Epoch 2/3
 - 1s - loss: 0.0177 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0156 - acc: 0.9924
# Training time = 0:04:34.107573!
# F-Score(Ordinary) = 0.485, Recall: 0.515, Precision: 0.458
# F-Score(lvc) = 0.4, Recall: 0.702, Precision: 0.28
# F-Score(ireflv) = 0.772, Recall: 0.719, Precision: 0.833
# F-Score(id) = 0.307, Recall: 0.292, Precision: 0.323
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3801308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_231 (Embedding)    (None, 12, 300)           3772500   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 3,801,308
Trainable params: 3,801,308
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 107
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0440 - acc: 0.9857 - val_loss: 0.0315 - val_acc: 0.9882
Epoch 2/15
 - 11s - loss: 0.0241 - acc: 0.9899 - val_loss: 0.0314 - val_acc: 0.9887
Epoch 3/15
 - 11s - loss: 0.0212 - acc: 0.9908 - val_loss: 0.0305 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0256 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0154 - acc: 0.9926
# Training time = 0:04:38.497692!
# F-Score(Ordinary) = 0.261, Recall: 0.386, Precision: 0.197
# F-Score(ireflv) = 0.016, Recall: 1.0, Precision: 0.008
# F-Score(id) = 0.438, Recall: 0.385, Precision: 0.509
********************
# Seed = 1
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3795308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_232 (Embedding)    (None, 12, 300)           3766500   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 3,795,308
Trainable params: 3,795,308
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 409
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0443 - acc: 0.9863 - val_loss: 0.0322 - val_acc: 0.9886
Epoch 2/15
 - 11s - loss: 0.0242 - acc: 0.9897 - val_loss: 0.0305 - val_acc: 0.9888
Epoch 3/15
 - 11s - loss: 0.0215 - acc: 0.9904 - val_loss: 0.0304 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0264 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0191 - acc: 0.9909
Epoch 3/3
 - 1s - loss: 0.0157 - acc: 0.9921
# Training time = 0:04:32.288608!
# F-Score(Ordinary) = 0.495, Recall: 0.631, Precision: 0.407
# F-Score(lvc) = 0.092, Recall: 0.778, Precision: 0.049
# F-Score(ireflv) = 0.786, Recall: 0.852, Precision: 0.73
# F-Score(id) = 0.476, Recall: 0.479, Precision: 0.473
********************
# Seed = 2
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3798608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_233 (Embedding)    (None, 12, 300)           3769800   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 3,798,608
Trainable params: 3,798,608
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 110
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0443 - acc: 0.9858 - val_loss: 0.0319 - val_acc: 0.9887
Epoch 2/15
 - 11s - loss: 0.0237 - acc: 0.9901 - val_loss: 0.0302 - val_acc: 0.9889
Epoch 3/15
 - 11s - loss: 0.0210 - acc: 0.9907 - val_loss: 0.0305 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0256 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0177 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0153 - acc: 0.9924
# Training time = 0:04:29.120033!
# F-Score(Ordinary) = 0.455, Recall: 0.496, Precision: 0.421
# F-Score(lvc) = 0.22, Recall: 0.857, Precision: 0.126
# F-Score(ireflv) = 0.729, Recall: 0.693, Precision: 0.77
# F-Score(id) = 0.366, Recall: 0.329, Precision: 0.413
********************
# Seed = 3
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3803408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_234 (Embedding)    (None, 12, 300)           3774600   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 3,803,408
Trainable params: 3,803,408
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 171
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0443 - acc: 0.9854 - val_loss: 0.0311 - val_acc: 0.9882
Epoch 2/15
 - 11s - loss: 0.0242 - acc: 0.9898 - val_loss: 0.0319 - val_acc: 0.9885
Epoch 3/15
 - 11s - loss: 0.0212 - acc: 0.9908 - val_loss: 0.0315 - val_acc: 0.9881
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0267 - acc: 0.9885
Epoch 2/3
 - 1s - loss: 0.0182 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0158 - acc: 0.9922
# Training time = 0:04:38.304712!
# F-Score(Ordinary) = 0.348, Recall: 0.294, Precision: 0.426
# F-Score(lvc) = 0.398, Recall: 0.441, Precision: 0.364
# F-Score(ireflv) = 0.546, Recall: 0.877, Precision: 0.397
# F-Score(id) = 0.262, Recall: 0.179, Precision: 0.491
********************
# Seed = 4
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3802508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_235 (Embedding)    (None, 12, 300)           3773700   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 3,802,508
Trainable params: 3,802,508
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 152
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0442 - acc: 0.9858 - val_loss: 0.0305 - val_acc: 0.9888
Epoch 2/15
 - 11s - loss: 0.0240 - acc: 0.9897 - val_loss: 0.0333 - val_acc: 0.9880
Epoch 3/15
 - 11s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0325 - val_acc: 0.9885
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0262 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0177 - acc: 0.9914
Epoch 3/3
 - 1s - loss: 0.0156 - acc: 0.9923
# Training time = 0:04:35.207394!
# F-Score(Ordinary) = 0.047, Recall: 0.344, Precision: 0.025
# F-Score(lvc) = 0.027, Recall: 0.667, Precision: 0.014
# F-Score(id) = 0.092, Recall: 0.31, Precision: 0.054
********************
# Seed = 5
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3806408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_236 (Embedding)    (None, 12, 300)           3777600   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 3,806,408
Trainable params: 3,806,408
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 266
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0443 - acc: 0.9862 - val_loss: 0.0305 - val_acc: 0.9881
Epoch 2/15
 - 11s - loss: 0.0241 - acc: 0.9898 - val_loss: 0.0311 - val_acc: 0.9889
Epoch 3/15
 - 11s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0314 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0263 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0181 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0156 - acc: 0.9922
# Training time = 0:04:31.844202!
# F-Score(Ordinary) = 0.42, Recall: 0.701, Precision: 0.3
# F-Score(lvc) = 0.378, Recall: 0.833, Precision: 0.245
# F-Score(ireflv) = 0.771, Recall: 0.848, Precision: 0.706
# F-Score(id) = 0.068, Recall: 0.175, Precision: 0.042
********************
# Seed = 6
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3805808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_237 (Embedding)    (None, 12, 300)           3777000   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 3,805,808
Trainable params: 3,805,808
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 375
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0442 - acc: 0.9859 - val_loss: 0.0308 - val_acc: 0.9884
Epoch 2/15
 - 11s - loss: 0.0240 - acc: 0.9899 - val_loss: 0.0293 - val_acc: 0.9891
Epoch 3/15
 - 11s - loss: 0.0213 - acc: 0.9907 - val_loss: 0.0302 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0258 - acc: 0.9889
Epoch 2/3
 - 1s - loss: 0.0176 - acc: 0.9918
Epoch 3/3
 - 1s - loss: 0.0154 - acc: 0.9922
# Training time = 0:04:44.722402!
# F-Score(Ordinary) = 0.211, Recall: 0.17, Precision: 0.277
# F-Score(lvc) = 0.442, Recall: 0.708, Precision: 0.322
# F-Score(ireflv) = 0.016, Recall: 0.5, Precision: 0.008
# F-Score(id) = 0.18, Recall: 0.113, Precision: 0.437
********************
# Seed = 7
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3806108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_238 (Embedding)    (None, 12, 300)           3777300   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 3,806,108
Trainable params: 3,806,108
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 390
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0445 - acc: 0.9862 - val_loss: 0.0300 - val_acc: 0.9887
Epoch 2/15
 - 11s - loss: 0.0240 - acc: 0.9900 - val_loss: 0.0314 - val_acc: 0.9887
Epoch 3/15
 - 11s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0312 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0155 - acc: 0.9923
# Training time = 0:04:53.106458!
# F-Score(Ordinary) = 0.263, Recall: 0.253, Precision: 0.275
# F-Score(lvc) = 0.4, Recall: 0.809, Precision: 0.266
# F-Score(id) = 0.277, Recall: 0.192, Precision: 0.491
********************
# Seed = 8
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3799508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_239 (Embedding)    (None, 12, 300)           3770700   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 3,799,508
Trainable params: 3,799,508
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 424
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0443 - acc: 0.9860 - val_loss: 0.0346 - val_acc: 0.9872
Epoch 2/15
 - 11s - loss: 0.0241 - acc: 0.9898 - val_loss: 0.0316 - val_acc: 0.9889
Epoch 3/15
 - 11s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0312 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0260 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0177 - acc: 0.9914
Epoch 3/3
 - 1s - loss: 0.0156 - acc: 0.9921
# Training time = 0:04:36.143404!
# F-Score(Ordinary) = 0.209, Recall: 0.38, Precision: 0.144
# F-Score(lvc) = 0.027, Recall: 0.5, Precision: 0.014
# F-Score(id) = 0.371, Recall: 0.377, Precision: 0.365
********************
# Seed = 9
********************
# XP = Tokens(300) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# token weight matrix = False
# Parameters = 3809108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
token (InputLayer)           (None, 12)                0         
_________________________________________________________________
embedding_240 (Embedding)    (None, 12, 300)           3780300   
_________________________________________________________________
tokenFlatten (Flatten)       (None, 3600)              0         
_________________________________________________________________
output (Dense)               (None, 8)                 28808     
=================================================================
Total params: 3,809,108
Trainable params: 3,809,108
Non-trainable params: 0
_________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0442 - acc: 0.9861 - val_loss: 0.0348 - val_acc: 0.9882
Epoch 2/15
 - 11s - loss: 0.0241 - acc: 0.9899 - val_loss: 0.0309 - val_acc: 0.9890
Epoch 3/15
 - 11s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0304 - val_acc: 0.9893
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0258 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0177 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0155 - acc: 0.9923
# Training time = 0:04:37.307320!
# F-Score(Ordinary) = 0.475, Recall: 0.519, Precision: 0.437
# F-Score(lvc) = 0.364, Recall: 0.655, Precision: 0.252
# F-Score(ireflv) = 0.759, Recall: 0.721, Precision: 0.802
# F-Score(id) = 0.318, Recall: 0.312, Precision: 0.323
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(25) POS(8) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 432625
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_241 (Embedding)       (None, 12, 8)        224         pos[0][0]                        
__________________________________________________________________________________________________
embedding_242 (Embedding)       (None, 12, 25)       429225      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 96)           0           embedding_241[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_242[0][0]              
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 396)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3176        concatenate_1[0][0]              
==================================================================================================
Total params: 432,625
Trainable params: 432,625
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 297
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0687 - acc: 0.9814 - val_loss: 0.0291 - val_acc: 0.9885
Epoch 2/15
 - 8s - loss: 0.0219 - acc: 0.9903 - val_loss: 0.0284 - val_acc: 0.9888
Epoch 3/15
 - 8s - loss: 0.0186 - acc: 0.9913 - val_loss: 0.0290 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0254 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0176 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0148 - acc: 0.9926
# Training time = 0:05:56.983166!
# F-Score(Ordinary) = 0.316, Recall: 0.706, Precision: 0.204
# F-Score(lvc) = 0.027, Recall: 0.5, Precision: 0.014
# F-Score(ireflv) = 0.016, Recall: 1.0, Precision: 0.008
# F-Score(id) = 0.59, Recall: 0.702, Precision: 0.509
********************
# Seed = 1
********************
# XP = Tokens(25) POS(8) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 432175
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_243 (Embedding)       (None, 12, 8)        224         pos[0][0]                        
__________________________________________________________________________________________________
embedding_244 (Embedding)       (None, 12, 25)       428775      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 96)           0           embedding_243[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_244[0][0]              
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 396)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3176        concatenate_2[0][0]              
==================================================================================================
Total params: 432,175
Trainable params: 432,175
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0679 - acc: 0.9845 - val_loss: 0.0286 - val_acc: 0.9888
Epoch 2/15
 - 8s - loss: 0.0219 - acc: 0.9902 - val_loss: 0.0281 - val_acc: 0.9891
Epoch 3/15
 - 8s - loss: 0.0185 - acc: 0.9913 - val_loss: 0.0300 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0255 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0181 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0149 - acc: 0.9926
# Training time = 0:04:57.102912!
# F-Score(Ordinary) = 0.483, Recall: 0.671, Precision: 0.378
# F-Score(lvc) = 0.279, Recall: 0.694, Precision: 0.175
# F-Score(ireflv) = 0.702, Recall: 0.798, Precision: 0.627
# F-Score(id) = 0.424, Recall: 0.532, Precision: 0.353
********************
# Seed = 2
********************
# XP = Tokens(25) POS(8) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 432325
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_245 (Embedding)       (None, 12, 8)        224         pos[0][0]                        
__________________________________________________________________________________________________
embedding_246 (Embedding)       (None, 12, 25)       428925      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 96)           0           embedding_245[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_246[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 396)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3176        concatenate_3[0][0]              
==================================================================================================
Total params: 432,325
Trainable params: 432,325
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 427
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0673 - acc: 0.9841 - val_loss: 0.0295 - val_acc: 0.9887
Epoch 2/15
 - 8s - loss: 0.0218 - acc: 0.9902 - val_loss: 0.0282 - val_acc: 0.9894
Epoch 3/15
 - 8s - loss: 0.0185 - acc: 0.9915 - val_loss: 0.0292 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0255 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0177 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0148 - acc: 0.9926
# Training time = 0:04:54.380566!
# F-Score(Ordinary) = 0.54, Recall: 0.653, Precision: 0.46
# F-Score(lvc) = 0.392, Recall: 0.696, Precision: 0.273
# F-Score(ireflv) = 0.687, Recall: 0.76, Precision: 0.627
# F-Score(id) = 0.521, Recall: 0.554, Precision: 0.491
********************
# Seed = 3
********************
# XP = Tokens(25) POS(8) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 432725
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_247 (Embedding)       (None, 12, 8)        224         pos[0][0]                        
__________________________________________________________________________________________________
embedding_248 (Embedding)       (None, 12, 25)       429325      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 96)           0           embedding_247[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_248[0][0]              
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 396)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3176        concatenate_4[0][0]              
==================================================================================================
Total params: 432,725
Trainable params: 432,725
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 433
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0675 - acc: 0.9838 - val_loss: 0.0289 - val_acc: 0.9886
Epoch 2/15
 - 8s - loss: 0.0219 - acc: 0.9901 - val_loss: 0.0289 - val_acc: 0.9889
Epoch 3/15
 - 7s - loss: 0.0185 - acc: 0.9913 - val_loss: 0.0298 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0259 - acc: 0.9894
Epoch 2/3
 - 1s - loss: 0.0180 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0150 - acc: 0.9923
# Training time = 0:05:11.024774!
# F-Score(Ordinary) = 0.433, Recall: 0.586, Precision: 0.343
# F-Score(lvc) = 0.459, Recall: 0.518, Precision: 0.413
# F-Score(ireflv) = 0.141, Recall: 0.625, Precision: 0.079
# F-Score(id) = 0.512, Recall: 0.595, Precision: 0.449
********************
# Seed = 4
********************
# XP = Tokens(25) POS(8) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 432575
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_249 (Embedding)       (None, 12, 8)        224         pos[0][0]                        
__________________________________________________________________________________________________
embedding_250 (Embedding)       (None, 12, 25)       429175      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 96)           0           embedding_249[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_250[0][0]              
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 396)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3176        concatenate_5[0][0]              
==================================================================================================
Total params: 432,575
Trainable params: 432,575
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 295
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0665 - acc: 0.9845 - val_loss: 0.0300 - val_acc: 0.9880
Epoch 2/15
 - 8s - loss: 0.0217 - acc: 0.9902 - val_loss: 0.0283 - val_acc: 0.9889
Epoch 3/15
 - 8s - loss: 0.0186 - acc: 0.9914 - val_loss: 0.0299 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0252 - acc: 0.9893
Epoch 2/3
 - 1s - loss: 0.0176 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0148 - acc: 0.9926
# Training time = 0:04:56.142944!
# F-Score(Ordinary) = 0.18, Recall: 0.714, Precision: 0.103
# F-Score(lvc) = 0.128, Recall: 0.769, Precision: 0.07
# F-Score(id) = 0.313, Recall: 0.68, Precision: 0.204
********************
# Seed = 5
********************
# XP = Tokens(25) POS(8) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 433075
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_251 (Embedding)       (None, 12, 8)        224         pos[0][0]                        
__________________________________________________________________________________________________
embedding_252 (Embedding)       (None, 12, 25)       429675      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 96)           0           embedding_251[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_252[0][0]              
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 396)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3176        concatenate_6[0][0]              
==================================================================================================
Total params: 433,075
Trainable params: 433,075
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 450
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0688 - acc: 0.9820 - val_loss: 0.0294 - val_acc: 0.9884
Epoch 2/15
 - 8s - loss: 0.0218 - acc: 0.9903 - val_loss: 0.0276 - val_acc: 0.9892
Epoch 3/15
 - 8s - loss: 0.0184 - acc: 0.9915 - val_loss: 0.0290 - val_acc: 0.9888
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0252 - acc: 0.9886
Epoch 2/3
 - 1s - loss: 0.0179 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0149 - acc: 0.9923
# Training time = 0:05:28.276114!
# F-Score(Ordinary) = 0.451, Recall: 0.761, Precision: 0.32
# F-Score(lvc) = 0.448, Recall: 0.701, Precision: 0.329
# F-Score(ireflv) = 0.7, Recall: 0.804, Precision: 0.619
# F-Score(id) = 0.139, Recall: 0.65, Precision: 0.078
********************
# Seed = 6
********************
# XP = Tokens(25) POS(8) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 433225
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_253 (Embedding)       (None, 12, 8)        224         pos[0][0]                        
__________________________________________________________________________________________________
embedding_254 (Embedding)       (None, 12, 25)       429825      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 96)           0           embedding_253[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_254[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 396)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3176        concatenate_7[0][0]              
==================================================================================================
Total params: 433,225
Trainable params: 433,225
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 483
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0689 - acc: 0.9827 - val_loss: 0.0323 - val_acc: 0.9875
Epoch 2/15
 - 7s - loss: 0.0218 - acc: 0.9903 - val_loss: 0.0278 - val_acc: 0.9892
Epoch 3/15
 - 7s - loss: 0.0187 - acc: 0.9912 - val_loss: 0.0292 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0254 - acc: 0.9891
Epoch 2/3
 - 1s - loss: 0.0177 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0149 - acc: 0.9925
# Training time = 0:04:54.459385!
# F-Score(Ordinary) = 0.404, Recall: 0.584, Precision: 0.309
# F-Score(lvc) = 0.455, Recall: 0.649, Precision: 0.35
# F-Score(ireflv) = 0.074, Recall: 0.556, Precision: 0.04
# F-Score(id) = 0.494, Recall: 0.531, Precision: 0.461
********************
# Seed = 7
********************
# XP = Tokens(25) POS(8) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 432950
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_255 (Embedding)       (None, 12, 8)        224         pos[0][0]                        
__________________________________________________________________________________________________
embedding_256 (Embedding)       (None, 12, 25)       429550      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 96)           0           embedding_255[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_256[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 396)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3176        concatenate_8[0][0]              
==================================================================================================
Total params: 432,950
Trainable params: 432,950
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 419
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0688 - acc: 0.9811 - val_loss: 0.0294 - val_acc: 0.9883
Epoch 2/15
 - 8s - loss: 0.0219 - acc: 0.9901 - val_loss: 0.0292 - val_acc: 0.9890
Epoch 3/15
 - 7s - loss: 0.0185 - acc: 0.9913 - val_loss: 0.0291 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0255 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0179 - acc: 0.9912
Epoch 3/3
 - 1s - loss: 0.0150 - acc: 0.9924
# Training time = 0:04:53.281955!
# F-Score(Ordinary) = 0.12, Recall: 0.617, Precision: 0.066
# F-Score(lvc) = 0.027, Recall: 0.5, Precision: 0.014
# F-Score(ireflv) = 0.016, Recall: 0.5, Precision: 0.008
# F-Score(id) = 0.25, Recall: 0.634, Precision: 0.156
********************
# Seed = 8
********************
# XP = Tokens(25) POS(8) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 432625
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_257 (Embedding)       (None, 12, 8)        224         pos[0][0]                        
__________________________________________________________________________________________________
embedding_258 (Embedding)       (None, 12, 25)       429225      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 96)           0           embedding_257[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_258[0][0]              
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 396)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3176        concatenate_9[0][0]              
==================================================================================================
Total params: 432,625
Trainable params: 432,625
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 263
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0672 - acc: 0.9807 - val_loss: 0.0304 - val_acc: 0.9882
Epoch 2/15
 - 7s - loss: 0.0221 - acc: 0.9901 - val_loss: 0.0280 - val_acc: 0.9890
Epoch 3/15
 - 7s - loss: 0.0185 - acc: 0.9913 - val_loss: 0.0291 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0256 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0150 - acc: 0.9923
# Training time = 0:04:54.400258!
# F-Score(Ordinary) = 0.326, Recall: 0.655, Precision: 0.217
# F-Score(lvc) = 0.182, Recall: 0.682, Precision: 0.105
# F-Score(ireflv) = 0.075, Recall: 0.625, Precision: 0.04
# F-Score(id) = 0.525, Recall: 0.643, Precision: 0.443
********************
# Seed = 9
********************
# XP = Tokens(25) POS(8) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 433050
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_259 (Embedding)       (None, 12, 8)        224         pos[0][0]                        
__________________________________________________________________________________________________
embedding_260 (Embedding)       (None, 12, 25)       429650      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 96)           0           embedding_259[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_260[0][0]              
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 396)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3176        concatenate_10[0][0]             
==================================================================================================
Total params: 433,050
Trainable params: 433,050
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 150
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0676 - acc: 0.9835 - val_loss: 0.0300 - val_acc: 0.9885
Epoch 2/15
 - 8s - loss: 0.0219 - acc: 0.9902 - val_loss: 0.0286 - val_acc: 0.9889
Epoch 3/15
 - 8s - loss: 0.0187 - acc: 0.9912 - val_loss: 0.0301 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0255 - acc: 0.9889
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9915
Epoch 3/3
 - 1s - loss: 0.0151 - acc: 0.9924
# Training time = 0:04:55.294914!
# F-Score(Ordinary) = 0.449, Recall: 0.749, Precision: 0.32
# F-Score(lvc) = 0.366, Recall: 0.729, Precision: 0.245
# F-Score(ireflv) = 0.747, Recall: 0.813, Precision: 0.69
# F-Score(id) = 0.171, Recall: 0.531, Precision: 0.102
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(25) POS(16) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 433617
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_261 (Embedding)       (None, 12, 16)       448         pos[0][0]                        
__________________________________________________________________________________________________
embedding_262 (Embedding)       (None, 12, 25)       429225      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 192)          0           embedding_261[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_262[0][0]              
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 492)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3944        concatenate_11[0][0]             
==================================================================================================
Total params: 433,617
Trainable params: 433,617
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 297
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0630 - acc: 0.9838 - val_loss: 0.0280 - val_acc: 0.9888
Epoch 2/15
 - 8s - loss: 0.0215 - acc: 0.9904 - val_loss: 0.0276 - val_acc: 0.9892
Epoch 3/15
 - 8s - loss: 0.0185 - acc: 0.9914 - val_loss: 0.0281 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0250 - acc: 0.9893
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9914
Epoch 3/3
 - 1s - loss: 0.0150 - acc: 0.9926
# Training time = 0:05:29.996616!
# F-Score(Ordinary) = 0.315, Recall: 0.75, Precision: 0.199
# F-Score(lvc) = 0.014, Recall: 0.5, Precision: 0.007
# F-Score(ireflv) = 0.031, Recall: 1.0, Precision: 0.016
# F-Score(id) = 0.595, Recall: 0.741, Precision: 0.497
********************
# Seed = 1
********************
# XP = Tokens(25) POS(16) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 433167
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_263 (Embedding)       (None, 12, 16)       448         pos[0][0]                        
__________________________________________________________________________________________________
embedding_264 (Embedding)       (None, 12, 25)       428775      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 192)          0           embedding_263[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_264[0][0]              
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 492)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3944        concatenate_12[0][0]             
==================================================================================================
Total params: 433,167
Trainable params: 433,167
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0640 - acc: 0.9834 - val_loss: 0.0284 - val_acc: 0.9888
Epoch 2/15
 - 8s - loss: 0.0217 - acc: 0.9902 - val_loss: 0.0279 - val_acc: 0.9892
Epoch 3/15
 - 8s - loss: 0.0185 - acc: 0.9913 - val_loss: 0.0295 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0254 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0184 - acc: 0.9910
Epoch 3/3
 - 1s - loss: 0.0151 - acc: 0.9924
# Training time = 0:05:04.076532!
# F-Score(Ordinary) = 0.485, Recall: 0.744, Precision: 0.359
# F-Score(lvc) = 0.197, Recall: 0.567, Precision: 0.119
# F-Score(ireflv) = 0.691, Recall: 0.794, Precision: 0.611
# F-Score(id) = 0.494, Recall: 0.738, Precision: 0.371
********************
# Seed = 2
********************
# XP = Tokens(25) POS(16) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 433317
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_265 (Embedding)       (None, 12, 16)       448         pos[0][0]                        
__________________________________________________________________________________________________
embedding_266 (Embedding)       (None, 12, 25)       428925      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 192)          0           embedding_265[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_266[0][0]              
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 492)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3944        concatenate_13[0][0]             
==================================================================================================
Total params: 433,317
Trainable params: 433,317
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 427
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0641 - acc: 0.9820 - val_loss: 0.0284 - val_acc: 0.9891
Epoch 2/15
 - 8s - loss: 0.0215 - acc: 0.9903 - val_loss: 0.0277 - val_acc: 0.9896
Epoch 3/15
 - 8s - loss: 0.0183 - acc: 0.9915 - val_loss: 0.0285 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0252 - acc: 0.9894
Epoch 2/3
 - 1s - loss: 0.0177 - acc: 0.9914
Epoch 3/3
 - 1s - loss: 0.0149 - acc: 0.9925
# Training time = 0:04:55.405442!
# F-Score(Ordinary) = 0.532, Recall: 0.643, Precision: 0.453
# F-Score(lvc) = 0.319, Recall: 0.667, Precision: 0.21
# F-Score(ireflv) = 0.695, Recall: 0.757, Precision: 0.643
# F-Score(id) = 0.533, Recall: 0.551, Precision: 0.515
********************
# Seed = 3
********************
# XP = Tokens(25) POS(16) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 433717
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_267 (Embedding)       (None, 12, 16)       448         pos[0][0]                        
__________________________________________________________________________________________________
embedding_268 (Embedding)       (None, 12, 25)       429325      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 192)          0           embedding_267[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_268[0][0]              
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 492)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3944        concatenate_14[0][0]             
==================================================================================================
Total params: 433,717
Trainable params: 433,717
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 433
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0629 - acc: 0.9826 - val_loss: 0.0284 - val_acc: 0.9889
Epoch 2/15
 - 8s - loss: 0.0216 - acc: 0.9903 - val_loss: 0.0282 - val_acc: 0.9890
Epoch 3/15
 - 8s - loss: 0.0183 - acc: 0.9914 - val_loss: 0.0289 - val_acc: 0.9890
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0255 - acc: 0.9894
Epoch 2/3
 - 1s - loss: 0.0181 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0151 - acc: 0.9922
# Training time = 0:04:55.740618!
# F-Score(Ordinary) = 0.472, Recall: 0.63, Precision: 0.378
# F-Score(lvc) = 0.483, Recall: 0.525, Precision: 0.448
# F-Score(ireflv) = 0.176, Recall: 0.591, Precision: 0.103
# F-Score(id) = 0.568, Recall: 0.686, Precision: 0.485
********************
# Seed = 4
********************
# XP = Tokens(25) POS(16) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 433567
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_269 (Embedding)       (None, 12, 16)       448         pos[0][0]                        
__________________________________________________________________________________________________
embedding_270 (Embedding)       (None, 12, 25)       429175      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 192)          0           embedding_269[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_270[0][0]              
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 492)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3944        concatenate_15[0][0]             
==================================================================================================
Total params: 433,567
Trainable params: 433,567
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 295
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0626 - acc: 0.9837 - val_loss: 0.0296 - val_acc: 0.9880
Epoch 2/15
 - 8s - loss: 0.0217 - acc: 0.9902 - val_loss: 0.0279 - val_acc: 0.9890
Epoch 3/15
 - 8s - loss: 0.0185 - acc: 0.9914 - val_loss: 0.0294 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0250 - acc: 0.9894
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0150 - acc: 0.9926
# Training time = 0:05:25.443409!
# F-Score(Ordinary) = 0.161, Recall: 0.678, Precision: 0.092
# F-Score(lvc) = 0.104, Recall: 0.727, Precision: 0.056
# F-Score(id) = 0.288, Recall: 0.646, Precision: 0.186
********************
# Seed = 5
********************
# XP = Tokens(25) POS(16) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 434067
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_271 (Embedding)       (None, 12, 16)       448         pos[0][0]                        
__________________________________________________________________________________________________
embedding_272 (Embedding)       (None, 12, 25)       429675      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 192)          0           embedding_271[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_272[0][0]              
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 492)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3944        concatenate_16[0][0]             
==================================================================================================
Total params: 434,067
Trainable params: 434,067
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 450
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0639 - acc: 0.9830 - val_loss: 0.0290 - val_acc: 0.9885
Epoch 2/15
 - 8s - loss: 0.0214 - acc: 0.9904 - val_loss: 0.0274 - val_acc: 0.9893
Epoch 3/15
 - 8s - loss: 0.0182 - acc: 0.9916 - val_loss: 0.0290 - val_acc: 0.9889
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0251 - acc: 0.9888
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9913
Epoch 3/3
 - 1s - loss: 0.0149 - acc: 0.9923
# Training time = 0:04:54.173885!
# F-Score(Ordinary) = 0.461, Recall: 0.777, Precision: 0.327
# F-Score(lvc) = 0.462, Recall: 0.71, Precision: 0.343
# F-Score(ireflv) = 0.717, Recall: 0.825, Precision: 0.635
# F-Score(id) = 0.119, Recall: 0.611, Precision: 0.066
********************
# Seed = 6
********************
# XP = Tokens(25) POS(16) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 434217
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_273 (Embedding)       (None, 12, 16)       448         pos[0][0]                        
__________________________________________________________________________________________________
embedding_274 (Embedding)       (None, 12, 25)       429825      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 192)          0           embedding_273[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_274[0][0]              
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 492)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3944        concatenate_17[0][0]             
==================================================================================================
Total params: 434,217
Trainable params: 434,217
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 483
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0624 - acc: 0.9835 - val_loss: 0.0321 - val_acc: 0.9876
Epoch 2/15
 - 7s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0275 - val_acc: 0.9892
Epoch 3/15
 - 8s - loss: 0.0184 - acc: 0.9913 - val_loss: 0.0287 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0252 - acc: 0.9893
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0150 - acc: 0.9926
# Training time = 0:05:55.273617!
# F-Score(Ordinary) = 0.453, Recall: 0.702, Precision: 0.334
# F-Score(lvc) = 0.449, Recall: 0.676, Precision: 0.336
# F-Score(ireflv) = 0.062, Recall: 1.0, Precision: 0.032
# F-Score(id) = 0.607, Recall: 0.684, Precision: 0.545
********************
# Seed = 7
********************
# XP = Tokens(25) POS(16) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 433942
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_275 (Embedding)       (None, 12, 16)       448         pos[0][0]                        
__________________________________________________________________________________________________
embedding_276 (Embedding)       (None, 12, 25)       429550      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 192)          0           embedding_275[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_276[0][0]              
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 492)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3944        concatenate_18[0][0]             
==================================================================================================
Total params: 433,942
Trainable params: 433,942
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 419
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0634 - acc: 0.9817 - val_loss: 0.0285 - val_acc: 0.9886
Epoch 2/15
 - 8s - loss: 0.0214 - acc: 0.9903 - val_loss: 0.0291 - val_acc: 0.9890
Epoch 3/15
 - 8s - loss: 0.0183 - acc: 0.9914 - val_loss: 0.0288 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0252 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0179 - acc: 0.9911
Epoch 3/3
 - 1s - loss: 0.0150 - acc: 0.9925
# Training time = 0:04:58.062958!
# F-Score(Ordinary) = 0.106, Recall: 0.735, Precision: 0.057
# F-Score(lvc) = 0.014, Recall: 0.5, Precision: 0.007
# F-Score(ireflv) = 0.016, Recall: 0.5, Precision: 0.008
# F-Score(id) = 0.223, Recall: 0.733, Precision: 0.132
********************
# Seed = 8
********************
# XP = Tokens(25) POS(16) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 433617
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_277 (Embedding)       (None, 12, 16)       448         pos[0][0]                        
__________________________________________________________________________________________________
embedding_278 (Embedding)       (None, 12, 25)       429225      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 192)          0           embedding_277[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_278[0][0]              
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 492)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3944        concatenate_19[0][0]             
==================================================================================================
Total params: 433,617
Trainable params: 433,617
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 263
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0616 - acc: 0.9817 - val_loss: 0.0288 - val_acc: 0.9884
Epoch 2/15
 - 8s - loss: 0.0215 - acc: 0.9903 - val_loss: 0.0270 - val_acc: 0.9890
Epoch 3/15
 - 8s - loss: 0.0183 - acc: 0.9915 - val_loss: 0.0282 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0250 - acc: 0.9894
Epoch 2/3
 - 1s - loss: 0.0175 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0148 - acc: 0.9923
# Training time = 0:05:22.869807!
# F-Score(Ordinary) = 0.313, Recall: 0.632, Precision: 0.208
# F-Score(lvc) = 0.161, Recall: 0.722, Precision: 0.091
# F-Score(ireflv) = 0.061, Recall: 0.8, Precision: 0.032
# F-Score(id) = 0.507, Recall: 0.603, Precision: 0.437
********************
# Seed = 9
********************
# XP = Tokens(25) POS(16) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 434042
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_279 (Embedding)       (None, 12, 16)       448         pos[0][0]                        
__________________________________________________________________________________________________
embedding_280 (Embedding)       (None, 12, 25)       429650      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 192)          0           embedding_279[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_280[0][0]              
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 492)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            3944        concatenate_20[0][0]             
==================================================================================================
Total params: 434,042
Trainable params: 434,042
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 150
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0636 - acc: 0.9817 - val_loss: 0.0293 - val_acc: 0.9888
Epoch 2/15
 - 8s - loss: 0.0216 - acc: 0.9904 - val_loss: 0.0279 - val_acc: 0.9891
Epoch 3/15
 - 8s - loss: 0.0185 - acc: 0.9914 - val_loss: 0.0294 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0252 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0179 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0152 - acc: 0.9924
# Training time = 0:04:55.458820!
# F-Score(Ordinary) = 0.439, Recall: 0.723, Precision: 0.316
# F-Score(lvc) = 0.374, Recall: 0.673, Precision: 0.259
# F-Score(ireflv) = 0.723, Recall: 0.78, Precision: 0.675
# F-Score(id) = 0.155, Recall: 0.556, Precision: 0.09
********************
Train enabled
# Seed = 0
********************
# XP = Tokens(25) POS(24) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 24
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 434609
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_281 (Embedding)       (None, 12, 24)       672         pos[0][0]                        
__________________________________________________________________________________________________
embedding_282 (Embedding)       (None, 12, 25)       429225      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 288)          0           embedding_281[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_282[0][0]              
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 588)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            4712        concatenate_21[0][0]             
==================================================================================================
Total params: 434,609
Trainable params: 434,609
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 297
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0600 - acc: 0.9823 - val_loss: 0.0278 - val_acc: 0.9888
Epoch 2/15
 - 8s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0275 - val_acc: 0.9892
Epoch 3/15
 - 8s - loss: 0.0184 - acc: 0.9914 - val_loss: 0.0281 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0250 - acc: 0.9894
Epoch 2/3
 - 1s - loss: 0.0177 - acc: 0.9916
Epoch 3/3
 - 1s - loss: 0.0148 - acc: 0.9927
# Training time = 0:04:55.723008!
# F-Score(Ordinary) = 0.301, Recall: 0.759, Precision: 0.188
# F-Score(ireflv) = 0.031, Recall: 0.667, Precision: 0.016
# F-Score(id) = 0.588, Recall: 0.762, Precision: 0.479
********************
# Seed = 1
********************
# XP = Tokens(25) POS(24) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 24
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 434159
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_283 (Embedding)       (None, 12, 24)       672         pos[0][0]                        
__________________________________________________________________________________________________
embedding_284 (Embedding)       (None, 12, 25)       428775      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 288)          0           embedding_283[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_284[0][0]              
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 588)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            4712        concatenate_22[0][0]             
==================================================================================================
Total params: 434,159
Trainable params: 434,159
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 320
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0582 - acc: 0.9856 - val_loss: 0.0279 - val_acc: 0.9891
Epoch 2/15
 - 8s - loss: 0.0214 - acc: 0.9903 - val_loss: 0.0279 - val_acc: 0.9892
Epoch 3/15
 - 8s - loss: 0.0184 - acc: 0.9914 - val_loss: 0.0295 - val_acc: 0.9891
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0255 - acc: 0.9890
Epoch 2/3
 - 1s - loss: 0.0184 - acc: 0.9911
Epoch 3/3
 - 1s - loss: 0.0151 - acc: 0.9923
# Training time = 0:05:01.815970!
# F-Score(Ordinary) = 0.473, Recall: 0.751, Precision: 0.346
# F-Score(lvc) = 0.171, Recall: 0.667, Precision: 0.098
# F-Score(ireflv) = 0.702, Recall: 0.798, Precision: 0.627
# F-Score(id) = 0.46, Recall: 0.704, Precision: 0.341
********************
# Seed = 2
********************
# XP = Tokens(25) POS(24) 
********************
********************
Deep model(Padding) 
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 24
# Features = False
# pos weight matrix = False
# token weight matrix = False
# Parameters = 434309
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
pos (InputLayer)                (None, 12)           0                                            
__________________________________________________________________________________________________
token (InputLayer)              (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_285 (Embedding)       (None, 12, 24)       672         pos[0][0]                        
__________________________________________________________________________________________________
embedding_286 (Embedding)       (None, 12, 25)       428925      token[0][0]                      
__________________________________________________________________________________________________
posFlatten (Flatten)            (None, 288)          0           embedding_285[0][0]              
__________________________________________________________________________________________________
tokenFlatten (Flatten)          (None, 300)          0           embedding_286[0][0]              
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 588)          0           posFlatten[0][0]                 
                                                                 tokenFlatten[0][0]               
__________________________________________________________________________________________________
output (Dense)                  (None, 8)            4712        concatenate_23[0][0]             
==================================================================================================
Total params: 434,309
Trainable params: 434,309
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Schema file: 427
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0582 - acc: 0.9844 - val_loss: 0.0284 - val_acc: 0.9892
Epoch 2/15
 - 8s - loss: 0.0214 - acc: 0.9904 - val_loss: 0.0276 - val_acc: 0.9896
Epoch 3/15
 - 8s - loss: 0.0183 - acc: 0.9915 - val_loss: 0.0283 - val_acc: 0.9892
Epoch 00003: early stopping
Epoch 1/3
 - 1s - loss: 0.0251 - acc: 0.9892
Epoch 2/3
 - 1s - loss: 0.0178 - acc: 0.9917
Epoch 3/3
 - 1s - loss: 0.0150 - acc: 0.9925
