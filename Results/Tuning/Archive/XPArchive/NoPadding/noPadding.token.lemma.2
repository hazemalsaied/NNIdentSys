INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
+_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 12858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 4, 25)             12050     
_________________________________________________________________
flatten_1 (Flatten)          (None, 100)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 8)                 808       
=================================================================
Total params: 12,858
Trainable params: 12,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.7340 - acc: 0.5211 - val_loss: 1.2130 - val_acc: 0.7018
Epoch 2/15
 - 0s - loss: 0.8124 - acc: 0.8669 - val_loss: 0.5377 - val_acc: 0.9715
Epoch 3/15
 - 0s - loss: 0.4285 - acc: 0.9745 - val_loss: 0.3241 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.2731 - acc: 0.9743 - val_loss: 0.2151 - val_acc: 0.9793
Epoch 5/15
 - 0s - loss: 0.1917 - acc: 0.9743 - val_loss: 0.1592 - val_acc: 0.9793
Epoch 00005: early stopping
# Training time = 0:00:07.287524
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_2 (Embedding)      (None, 4, 25)             503550    
_________________________________________________________________
flatten_2 (Flatten)          (None, 100)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0959 - acc: 0.9803 - val_loss: 0.0398 - val_acc: 0.9879
Epoch 2/15
 - 6s - loss: 0.0298 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9884
Epoch 3/15
 - 6s - loss: 0.0237 - acc: 0.9904 - val_loss: 0.0363 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:04:23.503343
# F-Score(Ordinary) = 0.175, Recall: 0.977, Precision: 0.096
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.224, Recall: 0.941, Precision: 0.127
# F-Score(id) = 0.185, Recall: 1.0, Precision: 0.102
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_3 (Embedding)      (None, 4, 25)             503550    
_________________________________________________________________
flatten_3 (Flatten)          (None, 100)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0987 - acc: 0.9803 - val_loss: 0.0396 - val_acc: 0.9880
Epoch 2/15
 - 6s - loss: 0.0293 - acc: 0.9896 - val_loss: 0.0355 - val_acc: 0.9885
Epoch 3/15
 - 6s - loss: 0.0234 - acc: 0.9902 - val_loss: 0.0358 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:04:31.811382
# F-Score(Ordinary) = 0.299, Recall: 0.929, Precision: 0.178
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.222, Recall: 0.889, Precision: 0.127
# F-Score(id) = 0.473, Recall: 0.93, Precision: 0.317
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_4 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_4 (Embedding)      (None, 4, 25)             503550    
_________________________________________________________________
flatten_4 (Flatten)          (None, 100)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0990 - acc: 0.9813 - val_loss: 0.0402 - val_acc: 0.9878
Epoch 2/15
 - 6s - loss: 0.0296 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9886
Epoch 3/15
 - 6s - loss: 0.0235 - acc: 0.9903 - val_loss: 0.0357 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:04:27.638282
# F-Score(Ordinary) = 0.239, Recall: 0.909, Precision: 0.137
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.308, Recall: 0.8, Precision: 0.19
# F-Score(id) = 0.287, Recall: 1.0, Precision: 0.168
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_5 (Embedding)      (None, 4, 25)             503550    
_________________________________________________________________
flatten_5 (Flatten)          (None, 100)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0958 - acc: 0.9828 - val_loss: 0.0402 - val_acc: 0.9878
Epoch 2/15
 - 6s - loss: 0.0297 - acc: 0.9896 - val_loss: 0.0358 - val_acc: 0.9882
Epoch 3/15
 - 6s - loss: 0.0234 - acc: 0.9902 - val_loss: 0.0362 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:04:09.182482
# F-Score(Ordinary) = 0.236, Recall: 0.937, Precision: 0.135
# F-Score(lvc) = 0.081, Recall: 1.0, Precision: 0.042
# F-Score(ireflv) = 0.305, Recall: 0.92, Precision: 0.183
# F-Score(id) = 0.302, Recall: 0.938, Precision: 0.18
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_6 (Embedding)      (None, 4, 25)             503550    
_________________________________________________________________
flatten_6 (Flatten)          (None, 100)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0961 - acc: 0.9823 - val_loss: 0.0407 - val_acc: 0.9878
Epoch 2/15
 - 6s - loss: 0.0302 - acc: 0.9897 - val_loss: 0.0363 - val_acc: 0.9884
Epoch 3/15
 - 6s - loss: 0.0240 - acc: 0.9904 - val_loss: 0.0363 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:04:09.822546
# F-Score(Ordinary) = 0.214, Recall: 0.914, Precision: 0.121
# F-Score(lvc) = 0.166, Recall: 0.929, Precision: 0.091
# F-Score(ireflv) = 0.28, Recall: 0.875, Precision: 0.167
# F-Score(id) = 0.203, Recall: 0.95, Precision: 0.114
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_7 (Embedding)      (None, 4, 25)             503550    
_________________________________________________________________
flatten_7 (Flatten)          (None, 100)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0977 - acc: 0.9817 - val_loss: 0.0392 - val_acc: 0.9881
Epoch 2/15
 - 6s - loss: 0.0291 - acc: 0.9898 - val_loss: 0.0352 - val_acc: 0.9884
Epoch 3/15
 - 6s - loss: 0.0232 - acc: 0.9903 - val_loss: 0.0355 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:04:12.451291
# F-Score(Ordinary) = 0.181, Recall: 0.917, Precision: 0.101
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.282, Recall: 0.913, Precision: 0.167
# F-Score(id) = 0.202, Recall: 0.905, Precision: 0.114
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_8 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_8 (Embedding)      (None, 4, 25)             503550    
_________________________________________________________________
flatten_8 (Flatten)          (None, 100)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0978 - acc: 0.9772 - val_loss: 0.0401 - val_acc: 0.9877
Epoch 2/15
 - 6s - loss: 0.0297 - acc: 0.9897 - val_loss: 0.0363 - val_acc: 0.9883
Epoch 3/15
 - 6s - loss: 0.0238 - acc: 0.9904 - val_loss: 0.0363 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:04:21.894997
# F-Score(Ordinary) = 0.338, Recall: 0.938, Precision: 0.206
# F-Score(lvc) = 0.178, Recall: 1.0, Precision: 0.098
# F-Score(ireflv) = 0.362, Recall: 0.853, Precision: 0.23
# F-Score(id) = 0.437, Recall: 0.979, Precision: 0.281
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_9 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_9 (Embedding)      (None, 4, 25)             503550    
_________________________________________________________________
flatten_9 (Flatten)          (None, 100)               0         
_________________________________________________________________
dense_9 (Dense)              (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0983 - acc: 0.9788 - val_loss: 0.0399 - val_acc: 0.9880
Epoch 2/15
 - 6s - loss: 0.0295 - acc: 0.9896 - val_loss: 0.0364 - val_acc: 0.9884
Epoch 3/15
 - 6s - loss: 0.0235 - acc: 0.9903 - val_loss: 0.0364 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:04:12.014545
# F-Score(Ordinary) = 0.204, Recall: 0.943, Precision: 0.114
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.32, Recall: 1.0, Precision: 0.19
# F-Score(id) = 0.201, Recall: 0.864, Precision: 0.114
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_10 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_10 (Embedding)     (None, 4, 25)             503550    
_________________________________________________________________
flatten_10 (Flatten)         (None, 100)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0980 - acc: 0.9815 - val_loss: 0.0396 - val_acc: 0.9880
Epoch 2/15
 - 6s - loss: 0.0298 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9883
Epoch 3/15
 - 6s - loss: 0.0238 - acc: 0.9902 - val_loss: 0.0357 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:04:32.593995
# F-Score(Ordinary) = 0.132, Recall: 0.969, Precision: 0.071
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.146, Recall: 0.909, Precision: 0.079
# F-Score(id) = 0.124, Recall: 1.0, Precision: 0.066
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_11 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_11 (Embedding)     (None, 4, 25)             503550    
_________________________________________________________________
flatten_11 (Flatten)         (None, 100)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0979 - acc: 0.9794 - val_loss: 0.0399 - val_acc: 0.9880
Epoch 2/15
 - 6s - loss: 0.0294 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9885
Epoch 3/15
 - 6s - loss: 0.0233 - acc: 0.9903 - val_loss: 0.0357 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:24.674731
# F-Score(Ordinary) = 0.182, Recall: 0.957, Precision: 0.101
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.25, Recall: 1.0, Precision: 0.143
# F-Score(id) = 0.173, Recall: 0.889, Precision: 0.096
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 25708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_12 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_12 (Embedding)     (None, 4, 50)             24100     
_________________________________________________________________
flatten_12 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 25,708
Trainable params: 25,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.5528 - acc: 0.8718 - val_loss: 0.8187 - val_acc: 0.9754
Epoch 2/15
 - 0s - loss: 0.4728 - acc: 0.9745 - val_loss: 0.2712 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.2158 - acc: 0.9744 - val_loss: 0.1610 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.1461 - acc: 0.9744 - val_loss: 0.1224 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:06.670396
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_13 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_13 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_13 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_13 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0818 - acc: 0.9836 - val_loss: 0.0381 - val_acc: 0.9882
Epoch 2/15
 - 6s - loss: 0.0282 - acc: 0.9897 - val_loss: 0.0358 - val_acc: 0.9886
Epoch 3/15
 - 6s - loss: 0.0228 - acc: 0.9903 - val_loss: 0.0367 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:04:12.734743
# F-Score(Ordinary) = 0.116, Recall: 0.964, Precision: 0.062
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.146, Recall: 0.909, Precision: 0.079
# F-Score(id) = 0.144, Recall: 1.0, Precision: 0.078
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_14 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_14 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_14 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0815 - acc: 0.9810 - val_loss: 0.0378 - val_acc: 0.9881
Epoch 2/15
 - 6s - loss: 0.0279 - acc: 0.9898 - val_loss: 0.0356 - val_acc: 0.9888
Epoch 3/15
 - 6s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0363 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:03:47.138280
# F-Score(Ordinary) = 0.322, Recall: 0.934, Precision: 0.195
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.222, Recall: 0.889, Precision: 0.127
# F-Score(id) = 0.545, Recall: 0.941, Precision: 0.383
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_15 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_15 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_15 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_15 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0799 - acc: 0.9843 - val_loss: 0.0395 - val_acc: 0.9879
Epoch 2/15
 - 6s - loss: 0.0284 - acc: 0.9897 - val_loss: 0.0367 - val_acc: 0.9883
Epoch 3/15
 - 6s - loss: 0.0228 - acc: 0.9904 - val_loss: 0.0368 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:04:12.819627
# F-Score(Ordinary) = 0.231, Recall: 0.892, Precision: 0.133
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.337, Recall: 0.794, Precision: 0.214
# F-Score(id) = 0.287, Recall: 1.0, Precision: 0.168
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_16 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_16 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_16 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0818 - acc: 0.9824 - val_loss: 0.0386 - val_acc: 0.9882
Epoch 2/15
 - 6s - loss: 0.0283 - acc: 0.9898 - val_loss: 0.0360 - val_acc: 0.9885
Epoch 3/15
 - 6s - loss: 0.0228 - acc: 0.9903 - val_loss: 0.0366 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:04:30.961029
# F-Score(Ordinary) = 0.247, Recall: 0.954, Precision: 0.142
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.34, Recall: 0.963, Precision: 0.206
# F-Score(id) = 0.31, Recall: 0.939, Precision: 0.186
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_17 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_17 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_17 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_17 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0817 - acc: 0.9834 - val_loss: 0.0388 - val_acc: 0.9881
Epoch 2/15
 - 6s - loss: 0.0283 - acc: 0.9898 - val_loss: 0.0361 - val_acc: 0.9882
Epoch 3/15
 - 6s - loss: 0.0227 - acc: 0.9902 - val_loss: 0.0366 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:04:18.528396
# F-Score(Ordinary) = 0.155, Recall: 0.925, Precision: 0.085
# F-Score(lvc) = 0.201, Recall: 1.0, Precision: 0.112
# F-Score(ireflv) = 0.257, Recall: 0.864, Precision: 0.151
# F-Score(id) = 0.024, Recall: 1.0, Precision: 0.012
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_18 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_18 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_18 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0811 - acc: 0.9839 - val_loss: 0.0381 - val_acc: 0.9879
Epoch 2/15
 - 6s - loss: 0.0280 - acc: 0.9897 - val_loss: 0.0354 - val_acc: 0.9886
Epoch 3/15
 - 6s - loss: 0.0228 - acc: 0.9902 - val_loss: 0.0359 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:39.618648
# F-Score(Ordinary) = 0.235, Recall: 0.894, Precision: 0.135
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.325, Recall: 0.893, Precision: 0.198
# F-Score(id) = 0.307, Recall: 0.886, Precision: 0.186
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_19 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_19 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_19 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_19 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0810 - acc: 0.9841 - val_loss: 0.0391 - val_acc: 0.9880
Epoch 2/15
 - 6s - loss: 0.0283 - acc: 0.9898 - val_loss: 0.0362 - val_acc: 0.9886
Epoch 3/15
 - 6s - loss: 0.0228 - acc: 0.9903 - val_loss: 0.0365 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:03:56.454873
# F-Score(Ordinary) = 0.408, Recall: 0.934, Precision: 0.261
# F-Score(lvc) = 0.275, Recall: 0.958, Precision: 0.161
# F-Score(ireflv) = 0.431, Recall: 0.878, Precision: 0.286
# F-Score(id) = 0.491, Recall: 0.965, Precision: 0.329
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_20 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_20 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_20 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0821 - acc: 0.9829 - val_loss: 0.0383 - val_acc: 0.9884
Epoch 2/15
 - 6s - loss: 0.0282 - acc: 0.9898 - val_loss: 0.0366 - val_acc: 0.9884
Epoch 3/15
 - 6s - loss: 0.0228 - acc: 0.9903 - val_loss: 0.0368 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:04:17.197626
# F-Score(Ordinary) = 0.17, Recall: 0.932, Precision: 0.094
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.286, Recall: 1.0, Precision: 0.167
# F-Score(id) = 0.162, Recall: 0.833, Precision: 0.09
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_21 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_21 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_21 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_21 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0817 - acc: 0.9794 - val_loss: 0.0379 - val_acc: 0.9882
Epoch 2/15
 - 6s - loss: 0.0281 - acc: 0.9898 - val_loss: 0.0363 - val_acc: 0.9883
Epoch 3/15
 - 6s - loss: 0.0229 - acc: 0.9902 - val_loss: 0.0359 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:04:16.590997
# F-Score(Ordinary) = 0.128, Recall: 1.0, Precision: 0.069
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.174, Recall: 1.0, Precision: 0.095
# F-Score(id) = 0.091, Recall: 1.0, Precision: 0.048
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_22 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_22 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_22 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_22 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0803 - acc: 0.9835 - val_loss: 0.0384 - val_acc: 0.9882
Epoch 2/15
 - 6s - loss: 0.0278 - acc: 0.9898 - val_loss: 0.0367 - val_acc: 0.9884
Epoch 3/15
 - 6s - loss: 0.0225 - acc: 0.9903 - val_loss: 0.0363 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:04:15.662269
# F-Score(Ordinary) = 0.144, Recall: 0.944, Precision: 0.078
# F-Score(lvc) = 0.143, Recall: 1.0, Precision: 0.077
# F-Score(ireflv) = 0.187, Recall: 1.0, Precision: 0.103
# F-Score(id) = 0.112, Recall: 0.833, Precision: 0.06
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 38558
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_23 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_23 (Embedding)     (None, 4, 75)             36150     
_________________________________________________________________
flatten_23 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_23 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 38,558
Trainable params: 38,558
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.4505 - acc: 0.7865 - val_loss: 0.6999 - val_acc: 0.9764
Epoch 2/15
 - 0s - loss: 0.4432 - acc: 0.9743 - val_loss: 0.2588 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.2001 - acc: 0.9744 - val_loss: 0.1441 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.1310 - acc: 0.9744 - val_loss: 0.1098 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:01.498910
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_24 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_24 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_24 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_24 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0753 - acc: 0.9809 - val_loss: 0.0375 - val_acc: 0.9881
Epoch 2/15
 - 6s - loss: 0.0275 - acc: 0.9898 - val_loss: 0.0362 - val_acc: 0.9884
Epoch 3/15
 - 6s - loss: 0.0224 - acc: 0.9903 - val_loss: 0.0370 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:04:00.758769
# F-Score(Ordinary) = 0.1, Recall: 0.958, Precision: 0.053
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(ireflv) = 0.159, Recall: 0.917, Precision: 0.087
# F-Score(id) = 0.113, Recall: 1.0, Precision: 0.06
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_25 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_25 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_25 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_25 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0738 - acc: 0.9844 - val_loss: 0.0370 - val_acc: 0.9883
Epoch 2/15
 - 6s - loss: 0.0272 - acc: 0.9898 - val_loss: 0.0358 - val_acc: 0.9886
Epoch 3/15
 - 6s - loss: 0.0224 - acc: 0.9903 - val_loss: 0.0368 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:04:32.732416
# F-Score(Ordinary) = 0.316, Recall: 0.933, Precision: 0.19
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.197, Recall: 0.875, Precision: 0.111
# F-Score(id) = 0.545, Recall: 0.941, Precision: 0.383
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_26 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_26 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_26 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_26 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0747 - acc: 0.9845 - val_loss: 0.0389 - val_acc: 0.9883
Epoch 2/15
 - 6s - loss: 0.0276 - acc: 0.9898 - val_loss: 0.0364 - val_acc: 0.9886
Epoch 3/15
 - 6s - loss: 0.0224 - acc: 0.9904 - val_loss: 0.0365 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:08.515965
# F-Score(Ordinary) = 0.242, Recall: 0.91, Precision: 0.14
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(ireflv) = 0.35, Recall: 0.824, Precision: 0.222
# F-Score(id) = 0.313, Recall: 1.0, Precision: 0.186
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_27 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_27 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_27 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_27 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0735 - acc: 0.9852 - val_loss: 0.0381 - val_acc: 0.9882
Epoch 2/15
 - 6s - loss: 0.0276 - acc: 0.9898 - val_loss: 0.0362 - val_acc: 0.9885
Epoch 3/15
 - 6s - loss: 0.0224 - acc: 0.9904 - val_loss: 0.0366 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:04:06.705860
# F-Score(Ordinary) = 0.273, Recall: 0.933, Precision: 0.16
# F-Score(lvc) = 0.054, Recall: 0.8, Precision: 0.028
# F-Score(ireflv) = 0.403, Recall: 0.97, Precision: 0.254
# F-Score(id) = 0.333, Recall: 0.919, Precision: 0.204
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_28 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_28 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_28 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_28 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0734 - acc: 0.9824 - val_loss: 0.0383 - val_acc: 0.9882
Epoch 2/15
 - 6s - loss: 0.0276 - acc: 0.9898 - val_loss: 0.0364 - val_acc: 0.9882
Epoch 3/15
 - 6s - loss: 0.0224 - acc: 0.9903 - val_loss: 0.0371 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:04:12.635106
# F-Score(Ordinary) = 0.124, Recall: 0.935, Precision: 0.066
# F-Score(lvc) = 0.178, Recall: 1.0, Precision: 0.098
# F-Score(ireflv) = 0.197, Recall: 0.875, Precision: 0.111
# F-Score(id) = 0.012, Recall: 1.0, Precision: 0.006
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_29 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_29 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_29 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_29 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0754 - acc: 0.9845 - val_loss: 0.0376 - val_acc: 0.9880
Epoch 2/15
 - 6s - loss: 0.0275 - acc: 0.9898 - val_loss: 0.0356 - val_acc: 0.9887
Epoch 3/15
 - 6s - loss: 0.0225 - acc: 0.9903 - val_loss: 0.0362 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:39.722643
# F-Score(Ordinary) = 0.266, Recall: 0.907, Precision: 0.156
# F-Score(lvc) = 0.041, Recall: 0.75, Precision: 0.021
# F-Score(ireflv) = 0.293, Recall: 0.917, Precision: 0.175
# F-Score(id) = 0.402, Recall: 0.915, Precision: 0.257
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_30 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_30 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_30 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_30 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0745 - acc: 0.9828 - val_loss: 0.0383 - val_acc: 0.9881
Epoch 2/15
 - 6s - loss: 0.0274 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9886
Epoch 3/15
 - 6s - loss: 0.0224 - acc: 0.9903 - val_loss: 0.0368 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:04:19.129661
# F-Score(Ordinary) = 0.435, Recall: 0.932, Precision: 0.284
# F-Score(lvc) = 0.326, Recall: 0.966, Precision: 0.196
# F-Score(ireflv) = 0.431, Recall: 0.878, Precision: 0.286
# F-Score(id) = 0.522, Recall: 0.952, Precision: 0.359
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_31 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_31 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_31 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_31 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0749 - acc: 0.9834 - val_loss: 0.0381 - val_acc: 0.9884
Epoch 2/15
 - 6s - loss: 0.0276 - acc: 0.9899 - val_loss: 0.0369 - val_acc: 0.9883
Epoch 3/15
 - 6s - loss: 0.0225 - acc: 0.9904 - val_loss: 0.0373 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:16.493906
# F-Score(Ordinary) = 0.152, Recall: 0.947, Precision: 0.082
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.25, Recall: 1.0, Precision: 0.143
# F-Score(id) = 0.153, Recall: 0.875, Precision: 0.084
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_32 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_32 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_32 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_32 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0745 - acc: 0.9843 - val_loss: 0.0373 - val_acc: 0.9882
Epoch 2/15
 - 6s - loss: 0.0274 - acc: 0.9898 - val_loss: 0.0366 - val_acc: 0.9883
Epoch 3/15
 - 6s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0361 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:03:58.531284
# F-Score(Ordinary) = 0.12, Recall: 0.966, Precision: 0.064
# F-Score(lvc) = 0.142, Recall: 0.917, Precision: 0.077
# F-Score(ireflv) = 0.174, Recall: 1.0, Precision: 0.095
# F-Score(id) = 0.058, Recall: 1.0, Precision: 0.03
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_33 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_33 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_33 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_33 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0737 - acc: 0.9843 - val_loss: 0.0379 - val_acc: 0.9883
Epoch 2/15
 - 6s - loss: 0.0275 - acc: 0.9898 - val_loss: 0.0369 - val_acc: 0.9885
Epoch 3/15
 - 6s - loss: 0.0224 - acc: 0.9904 - val_loss: 0.0361 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:04:21.411948
# F-Score(Ordinary) = 0.148, Recall: 0.946, Precision: 0.08
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.213, Recall: 1.0, Precision: 0.119
# F-Score(id) = 0.122, Recall: 0.846, Precision: 0.066
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 51408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_34 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_34 (Embedding)     (None, 4, 100)            48200     
_________________________________________________________________
flatten_34 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_34 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 51,408
Trainable params: 51,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.3386 - acc: 0.8678 - val_loss: 0.5610 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.3456 - acc: 0.9745 - val_loss: 0.1985 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1603 - acc: 0.9743 - val_loss: 0.1233 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.1130 - acc: 0.9747 - val_loss: 0.1001 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:01.486610
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_35 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_35 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_35 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_35 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0696 - acc: 0.9849 - val_loss: 0.0375 - val_acc: 0.9880
Epoch 2/15
 - 6s - loss: 0.0272 - acc: 0.9898 - val_loss: 0.0367 - val_acc: 0.9884
Epoch 3/15
 - 6s - loss: 0.0224 - acc: 0.9904 - val_loss: 0.0376 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:03:53.047864
# F-Score(Ordinary) = 0.087, Recall: 0.909, Precision: 0.046
# F-Score(lvc) = 0.027, Recall: 0.667, Precision: 0.014
# F-Score(ireflv) = 0.132, Recall: 0.9, Precision: 0.071
# F-Score(id) = 0.102, Recall: 1.0, Precision: 0.054
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_36 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_36 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_36 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_36 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0704 - acc: 0.9839 - val_loss: 0.0372 - val_acc: 0.9883
Epoch 2/15
 - 6s - loss: 0.0270 - acc: 0.9897 - val_loss: 0.0359 - val_acc: 0.9886
Epoch 3/15
 - 6s - loss: 0.0222 - acc: 0.9902 - val_loss: 0.0369 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:03:44.602293
# F-Score(Ordinary) = 0.335, Recall: 0.947, Precision: 0.204
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.211, Recall: 0.938, Precision: 0.119
# F-Score(id) = 0.575, Recall: 0.945, Precision: 0.413
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_37 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_37 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_37 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_37 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0704 - acc: 0.9846 - val_loss: 0.0388 - val_acc: 0.9884
Epoch 2/15
 - 6s - loss: 0.0273 - acc: 0.9898 - val_loss: 0.0365 - val_acc: 0.9886
Epoch 3/15
 - 6s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0366 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:03:54.900388
# F-Score(Ordinary) = 0.252, Recall: 0.914, Precision: 0.146
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(ireflv) = 0.36, Recall: 0.829, Precision: 0.23
# F-Score(id) = 0.33, Recall: 1.0, Precision: 0.198
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_38 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_38 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_38 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_38 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0700 - acc: 0.9844 - val_loss: 0.0378 - val_acc: 0.9882
Epoch 2/15
 - 6s - loss: 0.0273 - acc: 0.9898 - val_loss: 0.0363 - val_acc: 0.9886
Epoch 3/15
 - 6s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0368 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:04:54.894129
# F-Score(Ordinary) = 0.277, Recall: 0.934, Precision: 0.162
# F-Score(lvc) = 0.054, Recall: 0.8, Precision: 0.028
# F-Score(ireflv) = 0.403, Recall: 0.97, Precision: 0.254
# F-Score(id) = 0.341, Recall: 0.921, Precision: 0.21
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_39 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_39 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_39 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_39 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0703 - acc: 0.9851 - val_loss: 0.0380 - val_acc: 0.9880
Epoch 2/15
 - 6s - loss: 0.0272 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9883
Epoch 3/15
 - 6s - loss: 0.0222 - acc: 0.9903 - val_loss: 0.0369 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:04:03.860433
# F-Score(Ordinary) = 0.132, Recall: 0.939, Precision: 0.071
# F-Score(lvc) = 0.178, Recall: 1.0, Precision: 0.098
# F-Score(ireflv) = 0.222, Recall: 0.889, Precision: 0.127
# F-Score(id) = 0.012, Recall: 1.0, Precision: 0.006
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_40 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_40 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_40 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_40 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0709 - acc: 0.9821 - val_loss: 0.0375 - val_acc: 0.9880
Epoch 2/15
 - 6s - loss: 0.0271 - acc: 0.9898 - val_loss: 0.0358 - val_acc: 0.9886
Epoch 3/15
 - 6s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0364 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:11.067853
# F-Score(Ordinary) = 0.276, Recall: 0.922, Precision: 0.162
# F-Score(lvc) = 0.041, Recall: 0.75, Precision: 0.021
# F-Score(ireflv) = 0.284, Recall: 0.955, Precision: 0.167
# F-Score(id) = 0.431, Recall: 0.922, Precision: 0.281
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_41 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_41 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_41 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_41 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0700 - acc: 0.9832 - val_loss: 0.0382 - val_acc: 0.9882
Epoch 2/15
 - 6s - loss: 0.0272 - acc: 0.9898 - val_loss: 0.0361 - val_acc: 0.9886
Epoch 3/15
 - 6s - loss: 0.0224 - acc: 0.9903 - val_loss: 0.0368 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:04:47.193013
# F-Score(Ordinary) = 0.44, Recall: 0.926, Precision: 0.288
# F-Score(lvc) = 0.326, Recall: 0.966, Precision: 0.196
# F-Score(ireflv) = 0.452, Recall: 0.905, Precision: 0.302
# F-Score(id) = 0.517, Recall: 0.923, Precision: 0.359
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_42 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_42 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_42 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_42 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0702 - acc: 0.9846 - val_loss: 0.0379 - val_acc: 0.9885
Epoch 2/15
 - 6s - loss: 0.0272 - acc: 0.9899 - val_loss: 0.0371 - val_acc: 0.9883
Epoch 3/15
 - 6s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0376 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:41.281370
# F-Score(Ordinary) = 0.148, Recall: 0.946, Precision: 0.08
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.25, Recall: 1.0, Precision: 0.143
# F-Score(id) = 0.143, Recall: 0.867, Precision: 0.078
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_43 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_43 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_43 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_43 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0700 - acc: 0.9836 - val_loss: 0.0372 - val_acc: 0.9883
Epoch 2/15
 - 6s - loss: 0.0272 - acc: 0.9898 - val_loss: 0.0367 - val_acc: 0.9885
Epoch 3/15
 - 6s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0359 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:04:15.778258
# F-Score(Ordinary) = 0.112, Recall: 0.963, Precision: 0.059
# F-Score(lvc) = 0.154, Recall: 0.923, Precision: 0.084
# F-Score(ireflv) = 0.147, Recall: 1.0, Precision: 0.079
# F-Score(id) = 0.047, Recall: 1.0, Precision: 0.024
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_44 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_44 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_44 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_44 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0692 - acc: 0.9852 - val_loss: 0.0377 - val_acc: 0.9883
Epoch 2/15
 - 6s - loss: 0.0270 - acc: 0.9898 - val_loss: 0.0371 - val_acc: 0.9886
Epoch 3/15
 - 6s - loss: 0.0221 - acc: 0.9904 - val_loss: 0.0363 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:12.646628
# F-Score(Ordinary) = 0.136, Recall: 0.941, Precision: 0.073
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.187, Recall: 1.0, Precision: 0.103
# F-Score(id) = 0.122, Recall: 0.846, Precision: 0.066
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 64258
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_45 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_45 (Embedding)     (None, 4, 125)            60250     
_________________________________________________________________
flatten_45 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_45 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 64,258
Trainable params: 64,258
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.2308 - acc: 0.8993 - val_loss: 0.4564 - val_acc: 0.9783
Epoch 2/15
 - 0s - loss: 0.2824 - acc: 0.9743 - val_loss: 0.1676 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1414 - acc: 0.9742 - val_loss: 0.1124 - val_acc: 0.9783
Epoch 4/15
 - 0s - loss: 0.1038 - acc: 0.9748 - val_loss: 0.0941 - val_acc: 0.9783
Epoch 00004: early stopping
# Training time = 0:00:01.486771
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_46 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_46 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_46 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_46 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0665 - acc: 0.9855 - val_loss: 0.0371 - val_acc: 0.9880
Epoch 2/15
 - 7s - loss: 0.0270 - acc: 0.9898 - val_loss: 0.0365 - val_acc: 0.9885
Epoch 3/15
 - 7s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0374 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:04:07.345318
# F-Score(Ordinary) = 0.083, Recall: 0.95, Precision: 0.043
# F-Score(ireflv) = 0.146, Recall: 0.909, Precision: 0.079
# F-Score(id) = 0.102, Recall: 1.0, Precision: 0.054
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_47 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_47 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_47 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_47 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0673 - acc: 0.9855 - val_loss: 0.0371 - val_acc: 0.9884
Epoch 2/15
 - 7s - loss: 0.0269 - acc: 0.9897 - val_loss: 0.0358 - val_acc: 0.9886
Epoch 3/15
 - 7s - loss: 0.0222 - acc: 0.9902 - val_loss: 0.0368 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:04:35.947348
# F-Score(Ordinary) = 0.332, Recall: 0.946, Precision: 0.201
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.224, Recall: 0.941, Precision: 0.127
# F-Score(id) = 0.563, Recall: 0.944, Precision: 0.401
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_48 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_48 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_48 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_48 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0675 - acc: 0.9848 - val_loss: 0.0390 - val_acc: 0.9884
Epoch 2/15
 - 7s - loss: 0.0271 - acc: 0.9898 - val_loss: 0.0367 - val_acc: 0.9886
Epoch 3/15
 - 7s - loss: 0.0224 - acc: 0.9904 - val_loss: 0.0369 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:06.845634
# F-Score(Ordinary) = 0.246, Recall: 0.912, Precision: 0.142
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(ireflv) = 0.36, Recall: 0.829, Precision: 0.23
# F-Score(id) = 0.313, Recall: 1.0, Precision: 0.186
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_49 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_49 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_49 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_49 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0670 - acc: 0.9834 - val_loss: 0.0380 - val_acc: 0.9881
Epoch 2/15
 - 7s - loss: 0.0273 - acc: 0.9898 - val_loss: 0.0366 - val_acc: 0.9887
Epoch 3/15
 - 7s - loss: 0.0224 - acc: 0.9904 - val_loss: 0.0369 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:04:39.350964
# F-Score(Ordinary) = 0.287, Recall: 0.949, Precision: 0.169
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.422, Recall: 0.971, Precision: 0.27
# F-Score(id) = 0.35, Recall: 0.923, Precision: 0.216
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_50 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_50 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_50 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_50 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0661 - acc: 0.9859 - val_loss: 0.0382 - val_acc: 0.9880
Epoch 2/15
 - 7s - loss: 0.0273 - acc: 0.9897 - val_loss: 0.0364 - val_acc: 0.9883
Epoch 3/15
 - 7s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0373 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:04:37.786926
# F-Score(Ordinary) = 0.116, Recall: 0.931, Precision: 0.062
# F-Score(lvc) = 0.167, Recall: 1.0, Precision: 0.091
# F-Score(ireflv) = 0.184, Recall: 0.867, Precision: 0.103
# F-Score(id) = 0.012, Recall: 1.0, Precision: 0.006
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_51 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_51 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_51 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_51 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0671 - acc: 0.9852 - val_loss: 0.0374 - val_acc: 0.9879
Epoch 2/15
 - 7s - loss: 0.0269 - acc: 0.9897 - val_loss: 0.0359 - val_acc: 0.9886
Epoch 3/15
 - 7s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0365 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:10.912242
# F-Score(Ordinary) = 0.282, Recall: 0.912, Precision: 0.167
# F-Score(lvc) = 0.041, Recall: 0.75, Precision: 0.021
# F-Score(ireflv) = 0.282, Recall: 0.913, Precision: 0.167
# F-Score(id) = 0.445, Recall: 0.925, Precision: 0.293
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_52 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_52 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_52 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_52 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0669 - acc: 0.9848 - val_loss: 0.0384 - val_acc: 0.9880
Epoch 2/15
 - 7s - loss: 0.0270 - acc: 0.9898 - val_loss: 0.0362 - val_acc: 0.9886
Epoch 3/15
 - 7s - loss: 0.0223 - acc: 0.9903 - val_loss: 0.0372 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:04:16.435679
# F-Score(Ordinary) = 0.46, Recall: 0.924, Precision: 0.307
# F-Score(lvc) = 0.345, Recall: 0.968, Precision: 0.21
# F-Score(ireflv) = 0.459, Recall: 0.886, Precision: 0.31
# F-Score(id) = 0.549, Recall: 0.929, Precision: 0.389
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_53 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_53 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_53 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_53 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0671 - acc: 0.9839 - val_loss: 0.0382 - val_acc: 0.9885
Epoch 2/15
 - 7s - loss: 0.0271 - acc: 0.9898 - val_loss: 0.0373 - val_acc: 0.9883
Epoch 3/15
 - 7s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0379 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:21.525047
# F-Score(Ordinary) = 0.136, Recall: 0.941, Precision: 0.073
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.213, Recall: 1.0, Precision: 0.119
# F-Score(id) = 0.143, Recall: 0.867, Precision: 0.078
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_54 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_54 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_54 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_54 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0675 - acc: 0.9849 - val_loss: 0.0372 - val_acc: 0.9883
Epoch 2/15
 - 7s - loss: 0.0270 - acc: 0.9898 - val_loss: 0.0370 - val_acc: 0.9885
Epoch 3/15
 - 7s - loss: 0.0223 - acc: 0.9903 - val_loss: 0.0361 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:04:10.591546
# F-Score(Ordinary) = 0.124, Recall: 0.967, Precision: 0.066
# F-Score(lvc) = 0.177, Recall: 0.933, Precision: 0.098
# F-Score(ireflv) = 0.161, Recall: 1.0, Precision: 0.087
# F-Score(id) = 0.047, Recall: 1.0, Precision: 0.024
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_55 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_55 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_55 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_55 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0662 - acc: 0.9845 - val_loss: 0.0376 - val_acc: 0.9882
Epoch 2/15
 - 7s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0372 - val_acc: 0.9885
Epoch 3/15
 - 7s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0363 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:15.368974
# F-Score(Ordinary) = 0.148, Recall: 0.946, Precision: 0.08
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.174, Recall: 1.0, Precision: 0.095
# F-Score(id) = 0.143, Recall: 0.867, Precision: 0.078
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 77108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_56 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_56 (Embedding)     (None, 4, 150)            72300     
_________________________________________________________________
flatten_56 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_56 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 77,108
Trainable params: 77,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.1726 - acc: 0.8589 - val_loss: 0.4196 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.2560 - acc: 0.9743 - val_loss: 0.1511 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1298 - acc: 0.9745 - val_loss: 0.1056 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.0968 - acc: 0.9756 - val_loss: 0.0900 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:01.531695
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_57 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_57 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_57 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_57 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0654 - acc: 0.9851 - val_loss: 0.0372 - val_acc: 0.9881
Epoch 2/15
 - 8s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0368 - val_acc: 0.9885
Epoch 3/15
 - 8s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0378 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:03:57.173661
# F-Score(Ordinary) = 0.087, Recall: 0.952, Precision: 0.046
# F-Score(ireflv) = 0.159, Recall: 0.917, Precision: 0.087
# F-Score(id) = 0.102, Recall: 1.0, Precision: 0.054
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_58 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_58 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_58 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_58 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0645 - acc: 0.9851 - val_loss: 0.0372 - val_acc: 0.9884
Epoch 2/15
 - 8s - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0359 - val_acc: 0.9887
Epoch 3/15
 - 8s - loss: 0.0222 - acc: 0.9903 - val_loss: 0.0368 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:03:50.410252
# F-Score(Ordinary) = 0.338, Recall: 0.938, Precision: 0.206
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.21, Recall: 0.882, Precision: 0.119
# F-Score(id) = 0.581, Recall: 0.946, Precision: 0.419
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_59 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_59 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_59 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_59 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0652 - acc: 0.9852 - val_loss: 0.0389 - val_acc: 0.9884
Epoch 2/15
 - 8s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0366 - val_acc: 0.9886
Epoch 3/15
 - 8s - loss: 0.0221 - acc: 0.9905 - val_loss: 0.0368 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:02.731881
# F-Score(Ordinary) = 0.242, Recall: 0.91, Precision: 0.14
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(ireflv) = 0.362, Recall: 0.853, Precision: 0.23
# F-Score(id) = 0.303, Recall: 0.968, Precision: 0.18
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_60 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_60 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_60 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_60 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0645 - acc: 0.9861 - val_loss: 0.0379 - val_acc: 0.9881
Epoch 2/15
 - 8s - loss: 0.0271 - acc: 0.9898 - val_loss: 0.0365 - val_acc: 0.9885
Epoch 3/15
 - 8s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0368 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:04:50.313579
# F-Score(Ordinary) = 0.29, Recall: 0.926, Precision: 0.172
# F-Score(lvc) = 0.054, Recall: 0.8, Precision: 0.028
# F-Score(ireflv) = 0.41, Recall: 0.943, Precision: 0.262
# F-Score(id) = 0.365, Recall: 0.927, Precision: 0.228
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_61 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_61 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_61 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_61 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0645 - acc: 0.9855 - val_loss: 0.0384 - val_acc: 0.9878
Epoch 2/15
 - 8s - loss: 0.0271 - acc: 0.9898 - val_loss: 0.0366 - val_acc: 0.9883
Epoch 3/15
 - 8s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0375 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:04:42.927895
# F-Score(Ordinary) = 0.091, Recall: 0.913, Precision: 0.048
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.184, Recall: 0.867, Precision: 0.103
# F-Score(id) = 0.012, Recall: 1.0, Precision: 0.006
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_62 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_62 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_62 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_62 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0642 - acc: 0.9853 - val_loss: 0.0377 - val_acc: 0.9879
Epoch 2/15
 - 8s - loss: 0.0269 - acc: 0.9897 - val_loss: 0.0359 - val_acc: 0.9885
Epoch 3/15
 - 8s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0365 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:04:14.571948
# F-Score(Ordinary) = 0.303, Recall: 0.94, Precision: 0.181
# F-Score(lvc) = 0.027, Recall: 0.667, Precision: 0.014
# F-Score(ireflv) = 0.309, Recall: 1.0, Precision: 0.183
# F-Score(id) = 0.48, Recall: 0.931, Precision: 0.323
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_63 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_63 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_63 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_63 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0643 - acc: 0.9853 - val_loss: 0.0384 - val_acc: 0.9880
Epoch 2/15
 - 8s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0363 - val_acc: 0.9886
Epoch 3/15
 - 8s - loss: 0.0223 - acc: 0.9903 - val_loss: 0.0371 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:04:34.288723
# F-Score(Ordinary) = 0.455, Recall: 0.923, Precision: 0.302
# F-Score(lvc) = 0.343, Recall: 0.938, Precision: 0.21
# F-Score(ireflv) = 0.443, Recall: 0.902, Precision: 0.294
# F-Score(id) = 0.549, Recall: 0.929, Precision: 0.389
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_64 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_64 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_64 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_64 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0650 - acc: 0.9852 - val_loss: 0.0382 - val_acc: 0.9884
Epoch 2/15
 - 8s - loss: 0.0270 - acc: 0.9899 - val_loss: 0.0376 - val_acc: 0.9883
Epoch 3/15
 - 8s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0381 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:10.069000
# F-Score(Ordinary) = 0.124, Recall: 0.935, Precision: 0.066
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.213, Recall: 1.0, Precision: 0.119
# F-Score(id) = 0.122, Recall: 0.846, Precision: 0.066
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_65 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_65 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_65 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_65 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0644 - acc: 0.9852 - val_loss: 0.0374 - val_acc: 0.9882
Epoch 2/15
 - 8s - loss: 0.0268 - acc: 0.9899 - val_loss: 0.0373 - val_acc: 0.9883
Epoch 3/15
 - 8s - loss: 0.0224 - acc: 0.9903 - val_loss: 0.0364 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:04:23.311898
# F-Score(Ordinary) = 0.116, Recall: 0.964, Precision: 0.062
# F-Score(lvc) = 0.166, Recall: 0.929, Precision: 0.091
# F-Score(ireflv) = 0.147, Recall: 1.0, Precision: 0.079
# F-Score(id) = 0.047, Recall: 1.0, Precision: 0.024
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_66 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_66 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_66 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_66 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0648 - acc: 0.9851 - val_loss: 0.0376 - val_acc: 0.9882
Epoch 2/15
 - 8s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0373 - val_acc: 0.9885
Epoch 3/15
 - 8s - loss: 0.0221 - acc: 0.9904 - val_loss: 0.0362 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:04:15.659950
# F-Score(Ordinary) = 0.151, Recall: 0.923, Precision: 0.082
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.187, Recall: 1.0, Precision: 0.103
# F-Score(id) = 0.152, Recall: 0.824, Precision: 0.084
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 89958
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_67 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_67 (Embedding)     (None, 4, 175)            84350     
_________________________________________________________________
flatten_67 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_67 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 89,958
Trainable params: 89,958
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.1129 - acc: 0.8838 - val_loss: 0.3667 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.2275 - acc: 0.9743 - val_loss: 0.1399 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1221 - acc: 0.9745 - val_loss: 0.1014 - val_acc: 0.9783
Epoch 4/15
 - 0s - loss: 0.0926 - acc: 0.9759 - val_loss: 0.0875 - val_acc: 0.9783
Epoch 00004: early stopping
# Training time = 0:00:06.586293
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_68 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_68 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_68 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_68 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0627 - acc: 0.9854 - val_loss: 0.0371 - val_acc: 0.9881
Epoch 2/15
 - 9s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0365 - val_acc: 0.9885
Epoch 3/15
 - 9s - loss: 0.0221 - acc: 0.9904 - val_loss: 0.0375 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:04:27.910267
# F-Score(Ordinary) = 0.087, Recall: 0.952, Precision: 0.046
# F-Score(ireflv) = 0.146, Recall: 0.909, Precision: 0.079
# F-Score(id) = 0.113, Recall: 1.0, Precision: 0.06
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_69 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_69 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_69 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_69 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0631 - acc: 0.9853 - val_loss: 0.0376 - val_acc: 0.9884
Epoch 2/15
 - 9s - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9887
Epoch 3/15
 - 9s - loss: 0.0222 - acc: 0.9903 - val_loss: 0.0368 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:03:56.453126
# F-Score(Ordinary) = 0.331, Recall: 0.926, Precision: 0.201
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.221, Recall: 0.842, Precision: 0.127
# F-Score(id) = 0.569, Recall: 0.944, Precision: 0.407
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_70 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_70 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_70 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_70 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0631 - acc: 0.9857 - val_loss: 0.0390 - val_acc: 0.9884
Epoch 2/15
 - 9s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0364 - val_acc: 0.9885
Epoch 3/15
 - 9s - loss: 0.0221 - acc: 0.9904 - val_loss: 0.0364 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:03:52.852094
# F-Score(Ordinary) = 0.236, Recall: 0.922, Precision: 0.135
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.365, Recall: 0.879, Precision: 0.23
# F-Score(id) = 0.294, Recall: 0.967, Precision: 0.174
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_71 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_71 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_71 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_71 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0631 - acc: 0.9856 - val_loss: 0.0381 - val_acc: 0.9882
Epoch 2/15
 - 9s - loss: 0.0270 - acc: 0.9898 - val_loss: 0.0368 - val_acc: 0.9885
Epoch 3/15
 - 9s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0371 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:04:20.233401
# F-Score(Ordinary) = 0.297, Recall: 0.939, Precision: 0.176
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.41, Recall: 0.943, Precision: 0.262
# F-Score(id) = 0.373, Recall: 0.929, Precision: 0.234
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_72 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_72 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_72 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_72 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0634 - acc: 0.9850 - val_loss: 0.0384 - val_acc: 0.9878
Epoch 2/15
 - 9s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0365 - val_acc: 0.9883
Epoch 3/15
 - 9s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0374 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:04:00.557745
# F-Score(Ordinary) = 0.1, Recall: 0.92, Precision: 0.053
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.21, Recall: 0.882, Precision: 0.119
# F-Score(id) = 0.012, Recall: 1.0, Precision: 0.006
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_73 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_73 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_73 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_73 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0627 - acc: 0.9852 - val_loss: 0.0377 - val_acc: 0.9879
Epoch 2/15
 - 9s - loss: 0.0267 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9886
Epoch 3/15
 - 9s - loss: 0.0222 - acc: 0.9903 - val_loss: 0.0368 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:03:55.407834
# F-Score(Ordinary) = 0.303, Recall: 0.929, Precision: 0.181
# F-Score(lvc) = 0.027, Recall: 0.667, Precision: 0.014
# F-Score(ireflv) = 0.26, Recall: 0.95, Precision: 0.151
# F-Score(id) = 0.507, Recall: 0.935, Precision: 0.347
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_74 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_74 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_74 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_74 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0637 - acc: 0.9835 - val_loss: 0.0385 - val_acc: 0.9879
Epoch 2/15
 - 9s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0363 - val_acc: 0.9885
Epoch 3/15
 - 9s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0374 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:03:58.354756
# F-Score(Ordinary) = 0.462, Recall: 0.918, Precision: 0.309
# F-Score(lvc) = 0.345, Recall: 0.968, Precision: 0.21
# F-Score(ireflv) = 0.465, Recall: 0.87, Precision: 0.317
# F-Score(id) = 0.549, Recall: 0.929, Precision: 0.389
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_75 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_75 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_75 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_75 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0638 - acc: 0.9854 - val_loss: 0.0385 - val_acc: 0.9884
Epoch 2/15
 - 9s - loss: 0.0269 - acc: 0.9899 - val_loss: 0.0376 - val_acc: 0.9882
Epoch 3/15
 - 9s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0380 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:04:38.928969
# F-Score(Ordinary) = 0.124, Recall: 0.935, Precision: 0.066
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.2, Recall: 1.0, Precision: 0.111
# F-Score(id) = 0.122, Recall: 0.846, Precision: 0.066
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_76 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_76 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_76 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_76 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0626 - acc: 0.9844 - val_loss: 0.0374 - val_acc: 0.9882
Epoch 2/15
 - 9s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0373 - val_acc: 0.9883
Epoch 3/15
 - 9s - loss: 0.0224 - acc: 0.9903 - val_loss: 0.0362 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:06.108634
# F-Score(Ordinary) = 0.12, Recall: 0.966, Precision: 0.064
# F-Score(lvc) = 0.189, Recall: 0.938, Precision: 0.105
# F-Score(ireflv) = 0.147, Recall: 1.0, Precision: 0.079
# F-Score(id) = 0.035, Recall: 1.0, Precision: 0.018
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_77 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_77 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_77 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_77 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0626 - acc: 0.9851 - val_loss: 0.0378 - val_acc: 0.9883
Epoch 2/15
 - 9s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0374 - val_acc: 0.9885
Epoch 3/15
 - 9s - loss: 0.0221 - acc: 0.9904 - val_loss: 0.0362 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:00.576636
# F-Score(Ordinary) = 0.178, Recall: 0.935, Precision: 0.098
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.25, Recall: 1.0, Precision: 0.143
# F-Score(id) = 0.162, Recall: 0.833, Precision: 0.09
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 102808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_78 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_78 (Embedding)     (None, 4, 200)            96400     
_________________________________________________________________
flatten_78 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_78 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 102,808
Trainable params: 102,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.0337 - acc: 0.8884 - val_loss: 0.3276 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.2054 - acc: 0.9743 - val_loss: 0.1280 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1142 - acc: 0.9750 - val_loss: 0.0962 - val_acc: 0.9783
Epoch 4/15
 - 0s - loss: 0.0879 - acc: 0.9767 - val_loss: 0.0847 - val_acc: 0.9813
Epoch 5/15
 - 0s - loss: 0.0736 - acc: 0.9811 - val_loss: 0.0784 - val_acc: 0.9833
Epoch 00005: early stopping
# Training time = 0:00:06.699343
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_79 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_79 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_79 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_79 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0618 - acc: 0.9848 - val_loss: 0.0373 - val_acc: 0.9881
Epoch 2/15
 - 9s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0370 - val_acc: 0.9886
Epoch 3/15
 - 9s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0379 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:04:34.001551
# F-Score(Ordinary) = 0.083, Recall: 0.95, Precision: 0.043
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.132, Recall: 0.9, Precision: 0.071
# F-Score(id) = 0.102, Recall: 1.0, Precision: 0.054
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_80 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_80 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_80 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_80 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0620 - acc: 0.9844 - val_loss: 0.0376 - val_acc: 0.9883
Epoch 2/15
 - 9s - loss: 0.0266 - acc: 0.9897 - val_loss: 0.0360 - val_acc: 0.9887
Epoch 3/15
 - 9s - loss: 0.0221 - acc: 0.9903 - val_loss: 0.0369 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:03:54.944922
# F-Score(Ordinary) = 0.343, Recall: 0.929, Precision: 0.211
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.257, Recall: 0.864, Precision: 0.151
# F-Score(id) = 0.575, Recall: 0.945, Precision: 0.413
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_81 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_81 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_81 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_81 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0622 - acc: 0.9846 - val_loss: 0.0392 - val_acc: 0.9884
Epoch 2/15
 - 9s - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0365 - val_acc: 0.9885
Epoch 3/15
 - 9s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0367 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:09.152941
# F-Score(Ordinary) = 0.25, Recall: 0.926, Precision: 0.144
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.365, Recall: 0.879, Precision: 0.23
# F-Score(id) = 0.328, Recall: 0.971, Precision: 0.198
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_82 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_82 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_82 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_82 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0616 - acc: 0.9847 - val_loss: 0.0382 - val_acc: 0.9881
Epoch 2/15
 - 9s - loss: 0.0270 - acc: 0.9898 - val_loss: 0.0369 - val_acc: 0.9885
Epoch 3/15
 - 9s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0374 - val_acc: 0.9882
Epoch 00003: early stopping
# Training time = 0:03:55.298918
# F-Score(Ordinary) = 0.3, Recall: 0.94, Precision: 0.178
# F-Score(lvc) = 0.081, Recall: 1.0, Precision: 0.042
# F-Score(ireflv) = 0.41, Recall: 0.943, Precision: 0.262
# F-Score(id) = 0.373, Recall: 0.929, Precision: 0.234
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_83 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_83 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_83 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_83 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0617 - acc: 0.9850 - val_loss: 0.0385 - val_acc: 0.9878
Epoch 2/15
 - 9s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0367 - val_acc: 0.9883
Epoch 3/15
 - 9s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0377 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:03:54.906453
# F-Score(Ordinary) = 0.087, Recall: 0.952, Precision: 0.046
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.186, Recall: 0.929, Precision: 0.103
# F-Score(id) = 0.024, Recall: 1.0, Precision: 0.012
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_84 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_84 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_84 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_84 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0620 - acc: 0.9854 - val_loss: 0.0376 - val_acc: 0.9878
Epoch 2/15
 - 9s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0359 - val_acc: 0.9886
Epoch 3/15
 - 9s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0367 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:03:58.427949
# F-Score(Ordinary) = 0.303, Recall: 0.929, Precision: 0.181
# F-Score(lvc) = 0.027, Recall: 0.667, Precision: 0.014
# F-Score(ireflv) = 0.272, Recall: 0.952, Precision: 0.159
# F-Score(id) = 0.5, Recall: 0.934, Precision: 0.341
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_85 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_85 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_85 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_85 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0621 - acc: 0.9853 - val_loss: 0.0385 - val_acc: 0.9880
Epoch 2/15
 - 9s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0364 - val_acc: 0.9886
Epoch 3/15
 - 9s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0375 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:03:52.690208
# F-Score(Ordinary) = 0.466, Recall: 0.925, Precision: 0.311
# F-Score(lvc) = 0.335, Recall: 0.967, Precision: 0.203
# F-Score(ireflv) = 0.477, Recall: 0.891, Precision: 0.325
# F-Score(id) = 0.555, Recall: 0.93, Precision: 0.395
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_86 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_86 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_86 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_86 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0619 - acc: 0.9847 - val_loss: 0.0384 - val_acc: 0.9884
Epoch 2/15
 - 9s - loss: 0.0268 - acc: 0.9899 - val_loss: 0.0376 - val_acc: 0.9882
Epoch 3/15
 - 9s - loss: 0.0221 - acc: 0.9904 - val_loss: 0.0380 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:03:53.016077
# F-Score(Ordinary) = 0.112, Recall: 0.929, Precision: 0.059
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.161, Recall: 1.0, Precision: 0.087
# F-Score(id) = 0.122, Recall: 0.846, Precision: 0.066
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_87 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_87 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_87 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_87 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0620 - acc: 0.9857 - val_loss: 0.0376 - val_acc: 0.9881
Epoch 2/15
 - 9s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0375 - val_acc: 0.9883
Epoch 3/15
 - 9s - loss: 0.0223 - acc: 0.9903 - val_loss: 0.0363 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:04:05.990176
# F-Score(Ordinary) = 0.104, Recall: 1.0, Precision: 0.055
# F-Score(lvc) = 0.178, Recall: 1.0, Precision: 0.098
# F-Score(ireflv) = 0.119, Recall: 1.0, Precision: 0.063
# F-Score(id) = 0.024, Recall: 1.0, Precision: 0.012
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_88 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_88 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_88 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_88 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0615 - acc: 0.9859 - val_loss: 0.0379 - val_acc: 0.9883
Epoch 2/15
 - 9s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0375 - val_acc: 0.9886
Epoch 3/15
 - 9s - loss: 0.0221 - acc: 0.9905 - val_loss: 0.0363 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:03:57.845295
# F-Score(Ordinary) = 0.193, Recall: 0.94, Precision: 0.108
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.238, Recall: 1.0, Precision: 0.135
# F-Score(id) = 0.22, Recall: 0.875, Precision: 0.126
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 115658
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_89 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_89 (Embedding)     (None, 4, 225)            108450    
_________________________________________________________________
flatten_89 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_89 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 115,658
Trainable params: 115,658
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 0.9567 - acc: 0.9503 - val_loss: 0.2671 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.1758 - acc: 0.9744 - val_loss: 0.1166 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1059 - acc: 0.9752 - val_loss: 0.0914 - val_acc: 0.9793
Epoch 00003: early stopping
# Training time = 0:00:01.424440
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_90 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_90 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_90 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_90 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0603 - acc: 0.9863 - val_loss: 0.0373 - val_acc: 0.9882
Epoch 2/15
 - 10s - loss: 0.0267 - acc: 0.9899 - val_loss: 0.0370 - val_acc: 0.9886
Epoch 3/15
 - 10s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0379 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:04:11.557387
# F-Score(Ordinary) = 0.087, Recall: 0.952, Precision: 0.046
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.119, Recall: 0.889, Precision: 0.063
# F-Score(id) = 0.124, Recall: 1.0, Precision: 0.066
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_91 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_91 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_91 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_91 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0607 - acc: 0.9859 - val_loss: 0.0378 - val_acc: 0.9884
Epoch 2/15
 - 10s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0360 - val_acc: 0.9887
Epoch 3/15
 - 10s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0368 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:04:01.462331
# F-Score(Ordinary) = 0.343, Recall: 0.92, Precision: 0.211
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.255, Recall: 0.826, Precision: 0.151
# F-Score(id) = 0.569, Recall: 0.944, Precision: 0.407
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_92 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_92 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_92 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_92 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0603 - acc: 0.9856 - val_loss: 0.0395 - val_acc: 0.9883
Epoch 2/15
 - 10s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0368 - val_acc: 0.9885
Epoch 3/15
 - 10s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0370 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:03:58.424780
# F-Score(Ordinary) = 0.24, Recall: 0.938, Precision: 0.137
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.375, Recall: 0.882, Precision: 0.238
# F-Score(id) = 0.296, Recall: 1.0, Precision: 0.174
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_93 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_93 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_93 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_93 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0605 - acc: 0.9860 - val_loss: 0.0382 - val_acc: 0.9879
Epoch 2/15
 - 10s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0368 - val_acc: 0.9885
Epoch 3/15
 - 10s - loss: 0.0220 - acc: 0.9905 - val_loss: 0.0372 - val_acc: 0.9881
Epoch 00003: early stopping
# Training time = 0:04:20.352410
# F-Score(Ordinary) = 0.331, Recall: 0.936, Precision: 0.201
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.41, Recall: 0.943, Precision: 0.262
# F-Score(id) = 0.431, Recall: 0.922, Precision: 0.281
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_94 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_94 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_94 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_94 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0610 - acc: 0.9859 - val_loss: 0.0387 - val_acc: 0.9877
Epoch 2/15
 - 10s - loss: 0.0269 - acc: 0.9897 - val_loss: 0.0367 - val_acc: 0.9882
Epoch 3/15
 - 10s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0378 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:03:58.693187
# F-Score(Ordinary) = 0.087, Recall: 0.952, Precision: 0.046
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.199, Recall: 0.933, Precision: 0.111
# F-Score(id) = 0.012, Recall: 1.0, Precision: 0.006
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_95 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_95 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_95 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_95 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0605 - acc: 0.9858 - val_loss: 0.0381 - val_acc: 0.9878
Epoch 2/15
 - 10s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0362 - val_acc: 0.9885
Epoch 3/15
 - 10s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0368 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:03:57.673541
# F-Score(Ordinary) = 0.303, Recall: 0.929, Precision: 0.181
# F-Score(lvc) = 0.014, Recall: 0.5, Precision: 0.007
# F-Score(ireflv) = 0.284, Recall: 0.955, Precision: 0.167
# F-Score(id) = 0.5, Recall: 0.934, Precision: 0.341
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_96 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_96 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_96 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_96 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0601 - acc: 0.9837 - val_loss: 0.0384 - val_acc: 0.9879
Epoch 2/15
 - 10s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0363 - val_acc: 0.9885
Epoch 3/15
 - 10s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0375 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:03:57.236260
# F-Score(Ordinary) = 0.476, Recall: 0.927, Precision: 0.32
# F-Score(lvc) = 0.335, Recall: 0.967, Precision: 0.203
# F-Score(ireflv) = 0.486, Recall: 0.894, Precision: 0.333
# F-Score(id) = 0.573, Recall: 0.932, Precision: 0.413
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_97 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_97 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_97 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_97 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0611 - acc: 0.9849 - val_loss: 0.0387 - val_acc: 0.9885
Epoch 2/15
 - 10s - loss: 0.0268 - acc: 0.9899 - val_loss: 0.0379 - val_acc: 0.9882
Epoch 3/15
 - 10s - loss: 0.0221 - acc: 0.9904 - val_loss: 0.0382 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:04:02.380527
# F-Score(Ordinary) = 0.12, Recall: 0.933, Precision: 0.064
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.187, Recall: 1.0, Precision: 0.103
# F-Score(id) = 0.133, Recall: 0.857, Precision: 0.072
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_98 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_98 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_98 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_98 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0602 - acc: 0.9847 - val_loss: 0.0378 - val_acc: 0.9882
Epoch 2/15
 - 10s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0378 - val_acc: 0.9883
Epoch 3/15
 - 10s - loss: 0.0223 - acc: 0.9903 - val_loss: 0.0365 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:03:58.720499
# F-Score(Ordinary) = 0.108, Recall: 1.0, Precision: 0.057
# F-Score(lvc) = 0.167, Recall: 1.0, Precision: 0.091
# F-Score(ireflv) = 0.147, Recall: 1.0, Precision: 0.079
# F-Score(id) = 0.024, Recall: 1.0, Precision: 0.012
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_99 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_99 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_99 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_99 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0606 - acc: 0.9858 - val_loss: 0.0379 - val_acc: 0.9883
Epoch 2/15
 - 10s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0376 - val_acc: 0.9885
Epoch 3/15
 - 10s - loss: 0.0221 - acc: 0.9905 - val_loss: 0.0363 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:04:01.842295
# F-Score(Ordinary) = 0.186, Recall: 0.938, Precision: 0.103
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.238, Recall: 1.0, Precision: 0.135
# F-Score(id) = 0.191, Recall: 0.857, Precision: 0.108
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 128508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_100 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_100 (Embedding)    (None, 4, 250)            120500    
_________________________________________________________________
flatten_100 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_100 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 128,508
Trainable params: 128,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 0.9805 - acc: 0.9007 - val_loss: 0.2772 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.1787 - acc: 0.9743 - val_loss: 0.1166 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1053 - acc: 0.9750 - val_loss: 0.0908 - val_acc: 0.9793
Epoch 00003: early stopping
# Training time = 0:00:02.449646
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_101 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_101 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_101 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_101 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0593 - acc: 0.9857 - val_loss: 0.0374 - val_acc: 0.9882
Epoch 2/15
 - 11s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0371 - val_acc: 0.9886
Epoch 3/15
 - 11s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0382 - val_acc: 0.9882
Epoch 00003: early stopping
# Training time = 0:04:30.069245
# F-Score(Ordinary) = 0.096, Recall: 0.957, Precision: 0.05
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.146, Recall: 0.909, Precision: 0.079
# F-Score(id) = 0.124, Recall: 1.0, Precision: 0.066
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_102 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_102 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_102 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_102 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0605 - acc: 0.9842 - val_loss: 0.0381 - val_acc: 0.9884
Epoch 2/15
 - 11s - loss: 0.0267 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9887
Epoch 3/15
 - 11s - loss: 0.0222 - acc: 0.9903 - val_loss: 0.0370 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:04:01.074248
# F-Score(Ordinary) = 0.353, Recall: 0.931, Precision: 0.217
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.28, Recall: 0.875, Precision: 0.167
# F-Score(id) = 0.575, Recall: 0.945, Precision: 0.413
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_103 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_103 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_103 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_103 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0593 - acc: 0.9862 - val_loss: 0.0396 - val_acc: 0.9882
Epoch 2/15
 - 11s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0367 - val_acc: 0.9886
Epoch 3/15
 - 11s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0370 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:02.145435
# F-Score(Ordinary) = 0.25, Recall: 0.94, Precision: 0.144
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.375, Recall: 0.882, Precision: 0.238
# F-Score(id) = 0.322, Recall: 1.0, Precision: 0.192
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_104 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_104 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_104 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_104 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0592 - acc: 0.9852 - val_loss: 0.0382 - val_acc: 0.9880
Epoch 2/15
 - 11s - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0369 - val_acc: 0.9885
Epoch 3/15
 - 11s - loss: 0.0220 - acc: 0.9905 - val_loss: 0.0374 - val_acc: 0.9879
Epoch 00003: early stopping
# Training time = 0:04:02.346161
# F-Score(Ordinary) = 0.307, Recall: 0.941, Precision: 0.183
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.429, Recall: 0.946, Precision: 0.278
# F-Score(id) = 0.365, Recall: 0.927, Precision: 0.228
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_105 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_105 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_105 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_105 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0596 - acc: 0.9853 - val_loss: 0.0387 - val_acc: 0.9878
Epoch 2/15
 - 11s - loss: 0.0269 - acc: 0.9897 - val_loss: 0.0367 - val_acc: 0.9883
Epoch 3/15
 - 11s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0375 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:04:02.791325
# F-Score(Ordinary) = 0.083, Recall: 0.95, Precision: 0.043
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.186, Recall: 0.929, Precision: 0.103
# F-Score(id) = 0.012, Recall: 1.0, Precision: 0.006
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_106 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_106 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_106 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_106 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0595 - acc: 0.9859 - val_loss: 0.0380 - val_acc: 0.9877
Epoch 2/15
 - 11s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0361 - val_acc: 0.9885
Epoch 3/15
 - 11s - loss: 0.0224 - acc: 0.9904 - val_loss: 0.0369 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:04:00.625882
# F-Score(Ordinary) = 0.322, Recall: 0.934, Precision: 0.195
# F-Score(lvc) = 0.027, Recall: 0.667, Precision: 0.014
# F-Score(ireflv) = 0.307, Recall: 0.958, Precision: 0.183
# F-Score(id) = 0.519, Recall: 0.938, Precision: 0.359
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_107 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_107 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_107 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_107 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0601 - acc: 0.9849 - val_loss: 0.0384 - val_acc: 0.9878
Epoch 2/15
 - 11s - loss: 0.0266 - acc: 0.9898 - val_loss: 0.0363 - val_acc: 0.9886
Epoch 3/15
 - 11s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0377 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:04:02.321850
# F-Score(Ordinary) = 0.484, Recall: 0.929, Precision: 0.327
# F-Score(lvc) = 0.335, Recall: 0.967, Precision: 0.203
# F-Score(ireflv) = 0.52, Recall: 0.902, Precision: 0.365
# F-Score(id) = 0.567, Recall: 0.932, Precision: 0.407
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_108 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_108 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_108 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_108 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0596 - acc: 0.9857 - val_loss: 0.0388 - val_acc: 0.9884
Epoch 2/15
 - 11s - loss: 0.0269 - acc: 0.9899 - val_loss: 0.0379 - val_acc: 0.9882
Epoch 3/15
 - 11s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0382 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:04.563667
# F-Score(Ordinary) = 0.12, Recall: 0.933, Precision: 0.064
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.174, Recall: 1.0, Precision: 0.095
# F-Score(id) = 0.143, Recall: 0.867, Precision: 0.078
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_109 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_109 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_109 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_109 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0597 - acc: 0.9853 - val_loss: 0.0381 - val_acc: 0.9884
Epoch 2/15
 - 11s - loss: 0.0268 - acc: 0.9899 - val_loss: 0.0380 - val_acc: 0.9883
Epoch 3/15
 - 11s - loss: 0.0225 - acc: 0.9903 - val_loss: 0.0364 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:04:04.357927
# F-Score(Ordinary) = 0.104, Recall: 0.96, Precision: 0.055
# F-Score(lvc) = 0.189, Recall: 0.938, Precision: 0.105
# F-Score(ireflv) = 0.105, Recall: 1.0, Precision: 0.056
# F-Score(id) = 0.024, Recall: 1.0, Precision: 0.012
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_110 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_110 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_110 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_110 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0592 - acc: 0.9849 - val_loss: 0.0379 - val_acc: 0.9883
Epoch 2/15
 - 11s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0376 - val_acc: 0.9886
Epoch 3/15
 - 11s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0363 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:04:14.091145
# F-Score(Ordinary) = 0.222, Recall: 0.948, Precision: 0.126
# F-Score(lvc) = 0.143, Recall: 1.0, Precision: 0.077
# F-Score(ireflv) = 0.262, Recall: 1.0, Precision: 0.151
# F-Score(id) = 0.256, Recall: 0.893, Precision: 0.15
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 141358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_111 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_111 (Embedding)    (None, 4, 275)            132550    
_________________________________________________________________
flatten_111 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_111 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 141,358
Trainable params: 141,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 0.9193 - acc: 0.9280 - val_loss: 0.2398 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.1613 - acc: 0.9744 - val_loss: 0.1099 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1007 - acc: 0.9754 - val_loss: 0.0884 - val_acc: 0.9803
Epoch 00003: early stopping
# Training time = 0:00:01.422172
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_112 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_112 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_112 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_112 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0586 - acc: 0.9858 - val_loss: 0.0376 - val_acc: 0.9882
Epoch 2/15
 - 12s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0372 - val_acc: 0.9886
Epoch 3/15
 - 12s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0381 - val_acc: 0.9882
Epoch 00003: early stopping
# Training time = 0:04:05.709612
# F-Score(Ordinary) = 0.092, Recall: 0.955, Precision: 0.048
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.132, Recall: 0.9, Precision: 0.071
# F-Score(id) = 0.124, Recall: 1.0, Precision: 0.066
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_113 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_113 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_113 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_113 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0591 - acc: 0.9854 - val_loss: 0.0382 - val_acc: 0.9883
Epoch 2/15
 - 12s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0361 - val_acc: 0.9887
Epoch 3/15
 - 12s - loss: 0.0223 - acc: 0.9903 - val_loss: 0.0367 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:04:07.553253
# F-Score(Ordinary) = 0.336, Recall: 0.909, Precision: 0.206
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.267, Recall: 0.833, Precision: 0.159
# F-Score(id) = 0.549, Recall: 0.929, Precision: 0.389
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_114 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_114 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_114 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_114 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0587 - acc: 0.9859 - val_loss: 0.0396 - val_acc: 0.9883
Epoch 2/15
 - 12s - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0369 - val_acc: 0.9885
Epoch 3/15
 - 12s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0371 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:04:12.351448
# F-Score(Ordinary) = 0.253, Recall: 0.941, Precision: 0.146
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.375, Recall: 0.882, Precision: 0.238
# F-Score(id) = 0.33, Recall: 1.0, Precision: 0.198
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_115 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_115 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_115 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_115 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0590 - acc: 0.9850 - val_loss: 0.0383 - val_acc: 0.9879
Epoch 2/15
 - 12s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0370 - val_acc: 0.9885
Epoch 3/15
 - 12s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0373 - val_acc: 0.9880
Epoch 00003: early stopping
# Training time = 0:04:04.121448
# F-Score(Ordinary) = 0.307, Recall: 0.941, Precision: 0.183
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.41, Recall: 0.943, Precision: 0.262
# F-Score(id) = 0.381, Recall: 0.93, Precision: 0.24
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_116 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_116 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_116 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_116 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0589 - acc: 0.9854 - val_loss: 0.0389 - val_acc: 0.9877
Epoch 2/15
 - 12s - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0368 - val_acc: 0.9883
Epoch 3/15
 - 12s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0375 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:04:09.597661
# F-Score(Ordinary) = 0.092, Recall: 0.955, Precision: 0.048
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.199, Recall: 0.933, Precision: 0.111
# F-Score(id) = 0.024, Recall: 1.0, Precision: 0.012
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_117 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_117 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_117 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_117 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0590 - acc: 0.9857 - val_loss: 0.0380 - val_acc: 0.9878
Epoch 2/15
 - 12s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0359 - val_acc: 0.9886
Epoch 3/15
 - 12s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0366 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:04:07.121025
# F-Score(Ordinary) = 0.31, Recall: 0.953, Precision: 0.185
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(ireflv) = 0.286, Recall: 1.0, Precision: 0.167
# F-Score(id) = 0.507, Recall: 0.935, Precision: 0.347
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_118 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_118 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_118 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_118 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0584 - acc: 0.9860 - val_loss: 0.0388 - val_acc: 0.9878
Epoch 2/15
 - 12s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0365 - val_acc: 0.9884
Epoch 3/15
 - 12s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0378 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:04:05.210778
# F-Score(Ordinary) = 0.477, Recall: 0.933, Precision: 0.32
# F-Score(lvc) = 0.316, Recall: 0.964, Precision: 0.189
# F-Score(ireflv) = 0.486, Recall: 0.894, Precision: 0.333
# F-Score(id) = 0.587, Recall: 0.947, Precision: 0.425
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_119 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_119 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_119 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_119 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0589 - acc: 0.9854 - val_loss: 0.0388 - val_acc: 0.9884
Epoch 2/15
 - 12s - loss: 0.0267 - acc: 0.9899 - val_loss: 0.0379 - val_acc: 0.9882
Epoch 3/15
 - 12s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0383 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:05.289208
# F-Score(Ordinary) = 0.112, Recall: 0.929, Precision: 0.059
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.161, Recall: 1.0, Precision: 0.087
# F-Score(id) = 0.133, Recall: 0.857, Precision: 0.072
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_120 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_120 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_120 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_120 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0588 - acc: 0.9858 - val_loss: 0.0381 - val_acc: 0.9882
Epoch 2/15
 - 12s - loss: 0.0266 - acc: 0.9898 - val_loss: 0.0380 - val_acc: 0.9883
Epoch 3/15
 - 12s - loss: 0.0223 - acc: 0.9903 - val_loss: 0.0365 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:04:04.472630
# F-Score(Ordinary) = 0.112, Recall: 1.0, Precision: 0.059
# F-Score(lvc) = 0.201, Recall: 1.0, Precision: 0.112
# F-Score(ireflv) = 0.133, Recall: 1.0, Precision: 0.071
# F-Score(id) = 0.012, Recall: 1.0, Precision: 0.006
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_121 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_121 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_121 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_121 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0589 - acc: 0.9857 - val_loss: 0.0381 - val_acc: 0.9883
Epoch 2/15
 - 12s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0376 - val_acc: 0.9886
Epoch 3/15
 - 12s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0362 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:04:05.591491
# F-Score(Ordinary) = 0.229, Recall: 0.95, Precision: 0.13
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.286, Recall: 1.0, Precision: 0.167
# F-Score(id) = 0.283, Recall: 0.903, Precision: 0.168
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 154208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_122 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_122 (Embedding)    (None, 4, 300)            144600    
_________________________________________________________________
flatten_122 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_122 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 154,208
Trainable params: 154,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 0.8918 - acc: 0.9151 - val_loss: 0.2271 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.1538 - acc: 0.9743 - val_loss: 0.1060 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.0966 - acc: 0.9757 - val_loss: 0.0864 - val_acc: 0.9793
Epoch 00003: early stopping
# Training time = 0:00:01.458126
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_123 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_123 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_123 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_123 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0580 - acc: 0.9854 - val_loss: 0.0376 - val_acc: 0.9884
Epoch 2/15
 - 13s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0372 - val_acc: 0.9886
Epoch 3/15
 - 13s - loss: 0.0223 - acc: 0.9905 - val_loss: 0.0381 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:04:06.214484
# F-Score(Ordinary) = 0.087, Recall: 0.952, Precision: 0.046
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.132, Recall: 0.9, Precision: 0.071
# F-Score(id) = 0.113, Recall: 1.0, Precision: 0.06
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_124 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_124 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_124 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_124 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0584 - acc: 0.9858 - val_loss: 0.0383 - val_acc: 0.9884
Epoch 2/15
 - 13s - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0362 - val_acc: 0.9888
Epoch 3/15
 - 13s - loss: 0.0224 - acc: 0.9903 - val_loss: 0.0369 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:04:07.914429
# F-Score(Ordinary) = 0.342, Recall: 0.911, Precision: 0.211
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.267, Recall: 0.833, Precision: 0.159
# F-Score(id) = 0.567, Recall: 0.932, Precision: 0.407
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_125 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_125 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_125 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_125 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0579 - acc: 0.9858 - val_loss: 0.0396 - val_acc: 0.9883
Epoch 2/15
 - 13s - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0367 - val_acc: 0.9886
Epoch 3/15
 - 13s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0372 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:04:08.712238
# F-Score(Ordinary) = 0.257, Recall: 0.942, Precision: 0.149
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.365, Recall: 0.879, Precision: 0.23
# F-Score(id) = 0.347, Recall: 1.0, Precision: 0.21
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_126 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_126 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_126 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_126 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0582 - acc: 0.9847 - val_loss: 0.0386 - val_acc: 0.9878
Epoch 2/15
 - 13s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0370 - val_acc: 0.9884
Epoch 3/15
 - 13s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0373 - val_acc: 0.9880
Epoch 00003: early stopping
# Training time = 0:04:06.671805
# F-Score(Ordinary) = 0.316, Recall: 0.943, Precision: 0.19
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.42, Recall: 0.944, Precision: 0.27
# F-Score(id) = 0.396, Recall: 0.933, Precision: 0.251
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_127 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_127 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_127 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_127 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0578 - acc: 0.9859 - val_loss: 0.0392 - val_acc: 0.9875
Epoch 2/15
 - 13s - loss: 0.0269 - acc: 0.9897 - val_loss: 0.0372 - val_acc: 0.9883
Epoch 3/15
 - 13s - loss: 0.0223 - acc: 0.9905 - val_loss: 0.0380 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:04:08.268735
# F-Score(Ordinary) = 0.092, Recall: 0.955, Precision: 0.048
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.211, Recall: 0.938, Precision: 0.119
# F-Score(id) = 0.012, Recall: 1.0, Precision: 0.006
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_128 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_128 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_128 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_128 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0577 - acc: 0.9854 - val_loss: 0.0384 - val_acc: 0.9876
Epoch 2/15
 - 13s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0362 - val_acc: 0.9884
Epoch 3/15
 - 13s - loss: 0.0224 - acc: 0.9904 - val_loss: 0.0369 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:04:07.113521
# F-Score(Ordinary) = 0.297, Recall: 0.939, Precision: 0.176
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.236, Recall: 0.944, Precision: 0.135
# F-Score(id) = 0.513, Recall: 0.937, Precision: 0.353
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_129 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_129 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_129 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_129 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0586 - acc: 0.9850 - val_loss: 0.0390 - val_acc: 0.9878
Epoch 2/15
 - 13s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0365 - val_acc: 0.9885
Epoch 3/15
 - 13s - loss: 0.0223 - acc: 0.9903 - val_loss: 0.0379 - val_acc: 0.9882
Epoch 00003: early stopping
# Training time = 0:04:06.982260
# F-Score(Ordinary) = 0.489, Recall: 0.929, Precision: 0.332
# F-Score(lvc) = 0.345, Recall: 0.968, Precision: 0.21
# F-Score(ireflv) = 0.494, Recall: 0.896, Precision: 0.341
# F-Score(id) = 0.59, Recall: 0.935, Precision: 0.431
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_130 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_130 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_130 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_130 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0584 - acc: 0.9857 - val_loss: 0.0389 - val_acc: 0.9885
Epoch 2/15
 - 13s - loss: 0.0268 - acc: 0.9899 - val_loss: 0.0378 - val_acc: 0.9882
Epoch 3/15
 - 13s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0379 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:05.420891
# F-Score(Ordinary) = 0.112, Recall: 0.929, Precision: 0.059
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.161, Recall: 1.0, Precision: 0.087
# F-Score(id) = 0.133, Recall: 0.857, Precision: 0.072
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_131 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_131 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_131 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_131 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0577 - acc: 0.9856 - val_loss: 0.0384 - val_acc: 0.9881
Epoch 2/15
 - 13s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0381 - val_acc: 0.9883
Epoch 3/15
 - 13s - loss: 0.0223 - acc: 0.9903 - val_loss: 0.0365 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:04:06.066727
# F-Score(Ordinary) = 0.1, Recall: 1.0, Precision: 0.053
# F-Score(lvc) = 0.19, Recall: 1.0, Precision: 0.105
# F-Score(ireflv) = 0.091, Recall: 1.0, Precision: 0.048
# F-Score(id) = 0.024, Recall: 1.0, Precision: 0.012
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_132 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_132 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_132 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_132 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 13s - loss: 0.0581 - acc: 0.9861 - val_loss: 0.0383 - val_acc: 0.9883
Epoch 2/15
 - 13s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0379 - val_acc: 0.9884
Epoch 3/15
 - 13s - loss: 0.0223 - acc: 0.9905 - val_loss: 0.0365 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:05.706901
# F-Score(Ordinary) = 0.222, Recall: 0.948, Precision: 0.126
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.262, Recall: 1.0, Precision: 0.151
# F-Score(id) = 0.265, Recall: 0.897, Precision: 0.156
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 13558
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_133 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_133 (Embedding)    (None, 4, 25)             12750     
_________________________________________________________________
flatten_133 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_133 (Dense)            (None, 8)                 808       
=================================================================
Total params: 13,558
Trainable params: 13,558
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.6959 - acc: 0.8204 - val_loss: 1.1530 - val_acc: 0.9734
Epoch 2/15
 - 0s - loss: 0.7482 - acc: 0.9737 - val_loss: 0.4715 - val_acc: 0.9803
Epoch 3/15
 - 0s - loss: 0.3718 - acc: 0.9750 - val_loss: 0.2743 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.2360 - acc: 0.9747 - val_loss: 0.1849 - val_acc: 0.9793
Epoch 5/15
 - 0s - loss: 0.1711 - acc: 0.9747 - val_loss: 0.1407 - val_acc: 0.9793
Epoch 6/15
 - 0s - loss: 0.1367 - acc: 0.9748 - val_loss: 0.1157 - val_acc: 0.9793
Epoch 00006: early stopping
# Training time = 0:00:01.645475
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_134 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_134 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_134 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_134 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0918 - acc: 0.9817 - val_loss: 0.0351 - val_acc: 0.9887
Epoch 2/15
 - 6s - loss: 0.0270 - acc: 0.9897 - val_loss: 0.0304 - val_acc: 0.9893
Epoch 3/15
 - 6s - loss: 0.0221 - acc: 0.9904 - val_loss: 0.0301 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:59.227614
# F-Score(Ordinary) = 0.342, Recall: 0.958, Precision: 0.208
# F-Score(lvc) = 0.235, Recall: 1.0, Precision: 0.133
# F-Score(ireflv) = 0.539, Recall: 0.923, Precision: 0.381
# F-Score(id) = 0.251, Recall: 1.0, Precision: 0.144
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_135 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_135 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_135 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_135 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0939 - acc: 0.9791 - val_loss: 0.0343 - val_acc: 0.9890
Epoch 2/15
 - 6s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0303 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0220 - acc: 0.9904 - val_loss: 0.0296 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:03:46.593734
# F-Score(Ordinary) = 0.436, Recall: 0.939, Precision: 0.284
# F-Score(lvc) = 0.212, Recall: 1.0, Precision: 0.119
# F-Score(ireflv) = 0.398, Recall: 0.914, Precision: 0.254
# F-Score(id) = 0.607, Recall: 0.938, Precision: 0.449
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_136 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_136 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_136 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_136 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0933 - acc: 0.9806 - val_loss: 0.0355 - val_acc: 0.9887
Epoch 2/15
 - 6s - loss: 0.0270 - acc: 0.9898 - val_loss: 0.0303 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0220 - acc: 0.9906 - val_loss: 0.0299 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:43.639142
# F-Score(Ordinary) = 0.391, Recall: 0.939, Precision: 0.247
# F-Score(lvc) = 0.167, Recall: 1.0, Precision: 0.091
# F-Score(ireflv) = 0.538, Recall: 0.875, Precision: 0.389
# F-Score(id) = 0.432, Recall: 1.0, Precision: 0.275
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_137 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_137 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_137 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_137 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0911 - acc: 0.9823 - val_loss: 0.0352 - val_acc: 0.9888
Epoch 2/15
 - 6s - loss: 0.0271 - acc: 0.9898 - val_loss: 0.0305 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0221 - acc: 0.9905 - val_loss: 0.0301 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:03:42.154602
# F-Score(Ordinary) = 0.331, Recall: 0.936, Precision: 0.201
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.474, Recall: 0.872, Precision: 0.325
# F-Score(id) = 0.363, Recall: 1.0, Precision: 0.222
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_138 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_138 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_138 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_138 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0923 - acc: 0.9825 - val_loss: 0.0345 - val_acc: 0.9889
Epoch 2/15
 - 6s - loss: 0.0271 - acc: 0.9898 - val_loss: 0.0305 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0222 - acc: 0.9906 - val_loss: 0.0301 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:03:45.751308
# F-Score(Ordinary) = 0.351, Recall: 0.959, Precision: 0.215
# F-Score(lvc) = 0.409, Recall: 0.974, Precision: 0.259
# F-Score(ireflv) = 0.417, Recall: 0.919, Precision: 0.27
# F-Score(id) = 0.242, Recall: 1.0, Precision: 0.138
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_139 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_139 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_139 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_139 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0963 - acc: 0.9789 - val_loss: 0.0342 - val_acc: 0.9890
Epoch 2/15
 - 6s - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0296 - val_acc: 0.9896
Epoch 3/15
 - 6s - loss: 0.0220 - acc: 0.9904 - val_loss: 0.0296 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:46.858595
# F-Score(Ordinary) = 0.212, Recall: 0.963, Precision: 0.119
# F-Score(lvc) = 0.155, Recall: 1.0, Precision: 0.084
# F-Score(ireflv) = 0.316, Recall: 0.923, Precision: 0.19
# F-Score(id) = 0.175, Recall: 1.0, Precision: 0.096
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_140 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_140 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_140 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_140 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0914 - acc: 0.9760 - val_loss: 0.0347 - val_acc: 0.9890
Epoch 2/15
 - 6s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0302 - val_acc: 0.9893
Epoch 3/15
 - 6s - loss: 0.0220 - acc: 0.9904 - val_loss: 0.0301 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:03:44.409044
# F-Score(Ordinary) = 0.499, Recall: 0.949, Precision: 0.339
# F-Score(lvc) = 0.443, Recall: 0.976, Precision: 0.287
# F-Score(ireflv) = 0.552, Recall: 0.909, Precision: 0.397
# F-Score(id) = 0.504, Recall: 0.966, Precision: 0.341
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_141 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_141 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_141 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_141 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0935 - acc: 0.9822 - val_loss: 0.0345 - val_acc: 0.9890
Epoch 2/15
 - 6s - loss: 0.0267 - acc: 0.9900 - val_loss: 0.0306 - val_acc: 0.9896
Epoch 3/15
 - 6s - loss: 0.0220 - acc: 0.9905 - val_loss: 0.0303 - val_acc: 0.9896
Epoch 00003: early stopping
# Training time = 0:03:44.954697
# F-Score(Ordinary) = 0.31, Recall: 0.953, Precision: 0.185
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.542, Recall: 0.941, Precision: 0.381
# F-Score(id) = 0.259, Recall: 0.962, Precision: 0.15
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_142 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_142 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_142 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_142 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0927 - acc: 0.9816 - val_loss: 0.0346 - val_acc: 0.9890
Epoch 2/15
 - 6s - loss: 0.0270 - acc: 0.9897 - val_loss: 0.0302 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0221 - acc: 0.9904 - val_loss: 0.0296 - val_acc: 0.9896
Epoch 00003: early stopping
# Training time = 0:03:42.320758
# F-Score(Ordinary) = 0.248, Recall: 0.969, Precision: 0.142
# F-Score(lvc) = 0.265, Recall: 0.957, Precision: 0.154
# F-Score(ireflv) = 0.211, Recall: 0.938, Precision: 0.119
# F-Score(id) = 0.26, Recall: 1.0, Precision: 0.15
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_143 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_143 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_143 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_143 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0907 - acc: 0.9812 - val_loss: 0.0344 - val_acc: 0.9888
Epoch 2/15
 - 6s - loss: 0.0266 - acc: 0.9899 - val_loss: 0.0304 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0219 - acc: 0.9905 - val_loss: 0.0297 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:43.498847
# F-Score(Ordinary) = 0.285, Recall: 0.973, Precision: 0.167
# F-Score(lvc) = 0.267, Recall: 1.0, Precision: 0.154
# F-Score(ireflv) = 0.282, Recall: 0.913, Precision: 0.167
# F-Score(id) = 0.305, Recall: 1.0, Precision: 0.18
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 27108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_144 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_144 (Embedding)    (None, 4, 50)             25500     
_________________________________________________________________
flatten_144 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_144 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 27,108
Trainable params: 27,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.6184 - acc: 0.8286 - val_loss: 0.8999 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.5179 - acc: 0.9742 - val_loss: 0.2890 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.2272 - acc: 0.9744 - val_loss: 0.1605 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.1484 - acc: 0.9745 - val_loss: 0.1166 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:01.483443
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_145 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_145 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_145 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_145 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0775 - acc: 0.9833 - val_loss: 0.0330 - val_acc: 0.9889
Epoch 2/15
 - 6s - loss: 0.0255 - acc: 0.9900 - val_loss: 0.0298 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0301 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:45.938538
# F-Score(Ordinary) = 0.307, Recall: 0.952, Precision: 0.183
# F-Score(lvc) = 0.143, Recall: 1.0, Precision: 0.077
# F-Score(ireflv) = 0.539, Recall: 0.923, Precision: 0.381
# F-Score(id) = 0.223, Recall: 1.0, Precision: 0.126
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_146 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_146 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_146 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_146 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0780 - acc: 0.9823 - val_loss: 0.0323 - val_acc: 0.9892
Epoch 2/15
 - 6s - loss: 0.0254 - acc: 0.9899 - val_loss: 0.0302 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0299 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:46.566544
# F-Score(Ordinary) = 0.43, Recall: 0.931, Precision: 0.279
# F-Score(lvc) = 0.155, Recall: 1.0, Precision: 0.084
# F-Score(ireflv) = 0.415, Recall: 0.895, Precision: 0.27
# F-Score(id) = 0.613, Recall: 0.938, Precision: 0.455
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_147 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_147 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_147 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_147 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0766 - acc: 0.9840 - val_loss: 0.0338 - val_acc: 0.9891
Epoch 2/15
 - 6s - loss: 0.0256 - acc: 0.9900 - val_loss: 0.0302 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0214 - acc: 0.9906 - val_loss: 0.0303 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:03:46.287430
# F-Score(Ordinary) = 0.383, Recall: 0.938, Precision: 0.24
# F-Score(lvc) = 0.143, Recall: 1.0, Precision: 0.077
# F-Score(ireflv) = 0.53, Recall: 0.873, Precision: 0.381
# F-Score(id) = 0.432, Recall: 1.0, Precision: 0.275
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_148 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_148 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_148 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_148 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0767 - acc: 0.9839 - val_loss: 0.0330 - val_acc: 0.9892
Epoch 2/15
 - 6s - loss: 0.0256 - acc: 0.9899 - val_loss: 0.0300 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0300 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:57.250068
# F-Score(Ordinary) = 0.331, Recall: 0.926, Precision: 0.201
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.497, Recall: 0.863, Precision: 0.349
# F-Score(id) = 0.363, Recall: 1.0, Precision: 0.222
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_149 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_149 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_149 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_149 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0763 - acc: 0.9817 - val_loss: 0.0328 - val_acc: 0.9891
Epoch 2/15
 - 6s - loss: 0.0256 - acc: 0.9899 - val_loss: 0.0306 - val_acc: 0.9892
Epoch 3/15
 - 6s - loss: 0.0215 - acc: 0.9905 - val_loss: 0.0305 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:45.934502
# F-Score(Ordinary) = 0.291, Recall: 0.962, Precision: 0.172
# F-Score(lvc) = 0.375, Recall: 1.0, Precision: 0.231
# F-Score(ireflv) = 0.417, Recall: 0.919, Precision: 0.27
# F-Score(id) = 0.091, Recall: 1.0, Precision: 0.048
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_150 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_150 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_150 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_150 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0769 - acc: 0.9833 - val_loss: 0.0325 - val_acc: 0.9890
Epoch 2/15
 - 6s - loss: 0.0254 - acc: 0.9900 - val_loss: 0.0297 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0300 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:44.027312
# F-Score(Ordinary) = 0.208, Recall: 0.962, Precision: 0.117
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.26, Recall: 0.95, Precision: 0.151
# F-Score(id) = 0.25, Recall: 0.96, Precision: 0.144
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_151 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_151 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_151 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_151 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0769 - acc: 0.9837 - val_loss: 0.0331 - val_acc: 0.9890
Epoch 2/15
 - 6s - loss: 0.0254 - acc: 0.9900 - val_loss: 0.0299 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0302 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:43.999376
# F-Score(Ordinary) = 0.547, Recall: 0.934, Precision: 0.387
# F-Score(lvc) = 0.457, Recall: 0.956, Precision: 0.301
# F-Score(ireflv) = 0.618, Recall: 0.908, Precision: 0.468
# F-Score(id) = 0.563, Recall: 0.944, Precision: 0.401
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_152 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_152 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_152 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_152 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0780 - acc: 0.9840 - val_loss: 0.0327 - val_acc: 0.9895
Epoch 2/15
 - 6s - loss: 0.0255 - acc: 0.9900 - val_loss: 0.0304 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0305 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:45.125640
# F-Score(Ordinary) = 0.27, Recall: 0.932, Precision: 0.158
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.547, Recall: 0.925, Precision: 0.389
# F-Score(id) = 0.174, Recall: 0.941, Precision: 0.096
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_153 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_153 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_153 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_153 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0768 - acc: 0.9831 - val_loss: 0.0320 - val_acc: 0.9893
Epoch 2/15
 - 6s - loss: 0.0254 - acc: 0.9900 - val_loss: 0.0300 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0215 - acc: 0.9905 - val_loss: 0.0298 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:50.453880
# F-Score(Ordinary) = 0.282, Recall: 0.973, Precision: 0.165
# F-Score(lvc) = 0.318, Recall: 1.0, Precision: 0.189
# F-Score(ireflv) = 0.247, Recall: 0.9, Precision: 0.143
# F-Score(id) = 0.278, Recall: 1.0, Precision: 0.162
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_154 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_154 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_154 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_154 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0762 - acc: 0.9849 - val_loss: 0.0330 - val_acc: 0.9891
Epoch 2/15
 - 6s - loss: 0.0253 - acc: 0.9900 - val_loss: 0.0308 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0301 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:47.163671
# F-Score(Ordinary) = 0.248, Recall: 1.0, Precision: 0.142
# F-Score(lvc) = 0.256, Recall: 1.0, Precision: 0.147
# F-Score(ireflv) = 0.25, Recall: 1.0, Precision: 0.143
# F-Score(id) = 0.242, Recall: 1.0, Precision: 0.138
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 40658
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_155 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_155 (Embedding)    (None, 4, 75)             38250     
_________________________________________________________________
flatten_155 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_155 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 40,658
Trainable params: 40,658
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.4188 - acc: 0.6992 - val_loss: 0.6458 - val_acc: 0.9469
Epoch 2/15
 - 0s - loss: 0.3901 - acc: 0.9735 - val_loss: 0.2223 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1789 - acc: 0.9745 - val_loss: 0.1300 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.1228 - acc: 0.9746 - val_loss: 0.1002 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:02.488949
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_156 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_156 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_156 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_156 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0701 - acc: 0.9818 - val_loss: 0.0324 - val_acc: 0.9888
Epoch 2/15
 - 6s - loss: 0.0250 - acc: 0.9900 - val_loss: 0.0300 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0305 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:04:28.315178
# F-Score(Ordinary) = 0.277, Recall: 0.947, Precision: 0.162
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.556, Recall: 0.926, Precision: 0.397
# F-Score(id) = 0.134, Recall: 1.0, Precision: 0.072
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_157 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_157 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_157 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_157 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0695 - acc: 0.9844 - val_loss: 0.0315 - val_acc: 0.9893
Epoch 2/15
 - 6s - loss: 0.0249 - acc: 0.9900 - val_loss: 0.0302 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0300 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:03:44.301392
# F-Score(Ordinary) = 0.444, Recall: 0.941, Precision: 0.291
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.436, Recall: 0.923, Precision: 0.286
# F-Score(id) = 0.64, Recall: 0.942, Precision: 0.485
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_158 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_158 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_158 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_158 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0699 - acc: 0.9840 - val_loss: 0.0334 - val_acc: 0.9892
Epoch 2/15
 - 6s - loss: 0.0251 - acc: 0.9900 - val_loss: 0.0300 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0303 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:44.718262
# F-Score(Ordinary) = 0.388, Recall: 0.939, Precision: 0.245
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.562, Recall: 0.881, Precision: 0.413
# F-Score(id) = 0.439, Recall: 1.0, Precision: 0.281
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_159 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_159 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_159 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_159 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0707 - acc: 0.9836 - val_loss: 0.0321 - val_acc: 0.9892
Epoch 2/15
 - 6s - loss: 0.0250 - acc: 0.9900 - val_loss: 0.0303 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0211 - acc: 0.9907 - val_loss: 0.0303 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:45.852032
# F-Score(Ordinary) = 0.328, Recall: 0.926, Precision: 0.199
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.48, Recall: 0.857, Precision: 0.333
# F-Score(id) = 0.371, Recall: 1.0, Precision: 0.228
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_160 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_160 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_160 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_160 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0701 - acc: 0.9827 - val_loss: 0.0322 - val_acc: 0.9891
Epoch 2/15
 - 6s - loss: 0.0251 - acc: 0.9900 - val_loss: 0.0308 - val_acc: 0.9892
Epoch 3/15
 - 6s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0308 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:43.838751
# F-Score(Ordinary) = 0.254, Recall: 0.955, Precision: 0.146
# F-Score(lvc) = 0.366, Recall: 1.0, Precision: 0.224
# F-Score(ireflv) = 0.357, Recall: 0.903, Precision: 0.222
# F-Score(id) = 0.047, Recall: 1.0, Precision: 0.024
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_161 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_161 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_161 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_161 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0697 - acc: 0.9850 - val_loss: 0.0318 - val_acc: 0.9893
Epoch 2/15
 - 6s - loss: 0.0249 - acc: 0.9900 - val_loss: 0.0296 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0300 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:43.450695
# F-Score(Ordinary) = 0.25, Recall: 0.926, Precision: 0.144
# F-Score(lvc) = 0.067, Recall: 0.833, Precision: 0.035
# F-Score(ireflv) = 0.284, Recall: 0.955, Precision: 0.167
# F-Score(id) = 0.357, Recall: 0.925, Precision: 0.222
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_162 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_162 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_162 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_162 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0695 - acc: 0.9838 - val_loss: 0.0325 - val_acc: 0.9890
Epoch 2/15
 - 6s - loss: 0.0249 - acc: 0.9901 - val_loss: 0.0300 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0211 - acc: 0.9905 - val_loss: 0.0308 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:46.105253
# F-Score(Ordinary) = 0.578, Recall: 0.934, Precision: 0.419
# F-Score(lvc) = 0.482, Recall: 0.958, Precision: 0.322
# F-Score(ireflv) = 0.653, Recall: 0.914, Precision: 0.508
# F-Score(id) = 0.596, Recall: 0.936, Precision: 0.437
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_163 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_163 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_163 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_163 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0691 - acc: 0.9836 - val_loss: 0.0322 - val_acc: 0.9894
Epoch 2/15
 - 6s - loss: 0.0249 - acc: 0.9901 - val_loss: 0.0308 - val_acc: 0.9892
Epoch 3/15
 - 6s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0310 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:44.464218
# F-Score(Ordinary) = 0.236, Recall: 0.922, Precision: 0.135
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.506, Recall: 0.917, Precision: 0.349
# F-Score(id) = 0.133, Recall: 0.923, Precision: 0.072
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_164 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_164 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_164 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_164 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0696 - acc: 0.9823 - val_loss: 0.0317 - val_acc: 0.9895
Epoch 2/15
 - 6s - loss: 0.0250 - acc: 0.9900 - val_loss: 0.0303 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0299 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:42.947220
# F-Score(Ordinary) = 0.282, Recall: 0.973, Precision: 0.165
# F-Score(lvc) = 0.347, Recall: 1.0, Precision: 0.21
# F-Score(ireflv) = 0.247, Recall: 0.9, Precision: 0.143
# F-Score(id) = 0.251, Recall: 1.0, Precision: 0.144
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_165 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_165 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_165 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_165 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0696 - acc: 0.9831 - val_loss: 0.0328 - val_acc: 0.9891
Epoch 2/15
 - 6s - loss: 0.0250 - acc: 0.9900 - val_loss: 0.0309 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0301 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:42.644069
# F-Score(Ordinary) = 0.286, Recall: 0.986, Precision: 0.167
# F-Score(lvc) = 0.267, Recall: 1.0, Precision: 0.154
# F-Score(ireflv) = 0.272, Recall: 0.952, Precision: 0.159
# F-Score(id) = 0.313, Recall: 1.0, Precision: 0.186
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 54208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_166 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_166 (Embedding)    (None, 4, 100)            51000     
_________________________________________________________________
flatten_166 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_166 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 54,208
Trainable params: 54,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.3020 - acc: 0.8273 - val_loss: 0.5347 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.3303 - acc: 0.9746 - val_loss: 0.1894 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1584 - acc: 0.9745 - val_loss: 0.1167 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.1122 - acc: 0.9754 - val_loss: 0.0919 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:02.527621
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_167 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_167 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_167 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_167 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0652 - acc: 0.9857 - val_loss: 0.0320 - val_acc: 0.9888
Epoch 2/15
 - 6s - loss: 0.0247 - acc: 0.9901 - val_loss: 0.0301 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0306 - val_acc: 0.9890
Epoch 00003: early stopping
# Training time = 0:04:11.975240
# F-Score(Ordinary) = 0.264, Recall: 0.944, Precision: 0.153
# F-Score(lvc) = 0.081, Recall: 1.0, Precision: 0.042
# F-Score(ireflv) = 0.571, Recall: 0.929, Precision: 0.413
# F-Score(id) = 0.102, Recall: 1.0, Precision: 0.054
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_168 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_168 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_168 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_168 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0655 - acc: 0.9834 - val_loss: 0.0316 - val_acc: 0.9893
Epoch 2/15
 - 6s - loss: 0.0247 - acc: 0.9900 - val_loss: 0.0302 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0210 - acc: 0.9906 - val_loss: 0.0300 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:50.053710
# F-Score(Ordinary) = 0.44, Recall: 0.926, Precision: 0.288
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.431, Recall: 0.878, Precision: 0.286
# F-Score(id) = 0.64, Recall: 0.942, Precision: 0.485
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_169 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_169 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_169 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_169 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0653 - acc: 0.9852 - val_loss: 0.0332 - val_acc: 0.9891
Epoch 2/15
 - 6s - loss: 0.0248 - acc: 0.9901 - val_loss: 0.0301 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0305 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:03:46.230752
# F-Score(Ordinary) = 0.388, Recall: 0.939, Precision: 0.245
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.57, Recall: 0.883, Precision: 0.421
# F-Score(id) = 0.432, Recall: 1.0, Precision: 0.275
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_170 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_170 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_170 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_170 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0648 - acc: 0.9857 - val_loss: 0.0321 - val_acc: 0.9892
Epoch 2/15
 - 6s - loss: 0.0249 - acc: 0.9900 - val_loss: 0.0306 - val_acc: 0.9893
Epoch 3/15
 - 6s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0305 - val_acc: 0.9890
Epoch 00003: early stopping
# Training time = 0:03:47.906220
# F-Score(Ordinary) = 0.333, Recall: 0.918, Precision: 0.204
# F-Score(lvc) = 0.081, Recall: 1.0, Precision: 0.042
# F-Score(ireflv) = 0.494, Recall: 0.846, Precision: 0.349
# F-Score(id) = 0.379, Recall: 1.0, Precision: 0.234
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_171 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_171 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_171 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_171 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0648 - acc: 0.9854 - val_loss: 0.0317 - val_acc: 0.9892
Epoch 2/15
 - 6s - loss: 0.0248 - acc: 0.9900 - val_loss: 0.0310 - val_acc: 0.9890
Epoch 3/15
 - 6s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0308 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:43.587979
# F-Score(Ordinary) = 0.233, Recall: 0.951, Precision: 0.133
# F-Score(lvc) = 0.318, Recall: 1.0, Precision: 0.189
# F-Score(ireflv) = 0.346, Recall: 0.9, Precision: 0.214
# F-Score(id) = 0.047, Recall: 1.0, Precision: 0.024
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_172 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_172 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_172 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_172 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0657 - acc: 0.9836 - val_loss: 0.0318 - val_acc: 0.9892
Epoch 2/15
 - 6s - loss: 0.0248 - acc: 0.9900 - val_loss: 0.0298 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0302 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:03:45.729149
# F-Score(Ordinary) = 0.243, Recall: 0.924, Precision: 0.14
# F-Score(lvc) = 0.067, Recall: 0.833, Precision: 0.035
# F-Score(ireflv) = 0.224, Recall: 0.941, Precision: 0.127
# F-Score(id) = 0.381, Recall: 0.93, Precision: 0.24
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_173 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_173 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_173 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_173 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0657 - acc: 0.9848 - val_loss: 0.0322 - val_acc: 0.9890
Epoch 2/15
 - 6s - loss: 0.0247 - acc: 0.9902 - val_loss: 0.0299 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0307 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:44.407527
# F-Score(Ordinary) = 0.599, Recall: 0.932, Precision: 0.442
# F-Score(lvc) = 0.497, Recall: 0.96, Precision: 0.336
# F-Score(ireflv) = 0.657, Recall: 0.903, Precision: 0.516
# F-Score(id) = 0.635, Recall: 0.941, Precision: 0.479
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_174 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_174 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_174 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_174 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0663 - acc: 0.9845 - val_loss: 0.0319 - val_acc: 0.9895
Epoch 2/15
 - 6s - loss: 0.0247 - acc: 0.9902 - val_loss: 0.0308 - val_acc: 0.9893
Epoch 3/15
 - 6s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0311 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:46.022745
# F-Score(Ordinary) = 0.211, Recall: 0.929, Precision: 0.119
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(ireflv) = 0.5, Recall: 0.935, Precision: 0.341
# F-Score(id) = 0.08, Recall: 0.875, Precision: 0.042
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_175 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_175 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_175 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_175 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0655 - acc: 0.9842 - val_loss: 0.0313 - val_acc: 0.9894
Epoch 2/15
 - 6s - loss: 0.0247 - acc: 0.9901 - val_loss: 0.0303 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0212 - acc: 0.9905 - val_loss: 0.0298 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:46.578753
# F-Score(Ordinary) = 0.292, Recall: 0.974, Precision: 0.172
# F-Score(lvc) = 0.366, Recall: 1.0, Precision: 0.224
# F-Score(ireflv) = 0.234, Recall: 0.895, Precision: 0.135
# F-Score(id) = 0.269, Recall: 1.0, Precision: 0.156
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_176 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_176 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_176 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_176 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0645 - acc: 0.9857 - val_loss: 0.0327 - val_acc: 0.9891
Epoch 2/15
 - 6s - loss: 0.0247 - acc: 0.9901 - val_loss: 0.0310 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0302 - val_acc: 0.9896
Epoch 00003: early stopping
# Training time = 0:03:44.146659
# F-Score(Ordinary) = 0.3, Recall: 1.0, Precision: 0.176
# F-Score(lvc) = 0.277, Recall: 1.0, Precision: 0.161
# F-Score(ireflv) = 0.297, Recall: 1.0, Precision: 0.175
# F-Score(id) = 0.322, Recall: 1.0, Precision: 0.192
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 67758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_177 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_177 (Embedding)    (None, 4, 125)            63750     
_________________________________________________________________
flatten_177 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_177 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 67,758
Trainable params: 67,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.2381 - acc: 0.8893 - val_loss: 0.4637 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.2864 - acc: 0.9743 - val_loss: 0.1626 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1396 - acc: 0.9743 - val_loss: 0.1044 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.1013 - acc: 0.9755 - val_loss: 0.0843 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:01.493610
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_178 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_178 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_178 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_178 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0619 - acc: 0.9850 - val_loss: 0.0319 - val_acc: 0.9888
Epoch 2/15
 - 6s - loss: 0.0247 - acc: 0.9901 - val_loss: 0.0301 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0306 - val_acc: 0.9890
Epoch 00003: early stopping
# Training time = 0:04:00.449128
# F-Score(Ordinary) = 0.256, Recall: 0.929, Precision: 0.149
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.584, Recall: 0.915, Precision: 0.429
# F-Score(id) = 0.069, Recall: 1.0, Precision: 0.036
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_179 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_179 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_179 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_179 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0628 - acc: 0.9845 - val_loss: 0.0315 - val_acc: 0.9894
Epoch 2/15
 - 6s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0303 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0210 - acc: 0.9906 - val_loss: 0.0301 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:44.908574
# F-Score(Ordinary) = 0.438, Recall: 0.933, Precision: 0.286
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.434, Recall: 0.9, Precision: 0.286
# F-Score(id) = 0.64, Recall: 0.942, Precision: 0.485
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_180 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_180 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_180 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_180 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0623 - acc: 0.9848 - val_loss: 0.0335 - val_acc: 0.9892
Epoch 2/15
 - 6s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0304 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0211 - acc: 0.9907 - val_loss: 0.0306 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:03:41.164699
# F-Score(Ordinary) = 0.388, Recall: 0.939, Precision: 0.245
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.585, Recall: 0.887, Precision: 0.437
# F-Score(id) = 0.425, Recall: 1.0, Precision: 0.269
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_181 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_181 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_181 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_181 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0630 - acc: 0.9844 - val_loss: 0.0319 - val_acc: 0.9893
Epoch 2/15
 - 6s - loss: 0.0247 - acc: 0.9900 - val_loss: 0.0306 - val_acc: 0.9892
Epoch 3/15
 - 6s - loss: 0.0210 - acc: 0.9907 - val_loss: 0.0304 - val_acc: 0.9890
Epoch 00003: early stopping
# Training time = 0:03:44.761619
# F-Score(Ordinary) = 0.357, Recall: 0.915, Precision: 0.222
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.508, Recall: 0.836, Precision: 0.365
# F-Score(id) = 0.417, Recall: 1.0, Precision: 0.263
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_182 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_182 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_182 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_182 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0623 - acc: 0.9859 - val_loss: 0.0318 - val_acc: 0.9892
Epoch 2/15
 - 6s - loss: 0.0247 - acc: 0.9901 - val_loss: 0.0312 - val_acc: 0.9890
Epoch 3/15
 - 6s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0311 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:45.157806
# F-Score(Ordinary) = 0.215, Recall: 0.946, Precision: 0.121
# F-Score(lvc) = 0.318, Recall: 1.0, Precision: 0.189
# F-Score(ireflv) = 0.303, Recall: 0.885, Precision: 0.183
# F-Score(id) = 0.035, Recall: 1.0, Precision: 0.018
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_183 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_183 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_183 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_183 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0619 - acc: 0.9845 - val_loss: 0.0317 - val_acc: 0.9892
Epoch 2/15
 - 6s - loss: 0.0247 - acc: 0.9900 - val_loss: 0.0299 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0303 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:03:49.550183
# F-Score(Ordinary) = 0.257, Recall: 0.942, Precision: 0.149
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.236, Recall: 0.944, Precision: 0.135
# F-Score(id) = 0.411, Recall: 0.936, Precision: 0.263
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_184 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_184 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_184 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_184 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0620 - acc: 0.9854 - val_loss: 0.0321 - val_acc: 0.9891
Epoch 2/15
 - 6s - loss: 0.0245 - acc: 0.9902 - val_loss: 0.0299 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0309 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:44.237586
# F-Score(Ordinary) = 0.614, Recall: 0.943, Precision: 0.455
# F-Score(lvc) = 0.52, Recall: 0.962, Precision: 0.357
# F-Score(ireflv) = 0.677, Recall: 0.931, Precision: 0.532
# F-Score(id) = 0.64, Recall: 0.942, Precision: 0.485
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_185 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_185 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_185 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_185 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0622 - acc: 0.9849 - val_loss: 0.0320 - val_acc: 0.9895
Epoch 2/15
 - 6s - loss: 0.0247 - acc: 0.9902 - val_loss: 0.0311 - val_acc: 0.9892
Epoch 3/15
 - 6s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0314 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:42.459488
# F-Score(Ordinary) = 0.2, Recall: 0.907, Precision: 0.112
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.497, Recall: 0.915, Precision: 0.341
# F-Score(id) = 0.058, Recall: 0.833, Precision: 0.03
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_186 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_186 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_186 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_186 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0622 - acc: 0.9857 - val_loss: 0.0313 - val_acc: 0.9892
Epoch 2/15
 - 6s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0306 - val_acc: 0.9895
Epoch 3/15
 - 6s - loss: 0.0212 - acc: 0.9905 - val_loss: 0.0298 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:47.976611
# F-Score(Ordinary) = 0.288, Recall: 0.974, Precision: 0.169
# F-Score(lvc) = 0.375, Recall: 1.0, Precision: 0.231
# F-Score(ireflv) = 0.21, Recall: 0.882, Precision: 0.119
# F-Score(id) = 0.269, Recall: 1.0, Precision: 0.156
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_187 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_187 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_187 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_187 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 6s - loss: 0.0625 - acc: 0.9848 - val_loss: 0.0323 - val_acc: 0.9891
Epoch 2/15
 - 6s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0310 - val_acc: 0.9894
Epoch 3/15
 - 6s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0302 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:46.290128
# F-Score(Ordinary) = 0.325, Recall: 0.988, Precision: 0.195
# F-Score(lvc) = 0.318, Recall: 1.0, Precision: 0.189
# F-Score(ireflv) = 0.329, Recall: 0.962, Precision: 0.198
# F-Score(id) = 0.33, Recall: 1.0, Precision: 0.198
********************
********************
# XP = Lemma(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 81308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_188 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_188 (Embedding)    (None, 4, 150)            76500     
_________________________________________________________________
flatten_188 (Flatten)        (None, 600)               0         
_________________________________________________________________
dense_188 (Dense)            (None, 8)                 4808      
=================================================================
Total params: 81,308
Trainable params: 81,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.1728 - acc: 0.8946 - val_loss: 0.4025 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.2477 - acc: 0.9745 - val_loss: 0.1434 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1262 - acc: 0.9752 - val_loss: 0.0967 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.0932 - acc: 0.9775 - val_loss: 0.0795 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:01.507915
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 2226458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_189 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_189 (Embedding)    (None, 4, 150)            2221650   
_________________________________________________________________
flatten_189 (Flatten)        (None, 600)               0         
_________________________________________________________________
dense_189 (Dense)            (None, 8)                 4808      
=================================================================
Total params: 2,226,458
Trainable params: 2,226,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0605 - acc: 0.9845 - val_loss: 0.0319 - val_acc: 0.9889
Epoch 2/15
 - 7s - loss: 0.0247 - acc: 0.9901 - val_loss: 0.0301 - val_acc: 0.9894
Epoch 3/15
 - 7s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0307 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:52.008821
# F-Score(Ordinary) = 0.26, Recall: 0.943, Precision: 0.151
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.579, Recall: 0.93, Precision: 0.421
# F-Score(id) = 0.069, Recall: 1.0, Precision: 0.036
********************
********************
# XP = Lemma(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 2226458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_190 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_190 (Embedding)    (None, 4, 150)            2221650   
_________________________________________________________________
flatten_190 (Flatten)        (None, 600)               0         
_________________________________________________________________
dense_190 (Dense)            (None, 8)                 4808      
=================================================================
Total params: 2,226,458
Trainable params: 2,226,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0597 - acc: 0.9862 - val_loss: 0.0314 - val_acc: 0.9892
Epoch 2/15
 - 7s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0300 - val_acc: 0.9894
Epoch 3/15
 - 7s - loss: 0.0210 - acc: 0.9906 - val_loss: 0.0300 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:49.162209
# F-Score(Ordinary) = 0.459, Recall: 0.937, Precision: 0.304
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.462, Recall: 0.907, Precision: 0.31
# F-Score(id) = 0.656, Recall: 0.944, Precision: 0.503
********************
********************
# XP = Lemma(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 2226458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_191 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_191 (Embedding)    (None, 4, 150)            2221650   
_________________________________________________________________
flatten_191 (Flatten)        (None, 600)               0         
_________________________________________________________________
dense_191 (Dense)            (None, 8)                 4808      
=================================================================
Total params: 2,226,458
Trainable params: 2,226,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0602 - acc: 0.9854 - val_loss: 0.0338 - val_acc: 0.9891
Epoch 2/15
 - 7s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0302 - val_acc: 0.9895
Epoch 3/15
 - 7s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0306 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:46.881848
# F-Score(Ordinary) = 0.388, Recall: 0.939, Precision: 0.245
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.585, Recall: 0.887, Precision: 0.437
# F-Score(id) = 0.425, Recall: 1.0, Precision: 0.269
********************
********************
# XP = Lemma(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 2226458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_192 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_192 (Embedding)    (None, 4, 150)            2221650   
_________________________________________________________________
flatten_192 (Flatten)        (None, 600)               0         
_________________________________________________________________
dense_192 (Dense)            (None, 8)                 4808      
=================================================================
Total params: 2,226,458
Trainable params: 2,226,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0602 - acc: 0.9862 - val_loss: 0.0319 - val_acc: 0.9892
Epoch 2/15
 - 7s - loss: 0.0246 - acc: 0.9900 - val_loss: 0.0310 - val_acc: 0.9891
Epoch 3/15
 - 7s - loss: 0.0210 - acc: 0.9907 - val_loss: 0.0307 - val_acc: 0.9890
Epoch 00003: early stopping
# Training time = 0:03:47.629439
# F-Score(Ordinary) = 0.376, Recall: 0.928, Precision: 0.236
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.551, Recall: 0.864, Precision: 0.405
# F-Score(id) = 0.425, Recall: 1.0, Precision: 0.269
********************
********************
# XP = Lemma(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 2226458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_193 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_193 (Embedding)    (None, 4, 150)            2221650   
_________________________________________________________________
flatten_193 (Flatten)        (None, 600)               0         
_________________________________________________________________
dense_193 (Dense)            (None, 8)                 4808      
=================================================================
Total params: 2,226,458
Trainable params: 2,226,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0601 - acc: 0.9860 - val_loss: 0.0319 - val_acc: 0.9891
Epoch 2/15
 - 7s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0316 - val_acc: 0.9888
Epoch 3/15
 - 7s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0312 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:48.767478
# F-Score(Ordinary) = 0.211, Recall: 0.945, Precision: 0.119
# F-Score(lvc) = 0.256, Recall: 1.0, Precision: 0.147
# F-Score(ireflv) = 0.367, Recall: 0.906, Precision: 0.23
# F-Score(id) = 0.024, Recall: 1.0, Precision: 0.012
********************
********************
# XP = Lemma(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 2226458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_194 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_194 (Embedding)    (None, 4, 150)            2221650   
_________________________________________________________________
flatten_194 (Flatten)        (None, 600)               0         
_________________________________________________________________
dense_194 (Dense)            (None, 8)                 4808      
=================================================================
Total params: 2,226,458
Trainable params: 2,226,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0595 - acc: 0.9863 - val_loss: 0.0318 - val_acc: 0.9891
Epoch 2/15
 - 7s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0300 - val_acc: 0.9894
Epoch 3/15
 - 7s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0304 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:03:49.200193
# F-Score(Ordinary) = 0.275, Recall: 0.959, Precision: 0.16
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.238, Recall: 1.0, Precision: 0.135
# F-Score(id) = 0.447, Recall: 0.942, Precision: 0.293
********************
********************
# XP = Lemma(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 2226458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_195 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_195 (Embedding)    (None, 4, 150)            2221650   
_________________________________________________________________
flatten_195 (Flatten)        (None, 600)               0         
_________________________________________________________________
dense_195 (Dense)            (None, 8)                 4808      
=================================================================
Total params: 2,226,458
Trainable params: 2,226,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0596 - acc: 0.9851 - val_loss: 0.0322 - val_acc: 0.9889
Epoch 2/15
 - 7s - loss: 0.0245 - acc: 0.9902 - val_loss: 0.0303 - val_acc: 0.9894
Epoch 3/15
 - 7s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0311 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:48.129832
# F-Score(Ordinary) = 0.613, Recall: 0.93, Precision: 0.458
# F-Score(lvc) = 0.528, Recall: 0.963, Precision: 0.364
# F-Score(ireflv) = 0.646, Recall: 0.889, Precision: 0.508
# F-Score(id) = 0.656, Recall: 0.944, Precision: 0.503
********************
********************
# XP = Lemma(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 2226458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_196 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_196 (Embedding)    (None, 4, 150)            2221650   
_________________________________________________________________
flatten_196 (Flatten)        (None, 600)               0         
_________________________________________________________________
dense_196 (Dense)            (None, 8)                 4808      
=================================================================
Total params: 2,226,458
Trainable params: 2,226,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0599 - acc: 0.9862 - val_loss: 0.0319 - val_acc: 0.9896
Epoch 2/15
 - 7s - loss: 0.0245 - acc: 0.9902 - val_loss: 0.0313 - val_acc: 0.9892
Epoch 3/15
 - 7s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0316 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:03:51.384634
# F-Score(Ordinary) = 0.196, Recall: 0.923, Precision: 0.11
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.5, Recall: 0.935, Precision: 0.341
# F-Score(id) = 0.047, Recall: 0.8, Precision: 0.024
********************
********************
# XP = Lemma(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 2226458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_197 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_197 (Embedding)    (None, 4, 150)            2221650   
_________________________________________________________________
flatten_197 (Flatten)        (None, 600)               0         
_________________________________________________________________
dense_197 (Dense)            (None, 8)                 4808      
=================================================================
Total params: 2,226,458
Trainable params: 2,226,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0601 - acc: 0.9854 - val_loss: 0.0315 - val_acc: 0.9891
Epoch 2/15
 - 7s - loss: 0.0246 - acc: 0.9902 - val_loss: 0.0310 - val_acc: 0.9895
Epoch 3/15
 - 7s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0300 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:47.218025
# F-Score(Ordinary) = 0.282, Recall: 0.973, Precision: 0.165
# F-Score(lvc) = 0.375, Recall: 1.0, Precision: 0.231
# F-Score(ireflv) = 0.21, Recall: 0.882, Precision: 0.119
# F-Score(id) = 0.251, Recall: 1.0, Precision: 0.144
********************
********************
# XP = Lemma(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 2226458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_198 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_198 (Embedding)    (None, 4, 150)            2221650   
_________________________________________________________________
flatten_198 (Flatten)        (None, 600)               0         
_________________________________________________________________
dense_198 (Dense)            (None, 8)                 4808      
=================================================================
Total params: 2,226,458
Trainable params: 2,226,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0600 - acc: 0.9844 - val_loss: 0.0324 - val_acc: 0.9891
Epoch 2/15
 - 7s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0309 - val_acc: 0.9893
Epoch 3/15
 - 7s - loss: 0.0211 - acc: 0.9907 - val_loss: 0.0301 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:43.722040
# F-Score(Ordinary) = 0.328, Recall: 0.989, Precision: 0.197
# F-Score(lvc) = 0.308, Recall: 1.0, Precision: 0.182
# F-Score(ireflv) = 0.329, Recall: 0.962, Precision: 0.198
# F-Score(id) = 0.347, Recall: 1.0, Precision: 0.21
********************
********************
# XP = Lemma(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 94858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_199 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_199 (Embedding)    (None, 4, 175)            89250     
_________________________________________________________________
flatten_199 (Flatten)        (None, 700)               0         
_________________________________________________________________
dense_199 (Dense)            (None, 8)                 5608      
=================================================================
Total params: 94,858
Trainable params: 94,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.0952 - acc: 0.9162 - val_loss: 0.3293 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.2078 - acc: 0.9743 - val_loss: 0.1254 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1157 - acc: 0.9750 - val_loss: 0.0896 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.0883 - acc: 0.9777 - val_loss: 0.0751 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:06.641500
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 2597533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_200 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_200 (Embedding)    (None, 4, 175)            2591925   
_________________________________________________________________
flatten_200 (Flatten)        (None, 700)               0         
_________________________________________________________________
dense_200 (Dense)            (None, 8)                 5608      
=================================================================
Total params: 2,597,533
Trainable params: 2,597,533
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0579 - acc: 0.9861 - val_loss: 0.0319 - val_acc: 0.9889
Epoch 2/15
 - 7s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0304 - val_acc: 0.9894
Epoch 3/15
 - 7s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0310 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:04:22.400925
# F-Score(Ordinary) = 0.27, Recall: 0.932, Precision: 0.158
# F-Score(lvc) = 0.081, Recall: 1.0, Precision: 0.042
# F-Score(ireflv) = 0.599, Recall: 0.918, Precision: 0.444
# F-Score(id) = 0.08, Recall: 1.0, Precision: 0.042
********************
********************
# XP = Lemma(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 2597533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_201 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_201 (Embedding)    (None, 4, 175)            2591925   
_________________________________________________________________
flatten_201 (Flatten)        (None, 700)               0         
_________________________________________________________________
dense_201 (Dense)            (None, 8)                 5608      
=================================================================
Total params: 2,597,533
Trainable params: 2,597,533
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0582 - acc: 0.9856 - val_loss: 0.0316 - val_acc: 0.9892
Epoch 2/15
 - 7s - loss: 0.0244 - acc: 0.9901 - val_loss: 0.0302 - val_acc: 0.9894
Epoch 3/15
 - 7s - loss: 0.0210 - acc: 0.9906 - val_loss: 0.0301 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:50.748523
# F-Score(Ordinary) = 0.467, Recall: 0.932, Precision: 0.311
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.494, Recall: 0.896, Precision: 0.341
# F-Score(id) = 0.651, Recall: 0.943, Precision: 0.497
********************
********************
# XP = Lemma(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 2597533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_202 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_202 (Embedding)    (None, 4, 175)            2591925   
_________________________________________________________________
flatten_202 (Flatten)        (None, 700)               0         
_________________________________________________________________
dense_202 (Dense)            (None, 8)                 5608      
=================================================================
Total params: 2,597,533
Trainable params: 2,597,533
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0582 - acc: 0.9864 - val_loss: 0.0339 - val_acc: 0.9891
Epoch 2/15
 - 7s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0303 - val_acc: 0.9894
Epoch 3/15
 - 7s - loss: 0.0210 - acc: 0.9907 - val_loss: 0.0306 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:03:49.249878
# F-Score(Ordinary) = 0.394, Recall: 0.94, Precision: 0.249
# F-Score(lvc) = 0.081, Recall: 1.0, Precision: 0.042
# F-Score(ireflv) = 0.6, Recall: 0.891, Precision: 0.452
# F-Score(id) = 0.432, Recall: 1.0, Precision: 0.275
********************
********************
# XP = Lemma(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 2597533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_203 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_203 (Embedding)    (None, 4, 175)            2591925   
_________________________________________________________________
flatten_203 (Flatten)        (None, 700)               0         
_________________________________________________________________
dense_203 (Dense)            (None, 8)                 5608      
=================================================================
Total params: 2,597,533
Trainable params: 2,597,533
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0585 - acc: 0.9853 - val_loss: 0.0319 - val_acc: 0.9893
Epoch 2/15
 - 7s - loss: 0.0246 - acc: 0.9900 - val_loss: 0.0310 - val_acc: 0.9892
Epoch 3/15
 - 7s - loss: 0.0210 - acc: 0.9907 - val_loss: 0.0308 - val_acc: 0.9889
Epoch 00003: early stopping
# Training time = 0:03:53.669399
# F-Score(Ordinary) = 0.385, Recall: 0.93, Precision: 0.243
# F-Score(lvc) = 0.081, Recall: 1.0, Precision: 0.042
# F-Score(ireflv) = 0.582, Recall: 0.873, Precision: 0.437
# F-Score(id) = 0.425, Recall: 1.0, Precision: 0.269
********************
********************
# XP = Lemma(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 2597533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_204 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_204 (Embedding)    (None, 4, 175)            2591925   
_________________________________________________________________
flatten_204 (Flatten)        (None, 700)               0         
_________________________________________________________________
dense_204 (Dense)            (None, 8)                 5608      
=================================================================
Total params: 2,597,533
Trainable params: 2,597,533
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0583 - acc: 0.9862 - val_loss: 0.0320 - val_acc: 0.9891
Epoch 2/15
 - 7s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0317 - val_acc: 0.9888
Epoch 3/15
 - 7s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0312 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:49.769151
# F-Score(Ordinary) = 0.215, Recall: 0.93, Precision: 0.121
# F-Score(lvc) = 0.286, Recall: 0.96, Precision: 0.168
# F-Score(ireflv) = 0.325, Recall: 0.893, Precision: 0.198
# F-Score(id) = 0.047, Recall: 1.0, Precision: 0.024
********************
********************
# XP = Lemma(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 2597533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_205 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_205 (Embedding)    (None, 4, 175)            2591925   
_________________________________________________________________
flatten_205 (Flatten)        (None, 700)               0         
_________________________________________________________________
dense_205 (Dense)            (None, 8)                 5608      
=================================================================
Total params: 2,597,533
Trainable params: 2,597,533
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0586 - acc: 0.9862 - val_loss: 0.0316 - val_acc: 0.9891
Epoch 2/15
 - 7s - loss: 0.0244 - acc: 0.9901 - val_loss: 0.0299 - val_acc: 0.9894
Epoch 3/15
 - 7s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0304 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:49.338953
# F-Score(Ordinary) = 0.288, Recall: 0.961, Precision: 0.169
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.213, Recall: 1.0, Precision: 0.119
# F-Score(id) = 0.489, Recall: 0.948, Precision: 0.329
********************
********************
# XP = Lemma(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 2597533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_206 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_206 (Embedding)    (None, 4, 175)            2591925   
_________________________________________________________________
flatten_206 (Flatten)        (None, 700)               0         
_________________________________________________________________
dense_206 (Dense)            (None, 8)                 5608      
=================================================================
Total params: 2,597,533
Trainable params: 2,597,533
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0581 - acc: 0.9849 - val_loss: 0.0323 - val_acc: 0.9889
Epoch 2/15
 - 7s - loss: 0.0244 - acc: 0.9902 - val_loss: 0.0302 - val_acc: 0.9894
Epoch 3/15
 - 7s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0310 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:49.915910
# F-Score(Ordinary) = 0.619, Recall: 0.935, Precision: 0.462
# F-Score(lvc) = 0.513, Recall: 0.962, Precision: 0.35
# F-Score(ireflv) = 0.683, Recall: 0.908, Precision: 0.548
# F-Score(id) = 0.651, Recall: 0.943, Precision: 0.497
********************
********************
# XP = Lemma(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 2597533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_207 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_207 (Embedding)    (None, 4, 175)            2591925   
_________________________________________________________________
flatten_207 (Flatten)        (None, 700)               0         
_________________________________________________________________
dense_207 (Dense)            (None, 8)                 5608      
=================================================================
Total params: 2,597,533
Trainable params: 2,597,533
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0587 - acc: 0.9856 - val_loss: 0.0319 - val_acc: 0.9895
Epoch 2/15
 - 7s - loss: 0.0245 - acc: 0.9902 - val_loss: 0.0312 - val_acc: 0.9892
Epoch 3/15
 - 7s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0314 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:50.589157
# F-Score(Ordinary) = 0.2, Recall: 0.907, Precision: 0.112
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.506, Recall: 0.917, Precision: 0.349
# F-Score(id) = 0.047, Recall: 0.8, Precision: 0.024
********************
********************
# XP = Lemma(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 2597533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_208 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_208 (Embedding)    (None, 4, 175)            2591925   
_________________________________________________________________
flatten_208 (Flatten)        (None, 700)               0         
_________________________________________________________________
dense_208 (Dense)            (None, 8)                 5608      
=================================================================
Total params: 2,597,533
Trainable params: 2,597,533
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0594 - acc: 0.9857 - val_loss: 0.0314 - val_acc: 0.9892
Epoch 2/15
 - 7s - loss: 0.0246 - acc: 0.9902 - val_loss: 0.0311 - val_acc: 0.9895
Epoch 3/15
 - 7s - loss: 0.0212 - acc: 0.9905 - val_loss: 0.0300 - val_acc: 0.9896
Epoch 00003: early stopping
# Training time = 0:03:49.283412
# F-Score(Ordinary) = 0.288, Recall: 0.974, Precision: 0.169
# F-Score(lvc) = 0.393, Recall: 1.0, Precision: 0.245
# F-Score(ireflv) = 0.222, Recall: 0.889, Precision: 0.127
# F-Score(id) = 0.242, Recall: 1.0, Precision: 0.138
********************
********************
# XP = Lemma(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 2597533
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_209 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_209 (Embedding)    (None, 4, 175)            2591925   
_________________________________________________________________
flatten_209 (Flatten)        (None, 700)               0         
_________________________________________________________________
dense_209 (Dense)            (None, 8)                 5608      
=================================================================
Total params: 2,597,533
Trainable params: 2,597,533
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0578 - acc: 0.9860 - val_loss: 0.0326 - val_acc: 0.9891
Epoch 2/15
 - 7s - loss: 0.0244 - acc: 0.9901 - val_loss: 0.0311 - val_acc: 0.9893
Epoch 3/15
 - 7s - loss: 0.0210 - acc: 0.9906 - val_loss: 0.0303 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:48.371794
# F-Score(Ordinary) = 0.351, Recall: 1.0, Precision: 0.213
# F-Score(lvc) = 0.318, Recall: 1.0, Precision: 0.189
# F-Score(ireflv) = 0.353, Recall: 1.0, Precision: 0.214
# F-Score(id) = 0.379, Recall: 1.0, Precision: 0.234
********************
********************
# XP = Lemma(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 108408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_210 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_210 (Embedding)    (None, 4, 200)            102000    
_________________________________________________________________
flatten_210 (Flatten)        (None, 800)               0         
_________________________________________________________________
dense_210 (Dense)            (None, 8)                 6408      
=================================================================
Total params: 108,408
Trainable params: 108,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.0661 - acc: 0.8905 - val_loss: 0.3256 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.2038 - acc: 0.9743 - val_loss: 0.1224 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1127 - acc: 0.9748 - val_loss: 0.0877 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.0855 - acc: 0.9782 - val_loss: 0.0737 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:01.532917
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 2968608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_211 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_211 (Embedding)    (None, 4, 200)            2962200   
_________________________________________________________________
flatten_211 (Flatten)        (None, 800)               0         
_________________________________________________________________
dense_211 (Dense)            (None, 8)                 6408      
=================================================================
Total params: 2,968,608
Trainable params: 2,968,608
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0569 - acc: 0.9851 - val_loss: 0.0320 - val_acc: 0.9889
Epoch 2/15
 - 8s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0304 - val_acc: 0.9893
Epoch 3/15
 - 8s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0310 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:50.498252
# F-Score(Ordinary) = 0.29, Recall: 0.926, Precision: 0.172
# F-Score(lvc) = 0.081, Recall: 1.0, Precision: 0.042
# F-Score(ireflv) = 0.618, Recall: 0.908, Precision: 0.468
# F-Score(id) = 0.113, Recall: 1.0, Precision: 0.06
********************
********************
# XP = Lemma(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 2968608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_212 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_212 (Embedding)    (None, 4, 200)            2962200   
_________________________________________________________________
flatten_212 (Flatten)        (None, 800)               0         
_________________________________________________________________
dense_212 (Dense)            (None, 8)                 6408      
=================================================================
Total params: 2,968,608
Trainable params: 2,968,608
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0572 - acc: 0.9851 - val_loss: 0.0318 - val_acc: 0.9892
Epoch 2/15
 - 8s - loss: 0.0244 - acc: 0.9901 - val_loss: 0.0303 - val_acc: 0.9895
Epoch 3/15
 - 8s - loss: 0.0210 - acc: 0.9906 - val_loss: 0.0302 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:52.948575
# F-Score(Ordinary) = 0.464, Recall: 0.931, Precision: 0.309
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.511, Recall: 0.9, Precision: 0.357
# F-Score(id) = 0.646, Recall: 0.943, Precision: 0.491
********************
********************
# XP = Lemma(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 2968608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_213 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_213 (Embedding)    (None, 4, 200)            2962200   
_________________________________________________________________
flatten_213 (Flatten)        (None, 800)               0         
_________________________________________________________________
dense_213 (Dense)            (None, 8)                 6408      
=================================================================
Total params: 2,968,608
Trainable params: 2,968,608
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0566 - acc: 0.9863 - val_loss: 0.0339 - val_acc: 0.9891
Epoch 2/15
 - 8s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0303 - val_acc: 0.9895
Epoch 3/15
 - 8s - loss: 0.0210 - acc: 0.9907 - val_loss: 0.0305 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:51.547939
# F-Score(Ordinary) = 0.385, Recall: 0.938, Precision: 0.243
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.593, Recall: 0.889, Precision: 0.444
# F-Score(id) = 0.425, Recall: 1.0, Precision: 0.269
********************
********************
# XP = Lemma(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 2968608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_214 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_214 (Embedding)    (None, 4, 200)            2962200   
_________________________________________________________________
flatten_214 (Flatten)        (None, 800)               0         
_________________________________________________________________
dense_214 (Dense)            (None, 8)                 6408      
=================================================================
Total params: 2,968,608
Trainable params: 2,968,608
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0567 - acc: 0.9858 - val_loss: 0.0320 - val_acc: 0.9892
Epoch 2/15
 - 8s - loss: 0.0246 - acc: 0.9900 - val_loss: 0.0313 - val_acc: 0.9890
Epoch 3/15
 - 8s - loss: 0.0211 - acc: 0.9908 - val_loss: 0.0311 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:03:53.323402
# F-Score(Ordinary) = 0.39, Recall: 0.923, Precision: 0.247
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.564, Recall: 0.855, Precision: 0.421
# F-Score(id) = 0.439, Recall: 1.0, Precision: 0.281
********************
********************
# XP = Lemma(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 2968608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_215 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_215 (Embedding)    (None, 4, 200)            2962200   
_________________________________________________________________
flatten_215 (Flatten)        (None, 800)               0         
_________________________________________________________________
dense_215 (Dense)            (None, 8)                 6408      
=================================================================
Total params: 2,968,608
Trainable params: 2,968,608
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0571 - acc: 0.9856 - val_loss: 0.0319 - val_acc: 0.9891
Epoch 2/15
 - 8s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0319 - val_acc: 0.9887
Epoch 3/15
 - 8s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0313 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:51.412177
# F-Score(Ordinary) = 0.211, Recall: 0.929, Precision: 0.119
# F-Score(lvc) = 0.265, Recall: 0.957, Precision: 0.154
# F-Score(ireflv) = 0.346, Recall: 0.9, Precision: 0.214
# F-Score(id) = 0.035, Recall: 1.0, Precision: 0.018
********************
********************
# XP = Lemma(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 2968608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_216 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_216 (Embedding)    (None, 4, 200)            2962200   
_________________________________________________________________
flatten_216 (Flatten)        (None, 800)               0         
_________________________________________________________________
dense_216 (Dense)            (None, 8)                 6408      
=================================================================
Total params: 2,968,608
Trainable params: 2,968,608
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0564 - acc: 0.9863 - val_loss: 0.0317 - val_acc: 0.9891
Epoch 2/15
 - 8s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0299 - val_acc: 0.9895
Epoch 3/15
 - 8s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0303 - val_acc: 0.9896
Epoch 00003: early stopping
# Training time = 0:03:51.857942
# F-Score(Ordinary) = 0.295, Recall: 0.962, Precision: 0.174
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.225, Recall: 1.0, Precision: 0.127
# F-Score(id) = 0.502, Recall: 0.95, Precision: 0.341
********************
********************
# XP = Lemma(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 2968608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_217 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_217 (Embedding)    (None, 4, 200)            2962200   
_________________________________________________________________
flatten_217 (Flatten)        (None, 800)               0         
_________________________________________________________________
dense_217 (Dense)            (None, 8)                 6408      
=================================================================
Total params: 2,968,608
Trainable params: 2,968,608
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0567 - acc: 0.9860 - val_loss: 0.0323 - val_acc: 0.9890
Epoch 2/15
 - 8s - loss: 0.0244 - acc: 0.9902 - val_loss: 0.0303 - val_acc: 0.9894
Epoch 3/15
 - 8s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0310 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:51.786597
# F-Score(Ordinary) = 0.609, Recall: 0.93, Precision: 0.453
# F-Score(lvc) = 0.52, Recall: 0.962, Precision: 0.357
# F-Score(ireflv) = 0.667, Recall: 0.893, Precision: 0.532
# F-Score(id) = 0.635, Recall: 0.941, Precision: 0.479
********************
********************
# XP = Lemma(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 2968608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_218 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_218 (Embedding)    (None, 4, 200)            2962200   
_________________________________________________________________
flatten_218 (Flatten)        (None, 800)               0         
_________________________________________________________________
dense_218 (Dense)            (None, 8)                 6408      
=================================================================
Total params: 2,968,608
Trainable params: 2,968,608
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0569 - acc: 0.9858 - val_loss: 0.0320 - val_acc: 0.9896
Epoch 2/15
 - 8s - loss: 0.0244 - acc: 0.9902 - val_loss: 0.0314 - val_acc: 0.9890
Epoch 3/15
 - 8s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0316 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:55.022175
# F-Score(Ordinary) = 0.204, Recall: 0.926, Precision: 0.114
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.5, Recall: 0.935, Precision: 0.341
# F-Score(id) = 0.069, Recall: 0.857, Precision: 0.036
********************
********************
# XP = Lemma(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 2968608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_219 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_219 (Embedding)    (None, 4, 200)            2962200   
_________________________________________________________________
flatten_219 (Flatten)        (None, 800)               0         
_________________________________________________________________
dense_219 (Dense)            (None, 8)                 6408      
=================================================================
Total params: 2,968,608
Trainable params: 2,968,608
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0562 - acc: 0.9865 - val_loss: 0.0316 - val_acc: 0.9890
Epoch 2/15
 - 8s - loss: 0.0245 - acc: 0.9902 - val_loss: 0.0313 - val_acc: 0.9894
Epoch 3/15
 - 8s - loss: 0.0212 - acc: 0.9905 - val_loss: 0.0300 - val_acc: 0.9896
Epoch 00003: early stopping
# Training time = 0:03:51.180229
# F-Score(Ordinary) = 0.265, Recall: 0.971, Precision: 0.153
# F-Score(lvc) = 0.366, Recall: 1.0, Precision: 0.224
# F-Score(ireflv) = 0.184, Recall: 0.867, Precision: 0.103
# F-Score(id) = 0.233, Recall: 1.0, Precision: 0.132
********************
********************
# XP = Lemma(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 2968608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_220 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_220 (Embedding)    (None, 4, 200)            2962200   
_________________________________________________________________
flatten_220 (Flatten)        (None, 800)               0         
_________________________________________________________________
dense_220 (Dense)            (None, 8)                 6408      
=================================================================
Total params: 2,968,608
Trainable params: 2,968,608
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0570 - acc: 0.9853 - val_loss: 0.0327 - val_acc: 0.9892
Epoch 2/15
 - 8s - loss: 0.0244 - acc: 0.9901 - val_loss: 0.0312 - val_acc: 0.9894
Epoch 3/15
 - 8s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0304 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:03:51.777378
# F-Score(Ordinary) = 0.363, Recall: 1.0, Precision: 0.222
# F-Score(lvc) = 0.287, Recall: 1.0, Precision: 0.168
# F-Score(ireflv) = 0.405, Recall: 1.0, Precision: 0.254
# F-Score(id) = 0.394, Recall: 1.0, Precision: 0.246
********************
********************
# XP = Lemma(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 121958
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_221 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_221 (Embedding)    (None, 4, 225)            114750    
_________________________________________________________________
flatten_221 (Flatten)        (None, 900)               0         
_________________________________________________________________
dense_221 (Dense)            (None, 8)                 7208      
=================================================================
Total params: 121,958
Trainable params: 121,958
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 0.9895 - acc: 0.9217 - val_loss: 0.2775 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.1820 - acc: 0.9744 - val_loss: 0.1135 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1063 - acc: 0.9753 - val_loss: 0.0833 - val_acc: 0.9793
Epoch 00003: early stopping
# Training time = 0:00:01.434835
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 3339683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_222 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_222 (Embedding)    (None, 4, 225)            3332475   
_________________________________________________________________
flatten_222 (Flatten)        (None, 900)               0         
_________________________________________________________________
dense_222 (Dense)            (None, 8)                 7208      
=================================================================
Total params: 3,339,683
Trainable params: 3,339,683
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0553 - acc: 0.9865 - val_loss: 0.0320 - val_acc: 0.9889
Epoch 2/15
 - 8s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0304 - val_acc: 0.9895
Epoch 3/15
 - 8s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0309 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:52.186908
# F-Score(Ordinary) = 0.286, Recall: 0.925, Precision: 0.169
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.618, Recall: 0.908, Precision: 0.468
# F-Score(id) = 0.113, Recall: 1.0, Precision: 0.06
********************
********************
# XP = Lemma(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 3339683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_223 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_223 (Embedding)    (None, 4, 225)            3332475   
_________________________________________________________________
flatten_223 (Flatten)        (None, 900)               0         
_________________________________________________________________
dense_223 (Dense)            (None, 8)                 7208      
=================================================================
Total params: 3,339,683
Trainable params: 3,339,683
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0557 - acc: 0.9865 - val_loss: 0.0321 - val_acc: 0.9892
Epoch 2/15
 - 8s - loss: 0.0244 - acc: 0.9901 - val_loss: 0.0304 - val_acc: 0.9894
Epoch 3/15
 - 8s - loss: 0.0210 - acc: 0.9906 - val_loss: 0.0302 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:53.022537
# F-Score(Ordinary) = 0.469, Recall: 0.932, Precision: 0.314
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.511, Recall: 0.9, Precision: 0.357
# F-Score(id) = 0.656, Recall: 0.944, Precision: 0.503
********************
********************
# XP = Lemma(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 3339683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_224 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_224 (Embedding)    (None, 4, 225)            3332475   
_________________________________________________________________
flatten_224 (Flatten)        (None, 900)               0         
_________________________________________________________________
dense_224 (Dense)            (None, 8)                 7208      
=================================================================
Total params: 3,339,683
Trainable params: 3,339,683
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0557 - acc: 0.9864 - val_loss: 0.0343 - val_acc: 0.9891
Epoch 2/15
 - 8s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0305 - val_acc: 0.9894
Epoch 3/15
 - 8s - loss: 0.0211 - acc: 0.9907 - val_loss: 0.0306 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:03:49.055744
# F-Score(Ordinary) = 0.38, Recall: 0.937, Precision: 0.238
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.578, Recall: 0.885, Precision: 0.429
# F-Score(id) = 0.425, Recall: 1.0, Precision: 0.269
********************
********************
# XP = Lemma(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 3339683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_225 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_225 (Embedding)    (None, 4, 225)            3332475   
_________________________________________________________________
flatten_225 (Flatten)        (None, 900)               0         
_________________________________________________________________
dense_225 (Dense)            (None, 8)                 7208      
=================================================================
Total params: 3,339,683
Trainable params: 3,339,683
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0561 - acc: 0.9853 - val_loss: 0.0320 - val_acc: 0.9892
Epoch 2/15
 - 8s - loss: 0.0246 - acc: 0.9900 - val_loss: 0.0314 - val_acc: 0.9890
Epoch 3/15
 - 8s - loss: 0.0211 - acc: 0.9908 - val_loss: 0.0312 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:03:50.855593
# F-Score(Ordinary) = 0.407, Recall: 0.927, Precision: 0.261
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.579, Recall: 0.859, Precision: 0.437
# F-Score(id) = 0.454, Recall: 1.0, Precision: 0.293
********************
********************
# XP = Lemma(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 3339683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_226 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_226 (Embedding)    (None, 4, 225)            3332475   
_________________________________________________________________
flatten_226 (Flatten)        (None, 900)               0         
_________________________________________________________________
dense_226 (Dense)            (None, 8)                 7208      
=================================================================
Total params: 3,339,683
Trainable params: 3,339,683
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0552 - acc: 0.9867 - val_loss: 0.0321 - val_acc: 0.9888
Epoch 2/15
 - 8s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0320 - val_acc: 0.9887
Epoch 3/15
 - 8s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0313 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:54.605004
# F-Score(Ordinary) = 0.211, Recall: 0.929, Precision: 0.119
# F-Score(lvc) = 0.255, Recall: 0.955, Precision: 0.147
# F-Score(ireflv) = 0.357, Recall: 0.903, Precision: 0.222
# F-Score(id) = 0.035, Recall: 1.0, Precision: 0.018
********************
********************
# XP = Lemma(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 3339683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_227 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_227 (Embedding)    (None, 4, 225)            3332475   
_________________________________________________________________
flatten_227 (Flatten)        (None, 900)               0         
_________________________________________________________________
dense_227 (Dense)            (None, 8)                 7208      
=================================================================
Total params: 3,339,683
Trainable params: 3,339,683
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0557 - acc: 0.9864 - val_loss: 0.0319 - val_acc: 0.9890
Epoch 2/15
 - 8s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0300 - val_acc: 0.9895
Epoch 3/15
 - 8s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0304 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:54.738846
# F-Score(Ordinary) = 0.304, Recall: 0.963, Precision: 0.181
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.225, Recall: 1.0, Precision: 0.127
# F-Score(id) = 0.522, Recall: 0.952, Precision: 0.359
********************
********************
# XP = Lemma(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 3339683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_228 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_228 (Embedding)    (None, 4, 225)            3332475   
_________________________________________________________________
flatten_228 (Flatten)        (None, 900)               0         
_________________________________________________________________
dense_228 (Dense)            (None, 8)                 7208      
=================================================================
Total params: 3,339,683
Trainable params: 3,339,683
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0559 - acc: 0.9849 - val_loss: 0.0324 - val_acc: 0.9889
Epoch 2/15
 - 8s - loss: 0.0244 - acc: 0.9902 - val_loss: 0.0304 - val_acc: 0.9894
Epoch 3/15
 - 8s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0312 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:53.507430
# F-Score(Ordinary) = 0.605, Recall: 0.929, Precision: 0.449
# F-Score(lvc) = 0.528, Recall: 0.963, Precision: 0.364
# F-Score(ireflv) = 0.64, Recall: 0.887, Precision: 0.5
# F-Score(id) = 0.64, Recall: 0.942, Precision: 0.485
********************
********************
# XP = Lemma(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 3339683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_229 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_229 (Embedding)    (None, 4, 225)            3332475   
_________________________________________________________________
flatten_229 (Flatten)        (None, 900)               0         
_________________________________________________________________
dense_229 (Dense)            (None, 8)                 7208      
=================================================================
Total params: 3,339,683
Trainable params: 3,339,683
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0560 - acc: 0.9855 - val_loss: 0.0319 - val_acc: 0.9895
Epoch 2/15
 - 8s - loss: 0.0244 - acc: 0.9902 - val_loss: 0.0314 - val_acc: 0.9891
Epoch 3/15
 - 8s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0317 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:53.704712
# F-Score(Ordinary) = 0.167, Recall: 0.93, Precision: 0.092
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.42, Recall: 0.944, Precision: 0.27
# F-Score(id) = 0.058, Recall: 0.833, Precision: 0.03
********************
********************
# XP = Lemma(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 3339683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_230 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_230 (Embedding)    (None, 4, 225)            3332475   
_________________________________________________________________
flatten_230 (Flatten)        (None, 900)               0         
_________________________________________________________________
dense_230 (Dense)            (None, 8)                 7208      
=================================================================
Total params: 3,339,683
Trainable params: 3,339,683
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0556 - acc: 0.9860 - val_loss: 0.0316 - val_acc: 0.9889
Epoch 2/15
 - 8s - loss: 0.0245 - acc: 0.9902 - val_loss: 0.0314 - val_acc: 0.9895
Epoch 3/15
 - 8s - loss: 0.0212 - acc: 0.9905 - val_loss: 0.0300 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:57.005669
# F-Score(Ordinary) = 0.279, Recall: 0.986, Precision: 0.162
# F-Score(lvc) = 0.393, Recall: 1.0, Precision: 0.245
# F-Score(ireflv) = 0.187, Recall: 1.0, Precision: 0.103
# F-Score(id) = 0.241, Recall: 0.958, Precision: 0.138
********************
********************
# XP = Lemma(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 3339683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_231 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_231 (Embedding)    (None, 4, 225)            3332475   
_________________________________________________________________
flatten_231 (Flatten)        (None, 900)               0         
_________________________________________________________________
dense_231 (Dense)            (None, 8)                 7208      
=================================================================
Total params: 3,339,683
Trainable params: 3,339,683
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0555 - acc: 0.9867 - val_loss: 0.0328 - val_acc: 0.9891
Epoch 2/15
 - 8s - loss: 0.0245 - acc: 0.9902 - val_loss: 0.0312 - val_acc: 0.9893
Epoch 3/15
 - 8s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0305 - val_acc: 0.9896
Epoch 00003: early stopping
# Training time = 0:03:51.498948
# F-Score(Ordinary) = 0.378, Recall: 0.99, Precision: 0.233
# F-Score(lvc) = 0.318, Recall: 1.0, Precision: 0.189
# F-Score(ireflv) = 0.432, Recall: 0.972, Precision: 0.278
# F-Score(id) = 0.386, Recall: 1.0, Precision: 0.24
********************
********************
# XP = Lemma(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 135508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_232 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_232 (Embedding)    (None, 4, 250)            127500    
_________________________________________________________________
flatten_232 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_232 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 135,508
Trainable params: 135,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 0.9983 - acc: 0.9037 - val_loss: 0.2795 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.1792 - acc: 0.9743 - val_loss: 0.1099 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1030 - acc: 0.9752 - val_loss: 0.0811 - val_acc: 0.9793
Epoch 00003: early stopping
# Training time = 0:00:01.472379
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 3710758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_233 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_233 (Embedding)    (None, 4, 250)            3702750   
_________________________________________________________________
flatten_233 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_233 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 3,710,758
Trainable params: 3,710,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0546 - acc: 0.9861 - val_loss: 0.0320 - val_acc: 0.9890
Epoch 2/15
 - 9s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0305 - val_acc: 0.9894
Epoch 3/15
 - 9s - loss: 0.0211 - acc: 0.9907 - val_loss: 0.0310 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:57.872189
# F-Score(Ordinary) = 0.28, Recall: 0.923, Precision: 0.165
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.618, Recall: 0.908, Precision: 0.468
# F-Score(id) = 0.091, Recall: 1.0, Precision: 0.048
********************
********************
# XP = Lemma(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 3710758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_234 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_234 (Embedding)    (None, 4, 250)            3702750   
_________________________________________________________________
flatten_234 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_234 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 3,710,758
Trainable params: 3,710,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0549 - acc: 0.9854 - val_loss: 0.0322 - val_acc: 0.9892
Epoch 2/15
 - 9s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0306 - val_acc: 0.9895
Epoch 3/15
 - 9s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0304 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:56.274193
# F-Score(Ordinary) = 0.463, Recall: 0.925, Precision: 0.309
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.508, Recall: 0.882, Precision: 0.357
# F-Score(id) = 0.64, Recall: 0.942, Precision: 0.485
********************
********************
# XP = Lemma(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 3710758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_235 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_235 (Embedding)    (None, 4, 250)            3702750   
_________________________________________________________________
flatten_235 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_235 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 3,710,758
Trainable params: 3,710,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0546 - acc: 0.9863 - val_loss: 0.0343 - val_acc: 0.9891
Epoch 2/15
 - 9s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0308 - val_acc: 0.9895
Epoch 3/15
 - 9s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0309 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:03:57.604187
# F-Score(Ordinary) = 0.388, Recall: 0.939, Precision: 0.245
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.585, Recall: 0.887, Precision: 0.437
# F-Score(id) = 0.439, Recall: 1.0, Precision: 0.281
********************
********************
# XP = Lemma(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 3710758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_236 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_236 (Embedding)    (None, 4, 250)            3702750   
_________________________________________________________________
flatten_236 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_236 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 3,710,758
Trainable params: 3,710,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0547 - acc: 0.9863 - val_loss: 0.0320 - val_acc: 0.9891
Epoch 2/15
 - 9s - loss: 0.0246 - acc: 0.9900 - val_loss: 0.0315 - val_acc: 0.9890
Epoch 3/15
 - 9s - loss: 0.0211 - acc: 0.9907 - val_loss: 0.0314 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:03:55.544796
# F-Score(Ordinary) = 0.404, Recall: 0.926, Precision: 0.259
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.571, Recall: 0.857, Precision: 0.429
# F-Score(id) = 0.461, Recall: 1.0, Precision: 0.299
********************
********************
# XP = Lemma(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 3710758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_237 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_237 (Embedding)    (None, 4, 250)            3702750   
_________________________________________________________________
flatten_237 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_237 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 3,710,758
Trainable params: 3,710,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0548 - acc: 0.9856 - val_loss: 0.0322 - val_acc: 0.9888
Epoch 2/15
 - 9s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0323 - val_acc: 0.9886
Epoch 3/15
 - 9s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0314 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:56.287601
# F-Score(Ordinary) = 0.189, Recall: 0.92, Precision: 0.105
# F-Score(lvc) = 0.2, Recall: 0.941, Precision: 0.112
# F-Score(ireflv) = 0.346, Recall: 0.9, Precision: 0.214
# F-Score(id) = 0.035, Recall: 1.0, Precision: 0.018
********************
********************
# XP = Lemma(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 3710758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_238 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_238 (Embedding)    (None, 4, 250)            3702750   
_________________________________________________________________
flatten_238 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_238 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 3,710,758
Trainable params: 3,710,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0550 - acc: 0.9860 - val_loss: 0.0319 - val_acc: 0.9889
Epoch 2/15
 - 9s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0301 - val_acc: 0.9895
Epoch 3/15
 - 9s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0305 - val_acc: 0.9896
Epoch 00003: early stopping
# Training time = 0:03:54.516824
# F-Score(Ordinary) = 0.311, Recall: 0.964, Precision: 0.185
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.225, Recall: 1.0, Precision: 0.127
# F-Score(id) = 0.534, Recall: 0.954, Precision: 0.371
********************
********************
# XP = Lemma(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 3710758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_239 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_239 (Embedding)    (None, 4, 250)            3702750   
_________________________________________________________________
flatten_239 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_239 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 3,710,758
Trainable params: 3,710,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0550 - acc: 0.9861 - val_loss: 0.0324 - val_acc: 0.9889
Epoch 2/15
 - 9s - loss: 0.0245 - acc: 0.9902 - val_loss: 0.0304 - val_acc: 0.9894
Epoch 3/15
 - 9s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0311 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:55.902051
# F-Score(Ordinary) = 0.609, Recall: 0.938, Precision: 0.451
# F-Score(lvc) = 0.523, Recall: 0.981, Precision: 0.357
# F-Score(ireflv) = 0.65, Recall: 0.901, Precision: 0.508
# F-Score(id) = 0.646, Recall: 0.943, Precision: 0.491
********************
********************
# XP = Lemma(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 3710758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_240 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_240 (Embedding)    (None, 4, 250)            3702750   
_________________________________________________________________
flatten_240 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_240 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 3,710,758
Trainable params: 3,710,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0545 - acc: 0.9863 - val_loss: 0.0321 - val_acc: 0.9895
Epoch 2/15
 - 9s - loss: 0.0245 - acc: 0.9902 - val_loss: 0.0315 - val_acc: 0.9891
Epoch 3/15
 - 9s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0317 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:55.776372
# F-Score(Ordinary) = 0.175, Recall: 0.955, Precision: 0.096
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.461, Recall: 0.974, Precision: 0.302
# F-Score(id) = 0.035, Recall: 0.75, Precision: 0.018
********************
********************
# XP = Lemma(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 3710758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_241 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_241 (Embedding)    (None, 4, 250)            3702750   
_________________________________________________________________
flatten_241 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_241 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 3,710,758
Trainable params: 3,710,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0544 - acc: 0.9862 - val_loss: 0.0319 - val_acc: 0.9889
Epoch 2/15
 - 9s - loss: 0.0245 - acc: 0.9902 - val_loss: 0.0318 - val_acc: 0.9894
Epoch 3/15
 - 9s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0301 - val_acc: 0.9896
Epoch 00003: early stopping
# Training time = 0:03:57.188924
# F-Score(Ordinary) = 0.259, Recall: 1.0, Precision: 0.149
# F-Score(lvc) = 0.393, Recall: 1.0, Precision: 0.245
# F-Score(ireflv) = 0.161, Recall: 1.0, Precision: 0.087
# F-Score(id) = 0.204, Recall: 1.0, Precision: 0.114
********************
********************
# XP = Lemma(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 3710758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_242 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_242 (Embedding)    (None, 4, 250)            3702750   
_________________________________________________________________
flatten_242 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_242 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 3,710,758
Trainable params: 3,710,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0542 - acc: 0.9869 - val_loss: 0.0327 - val_acc: 0.9892
Epoch 2/15
 - 9s - loss: 0.0243 - acc: 0.9902 - val_loss: 0.0310 - val_acc: 0.9894
Epoch 3/15
 - 9s - loss: 0.0210 - acc: 0.9906 - val_loss: 0.0301 - val_acc: 0.9896
Epoch 00003: early stopping
# Training time = 0:03:53.566744
# F-Score(Ordinary) = 0.363, Recall: 1.0, Precision: 0.222
# F-Score(lvc) = 0.308, Recall: 1.0, Precision: 0.182
# F-Score(ireflv) = 0.415, Recall: 1.0, Precision: 0.262
# F-Score(id) = 0.371, Recall: 1.0, Precision: 0.228
********************
********************
# XP = Lemma(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 149058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_243 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_243 (Embedding)    (None, 4, 275)            140250    
_________________________________________________________________
flatten_243 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_243 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 149,058
Trainable params: 149,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 0.9175 - acc: 0.9291 - val_loss: 0.2260 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.1554 - acc: 0.9743 - val_loss: 0.1004 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.0975 - acc: 0.9755 - val_loss: 0.0770 - val_acc: 0.9793
Epoch 00003: early stopping
# Training time = 0:00:01.438106
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 4081833
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_244 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_244 (Embedding)    (None, 4, 275)            4073025   
_________________________________________________________________
flatten_244 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_244 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 4,081,833
Trainable params: 4,081,833
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0540 - acc: 0.9865 - val_loss: 0.0322 - val_acc: 0.9889
Epoch 2/15
 - 10s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0305 - val_acc: 0.9894
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0310 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:58.275284
# F-Score(Ordinary) = 0.286, Recall: 0.925, Precision: 0.169
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.625, Recall: 0.909, Precision: 0.476
# F-Score(id) = 0.102, Recall: 1.0, Precision: 0.054
********************
********************
# XP = Lemma(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 4081833
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_245 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_245 (Embedding)    (None, 4, 275)            4073025   
_________________________________________________________________
flatten_245 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_245 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 4,081,833
Trainable params: 4,081,833
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0539 - acc: 0.9865 - val_loss: 0.0324 - val_acc: 0.9892
Epoch 2/15
 - 10s - loss: 0.0244 - acc: 0.9901 - val_loss: 0.0305 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0302 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:54.101513
# F-Score(Ordinary) = 0.468, Recall: 0.926, Precision: 0.314
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.517, Recall: 0.885, Precision: 0.365
# F-Score(id) = 0.656, Recall: 0.944, Precision: 0.503
********************
********************
# XP = Lemma(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 4081833
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_246 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_246 (Embedding)    (None, 4, 275)            4073025   
_________________________________________________________________
flatten_246 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_246 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 4,081,833
Trainable params: 4,081,833
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0539 - acc: 0.9866 - val_loss: 0.0343 - val_acc: 0.9891
Epoch 2/15
 - 10s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0307 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0307 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:03:58.038811
# F-Score(Ordinary) = 0.38, Recall: 0.937, Precision: 0.238
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.585, Recall: 0.887, Precision: 0.437
# F-Score(id) = 0.417, Recall: 1.0, Precision: 0.263
********************
********************
# XP = Lemma(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 4081833
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_247 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_247 (Embedding)    (None, 4, 275)            4073025   
_________________________________________________________________
flatten_247 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_247 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 4,081,833
Trainable params: 4,081,833
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0541 - acc: 0.9857 - val_loss: 0.0322 - val_acc: 0.9893
Epoch 2/15
 - 10s - loss: 0.0247 - acc: 0.9900 - val_loss: 0.0318 - val_acc: 0.9890
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0317 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:03:56.601530
# F-Score(Ordinary) = 0.421, Recall: 0.93, Precision: 0.272
# F-Score(lvc) = 0.155, Recall: 1.0, Precision: 0.084
# F-Score(ireflv) = 0.586, Recall: 0.862, Precision: 0.444
# F-Score(id) = 0.468, Recall: 1.0, Precision: 0.305
********************
********************
# XP = Lemma(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 4081833
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_248 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_248 (Embedding)    (None, 4, 275)            4073025   
_________________________________________________________________
flatten_248 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_248 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 4,081,833
Trainable params: 4,081,833
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0532 - acc: 0.9867 - val_loss: 0.0323 - val_acc: 0.9889
Epoch 2/15
 - 10s - loss: 0.0247 - acc: 0.9900 - val_loss: 0.0325 - val_acc: 0.9886
Epoch 3/15
 - 10s - loss: 0.0214 - acc: 0.9906 - val_loss: 0.0315 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:58.641366
# F-Score(Ordinary) = 0.193, Recall: 0.94, Precision: 0.108
# F-Score(lvc) = 0.201, Recall: 1.0, Precision: 0.112
# F-Score(ireflv) = 0.346, Recall: 0.9, Precision: 0.214
# F-Score(id) = 0.047, Recall: 1.0, Precision: 0.024
********************
********************
# XP = Lemma(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 4081833
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_249 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_249 (Embedding)    (None, 4, 275)            4073025   
_________________________________________________________________
flatten_249 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_249 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 4,081,833
Trainable params: 4,081,833
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0538 - acc: 0.9868 - val_loss: 0.0320 - val_acc: 0.9889
Epoch 2/15
 - 10s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0300 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0305 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:58.937109
# F-Score(Ordinary) = 0.28, Recall: 1.0, Precision: 0.162
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.225, Recall: 1.0, Precision: 0.127
# F-Score(id) = 0.468, Recall: 1.0, Precision: 0.305
********************
********************
# XP = Lemma(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 4081833
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_250 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_250 (Embedding)    (None, 4, 275)            4073025   
_________________________________________________________________
flatten_250 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_250 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 4,081,833
Trainable params: 4,081,833
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0536 - acc: 0.9858 - val_loss: 0.0326 - val_acc: 0.9889
Epoch 2/15
 - 10s - loss: 0.0245 - acc: 0.9902 - val_loss: 0.0305 - val_acc: 0.9894
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0309 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:58.176495
# F-Score(Ordinary) = 0.598, Recall: 0.937, Precision: 0.439
# F-Score(lvc) = 0.508, Recall: 0.98, Precision: 0.343
# F-Score(ireflv) = 0.65, Recall: 0.901, Precision: 0.508
# F-Score(id) = 0.629, Recall: 0.94, Precision: 0.473
********************
********************
# XP = Lemma(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 4081833
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_251 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_251 (Embedding)    (None, 4, 275)            4073025   
_________________________________________________________________
flatten_251 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_251 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 4,081,833
Trainable params: 4,081,833
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0536 - acc: 0.9866 - val_loss: 0.0322 - val_acc: 0.9896
Epoch 2/15
 - 10s - loss: 0.0245 - acc: 0.9902 - val_loss: 0.0315 - val_acc: 0.9891
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0316 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:58.218432
# F-Score(Ordinary) = 0.186, Recall: 0.957, Precision: 0.103
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(ireflv) = 0.479, Recall: 0.976, Precision: 0.317
# F-Score(id) = 0.035, Recall: 0.75, Precision: 0.018
********************
********************
# XP = Lemma(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 4081833
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_252 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_252 (Embedding)    (None, 4, 275)            4073025   
_________________________________________________________________
flatten_252 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_252 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 4,081,833
Trainable params: 4,081,833
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0538 - acc: 0.9866 - val_loss: 0.0322 - val_acc: 0.9888
Epoch 2/15
 - 10s - loss: 0.0246 - acc: 0.9902 - val_loss: 0.0319 - val_acc: 0.9894
Epoch 3/15
 - 10s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0302 - val_acc: 0.9897
Epoch 00003: early stopping
# Training time = 0:03:56.291843
# F-Score(Ordinary) = 0.244, Recall: 0.984, Precision: 0.14
# F-Score(lvc) = 0.366, Recall: 1.0, Precision: 0.224
# F-Score(ireflv) = 0.147, Recall: 1.0, Precision: 0.079
# F-Score(id) = 0.203, Recall: 0.95, Precision: 0.114
********************
********************
# XP = Lemma(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 4081833
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_253 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_253 (Embedding)    (None, 4, 275)            4073025   
_________________________________________________________________
flatten_253 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_253 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 4,081,833
Trainable params: 4,081,833
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0531 - acc: 0.9868 - val_loss: 0.0330 - val_acc: 0.9892
Epoch 2/15
 - 10s - loss: 0.0244 - acc: 0.9902 - val_loss: 0.0311 - val_acc: 0.9893
Epoch 3/15
 - 10s - loss: 0.0210 - acc: 0.9906 - val_loss: 0.0304 - val_acc: 0.9896
Epoch 00003: early stopping
# Training time = 0:03:59.011878
# F-Score(Ordinary) = 0.384, Recall: 1.0, Precision: 0.238
# F-Score(lvc) = 0.308, Recall: 1.0, Precision: 0.182
# F-Score(ireflv) = 0.454, Recall: 1.0, Precision: 0.294
# F-Score(id) = 0.394, Recall: 1.0, Precision: 0.246
********************
********************
# XP = Lemma(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 162608
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_254 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_254 (Embedding)    (None, 4, 300)            153000    
_________________________________________________________________
flatten_254 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_254 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 162,608
Trainable params: 162,608
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 0.9028 - acc: 0.9184 - val_loss: 0.2238 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.1527 - acc: 0.9743 - val_loss: 0.0997 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.0949 - acc: 0.9767 - val_loss: 0.0766 - val_acc: 0.9793
Epoch 00003: early stopping
# Training time = 0:00:01.460196
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 4452908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_255 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_255 (Embedding)    (None, 4, 300)            4443300   
_________________________________________________________________
flatten_255 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_255 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 4,452,908
Trainable params: 4,452,908
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0529 - acc: 0.9856 - val_loss: 0.0321 - val_acc: 0.9890
Epoch 2/15
 - 10s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0304 - val_acc: 0.9894
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0309 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:59.734128
# F-Score(Ordinary) = 0.293, Recall: 0.927, Precision: 0.174
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.625, Recall: 0.909, Precision: 0.476
# F-Score(id) = 0.124, Recall: 1.0, Precision: 0.066
********************
********************
# XP = Lemma(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 4452908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_256 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_256 (Embedding)    (None, 4, 300)            4443300   
_________________________________________________________________
flatten_256 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_256 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 4,452,908
Trainable params: 4,452,908
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0531 - acc: 0.9868 - val_loss: 0.0325 - val_acc: 0.9891
Epoch 2/15
 - 10s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0305 - val_acc: 0.9896
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0301 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:04:01.790290
# F-Score(Ordinary) = 0.475, Recall: 0.939, Precision: 0.318
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.528, Recall: 0.904, Precision: 0.373
# F-Score(id) = 0.659, Recall: 0.955, Precision: 0.503
********************
********************
# XP = Lemma(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 4452908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_257 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_257 (Embedding)    (None, 4, 300)            4443300   
_________________________________________________________________
flatten_257 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_257 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 4,452,908
Trainable params: 4,452,908
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0532 - acc: 0.9859 - val_loss: 0.0344 - val_acc: 0.9891
Epoch 2/15
 - 10s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0307 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0308 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:03:56.920501
# F-Score(Ordinary) = 0.38, Recall: 0.937, Precision: 0.238
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.593, Recall: 0.889, Precision: 0.444
# F-Score(id) = 0.417, Recall: 1.0, Precision: 0.263
********************
********************
# XP = Lemma(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 4452908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_258 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_258 (Embedding)    (None, 4, 300)            4443300   
_________________________________________________________________
flatten_258 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_258 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 4,452,908
Trainable params: 4,452,908
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0535 - acc: 0.9856 - val_loss: 0.0322 - val_acc: 0.9892
Epoch 2/15
 - 10s - loss: 0.0247 - acc: 0.9901 - val_loss: 0.0317 - val_acc: 0.9890
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9908 - val_loss: 0.0314 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:04:00.007458
# F-Score(Ordinary) = 0.415, Recall: 0.921, Precision: 0.268
# F-Score(lvc) = 0.143, Recall: 1.0, Precision: 0.077
# F-Score(ireflv) = 0.576, Recall: 0.846, Precision: 0.437
# F-Score(id) = 0.468, Recall: 1.0, Precision: 0.305
********************
********************
# XP = Lemma(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 4452908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_259 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_259 (Embedding)    (None, 4, 300)            4443300   
_________________________________________________________________
flatten_259 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_259 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 4,452,908
Trainable params: 4,452,908
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0532 - acc: 0.9867 - val_loss: 0.0323 - val_acc: 0.9888
Epoch 2/15
 - 10s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0326 - val_acc: 0.9886
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0315 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:58.073714
# F-Score(Ordinary) = 0.215, Recall: 0.93, Precision: 0.121
# F-Score(lvc) = 0.211, Recall: 0.944, Precision: 0.119
# F-Score(ireflv) = 0.407, Recall: 0.917, Precision: 0.262
# F-Score(id) = 0.035, Recall: 1.0, Precision: 0.018
********************
********************
# XP = Lemma(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 4452908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_260 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_260 (Embedding)    (None, 4, 300)            4443300   
_________________________________________________________________
flatten_260 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_260 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 4,452,908
Trainable params: 4,452,908
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0535 - acc: 0.9859 - val_loss: 0.0322 - val_acc: 0.9888
Epoch 2/15
 - 10s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0302 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0306 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:59.423631
# F-Score(Ordinary) = 0.276, Recall: 1.0, Precision: 0.16
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(ireflv) = 0.213, Recall: 1.0, Precision: 0.119
# F-Score(id) = 0.482, Recall: 1.0, Precision: 0.317
********************
********************
# XP = Lemma(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 4452908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_261 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_261 (Embedding)    (None, 4, 300)            4443300   
_________________________________________________________________
flatten_261 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_261 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 4,452,908
Trainable params: 4,452,908
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0533 - acc: 0.9850 - val_loss: 0.0326 - val_acc: 0.9889
Epoch 2/15
 - 10s - loss: 0.0245 - acc: 0.9902 - val_loss: 0.0306 - val_acc: 0.9894
Epoch 3/15
 - 10s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0310 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:03:57.724582
# F-Score(Ordinary) = 0.607, Recall: 0.938, Precision: 0.449
# F-Score(lvc) = 0.523, Recall: 0.981, Precision: 0.357
# F-Score(ireflv) = 0.65, Recall: 0.901, Precision: 0.508
# F-Score(id) = 0.64, Recall: 0.942, Precision: 0.485
********************
********************
# XP = Lemma(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 4452908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_262 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_262 (Embedding)    (None, 4, 300)            4443300   
_________________________________________________________________
flatten_262 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_262 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 4,452,908
Trainable params: 4,452,908
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0532 - acc: 0.9864 - val_loss: 0.0322 - val_acc: 0.9896
Epoch 2/15
 - 10s - loss: 0.0246 - acc: 0.9902 - val_loss: 0.0315 - val_acc: 0.9891
Epoch 3/15
 - 10s - loss: 0.0213 - acc: 0.9907 - val_loss: 0.0317 - val_acc: 0.9896
Epoch 00003: early stopping
# Training time = 0:03:57.600662
# F-Score(Ordinary) = 0.178, Recall: 0.956, Precision: 0.098
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(ireflv) = 0.451, Recall: 0.974, Precision: 0.294
# F-Score(id) = 0.047, Recall: 0.8, Precision: 0.024
********************
********************
# XP = Lemma(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 4452908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_263 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_263 (Embedding)    (None, 4, 300)            4443300   
_________________________________________________________________
flatten_263 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_263 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 4,452,908
Trainable params: 4,452,908
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0531 - acc: 0.9860 - val_loss: 0.0322 - val_acc: 0.9888
Epoch 2/15
 - 10s - loss: 0.0246 - acc: 0.9902 - val_loss: 0.0320 - val_acc: 0.9894
Epoch 3/15
 - 10s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0302 - val_acc: 0.9896
Epoch 00003: early stopping
# Training time = 0:03:58.426894
# F-Score(Ordinary) = 0.237, Recall: 0.983, Precision: 0.135
# F-Score(lvc) = 0.366, Recall: 1.0, Precision: 0.224
# F-Score(ireflv) = 0.161, Recall: 1.0, Precision: 0.087
# F-Score(id) = 0.174, Recall: 0.941, Precision: 0.096
********************
********************
# XP = Lemma(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 4452908
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_264 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_264 (Embedding)    (None, 4, 300)            4443300   
_________________________________________________________________
flatten_264 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_264 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 4,452,908
Trainable params: 4,452,908
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0526 - acc: 0.9865 - val_loss: 0.0333 - val_acc: 0.9891
Epoch 2/15
 - 10s - loss: 0.0244 - acc: 0.9902 - val_loss: 0.0312 - val_acc: 0.9893
Epoch 3/15
 - 10s - loss: 0.0211 - acc: 0.9907 - val_loss: 0.0303 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:56.426079
# F-Score(Ordinary) = 0.396, Recall: 1.0, Precision: 0.247
# F-Score(lvc) = 0.308, Recall: 1.0, Precision: 0.182
# F-Score(ireflv) = 0.454, Recall: 1.0, Precision: 0.294
# F-Score(id) = 0.425, Recall: 1.0, Precision: 0.269
********************
********************
# XP = Token(25) POS(8) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# Parameters = 13418
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_265 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_266 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_265 (Embedding)       (None, 4, 25)        12050       input_265[0][0]                  
__________________________________________________________________________________________________
embedding_266 (Embedding)       (None, 4, 8)         304         input_266[0][0]                  
__________________________________________________________________________________________________
flatten_265 (Flatten)           (None, 100)          0           embedding_265[0][0]              
__________________________________________________________________________________________________
flatten_266 (Flatten)           (None, 32)           0           embedding_266[0][0]              
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 132)          0           flatten_265[0][0]                
                                                                 flatten_266[0][0]                
__________________________________________________________________________________________________
dense_265 (Dense)               (None, 8)            1064        concatenate_1[0][0]              
==================================================================================================
Total params: 13,418
Trainable params: 13,418
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.7002 - acc: 0.7188 - val_loss: 1.1123 - val_acc: 0.9409
Epoch 2/15
 - 0s - loss: 0.7093 - acc: 0.9676 - val_loss: 0.4454 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.3442 - acc: 0.9752 - val_loss: 0.2443 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.2077 - acc: 0.9750 - val_loss: 0.1604 - val_acc: 0.9793
Epoch 5/15
 - 0s - loss: 0.1490 - acc: 0.9745 - val_loss: 0.1234 - val_acc: 0.9793
Epoch 00005: early stopping
# Training time = 0:00:02.779775
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(25) POS(8) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# Parameters = 506502
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_267 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_268 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_267 (Embedding)       (None, 4, 25)        503550      input_267[0][0]                  
__________________________________________________________________________________________________
embedding_268 (Embedding)       (None, 4, 8)         1888        input_268[0][0]                  
__________________________________________________________________________________________________
flatten_267 (Flatten)           (None, 100)          0           embedding_267[0][0]              
__________________________________________________________________________________________________
flatten_268 (Flatten)           (None, 32)           0           embedding_268[0][0]              
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 132)          0           flatten_267[0][0]                
                                                                 flatten_268[0][0]                
__________________________________________________________________________________________________
dense_266 (Dense)               (None, 8)            1064        concatenate_2[0][0]              
==================================================================================================
Total params: 506,502
Trainable params: 506,502
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0769 - acc: 0.9822 - val_loss: 0.0277 - val_acc: 0.9885
Epoch 2/15
 - 7s - loss: 0.0208 - acc: 0.9903 - val_loss: 0.0264 - val_acc: 0.9896
Epoch 3/15
 - 7s - loss: 0.0177 - acc: 0.9912 - val_loss: 0.0275 - val_acc: 0.9890
Epoch 00003: early stopping
# Training time = 0:04:03.174335
# F-Score(Ordinary) = 0.32, Recall: 0.851, Precision: 0.197
# F-Score(lvc) = 0.398, Recall: 0.736, Precision: 0.273
# F-Score(ireflv) = 0.13, Recall: 0.75, Precision: 0.071
# F-Score(id) = 0.345, Recall: 0.972, Precision: 0.21
********************
********************
# XP = Token(25) POS(8) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# Parameters = 506502
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_269 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_270 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_269 (Embedding)       (None, 4, 25)        503550      input_269[0][0]                  
__________________________________________________________________________________________________
embedding_270 (Embedding)       (None, 4, 8)         1888        input_270[0][0]                  
__________________________________________________________________________________________________
flatten_269 (Flatten)           (None, 100)          0           embedding_269[0][0]              
__________________________________________________________________________________________________
flatten_270 (Flatten)           (None, 32)           0           embedding_270[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 132)          0           flatten_269[0][0]                
                                                                 flatten_270[0][0]                
__________________________________________________________________________________________________
dense_267 (Dense)               (None, 8)            1064        concatenate_3[0][0]              
==================================================================================================
Total params: 506,502
Trainable params: 506,502
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0750 - acc: 0.9841 - val_loss: 0.0273 - val_acc: 0.9890
Epoch 2/15
 - 7s - loss: 0.0205 - acc: 0.9904 - val_loss: 0.0268 - val_acc: 0.9892
Epoch 3/15
 - 7s - loss: 0.0175 - acc: 0.9911 - val_loss: 0.0285 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:03:50.302196
# F-Score(Ordinary) = 0.223, Recall: 0.76, Precision: 0.13
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.495, Recall: 0.734, Precision: 0.373
# F-Score(id) = 0.012, Recall: 0.5, Precision: 0.006
********************
********************
# XP = Token(25) POS(8) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# Parameters = 506502
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_271 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_272 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_271 (Embedding)       (None, 4, 25)        503550      input_271[0][0]                  
__________________________________________________________________________________________________
embedding_272 (Embedding)       (None, 4, 8)         1888        input_272[0][0]                  
__________________________________________________________________________________________________
flatten_271 (Flatten)           (None, 100)          0           embedding_271[0][0]              
__________________________________________________________________________________________________
flatten_272 (Flatten)           (None, 32)           0           embedding_272[0][0]              
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 132)          0           flatten_271[0][0]                
                                                                 flatten_272[0][0]                
__________________________________________________________________________________________________
dense_268 (Dense)               (None, 8)            1064        concatenate_4[0][0]              
==================================================================================================
Total params: 506,502
Trainable params: 506,502
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0750 - acc: 0.9843 - val_loss: 0.0270 - val_acc: 0.9892
Epoch 2/15
 - 7s - loss: 0.0206 - acc: 0.9904 - val_loss: 0.0260 - val_acc: 0.9894
Epoch 3/15
 - 7s - loss: 0.0176 - acc: 0.9913 - val_loss: 0.0274 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:03:50.678747
# F-Score(Ordinary) = 0.275, Recall: 0.959, Precision: 0.16
# F-Score(lvc) = 0.272, Recall: 0.885, Precision: 0.161
# F-Score(ireflv) = 0.105, Recall: 1.0, Precision: 0.056
# F-Score(id) = 0.377, Recall: 0.975, Precision: 0.234
********************
********************
# XP = Token(25) POS(8) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# Parameters = 506502
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_273 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_274 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_273 (Embedding)       (None, 4, 25)        503550      input_273[0][0]                  
__________________________________________________________________________________________________
embedding_274 (Embedding)       (None, 4, 8)         1888        input_274[0][0]                  
__________________________________________________________________________________________________
flatten_273 (Flatten)           (None, 100)          0           embedding_273[0][0]              
__________________________________________________________________________________________________
flatten_274 (Flatten)           (None, 32)           0           embedding_274[0][0]              
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 132)          0           flatten_273[0][0]                
                                                                 flatten_274[0][0]                
__________________________________________________________________________________________________
dense_269 (Dense)               (None, 8)            1064        concatenate_5[0][0]              
==================================================================================================
Total params: 506,502
Trainable params: 506,502
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0743 - acc: 0.9835 - val_loss: 0.0274 - val_acc: 0.9888
Epoch 2/15
 - 7s - loss: 0.0206 - acc: 0.9903 - val_loss: 0.0268 - val_acc: 0.9890
Epoch 3/15
 - 7s - loss: 0.0176 - acc: 0.9911 - val_loss: 0.0278 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:51.075650
# F-Score(Ordinary) = 0.367, Recall: 0.8, Precision: 0.238
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(ireflv) = 0.61, Recall: 0.747, Precision: 0.516
# F-Score(id) = 0.356, Recall: 0.902, Precision: 0.222
********************
********************
# XP = Token(25) POS(8) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# Parameters = 506502
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_275 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_276 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_275 (Embedding)       (None, 4, 25)        503550      input_275[0][0]                  
__________________________________________________________________________________________________
embedding_276 (Embedding)       (None, 4, 8)         1888        input_276[0][0]                  
__________________________________________________________________________________________________
flatten_275 (Flatten)           (None, 100)          0           embedding_275[0][0]              
__________________________________________________________________________________________________
flatten_276 (Flatten)           (None, 32)           0           embedding_276[0][0]              
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 132)          0           flatten_275[0][0]                
                                                                 flatten_276[0][0]                
__________________________________________________________________________________________________
dense_270 (Dense)               (None, 8)            1064        concatenate_6[0][0]              
==================================================================================================
Total params: 506,502
Trainable params: 506,502
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0754 - acc: 0.9832 - val_loss: 0.0269 - val_acc: 0.9887
Epoch 2/15
 - 7s - loss: 0.0205 - acc: 0.9903 - val_loss: 0.0268 - val_acc: 0.9889
Epoch 3/15
 - 7s - loss: 0.0175 - acc: 0.9913 - val_loss: 0.0278 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:49.902568
# F-Score(Ordinary) = 0.336, Recall: 0.875, Precision: 0.208
# F-Score(lvc) = 0.2, Recall: 0.941, Precision: 0.112
# F-Score(ireflv) = 0.647, Recall: 0.846, Precision: 0.524
# F-Score(id) = 0.102, Recall: 1.0, Precision: 0.054
********************
********************
# XP = Token(25) POS(8) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# Parameters = 506502
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_277 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_278 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_277 (Embedding)       (None, 4, 25)        503550      input_277[0][0]                  
__________________________________________________________________________________________________
embedding_278 (Embedding)       (None, 4, 8)         1888        input_278[0][0]                  
__________________________________________________________________________________________________
flatten_277 (Flatten)           (None, 100)          0           embedding_277[0][0]              
__________________________________________________________________________________________________
flatten_278 (Flatten)           (None, 32)           0           embedding_278[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 132)          0           flatten_277[0][0]                
                                                                 flatten_278[0][0]                
__________________________________________________________________________________________________
dense_271 (Dense)               (None, 8)            1064        concatenate_7[0][0]              
==================================================================================================
Total params: 506,502
Trainable params: 506,502
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0763 - acc: 0.9825 - val_loss: 0.0270 - val_acc: 0.9890
Epoch 2/15
 - 7s - loss: 0.0207 - acc: 0.9903 - val_loss: 0.0263 - val_acc: 0.9893
Epoch 3/15
 - 7s - loss: 0.0177 - acc: 0.9912 - val_loss: 0.0275 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:49.618542
# F-Score(Ordinary) = 0.32, Recall: 0.821, Precision: 0.199
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.529, Recall: 0.794, Precision: 0.397
# F-Score(id) = 0.344, Recall: 0.857, Precision: 0.216
********************
********************
# XP = Token(25) POS(8) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# Parameters = 506502
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_279 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_280 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_279 (Embedding)       (None, 4, 25)        503550      input_279[0][0]                  
__________________________________________________________________________________________________
embedding_280 (Embedding)       (None, 4, 8)         1888        input_280[0][0]                  
__________________________________________________________________________________________________
flatten_279 (Flatten)           (None, 100)          0           embedding_279[0][0]              
__________________________________________________________________________________________________
flatten_280 (Flatten)           (None, 32)           0           embedding_280[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 132)          0           flatten_279[0][0]                
                                                                 flatten_280[0][0]                
__________________________________________________________________________________________________
dense_272 (Dense)               (None, 8)            1064        concatenate_8[0][0]              
==================================================================================================
Total params: 506,502
Trainable params: 506,502
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0761 - acc: 0.9830 - val_loss: 0.0273 - val_acc: 0.9887
Epoch 2/15
 - 8s - loss: 0.0205 - acc: 0.9905 - val_loss: 0.0259 - val_acc: 0.9895
Epoch 3/15
 - 8s - loss: 0.0175 - acc: 0.9911 - val_loss: 0.0272 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:03:51.173935
# F-Score(Ordinary) = 0.585, Recall: 0.795, Precision: 0.462
# F-Score(lvc) = 0.448, Recall: 0.701, Precision: 0.329
# F-Score(ireflv) = 0.715, Recall: 0.733, Precision: 0.698
# F-Score(id) = 0.538, Recall: 0.94, Precision: 0.377
********************
********************
# XP = Token(25) POS(8) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# Parameters = 506502
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_281 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_282 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_281 (Embedding)       (None, 4, 25)        503550      input_281[0][0]                  
__________________________________________________________________________________________________
embedding_282 (Embedding)       (None, 4, 8)         1888        input_282[0][0]                  
__________________________________________________________________________________________________
flatten_281 (Flatten)           (None, 100)          0           embedding_281[0][0]              
__________________________________________________________________________________________________
flatten_282 (Flatten)           (None, 32)           0           embedding_282[0][0]              
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 132)          0           flatten_281[0][0]                
                                                                 flatten_282[0][0]                
__________________________________________________________________________________________________
dense_273 (Dense)               (None, 8)            1064        concatenate_9[0][0]              
==================================================================================================
Total params: 506,502
Trainable params: 506,502
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0748 - acc: 0.9836 - val_loss: 0.0273 - val_acc: 0.9891
Epoch 2/15
 - 7s - loss: 0.0208 - acc: 0.9903 - val_loss: 0.0272 - val_acc: 0.9891
Epoch 3/15
 - 7s - loss: 0.0177 - acc: 0.9912 - val_loss: 0.0279 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:03:51.995641
# F-Score(Ordinary) = 0.262, Recall: 0.985, Precision: 0.151
# F-Score(lvc) = 0.143, Recall: 1.0, Precision: 0.077
# F-Score(ireflv) = 0.016, Recall: 1.0, Precision: 0.008
# F-Score(id) = 0.486, Recall: 0.982, Precision: 0.323
********************
********************
# XP = Token(25) POS(8) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# Parameters = 506502
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_283 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_284 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_283 (Embedding)       (None, 4, 25)        503550      input_283[0][0]                  
__________________________________________________________________________________________________
embedding_284 (Embedding)       (None, 4, 8)         1888        input_284[0][0]                  
__________________________________________________________________________________________________
flatten_283 (Flatten)           (None, 100)          0           embedding_283[0][0]              
__________________________________________________________________________________________________
flatten_284 (Flatten)           (None, 32)           0           embedding_284[0][0]              
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 132)          0           flatten_283[0][0]                
                                                                 flatten_284[0][0]                
__________________________________________________________________________________________________
dense_274 (Dense)               (None, 8)            1064        concatenate_10[0][0]             
==================================================================================================
Total params: 506,502
Trainable params: 506,502
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0752 - acc: 0.9828 - val_loss: 0.0265 - val_acc: 0.9889
Epoch 2/15
 - 7s - loss: 0.0206 - acc: 0.9903 - val_loss: 0.0262 - val_acc: 0.9893
Epoch 3/15
 - 7s - loss: 0.0175 - acc: 0.9911 - val_loss: 0.0276 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:51.749525
# F-Score(Ordinary) = 0.325, Recall: 0.925, Precision: 0.197
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.447, Recall: 0.864, Precision: 0.302
# F-Score(id) = 0.377, Recall: 0.975, Precision: 0.234
********************
********************
# XP = Token(25) POS(8) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 8
# Features = False
# Parameters = 506502
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_285 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_286 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_285 (Embedding)       (None, 4, 25)        503550      input_285[0][0]                  
__________________________________________________________________________________________________
embedding_286 (Embedding)       (None, 4, 8)         1888        input_286[0][0]                  
__________________________________________________________________________________________________
flatten_285 (Flatten)           (None, 100)          0           embedding_285[0][0]              
__________________________________________________________________________________________________
flatten_286 (Flatten)           (None, 32)           0           embedding_286[0][0]              
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 132)          0           flatten_285[0][0]                
                                                                 flatten_286[0][0]                
__________________________________________________________________________________________________
dense_275 (Dense)               (None, 8)            1064        concatenate_11[0][0]             
==================================================================================================
Total params: 506,502
Trainable params: 506,502
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0759 - acc: 0.9825 - val_loss: 0.0270 - val_acc: 0.9890
Epoch 2/15
 - 8s - loss: 0.0206 - acc: 0.9904 - val_loss: 0.0267 - val_acc: 0.9893
Epoch 3/15
 - 8s - loss: 0.0176 - acc: 0.9911 - val_loss: 0.0280 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:48.933893
# F-Score(Ordinary) = 0.175, Recall: 0.977, Precision: 0.096
# F-Score(lvc) = 0.143, Recall: 1.0, Precision: 0.077
# F-Score(id) = 0.312, Recall: 0.969, Precision: 0.186
********************
********************
# XP = Token(25) POS(16) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# Parameters = 13978
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_287 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_288 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_287 (Embedding)       (None, 4, 25)        12050       input_287[0][0]                  
__________________________________________________________________________________________________
embedding_288 (Embedding)       (None, 4, 16)        608         input_288[0][0]                  
__________________________________________________________________________________________________
flatten_287 (Flatten)           (None, 100)          0           embedding_287[0][0]              
__________________________________________________________________________________________________
flatten_288 (Flatten)           (None, 64)           0           embedding_288[0][0]              
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 164)          0           flatten_287[0][0]                
                                                                 flatten_288[0][0]                
__________________________________________________________________________________________________
dense_276 (Dense)               (None, 8)            1320        concatenate_12[0][0]             
==================================================================================================
Total params: 13,978
Trainable params: 13,978
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.5675 - acc: 0.8465 - val_loss: 0.9029 - val_acc: 0.9774
Epoch 2/15
 - 0s - loss: 0.6027 - acc: 0.9742 - val_loss: 0.3903 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.2959 - acc: 0.9743 - val_loss: 0.2022 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.1737 - acc: 0.9743 - val_loss: 0.1331 - val_acc: 0.9793
Epoch 5/15
 - 0s - loss: 0.1260 - acc: 0.9745 - val_loss: 0.1041 - val_acc: 0.9793
Epoch 6/15
 - 0s - loss: 0.1020 - acc: 0.9751 - val_loss: 0.0885 - val_acc: 0.9793
Epoch 00006: early stopping
# Training time = 0:00:03.116890
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(25) POS(16) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# Parameters = 508646
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_289 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_290 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_289 (Embedding)       (None, 4, 25)        503550      input_289[0][0]                  
__________________________________________________________________________________________________
embedding_290 (Embedding)       (None, 4, 16)        3776        input_290[0][0]                  
__________________________________________________________________________________________________
flatten_289 (Flatten)           (None, 100)          0           embedding_289[0][0]              
__________________________________________________________________________________________________
flatten_290 (Flatten)           (None, 64)           0           embedding_290[0][0]              
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 164)          0           flatten_289[0][0]                
                                                                 flatten_290[0][0]                
__________________________________________________________________________________________________
dense_277 (Dense)               (None, 8)            1320        concatenate_13[0][0]             
==================================================================================================
Total params: 508,646
Trainable params: 508,646
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0707 - acc: 0.9837 - val_loss: 0.0265 - val_acc: 0.9888
Epoch 2/15
 - 7s - loss: 0.0202 - acc: 0.9905 - val_loss: 0.0259 - val_acc: 0.9896
Epoch 3/15
 - 8s - loss: 0.0174 - acc: 0.9913 - val_loss: 0.0272 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:56.019175
# F-Score(Ordinary) = 0.365, Recall: 0.755, Precision: 0.24
# F-Score(lvc) = 0.475, Recall: 0.588, Precision: 0.399
# F-Score(ireflv) = 0.118, Recall: 0.8, Precision: 0.063
# F-Score(id) = 0.322, Recall: 1.0, Precision: 0.192
********************
********************
# XP = Token(25) POS(16) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# Parameters = 508646
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_291 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_292 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_291 (Embedding)       (None, 4, 25)        503550      input_291[0][0]                  
__________________________________________________________________________________________________
embedding_292 (Embedding)       (None, 4, 16)        3776        input_292[0][0]                  
__________________________________________________________________________________________________
flatten_291 (Flatten)           (None, 100)          0           embedding_291[0][0]              
__________________________________________________________________________________________________
flatten_292 (Flatten)           (None, 64)           0           embedding_292[0][0]              
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 164)          0           flatten_291[0][0]                
                                                                 flatten_292[0][0]                
__________________________________________________________________________________________________
dense_278 (Dense)               (None, 8)            1320        concatenate_14[0][0]             
==================================================================================================
Total params: 508,646
Trainable params: 508,646
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0688 - acc: 0.9839 - val_loss: 0.0261 - val_acc: 0.9892
Epoch 2/15
 - 7s - loss: 0.0203 - acc: 0.9904 - val_loss: 0.0261 - val_acc: 0.9894
Epoch 3/15
 - 7s - loss: 0.0175 - acc: 0.9913 - val_loss: 0.0280 - val_acc: 0.9897
Epoch 00003: early stopping
# Training time = 0:03:49.802310
# F-Score(Ordinary) = 0.259, Recall: 0.764, Precision: 0.156
# F-Score(lvc) = 0.092, Recall: 0.7, Precision: 0.049
# F-Score(ireflv) = 0.578, Recall: 0.756, Precision: 0.468
********************
********************
# XP = Token(25) POS(16) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# Parameters = 508646
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_293 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_294 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_293 (Embedding)       (None, 4, 25)        503550      input_293[0][0]                  
__________________________________________________________________________________________________
embedding_294 (Embedding)       (None, 4, 16)        3776        input_294[0][0]                  
__________________________________________________________________________________________________
flatten_293 (Flatten)           (None, 100)          0           embedding_293[0][0]              
__________________________________________________________________________________________________
flatten_294 (Flatten)           (None, 64)           0           embedding_294[0][0]              
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 164)          0           flatten_293[0][0]                
                                                                 flatten_294[0][0]                
__________________________________________________________________________________________________
dense_279 (Dense)               (None, 8)            1320        concatenate_15[0][0]             
==================================================================================================
Total params: 508,646
Trainable params: 508,646
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0671 - acc: 0.9852 - val_loss: 0.0265 - val_acc: 0.9894
Epoch 2/15
 - 7s - loss: 0.0202 - acc: 0.9905 - val_loss: 0.0258 - val_acc: 0.9895
Epoch 3/15
 - 8s - loss: 0.0174 - acc: 0.9914 - val_loss: 0.0275 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:03:51.190967
# F-Score(Ordinary) = 0.287, Recall: 0.949, Precision: 0.169
# F-Score(lvc) = 0.294, Recall: 0.926, Precision: 0.175
# F-Score(ireflv) = 0.09, Recall: 0.857, Precision: 0.048
# F-Score(id) = 0.408, Recall: 0.977, Precision: 0.257
********************
********************
# XP = Token(25) POS(16) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# Parameters = 508646
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_295 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_296 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_295 (Embedding)       (None, 4, 25)        503550      input_295[0][0]                  
__________________________________________________________________________________________________
embedding_296 (Embedding)       (None, 4, 16)        3776        input_296[0][0]                  
__________________________________________________________________________________________________
flatten_295 (Flatten)           (None, 100)          0           embedding_295[0][0]              
__________________________________________________________________________________________________
flatten_296 (Flatten)           (None, 64)           0           embedding_296[0][0]              
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 164)          0           flatten_295[0][0]                
                                                                 flatten_296[0][0]                
__________________________________________________________________________________________________
dense_280 (Dense)               (None, 8)            1320        concatenate_16[0][0]             
==================================================================================================
Total params: 508,646
Trainable params: 508,646
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0684 - acc: 0.9845 - val_loss: 0.0266 - val_acc: 0.9888
Epoch 2/15
 - 7s - loss: 0.0203 - acc: 0.9904 - val_loss: 0.0265 - val_acc: 0.9892
Epoch 3/15
 - 8s - loss: 0.0175 - acc: 0.9912 - val_loss: 0.0276 - val_acc: 0.9890
Epoch 00003: early stopping
# Training time = 0:03:51.731366
# F-Score(Ordinary) = 0.401, Recall: 0.741, Precision: 0.275
# F-Score(lvc) = 0.027, Recall: 0.667, Precision: 0.014
# F-Score(ireflv) = 0.645, Recall: 0.672, Precision: 0.619
# F-Score(id) = 0.371, Recall: 0.907, Precision: 0.234
********************
********************
# XP = Token(25) POS(16) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# Parameters = 508646
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_297 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_298 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_297 (Embedding)       (None, 4, 25)        503550      input_297[0][0]                  
__________________________________________________________________________________________________
embedding_298 (Embedding)       (None, 4, 16)        3776        input_298[0][0]                  
__________________________________________________________________________________________________
flatten_297 (Flatten)           (None, 100)          0           embedding_297[0][0]              
__________________________________________________________________________________________________
flatten_298 (Flatten)           (None, 64)           0           embedding_298[0][0]              
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 164)          0           flatten_297[0][0]                
                                                                 flatten_298[0][0]                
__________________________________________________________________________________________________
dense_281 (Dense)               (None, 8)            1320        concatenate_17[0][0]             
==================================================================================================
Total params: 508,646
Trainable params: 508,646
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0691 - acc: 0.9844 - val_loss: 0.0263 - val_acc: 0.9889
Epoch 2/15
 - 7s - loss: 0.0203 - acc: 0.9904 - val_loss: 0.0264 - val_acc: 0.9890
Epoch 3/15
 - 7s - loss: 0.0174 - acc: 0.9913 - val_loss: 0.0274 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:03:50.700591
# F-Score(Ordinary) = 0.333, Recall: 0.835, Precision: 0.208
# F-Score(lvc) = 0.159, Recall: 0.619, Precision: 0.091
# F-Score(ireflv) = 0.634, Recall: 0.823, Precision: 0.516
# F-Score(id) = 0.102, Recall: 1.0, Precision: 0.054
********************
********************
# XP = Token(25) POS(16) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# Parameters = 508646
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_299 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_300 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_299 (Embedding)       (None, 4, 25)        503550      input_299[0][0]                  
__________________________________________________________________________________________________
embedding_300 (Embedding)       (None, 4, 16)        3776        input_300[0][0]                  
__________________________________________________________________________________________________
flatten_299 (Flatten)           (None, 100)          0           embedding_299[0][0]              
__________________________________________________________________________________________________
flatten_300 (Flatten)           (None, 64)           0           embedding_300[0][0]              
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 164)          0           flatten_299[0][0]                
                                                                 flatten_300[0][0]                
__________________________________________________________________________________________________
dense_282 (Dense)               (None, 8)            1320        concatenate_18[0][0]             
==================================================================================================
Total params: 508,646
Trainable params: 508,646
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0682 - acc: 0.9845 - val_loss: 0.0261 - val_acc: 0.9892
Epoch 2/15
 - 7s - loss: 0.0202 - acc: 0.9905 - val_loss: 0.0257 - val_acc: 0.9895
Epoch 3/15
 - 7s - loss: 0.0174 - acc: 0.9914 - val_loss: 0.0268 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:03:49.124299
# F-Score(Ordinary) = 0.345, Recall: 0.841, Precision: 0.217
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.586, Recall: 0.806, Precision: 0.46
# F-Score(id) = 0.348, Recall: 0.9, Precision: 0.216
********************
********************
# XP = Token(25) POS(16) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# Parameters = 508646
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_301 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_302 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_301 (Embedding)       (None, 4, 25)        503550      input_301[0][0]                  
__________________________________________________________________________________________________
embedding_302 (Embedding)       (None, 4, 16)        3776        input_302[0][0]                  
__________________________________________________________________________________________________
flatten_301 (Flatten)           (None, 100)          0           embedding_301[0][0]              
__________________________________________________________________________________________________
flatten_302 (Flatten)           (None, 64)           0           embedding_302[0][0]              
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 164)          0           flatten_301[0][0]                
                                                                 flatten_302[0][0]                
__________________________________________________________________________________________________
dense_283 (Dense)               (None, 8)            1320        concatenate_19[0][0]             
==================================================================================================
Total params: 508,646
Trainable params: 508,646
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0687 - acc: 0.9837 - val_loss: 0.0268 - val_acc: 0.9890
Epoch 2/15
 - 7s - loss: 0.0203 - acc: 0.9906 - val_loss: 0.0259 - val_acc: 0.9895
Epoch 3/15
 - 7s - loss: 0.0175 - acc: 0.9912 - val_loss: 0.0273 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:03:53.112012
# F-Score(Ordinary) = 0.594, Recall: 0.749, Precision: 0.492
# F-Score(lvc) = 0.481, Recall: 0.622, Precision: 0.392
# F-Score(ireflv) = 0.683, Recall: 0.7, Precision: 0.667
# F-Score(id) = 0.557, Recall: 0.883, Precision: 0.407
********************
********************
# XP = Token(25) POS(16) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# Parameters = 508646
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_303 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_304 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_303 (Embedding)       (None, 4, 25)        503550      input_303[0][0]                  
__________________________________________________________________________________________________
embedding_304 (Embedding)       (None, 4, 16)        3776        input_304[0][0]                  
__________________________________________________________________________________________________
flatten_303 (Flatten)           (None, 100)          0           embedding_303[0][0]              
__________________________________________________________________________________________________
flatten_304 (Flatten)           (None, 64)           0           embedding_304[0][0]              
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 164)          0           flatten_303[0][0]                
                                                                 flatten_304[0][0]                
__________________________________________________________________________________________________
dense_284 (Dense)               (None, 8)            1320        concatenate_20[0][0]             
==================================================================================================
Total params: 508,646
Trainable params: 508,646
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0666 - acc: 0.9854 - val_loss: 0.0267 - val_acc: 0.9891
Epoch 2/15
 - 7s - loss: 0.0205 - acc: 0.9905 - val_loss: 0.0268 - val_acc: 0.9893
Epoch 3/15
 - 7s - loss: 0.0175 - acc: 0.9913 - val_loss: 0.0275 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:03:49.332056
# F-Score(Ordinary) = 0.275, Recall: 0.887, Precision: 0.162
# F-Score(lvc) = 0.204, Recall: 0.708, Precision: 0.119
# F-Score(id) = 0.475, Recall: 0.946, Precision: 0.317
********************
********************
# XP = Token(25) POS(16) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# Parameters = 508646
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_305 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_306 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_305 (Embedding)       (None, 4, 25)        503550      input_305[0][0]                  
__________________________________________________________________________________________________
embedding_306 (Embedding)       (None, 4, 16)        3776        input_306[0][0]                  
__________________________________________________________________________________________________
flatten_305 (Flatten)           (None, 100)          0           embedding_305[0][0]              
__________________________________________________________________________________________________
flatten_306 (Flatten)           (None, 64)           0           embedding_306[0][0]              
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 164)          0           flatten_305[0][0]                
                                                                 flatten_306[0][0]                
__________________________________________________________________________________________________
dense_285 (Dense)               (None, 8)            1320        concatenate_21[0][0]             
==================================================================================================
Total params: 508,646
Trainable params: 508,646
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0708 - acc: 0.9820 - val_loss: 0.0255 - val_acc: 0.9892
Epoch 2/15
 - 7s - loss: 0.0202 - acc: 0.9905 - val_loss: 0.0257 - val_acc: 0.9894
Epoch 3/15
 - 7s - loss: 0.0174 - acc: 0.9913 - val_loss: 0.0271 - val_acc: 0.9896
Epoch 00003: early stopping
# Training time = 0:03:51.451695
# F-Score(Ordinary) = 0.378, Recall: 0.882, Precision: 0.24
# F-Score(lvc) = 0.118, Recall: 0.9, Precision: 0.063
# F-Score(ireflv) = 0.519, Recall: 0.814, Precision: 0.381
# F-Score(id) = 0.442, Recall: 0.96, Precision: 0.287
********************
********************
# XP = Token(25) POS(16) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 16
# Features = False
# Parameters = 508646
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_307 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_308 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_307 (Embedding)       (None, 4, 25)        503550      input_307[0][0]                  
__________________________________________________________________________________________________
embedding_308 (Embedding)       (None, 4, 16)        3776        input_308[0][0]                  
__________________________________________________________________________________________________
flatten_307 (Flatten)           (None, 100)          0           embedding_307[0][0]              
__________________________________________________________________________________________________
flatten_308 (Flatten)           (None, 64)           0           embedding_308[0][0]              
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 164)          0           flatten_307[0][0]                
                                                                 flatten_308[0][0]                
__________________________________________________________________________________________________
dense_286 (Dense)               (None, 8)            1320        concatenate_22[0][0]             
==================================================================================================
Total params: 508,646
Trainable params: 508,646
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0695 - acc: 0.9842 - val_loss: 0.0262 - val_acc: 0.9892
Epoch 2/15
 - 7s - loss: 0.0203 - acc: 0.9905 - val_loss: 0.0262 - val_acc: 0.9895
Epoch 3/15
 - 7s - loss: 0.0174 - acc: 0.9912 - val_loss: 0.0279 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:51.730322
# F-Score(Ordinary) = 0.186, Recall: 0.978, Precision: 0.103
# F-Score(lvc) = 0.189, Recall: 0.938, Precision: 0.105
# F-Score(id) = 0.305, Recall: 1.0, Precision: 0.18
********************
********************
# XP = Token(25) POS(24) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 24
# Features = False
# Parameters = 14538
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_309 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_310 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_309 (Embedding)       (None, 4, 25)        12050       input_309[0][0]                  
__________________________________________________________________________________________________
embedding_310 (Embedding)       (None, 4, 24)        912         input_310[0][0]                  
__________________________________________________________________________________________________
flatten_309 (Flatten)           (None, 100)          0           embedding_309[0][0]              
__________________________________________________________________________________________________
flatten_310 (Flatten)           (None, 96)           0           embedding_310[0][0]              
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 196)          0           flatten_309[0][0]                
                                                                 flatten_310[0][0]                
__________________________________________________________________________________________________
dense_287 (Dense)               (None, 8)            1576        concatenate_23[0][0]             
==================================================================================================
Total params: 14,538
Trainable params: 14,538
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.5779 - acc: 0.7589 - val_loss: 0.8670 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.5424 - acc: 0.9750 - val_loss: 0.3207 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.2425 - acc: 0.9744 - val_loss: 0.1668 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.1495 - acc: 0.9746 - val_loss: 0.1176 - val_acc: 0.9793
Epoch 5/15
 - 0s - loss: 0.1136 - acc: 0.9748 - val_loss: 0.0955 - val_acc: 0.9793
Epoch 6/15
 - 0s - loss: 0.0936 - acc: 0.9755 - val_loss: 0.0823 - val_acc: 0.9803
Epoch 00006: early stopping
# Training time = 0:00:02.028707
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(25) POS(24) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 24
# Features = False
# Parameters = 510790
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_311 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_312 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_311 (Embedding)       (None, 4, 25)        503550      input_311[0][0]                  
__________________________________________________________________________________________________
embedding_312 (Embedding)       (None, 4, 24)        5664        input_312[0][0]                  
__________________________________________________________________________________________________
flatten_311 (Flatten)           (None, 100)          0           embedding_311[0][0]              
__________________________________________________________________________________________________
flatten_312 (Flatten)           (None, 96)           0           embedding_312[0][0]              
__________________________________________________________________________________________________
concatenate_24 (Concatenate)    (None, 196)          0           flatten_311[0][0]                
                                                                 flatten_312[0][0]                
__________________________________________________________________________________________________
dense_288 (Dense)               (None, 8)            1576        concatenate_24[0][0]             
==================================================================================================
Total params: 510,790
Trainable params: 510,790
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0651 - acc: 0.9835 - val_loss: 0.0260 - val_acc: 0.9889
Epoch 2/15
 - 8s - loss: 0.0200 - acc: 0.9906 - val_loss: 0.0256 - val_acc: 0.9897
Epoch 3/15
 - 8s - loss: 0.0174 - acc: 0.9914 - val_loss: 0.0270 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:03:54.172978
# F-Score(Ordinary) = 0.376, Recall: 0.762, Precision: 0.249
# F-Score(lvc) = 0.444, Recall: 0.552, Precision: 0.371
# F-Score(ireflv) = 0.133, Recall: 1.0, Precision: 0.071
# F-Score(id) = 0.371, Recall: 1.0, Precision: 0.228
********************
********************
# XP = Token(25) POS(24) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 24
# Features = False
# Parameters = 510790
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_313 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_314 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_313 (Embedding)       (None, 4, 25)        503550      input_313[0][0]                  
__________________________________________________________________________________________________
embedding_314 (Embedding)       (None, 4, 24)        5664        input_314[0][0]                  
__________________________________________________________________________________________________
flatten_313 (Flatten)           (None, 100)          0           embedding_313[0][0]              
__________________________________________________________________________________________________
flatten_314 (Flatten)           (None, 96)           0           embedding_314[0][0]              
__________________________________________________________________________________________________
concatenate_25 (Concatenate)    (None, 196)          0           flatten_313[0][0]                
                                                                 flatten_314[0][0]                
__________________________________________________________________________________________________
dense_289 (Dense)               (None, 8)            1576        concatenate_25[0][0]             
==================================================================================================
Total params: 510,790
Trainable params: 510,790
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0639 - acc: 0.9848 - val_loss: 0.0256 - val_acc: 0.9894
Epoch 2/15
 - 7s - loss: 0.0201 - acc: 0.9906 - val_loss: 0.0258 - val_acc: 0.9895
Epoch 3/15
 - 8s - loss: 0.0174 - acc: 0.9913 - val_loss: 0.0279 - val_acc: 0.9897
Epoch 00003: early stopping
# Training time = 0:03:48.097481
# F-Score(Ordinary) = 0.319, Recall: 0.736, Precision: 0.204
# F-Score(lvc) = 0.14, Recall: 0.786, Precision: 0.077
# F-Score(ireflv) = 0.638, Recall: 0.698, Precision: 0.587
********************
********************
# XP = Token(25) POS(24) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 24
# Features = False
# Parameters = 510790
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_315 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_316 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_315 (Embedding)       (None, 4, 25)        503550      input_315[0][0]                  
__________________________________________________________________________________________________
embedding_316 (Embedding)       (None, 4, 24)        5664        input_316[0][0]                  
__________________________________________________________________________________________________
flatten_315 (Flatten)           (None, 100)          0           embedding_315[0][0]              
__________________________________________________________________________________________________
flatten_316 (Flatten)           (None, 96)           0           embedding_316[0][0]              
__________________________________________________________________________________________________
concatenate_26 (Concatenate)    (None, 196)          0           flatten_315[0][0]                
                                                                 flatten_316[0][0]                
__________________________________________________________________________________________________
dense_290 (Dense)               (None, 8)            1576        concatenate_26[0][0]             
==================================================================================================
Total params: 510,790
Trainable params: 510,790
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0648 - acc: 0.9820 - val_loss: 0.0263 - val_acc: 0.9894
Epoch 2/15
 - 8s - loss: 0.0202 - acc: 0.9905 - val_loss: 0.0254 - val_acc: 0.9895
Epoch 3/15
 - 8s - loss: 0.0174 - acc: 0.9915 - val_loss: 0.0270 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:03:48.313262
# F-Score(Ordinary) = 0.263, Recall: 0.918, Precision: 0.153
# F-Score(lvc) = 0.277, Recall: 0.8, Precision: 0.168
# F-Score(id) = 0.4, Recall: 0.977, Precision: 0.251
********************
********************
# XP = Token(25) POS(24) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 24
# Features = False
# Parameters = 510790
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_317 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_318 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_317 (Embedding)       (None, 4, 25)        503550      input_317[0][0]                  
__________________________________________________________________________________________________
embedding_318 (Embedding)       (None, 4, 24)        5664        input_318[0][0]                  
__________________________________________________________________________________________________
flatten_317 (Flatten)           (None, 100)          0           embedding_317[0][0]              
__________________________________________________________________________________________________
flatten_318 (Flatten)           (None, 96)           0           embedding_318[0][0]              
__________________________________________________________________________________________________
concatenate_27 (Concatenate)    (None, 196)          0           flatten_317[0][0]                
                                                                 flatten_318[0][0]                
__________________________________________________________________________________________________
dense_291 (Dense)               (None, 8)            1576        concatenate_27[0][0]             
==================================================================================================
Total params: 510,790
Trainable params: 510,790
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0633 - acc: 0.9855 - val_loss: 0.0263 - val_acc: 0.9887
Epoch 2/15
 - 8s - loss: 0.0201 - acc: 0.9905 - val_loss: 0.0262 - val_acc: 0.9892
Epoch 3/15
 - 8s - loss: 0.0174 - acc: 0.9913 - val_loss: 0.0275 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:03:48.886660
# F-Score(Ordinary) = 0.431, Recall: 0.714, Precision: 0.309
# F-Score(lvc) = 0.027, Recall: 0.286, Precision: 0.014
# F-Score(ireflv) = 0.672, Recall: 0.647, Precision: 0.698
# F-Score(id) = 0.394, Recall: 0.913, Precision: 0.251
********************
********************
# XP = Token(25) POS(24) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 24
# Features = False
# Parameters = 510790
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_319 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_320 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_319 (Embedding)       (None, 4, 25)        503550      input_319[0][0]                  
__________________________________________________________________________________________________
embedding_320 (Embedding)       (None, 4, 24)        5664        input_320[0][0]                  
__________________________________________________________________________________________________
flatten_319 (Flatten)           (None, 100)          0           embedding_319[0][0]              
__________________________________________________________________________________________________
flatten_320 (Flatten)           (None, 96)           0           embedding_320[0][0]              
__________________________________________________________________________________________________
concatenate_28 (Concatenate)    (None, 196)          0           flatten_319[0][0]                
                                                                 flatten_320[0][0]                
__________________________________________________________________________________________________
dense_292 (Dense)               (None, 8)            1576        concatenate_28[0][0]             
==================================================================================================
Total params: 510,790
Trainable params: 510,790
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0636 - acc: 0.9854 - val_loss: 0.0258 - val_acc: 0.9889
Epoch 2/15
 - 8s - loss: 0.0201 - acc: 0.9905 - val_loss: 0.0264 - val_acc: 0.9889
Epoch 3/15
 - 8s - loss: 0.0174 - acc: 0.9913 - val_loss: 0.0275 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:03:51.279859
# F-Score(Ordinary) = 0.32, Recall: 0.851, Precision: 0.197
# F-Score(lvc) = 0.105, Recall: 0.889, Precision: 0.056
# F-Score(ireflv) = 0.66, Recall: 0.831, Precision: 0.548
# F-Score(id) = 0.091, Recall: 0.889, Precision: 0.048
********************
********************
# XP = Token(25) POS(24) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 24
# Features = False
# Parameters = 510790
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_321 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_322 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_321 (Embedding)       (None, 4, 25)        503550      input_321[0][0]                  
__________________________________________________________________________________________________
embedding_322 (Embedding)       (None, 4, 24)        5664        input_322[0][0]                  
__________________________________________________________________________________________________
flatten_321 (Flatten)           (None, 100)          0           embedding_321[0][0]              
__________________________________________________________________________________________________
flatten_322 (Flatten)           (None, 96)           0           embedding_322[0][0]              
__________________________________________________________________________________________________
concatenate_29 (Concatenate)    (None, 196)          0           flatten_321[0][0]                
                                                                 flatten_322[0][0]                
__________________________________________________________________________________________________
dense_293 (Dense)               (None, 8)            1576        concatenate_29[0][0]             
==================================================================================================
Total params: 510,790
Trainable params: 510,790
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0664 - acc: 0.9844 - val_loss: 0.0259 - val_acc: 0.9893
Epoch 2/15
 - 8s - loss: 0.0202 - acc: 0.9905 - val_loss: 0.0256 - val_acc: 0.9896
Epoch 3/15
 - 8s - loss: 0.0174 - acc: 0.9914 - val_loss: 0.0269 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:03:48.895488
# F-Score(Ordinary) = 0.356, Recall: 0.867, Precision: 0.224
# F-Score(ireflv) = 0.545, Recall: 0.836, Precision: 0.405
# F-Score(id) = 0.429, Recall: 0.904, Precision: 0.281
********************
********************
# XP = Token(25) POS(24) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 24
# Features = False
# Parameters = 510790
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_323 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_324 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_323 (Embedding)       (None, 4, 25)        503550      input_323[0][0]                  
__________________________________________________________________________________________________
embedding_324 (Embedding)       (None, 4, 24)        5664        input_324[0][0]                  
__________________________________________________________________________________________________
flatten_323 (Flatten)           (None, 100)          0           embedding_323[0][0]              
__________________________________________________________________________________________________
flatten_324 (Flatten)           (None, 96)           0           embedding_324[0][0]              
__________________________________________________________________________________________________
concatenate_30 (Concatenate)    (None, 196)          0           flatten_323[0][0]                
                                                                 flatten_324[0][0]                
__________________________________________________________________________________________________
dense_294 (Dense)               (None, 8)            1576        concatenate_30[0][0]             
==================================================================================================
Total params: 510,790
Trainable params: 510,790
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0647 - acc: 0.9849 - val_loss: 0.0265 - val_acc: 0.9889
Epoch 2/15
 - 8s - loss: 0.0201 - acc: 0.9907 - val_loss: 0.0257 - val_acc: 0.9896
Epoch 3/15
 - 8s - loss: 0.0174 - acc: 0.9912 - val_loss: 0.0272 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:03:51.307587
# F-Score(Ordinary) = 0.555, Recall: 0.704, Precision: 0.458
# F-Score(lvc) = 0.416, Recall: 0.712, Precision: 0.294
# F-Score(ireflv) = 0.693, Recall: 0.696, Precision: 0.69
# F-Score(id) = 0.509, Recall: 0.68, Precision: 0.407
********************
********************
# XP = Token(25) POS(24) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 24
# Features = False
# Parameters = 510790
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_325 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_326 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_325 (Embedding)       (None, 4, 25)        503550      input_325[0][0]                  
__________________________________________________________________________________________________
embedding_326 (Embedding)       (None, 4, 24)        5664        input_326[0][0]                  
__________________________________________________________________________________________________
flatten_325 (Flatten)           (None, 100)          0           embedding_325[0][0]              
__________________________________________________________________________________________________
flatten_326 (Flatten)           (None, 96)           0           embedding_326[0][0]              
__________________________________________________________________________________________________
concatenate_31 (Concatenate)    (None, 196)          0           flatten_325[0][0]                
                                                                 flatten_326[0][0]                
__________________________________________________________________________________________________
dense_295 (Dense)               (None, 8)            1576        concatenate_31[0][0]             
==================================================================================================
Total params: 510,790
Trainable params: 510,790
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0634 - acc: 0.9856 - val_loss: 0.0260 - val_acc: 0.9893
Epoch 2/15
 - 8s - loss: 0.0201 - acc: 0.9906 - val_loss: 0.0267 - val_acc: 0.9895
Epoch 3/15
 - 8s - loss: 0.0173 - acc: 0.9914 - val_loss: 0.0274 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:03:51.325832
# F-Score(Ordinary) = 0.276, Recall: 0.91, Precision: 0.162
# F-Score(lvc) = 0.16, Recall: 0.684, Precision: 0.091
# F-Score(ireflv) = 0.016, Recall: 1.0, Precision: 0.008
# F-Score(id) = 0.507, Recall: 0.983, Precision: 0.341
********************
********************
# XP = Token(25) POS(24) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 24
# Features = False
# Parameters = 510790
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_327 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_328 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_327 (Embedding)       (None, 4, 25)        503550      input_327[0][0]                  
__________________________________________________________________________________________________
embedding_328 (Embedding)       (None, 4, 24)        5664        input_328[0][0]                  
__________________________________________________________________________________________________
flatten_327 (Flatten)           (None, 100)          0           embedding_327[0][0]              
__________________________________________________________________________________________________
flatten_328 (Flatten)           (None, 96)           0           embedding_328[0][0]              
__________________________________________________________________________________________________
concatenate_32 (Concatenate)    (None, 196)          0           flatten_327[0][0]                
                                                                 flatten_328[0][0]                
__________________________________________________________________________________________________
dense_296 (Dense)               (None, 8)            1576        concatenate_32[0][0]             
==================================================================================================
Total params: 510,790
Trainable params: 510,790
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0637 - acc: 0.9834 - val_loss: 0.0254 - val_acc: 0.9892
Epoch 2/15
 - 8s - loss: 0.0201 - acc: 0.9905 - val_loss: 0.0256 - val_acc: 0.9895
Epoch 3/15
 - 8s - loss: 0.0174 - acc: 0.9913 - val_loss: 0.0270 - val_acc: 0.9896
Epoch 00003: early stopping
# Training time = 0:03:53.586867
# F-Score(Ordinary) = 0.392, Recall: 0.887, Precision: 0.252
# F-Score(lvc) = 0.118, Recall: 0.9, Precision: 0.063
# F-Score(ireflv) = 0.57, Recall: 0.821, Precision: 0.437
# F-Score(id) = 0.43, Recall: 0.979, Precision: 0.275
********************
********************
# XP = Token(25) POS(24) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 24
# Features = False
# Parameters = 510790
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_329 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_330 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_329 (Embedding)       (None, 4, 25)        503550      input_329[0][0]                  
__________________________________________________________________________________________________
embedding_330 (Embedding)       (None, 4, 24)        5664        input_330[0][0]                  
__________________________________________________________________________________________________
flatten_329 (Flatten)           (None, 100)          0           embedding_329[0][0]              
__________________________________________________________________________________________________
flatten_330 (Flatten)           (None, 96)           0           embedding_330[0][0]              
__________________________________________________________________________________________________
concatenate_33 (Concatenate)    (None, 196)          0           flatten_329[0][0]                
                                                                 flatten_330[0][0]                
__________________________________________________________________________________________________
dense_297 (Dense)               (None, 8)            1576        concatenate_33[0][0]             
==================================================================================================
Total params: 510,790
Trainable params: 510,790
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0645 - acc: 0.9842 - val_loss: 0.0258 - val_acc: 0.9893
Epoch 2/15
 - 8s - loss: 0.0201 - acc: 0.9906 - val_loss: 0.0260 - val_acc: 0.9894
Epoch 3/15
 - 8s - loss: 0.0174 - acc: 0.9913 - val_loss: 0.0277 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:48.868408
# F-Score(Ordinary) = 0.198, Recall: 0.98, Precision: 0.11
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(id) = 0.369, Recall: 0.974, Precision: 0.228
********************
********************
# XP = Token(25) POS(32) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 32
# Features = False
# Parameters = 15098
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_331 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_332 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_331 (Embedding)       (None, 4, 25)        12050       input_331[0][0]                  
__________________________________________________________________________________________________
embedding_332 (Embedding)       (None, 4, 32)        1216        input_332[0][0]                  
__________________________________________________________________________________________________
flatten_331 (Flatten)           (None, 100)          0           embedding_331[0][0]              
__________________________________________________________________________________________________
flatten_332 (Flatten)           (None, 128)          0           embedding_332[0][0]              
__________________________________________________________________________________________________
concatenate_34 (Concatenate)    (None, 228)          0           flatten_331[0][0]                
                                                                 flatten_332[0][0]                
__________________________________________________________________________________________________
dense_298 (Dense)               (None, 8)            1832        concatenate_34[0][0]             
==================================================================================================
Total params: 15,098
Trainable params: 15,098
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.5082 - acc: 0.7129 - val_loss: 0.7603 - val_acc: 0.9764
Epoch 2/15
 - 0s - loss: 0.4649 - acc: 0.9747 - val_loss: 0.2690 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.2108 - acc: 0.9748 - val_loss: 0.1478 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.1369 - acc: 0.9748 - val_loss: 0.1073 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:02.899417
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(25) POS(32) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 32
# Features = False
# Parameters = 512934
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_333 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_334 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_333 (Embedding)       (None, 4, 25)        503550      input_333[0][0]                  
__________________________________________________________________________________________________
embedding_334 (Embedding)       (None, 4, 32)        7552        input_334[0][0]                  
__________________________________________________________________________________________________
flatten_333 (Flatten)           (None, 100)          0           embedding_333[0][0]              
__________________________________________________________________________________________________
flatten_334 (Flatten)           (None, 128)          0           embedding_334[0][0]              
__________________________________________________________________________________________________
concatenate_35 (Concatenate)    (None, 228)          0           flatten_333[0][0]                
                                                                 flatten_334[0][0]                
__________________________________________________________________________________________________
dense_299 (Dense)               (None, 8)            1832        concatenate_35[0][0]             
==================================================================================================
Total params: 512,934
Trainable params: 512,934
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0617 - acc: 0.9849 - val_loss: 0.0260 - val_acc: 0.9890
Epoch 2/15
 - 8s - loss: 0.0201 - acc: 0.9906 - val_loss: 0.0255 - val_acc: 0.9898
Epoch 3/15
 - 8s - loss: 0.0174 - acc: 0.9914 - val_loss: 0.0268 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:03:54.977006
# F-Score(Ordinary) = 0.392, Recall: 0.772, Precision: 0.263
# F-Score(lvc) = 0.483, Recall: 0.598, Precision: 0.406
# F-Score(ireflv) = 0.145, Recall: 0.833, Precision: 0.079
# F-Score(id) = 0.377, Recall: 0.975, Precision: 0.234
********************
********************
# XP = Token(25) POS(32) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 32
# Features = False
# Parameters = 512934
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_335 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_336 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_335 (Embedding)       (None, 4, 25)        503550      input_335[0][0]                  
__________________________________________________________________________________________________
embedding_336 (Embedding)       (None, 4, 32)        7552        input_336[0][0]                  
__________________________________________________________________________________________________
flatten_335 (Flatten)           (None, 100)          0           embedding_335[0][0]              
__________________________________________________________________________________________________
flatten_336 (Flatten)           (None, 128)          0           embedding_336[0][0]              
__________________________________________________________________________________________________
concatenate_36 (Concatenate)    (None, 228)          0           flatten_335[0][0]                
                                                                 flatten_336[0][0]                
__________________________________________________________________________________________________
dense_300 (Dense)               (None, 8)            1832        concatenate_36[0][0]             
==================================================================================================
Total params: 512,934
Trainable params: 512,934
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0615 - acc: 0.9847 - val_loss: 0.0256 - val_acc: 0.9894
Epoch 2/15
 - 8s - loss: 0.0201 - acc: 0.9906 - val_loss: 0.0258 - val_acc: 0.9893
Epoch 3/15
 - 8s - loss: 0.0174 - acc: 0.9914 - val_loss: 0.0278 - val_acc: 0.9897
Epoch 00003: early stopping
# Training time = 0:03:49.406226
# F-Score(Ordinary) = 0.32, Recall: 0.714, Precision: 0.206
# F-Score(lvc) = 0.103, Recall: 0.615, Precision: 0.056
# F-Score(ireflv) = 0.655, Recall: 0.696, Precision: 0.619
********************
********************
# XP = Token(25) POS(32) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 32
# Features = False
# Parameters = 512934
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_337 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_338 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_337 (Embedding)       (None, 4, 25)        503550      input_337[0][0]                  
__________________________________________________________________________________________________
embedding_338 (Embedding)       (None, 4, 32)        7552        input_338[0][0]                  
__________________________________________________________________________________________________
flatten_337 (Flatten)           (None, 100)          0           embedding_337[0][0]              
__________________________________________________________________________________________________
flatten_338 (Flatten)           (None, 128)          0           embedding_338[0][0]              
__________________________________________________________________________________________________
concatenate_37 (Concatenate)    (None, 228)          0           flatten_337[0][0]                
                                                                 flatten_338[0][0]                
__________________________________________________________________________________________________
dense_301 (Dense)               (None, 8)            1832        concatenate_37[0][0]             
==================================================================================================
Total params: 512,934
Trainable params: 512,934
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0615 - acc: 0.9838 - val_loss: 0.0263 - val_acc: 0.9895
Epoch 2/15
 - 8s - loss: 0.0202 - acc: 0.9905 - val_loss: 0.0253 - val_acc: 0.9896
Epoch 3/15
 - 8s - loss: 0.0175 - acc: 0.9915 - val_loss: 0.0269 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:03:51.717686
# F-Score(Ordinary) = 0.221, Recall: 0.917, Precision: 0.126
# F-Score(lvc) = 0.289, Recall: 0.833, Precision: 0.175
# F-Score(id) = 0.294, Recall: 0.967, Precision: 0.174
********************
********************
# XP = Token(25) POS(32) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 32
# Features = False
# Parameters = 512934
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_339 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_340 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_339 (Embedding)       (None, 4, 25)        503550      input_339[0][0]                  
__________________________________________________________________________________________________
embedding_340 (Embedding)       (None, 4, 32)        7552        input_340[0][0]                  
__________________________________________________________________________________________________
flatten_339 (Flatten)           (None, 100)          0           embedding_339[0][0]              
__________________________________________________________________________________________________
flatten_340 (Flatten)           (None, 128)          0           embedding_340[0][0]              
__________________________________________________________________________________________________
concatenate_38 (Concatenate)    (None, 228)          0           flatten_339[0][0]                
                                                                 flatten_340[0][0]                
__________________________________________________________________________________________________
dense_302 (Dense)               (None, 8)            1832        concatenate_38[0][0]             
==================================================================================================
Total params: 512,934
Trainable params: 512,934
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0613 - acc: 0.9852 - val_loss: 0.0260 - val_acc: 0.9888
Epoch 2/15
 - 8s - loss: 0.0201 - acc: 0.9905 - val_loss: 0.0261 - val_acc: 0.9893
Epoch 3/15
 - 8s - loss: 0.0174 - acc: 0.9913 - val_loss: 0.0274 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:03:50.722364
# F-Score(Ordinary) = 0.435, Recall: 0.734, Precision: 0.309
# F-Score(lvc) = 0.014, Recall: 0.25, Precision: 0.007
# F-Score(ireflv) = 0.697, Recall: 0.674, Precision: 0.722
# F-Score(id) = 0.387, Recall: 0.911, Precision: 0.246
********************
********************
# XP = Token(25) POS(32) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 32
# Features = False
# Parameters = 512934
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_341 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_342 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_341 (Embedding)       (None, 4, 25)        503550      input_341[0][0]                  
__________________________________________________________________________________________________
embedding_342 (Embedding)       (None, 4, 32)        7552        input_342[0][0]                  
__________________________________________________________________________________________________
flatten_341 (Flatten)           (None, 100)          0           embedding_341[0][0]              
__________________________________________________________________________________________________
flatten_342 (Flatten)           (None, 128)          0           embedding_342[0][0]              
__________________________________________________________________________________________________
concatenate_39 (Concatenate)    (None, 228)          0           flatten_341[0][0]                
                                                                 flatten_342[0][0]                
__________________________________________________________________________________________________
dense_303 (Dense)               (None, 8)            1832        concatenate_39[0][0]             
==================================================================================================
Total params: 512,934
Trainable params: 512,934
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0623 - acc: 0.9853 - val_loss: 0.0258 - val_acc: 0.9890
Epoch 2/15
 - 8s - loss: 0.0201 - acc: 0.9905 - val_loss: 0.0261 - val_acc: 0.9890
Epoch 3/15
 - 8s - loss: 0.0174 - acc: 0.9914 - val_loss: 0.0275 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:03:52.709854
# F-Score(Ordinary) = 0.311, Recall: 0.865, Precision: 0.19
# F-Score(lvc) = 0.093, Recall: 0.875, Precision: 0.049
# F-Score(ireflv) = 0.644, Recall: 0.835, Precision: 0.524
# F-Score(id) = 0.091, Recall: 0.889, Precision: 0.048
********************
********************
# XP = Token(25) POS(32) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 32
# Features = False
# Parameters = 512934
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_343 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_344 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_343 (Embedding)       (None, 4, 25)        503550      input_343[0][0]                  
__________________________________________________________________________________________________
embedding_344 (Embedding)       (None, 4, 32)        7552        input_344[0][0]                  
__________________________________________________________________________________________________
flatten_343 (Flatten)           (None, 100)          0           embedding_343[0][0]              
__________________________________________________________________________________________________
flatten_344 (Flatten)           (None, 128)          0           embedding_344[0][0]              
__________________________________________________________________________________________________
concatenate_40 (Concatenate)    (None, 228)          0           flatten_343[0][0]                
                                                                 flatten_344[0][0]                
__________________________________________________________________________________________________
dense_304 (Dense)               (None, 8)            1832        concatenate_40[0][0]             
==================================================================================================
Total params: 512,934
Trainable params: 512,934
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 8s - loss: 0.0617 - acc: 0.9847 - val_loss: 0.0257 - val_acc: 0.9893
Epoch 2/15
 - 7s - loss: 0.0200 - acc: 0.9906 - val_loss: 0.0257 - val_acc: 0.9895
Epoch 3/15
 - 7s - loss: 0.0174 - acc: 0.9915 - val_loss: 0.0270 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:03:50.864926
# F-Score(Ordinary) = 0.348, Recall: 0.872, Precision: 0.217
# F-Score(ireflv) = 0.548, Recall: 0.85, Precision: 0.405
# F-Score(id) = 0.407, Recall: 0.898, Precision: 0.263
********************
********************
# XP = Token(25) POS(32) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = True
# POS emb = 32
# Features = False
# Parameters = 512934
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_345 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_346 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_345 (Embedding)       (None, 4, 25)        503550      input_345[0][0]                  
__________________________________________________________________________________________________
embedding_346 (Embedding)       (None, 4, 32)        7552        input_346[0][0]                  
__________________________________________________________________________________________________
flatten_345 (Flatten)           (None, 100)          0           embedding_345[0][0]              
__________________________________________________________________________________________________
flatten_346 (Flatten)           (None, 128)          0           embedding_346[0][0]              
__________________________________________________________________________________________________
concatenate_41 (Concatenate)    (None, 228)          0           flatten_345[0][0]                
                                                                 flatten_346[0][0]                
__________________________________________________________________________________________________
dense_305 (Dense)               (None, 8)            1832        concatenate_41[0][0]             
==================================================================================================
Total params: 512,934
Trainable params: 512,934
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 7s - loss: 0.0616 - acc: 0.9846 - val_loss: 0.0263 - val_acc: 0.9890
Epoch 2/15
 - 7s - loss: 0.0199 - acc: 0.9907 - val_loss: 0.0256 - val_acc: 0.9897
Epoch 3/15
 - 7s - loss: 0.0174 - acc: 0.9912 - val_loss: 0.0270 - val_acc: 0.9894
