INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
+_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
+_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 12858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 4, 25)             12050     
_________________________________________________________________
flatten_1 (Flatten)          (None, 100)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 8)                 808       
=================================================================
Total params: 12,858
Trainable params: 12,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 1s - loss: 1.7533 - acc: 0.5582 - val_loss: 1.2412 - val_acc: 0.7372
Epoch 2/15
 - 0s - loss: 0.8214 - acc: 0.8848 - val_loss: 0.5255 - val_acc: 0.9606
Epoch 3/15
 - 0s - loss: 0.4065 - acc: 0.9739 - val_loss: 0.2958 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.2471 - acc: 0.9748 - val_loss: 0.1933 - val_acc: 0.9793
Epoch 5/15
 - 0s - loss: 0.1745 - acc: 0.9745 - val_loss: 0.1460 - val_acc: 0.9783
Epoch 00005: early stopping
# Training time = 0:00:55.787191
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_2 (Embedding)      (None, 4, 25)             503550    
_________________________________________________________________
flatten_2 (Flatten)          (None, 100)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0959 - acc: 0.9803 - val_loss: 0.0398 - val_acc: 0.9879
Epoch 2/15
 - 9s - loss: 0.0298 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9884
Epoch 3/15
 - 9s - loss: 0.0237 - acc: 0.9904 - val_loss: 0.0363 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:07:10.393367
# F-Score(Ordinary) = 0.175, Recall: 0.977, Precision: 0.096
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.224, Recall: 0.941, Precision: 0.127
# F-Score(id) = 0.185, Recall: 1.0, Precision: 0.102
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_3 (Embedding)      (None, 4, 25)             503550    
_________________________________________________________________
flatten_3 (Flatten)          (None, 100)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0987 - acc: 0.9803 - val_loss: 0.0396 - val_acc: 0.9880
Epoch 2/15
 - 9s - loss: 0.0293 - acc: 0.9896 - val_loss: 0.0355 - val_acc: 0.9885
Epoch 3/15
 - 9s - loss: 0.0234 - acc: 0.9902 - val_loss: 0.0358 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:07:19.000104
# F-Score(Ordinary) = 0.299, Recall: 0.929, Precision: 0.178
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.222, Recall: 0.889, Precision: 0.127
# F-Score(id) = 0.473, Recall: 0.93, Precision: 0.317
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_4 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_4 (Embedding)      (None, 4, 25)             503550    
_________________________________________________________________
flatten_4 (Flatten)          (None, 100)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0990 - acc: 0.9813 - val_loss: 0.0402 - val_acc: 0.9878
Epoch 2/15
 - 9s - loss: 0.0296 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9886
Epoch 3/15
 - 9s - loss: 0.0235 - acc: 0.9903 - val_loss: 0.0357 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:06:47.005247
# F-Score(Ordinary) = 0.239, Recall: 0.909, Precision: 0.137
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.308, Recall: 0.8, Precision: 0.19
# F-Score(id) = 0.287, Recall: 1.0, Precision: 0.168
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_5 (Embedding)      (None, 4, 25)             503550    
_________________________________________________________________
flatten_5 (Flatten)          (None, 100)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0958 - acc: 0.9828 - val_loss: 0.0402 - val_acc: 0.9878
Epoch 2/15
 - 9s - loss: 0.0297 - acc: 0.9896 - val_loss: 0.0358 - val_acc: 0.9882
Epoch 3/15
 - 9s - loss: 0.0234 - acc: 0.9902 - val_loss: 0.0362 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:07:10.461711
# F-Score(Ordinary) = 0.236, Recall: 0.937, Precision: 0.135
# F-Score(lvc) = 0.081, Recall: 1.0, Precision: 0.042
# F-Score(ireflv) = 0.305, Recall: 0.92, Precision: 0.183
# F-Score(id) = 0.302, Recall: 0.938, Precision: 0.18
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_6 (Embedding)      (None, 4, 25)             503550    
_________________________________________________________________
flatten_6 (Flatten)          (None, 100)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0961 - acc: 0.9823 - val_loss: 0.0407 - val_acc: 0.9878
Epoch 2/15
 - 9s - loss: 0.0302 - acc: 0.9897 - val_loss: 0.0363 - val_acc: 0.9884
Epoch 3/15
 - 9s - loss: 0.0240 - acc: 0.9904 - val_loss: 0.0363 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:07:16.265692
# F-Score(Ordinary) = 0.214, Recall: 0.914, Precision: 0.121
# F-Score(lvc) = 0.166, Recall: 0.929, Precision: 0.091
# F-Score(ireflv) = 0.28, Recall: 0.875, Precision: 0.167
# F-Score(id) = 0.203, Recall: 0.95, Precision: 0.114
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_7 (Embedding)      (None, 4, 25)             503550    
_________________________________________________________________
flatten_7 (Flatten)          (None, 100)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0977 - acc: 0.9817 - val_loss: 0.0392 - val_acc: 0.9881
Epoch 2/15
 - 9s - loss: 0.0291 - acc: 0.9898 - val_loss: 0.0352 - val_acc: 0.9884
Epoch 3/15
 - 9s - loss: 0.0232 - acc: 0.9903 - val_loss: 0.0355 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:06:24.991253
# F-Score(Ordinary) = 0.181, Recall: 0.917, Precision: 0.101
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.282, Recall: 0.913, Precision: 0.167
# F-Score(id) = 0.202, Recall: 0.905, Precision: 0.114
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_8 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_8 (Embedding)      (None, 4, 25)             503550    
_________________________________________________________________
flatten_8 (Flatten)          (None, 100)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0978 - acc: 0.9772 - val_loss: 0.0401 - val_acc: 0.9877
Epoch 2/15
 - 9s - loss: 0.0297 - acc: 0.9897 - val_loss: 0.0363 - val_acc: 0.9883
Epoch 3/15
 - 9s - loss: 0.0238 - acc: 0.9904 - val_loss: 0.0363 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:06:51.109564
# F-Score(Ordinary) = 0.338, Recall: 0.938, Precision: 0.206
# F-Score(lvc) = 0.178, Recall: 1.0, Precision: 0.098
# F-Score(ireflv) = 0.362, Recall: 0.853, Precision: 0.23
# F-Score(id) = 0.437, Recall: 0.979, Precision: 0.281
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_9 (InputLayer)         (None, 4)                 0         
_________________________________________________________________
embedding_9 (Embedding)      (None, 4, 25)             503550    
_________________________________________________________________
flatten_9 (Flatten)          (None, 100)               0         
_________________________________________________________________
dense_9 (Dense)              (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0983 - acc: 0.9788 - val_loss: 0.0399 - val_acc: 0.9880
Epoch 2/15
 - 9s - loss: 0.0295 - acc: 0.9896 - val_loss: 0.0364 - val_acc: 0.9884
Epoch 3/15
 - 9s - loss: 0.0235 - acc: 0.9903 - val_loss: 0.0364 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:06:58.071307
# F-Score(Ordinary) = 0.204, Recall: 0.943, Precision: 0.114
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.32, Recall: 1.0, Precision: 0.19
# F-Score(id) = 0.201, Recall: 0.864, Precision: 0.114
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_10 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_10 (Embedding)     (None, 4, 25)             503550    
_________________________________________________________________
flatten_10 (Flatten)         (None, 100)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0980 - acc: 0.9815 - val_loss: 0.0396 - val_acc: 0.9880
Epoch 2/15
 - 9s - loss: 0.0298 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9883
Epoch 3/15
 - 9s - loss: 0.0238 - acc: 0.9902 - val_loss: 0.0357 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:07:11.397423
# F-Score(Ordinary) = 0.132, Recall: 0.969, Precision: 0.071
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.146, Recall: 0.909, Precision: 0.079
# F-Score(id) = 0.124, Recall: 1.0, Precision: 0.066
********************
********************
# XP = Token(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 504358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_11 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_11 (Embedding)     (None, 4, 25)             503550    
_________________________________________________________________
flatten_11 (Flatten)         (None, 100)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 8)                 808       
=================================================================
Total params: 504,358
Trainable params: 504,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0979 - acc: 0.9794 - val_loss: 0.0399 - val_acc: 0.9880
Epoch 2/15
 - 9s - loss: 0.0294 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9885
Epoch 3/15
 - 9s - loss: 0.0233 - acc: 0.9903 - val_loss: 0.0357 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:28.126616
# F-Score(Ordinary) = 0.182, Recall: 0.957, Precision: 0.101
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.25, Recall: 1.0, Precision: 0.143
# F-Score(id) = 0.173, Recall: 0.889, Precision: 0.096
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 25708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_12 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_12 (Embedding)     (None, 4, 50)             24100     
_________________________________________________________________
flatten_12 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 25,708
Trainable params: 25,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.5528 - acc: 0.8718 - val_loss: 0.8187 - val_acc: 0.9754
Epoch 2/15
 - 0s - loss: 0.4728 - acc: 0.9745 - val_loss: 0.2712 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.2158 - acc: 0.9744 - val_loss: 0.1610 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.1461 - acc: 0.9744 - val_loss: 0.1224 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:02.436244
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_13 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_13 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_13 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_13 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0818 - acc: 0.9836 - val_loss: 0.0381 - val_acc: 0.9882
Epoch 2/15
 - 9s - loss: 0.0282 - acc: 0.9897 - val_loss: 0.0358 - val_acc: 0.9886
Epoch 3/15
 - 9s - loss: 0.0228 - acc: 0.9903 - val_loss: 0.0367 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:06:36.904139
# F-Score(Ordinary) = 0.116, Recall: 0.964, Precision: 0.062
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.146, Recall: 0.909, Precision: 0.079
# F-Score(id) = 0.144, Recall: 1.0, Precision: 0.078
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_14 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_14 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_14 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0815 - acc: 0.9810 - val_loss: 0.0378 - val_acc: 0.9881
Epoch 2/15
 - 9s - loss: 0.0279 - acc: 0.9898 - val_loss: 0.0356 - val_acc: 0.9888
Epoch 3/15
 - 9s - loss: 0.0226 - acc: 0.9902 - val_loss: 0.0363 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:06:05.043302
# F-Score(Ordinary) = 0.322, Recall: 0.934, Precision: 0.195
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.222, Recall: 0.889, Precision: 0.127
# F-Score(id) = 0.545, Recall: 0.941, Precision: 0.383
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_15 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_15 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_15 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_15 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0799 - acc: 0.9843 - val_loss: 0.0395 - val_acc: 0.9879
Epoch 2/15
 - 9s - loss: 0.0284 - acc: 0.9897 - val_loss: 0.0367 - val_acc: 0.9883
Epoch 3/15
 - 9s - loss: 0.0228 - acc: 0.9904 - val_loss: 0.0368 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:06:57.635674
# F-Score(Ordinary) = 0.231, Recall: 0.892, Precision: 0.133
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.337, Recall: 0.794, Precision: 0.214
# F-Score(id) = 0.287, Recall: 1.0, Precision: 0.168
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_16 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_16 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_16 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0818 - acc: 0.9824 - val_loss: 0.0386 - val_acc: 0.9882
Epoch 2/15
 - 9s - loss: 0.0283 - acc: 0.9898 - val_loss: 0.0360 - val_acc: 0.9885
Epoch 3/15
 - 9s - loss: 0.0228 - acc: 0.9903 - val_loss: 0.0366 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:06:52.522061
# F-Score(Ordinary) = 0.247, Recall: 0.954, Precision: 0.142
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.34, Recall: 0.963, Precision: 0.206
# F-Score(id) = 0.31, Recall: 0.939, Precision: 0.186
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_17 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_17 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_17 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_17 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0817 - acc: 0.9834 - val_loss: 0.0388 - val_acc: 0.9881
Epoch 2/15
 - 9s - loss: 0.0283 - acc: 0.9898 - val_loss: 0.0361 - val_acc: 0.9882
Epoch 3/15
 - 9s - loss: 0.0227 - acc: 0.9902 - val_loss: 0.0366 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:07:08.906341
# F-Score(Ordinary) = 0.155, Recall: 0.925, Precision: 0.085
# F-Score(lvc) = 0.201, Recall: 1.0, Precision: 0.112
# F-Score(ireflv) = 0.257, Recall: 0.864, Precision: 0.151
# F-Score(id) = 0.024, Recall: 1.0, Precision: 0.012
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_18 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_18 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_18 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0811 - acc: 0.9839 - val_loss: 0.0381 - val_acc: 0.9879
Epoch 2/15
 - 9s - loss: 0.0280 - acc: 0.9897 - val_loss: 0.0354 - val_acc: 0.9886
Epoch 3/15
 - 9s - loss: 0.0228 - acc: 0.9902 - val_loss: 0.0359 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:07:29.883782
# F-Score(Ordinary) = 0.235, Recall: 0.894, Precision: 0.135
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.325, Recall: 0.893, Precision: 0.198
# F-Score(id) = 0.307, Recall: 0.886, Precision: 0.186
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_19 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_19 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_19 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_19 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0810 - acc: 0.9841 - val_loss: 0.0391 - val_acc: 0.9880
Epoch 2/15
 - 9s - loss: 0.0283 - acc: 0.9898 - val_loss: 0.0362 - val_acc: 0.9886
Epoch 3/15
 - 9s - loss: 0.0228 - acc: 0.9903 - val_loss: 0.0365 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:06:38.784469
# F-Score(Ordinary) = 0.408, Recall: 0.934, Precision: 0.261
# F-Score(lvc) = 0.275, Recall: 0.958, Precision: 0.161
# F-Score(ireflv) = 0.431, Recall: 0.878, Precision: 0.286
# F-Score(id) = 0.491, Recall: 0.965, Precision: 0.329
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_20 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_20 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_20 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0821 - acc: 0.9829 - val_loss: 0.0383 - val_acc: 0.9884
Epoch 2/15
 - 9s - loss: 0.0282 - acc: 0.9898 - val_loss: 0.0366 - val_acc: 0.9884
Epoch 3/15
 - 9s - loss: 0.0228 - acc: 0.9903 - val_loss: 0.0368 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:06:32.103923
# F-Score(Ordinary) = 0.17, Recall: 0.932, Precision: 0.094
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.286, Recall: 1.0, Precision: 0.167
# F-Score(id) = 0.162, Recall: 0.833, Precision: 0.09
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_21 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_21 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_21 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_21 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0817 - acc: 0.9794 - val_loss: 0.0379 - val_acc: 0.9882
Epoch 2/15
 - 9s - loss: 0.0281 - acc: 0.9898 - val_loss: 0.0363 - val_acc: 0.9883
Epoch 3/15
 - 9s - loss: 0.0229 - acc: 0.9902 - val_loss: 0.0359 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:07:08.595231
# F-Score(Ordinary) = 0.128, Recall: 1.0, Precision: 0.069
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.174, Recall: 1.0, Precision: 0.095
# F-Score(id) = 0.091, Recall: 1.0, Precision: 0.048
********************
********************
# XP = Token(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 1008708
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_22 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_22 (Embedding)     (None, 4, 50)             1007100   
_________________________________________________________________
flatten_22 (Flatten)         (None, 200)               0         
_________________________________________________________________
dense_22 (Dense)             (None, 8)                 1608      
=================================================================
Total params: 1,008,708
Trainable params: 1,008,708
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0803 - acc: 0.9835 - val_loss: 0.0384 - val_acc: 0.9882
Epoch 2/15
 - 9s - loss: 0.0278 - acc: 0.9898 - val_loss: 0.0367 - val_acc: 0.9884
Epoch 3/15
 - 9s - loss: 0.0225 - acc: 0.9903 - val_loss: 0.0363 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:07:10.005334
# F-Score(Ordinary) = 0.144, Recall: 0.944, Precision: 0.078
# F-Score(lvc) = 0.143, Recall: 1.0, Precision: 0.077
# F-Score(ireflv) = 0.187, Recall: 1.0, Precision: 0.103
# F-Score(id) = 0.112, Recall: 0.833, Precision: 0.06
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 38558
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_23 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_23 (Embedding)     (None, 4, 75)             36150     
_________________________________________________________________
flatten_23 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_23 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 38,558
Trainable params: 38,558
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.4505 - acc: 0.7865 - val_loss: 0.6999 - val_acc: 0.9764
Epoch 2/15
 - 0s - loss: 0.4432 - acc: 0.9743 - val_loss: 0.2588 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.2001 - acc: 0.9744 - val_loss: 0.1441 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.1310 - acc: 0.9744 - val_loss: 0.1098 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:02.446225
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_24 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_24 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_24 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_24 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0753 - acc: 0.9809 - val_loss: 0.0375 - val_acc: 0.9881
Epoch 2/15
 - 9s - loss: 0.0275 - acc: 0.9898 - val_loss: 0.0362 - val_acc: 0.9884
Epoch 3/15
 - 9s - loss: 0.0224 - acc: 0.9903 - val_loss: 0.0370 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:06:39.836311
# F-Score(Ordinary) = 0.1, Recall: 0.958, Precision: 0.053
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(ireflv) = 0.159, Recall: 0.917, Precision: 0.087
# F-Score(id) = 0.113, Recall: 1.0, Precision: 0.06
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_25 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_25 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_25 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_25 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0738 - acc: 0.9844 - val_loss: 0.0370 - val_acc: 0.9883
Epoch 2/15
 - 10s - loss: 0.0272 - acc: 0.9898 - val_loss: 0.0358 - val_acc: 0.9886
Epoch 3/15
 - 10s - loss: 0.0224 - acc: 0.9903 - val_loss: 0.0368 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:06:30.656070
# F-Score(Ordinary) = 0.316, Recall: 0.933, Precision: 0.19
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.197, Recall: 0.875, Precision: 0.111
# F-Score(id) = 0.545, Recall: 0.941, Precision: 0.383
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_26 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_26 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_26 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_26 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0747 - acc: 0.9845 - val_loss: 0.0389 - val_acc: 0.9883
Epoch 2/15
 - 9s - loss: 0.0276 - acc: 0.9898 - val_loss: 0.0364 - val_acc: 0.9886
Epoch 3/15
 - 9s - loss: 0.0224 - acc: 0.9904 - val_loss: 0.0365 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:08.887910
# F-Score(Ordinary) = 0.242, Recall: 0.91, Precision: 0.14
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(ireflv) = 0.35, Recall: 0.824, Precision: 0.222
# F-Score(id) = 0.313, Recall: 1.0, Precision: 0.186
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_27 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_27 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_27 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_27 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0735 - acc: 0.9852 - val_loss: 0.0381 - val_acc: 0.9882
Epoch 2/15
 - 9s - loss: 0.0276 - acc: 0.9898 - val_loss: 0.0362 - val_acc: 0.9885
Epoch 3/15
 - 9s - loss: 0.0224 - acc: 0.9904 - val_loss: 0.0366 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:07:03.538253
# F-Score(Ordinary) = 0.273, Recall: 0.933, Precision: 0.16
# F-Score(lvc) = 0.054, Recall: 0.8, Precision: 0.028
# F-Score(ireflv) = 0.403, Recall: 0.97, Precision: 0.254
# F-Score(id) = 0.333, Recall: 0.919, Precision: 0.204
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_28 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_28 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_28 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_28 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0734 - acc: 0.9824 - val_loss: 0.0383 - val_acc: 0.9882
Epoch 2/15
 - 9s - loss: 0.0276 - acc: 0.9898 - val_loss: 0.0364 - val_acc: 0.9882
Epoch 3/15
 - 9s - loss: 0.0224 - acc: 0.9903 - val_loss: 0.0371 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:07:04.434569
# F-Score(Ordinary) = 0.124, Recall: 0.935, Precision: 0.066
# F-Score(lvc) = 0.178, Recall: 1.0, Precision: 0.098
# F-Score(ireflv) = 0.197, Recall: 0.875, Precision: 0.111
# F-Score(id) = 0.012, Recall: 1.0, Precision: 0.006
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_29 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_29 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_29 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_29 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0754 - acc: 0.9845 - val_loss: 0.0376 - val_acc: 0.9880
Epoch 2/15
 - 9s - loss: 0.0275 - acc: 0.9898 - val_loss: 0.0356 - val_acc: 0.9887
Epoch 3/15
 - 9s - loss: 0.0225 - acc: 0.9903 - val_loss: 0.0362 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:07:11.436502
# F-Score(Ordinary) = 0.266, Recall: 0.907, Precision: 0.156
# F-Score(lvc) = 0.041, Recall: 0.75, Precision: 0.021
# F-Score(ireflv) = 0.293, Recall: 0.917, Precision: 0.175
# F-Score(id) = 0.402, Recall: 0.915, Precision: 0.257
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_30 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_30 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_30 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_30 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0745 - acc: 0.9828 - val_loss: 0.0383 - val_acc: 0.9881
Epoch 2/15
 - 9s - loss: 0.0274 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9886
Epoch 3/15
 - 9s - loss: 0.0224 - acc: 0.9903 - val_loss: 0.0368 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:07:09.463083
# F-Score(Ordinary) = 0.435, Recall: 0.932, Precision: 0.284
# F-Score(lvc) = 0.326, Recall: 0.966, Precision: 0.196
# F-Score(ireflv) = 0.431, Recall: 0.878, Precision: 0.286
# F-Score(id) = 0.522, Recall: 0.952, Precision: 0.359
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_31 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_31 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_31 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_31 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0749 - acc: 0.9834 - val_loss: 0.0381 - val_acc: 0.9884
Epoch 2/15
 - 9s - loss: 0.0276 - acc: 0.9899 - val_loss: 0.0369 - val_acc: 0.9883
Epoch 3/15
 - 10s - loss: 0.0225 - acc: 0.9904 - val_loss: 0.0373 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:47.108022
# F-Score(Ordinary) = 0.152, Recall: 0.947, Precision: 0.082
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.25, Recall: 1.0, Precision: 0.143
# F-Score(id) = 0.153, Recall: 0.875, Precision: 0.084
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_32 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_32 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_32 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_32 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0745 - acc: 0.9843 - val_loss: 0.0373 - val_acc: 0.9882
Epoch 2/15
 - 9s - loss: 0.0274 - acc: 0.9898 - val_loss: 0.0366 - val_acc: 0.9883
Epoch 3/15
 - 9s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0361 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:06:37.788568
# F-Score(Ordinary) = 0.12, Recall: 0.966, Precision: 0.064
# F-Score(lvc) = 0.142, Recall: 0.917, Precision: 0.077
# F-Score(ireflv) = 0.174, Recall: 1.0, Precision: 0.095
# F-Score(id) = 0.058, Recall: 1.0, Precision: 0.03
********************
********************
# XP = Token(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1513058
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_33 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_33 (Embedding)     (None, 4, 75)             1510650   
_________________________________________________________________
flatten_33 (Flatten)         (None, 300)               0         
_________________________________________________________________
dense_33 (Dense)             (None, 8)                 2408      
=================================================================
Total params: 1,513,058
Trainable params: 1,513,058
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0737 - acc: 0.9843 - val_loss: 0.0379 - val_acc: 0.9883
Epoch 2/15
 - 10s - loss: 0.0275 - acc: 0.9898 - val_loss: 0.0369 - val_acc: 0.9885
Epoch 3/15
 - 9s - loss: 0.0224 - acc: 0.9904 - val_loss: 0.0361 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:06:45.657407
# F-Score(Ordinary) = 0.148, Recall: 0.946, Precision: 0.08
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.213, Recall: 1.0, Precision: 0.119
# F-Score(id) = 0.122, Recall: 0.846, Precision: 0.066
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 51408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_34 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_34 (Embedding)     (None, 4, 100)            48200     
_________________________________________________________________
flatten_34 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_34 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 51,408
Trainable params: 51,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.3386 - acc: 0.8678 - val_loss: 0.5610 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.3456 - acc: 0.9745 - val_loss: 0.1985 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1603 - acc: 0.9743 - val_loss: 0.1233 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.1130 - acc: 0.9747 - val_loss: 0.1001 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:10.228777
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_35 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_35 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_35 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_35 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0696 - acc: 0.9849 - val_loss: 0.0375 - val_acc: 0.9880
Epoch 2/15
 - 10s - loss: 0.0272 - acc: 0.9898 - val_loss: 0.0367 - val_acc: 0.9884
Epoch 3/15
 - 10s - loss: 0.0224 - acc: 0.9904 - val_loss: 0.0376 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:06:57.305324
# F-Score(Ordinary) = 0.087, Recall: 0.909, Precision: 0.046
# F-Score(lvc) = 0.027, Recall: 0.667, Precision: 0.014
# F-Score(ireflv) = 0.132, Recall: 0.9, Precision: 0.071
# F-Score(id) = 0.102, Recall: 1.0, Precision: 0.054
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_36 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_36 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_36 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_36 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0704 - acc: 0.9839 - val_loss: 0.0372 - val_acc: 0.9883
Epoch 2/15
 - 10s - loss: 0.0270 - acc: 0.9897 - val_loss: 0.0359 - val_acc: 0.9886
Epoch 3/15
 - 9s - loss: 0.0222 - acc: 0.9902 - val_loss: 0.0369 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:06:08.051169
# F-Score(Ordinary) = 0.335, Recall: 0.947, Precision: 0.204
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.211, Recall: 0.938, Precision: 0.119
# F-Score(id) = 0.575, Recall: 0.945, Precision: 0.413
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_37 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_37 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_37 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_37 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0704 - acc: 0.9846 - val_loss: 0.0388 - val_acc: 0.9884
Epoch 2/15
 - 10s - loss: 0.0273 - acc: 0.9898 - val_loss: 0.0365 - val_acc: 0.9886
Epoch 3/15
 - 10s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0366 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:07:16.777059
# F-Score(Ordinary) = 0.252, Recall: 0.914, Precision: 0.146
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(ireflv) = 0.36, Recall: 0.829, Precision: 0.23
# F-Score(id) = 0.33, Recall: 1.0, Precision: 0.198
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_38 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_38 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_38 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_38 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0700 - acc: 0.9844 - val_loss: 0.0378 - val_acc: 0.9882
Epoch 2/15
 - 10s - loss: 0.0273 - acc: 0.9898 - val_loss: 0.0363 - val_acc: 0.9886
Epoch 3/15
 - 10s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0368 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:07:12.230268
# F-Score(Ordinary) = 0.277, Recall: 0.934, Precision: 0.162
# F-Score(lvc) = 0.054, Recall: 0.8, Precision: 0.028
# F-Score(ireflv) = 0.403, Recall: 0.97, Precision: 0.254
# F-Score(id) = 0.341, Recall: 0.921, Precision: 0.21
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_39 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_39 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_39 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_39 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0703 - acc: 0.9851 - val_loss: 0.0380 - val_acc: 0.9880
Epoch 2/15
 - 9s - loss: 0.0272 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9883
Epoch 3/15
 - 10s - loss: 0.0222 - acc: 0.9903 - val_loss: 0.0369 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:07:14.736605
# F-Score(Ordinary) = 0.132, Recall: 0.939, Precision: 0.071
# F-Score(lvc) = 0.178, Recall: 1.0, Precision: 0.098
# F-Score(ireflv) = 0.222, Recall: 0.889, Precision: 0.127
# F-Score(id) = 0.012, Recall: 1.0, Precision: 0.006
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_40 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_40 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_40 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_40 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0709 - acc: 0.9821 - val_loss: 0.0375 - val_acc: 0.9880
Epoch 2/15
 - 10s - loss: 0.0271 - acc: 0.9898 - val_loss: 0.0358 - val_acc: 0.9886
Epoch 3/15
 - 9s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0364 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:07:01.061568
# F-Score(Ordinary) = 0.276, Recall: 0.922, Precision: 0.162
# F-Score(lvc) = 0.041, Recall: 0.75, Precision: 0.021
# F-Score(ireflv) = 0.284, Recall: 0.955, Precision: 0.167
# F-Score(id) = 0.431, Recall: 0.922, Precision: 0.281
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_41 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_41 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_41 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_41 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0700 - acc: 0.9832 - val_loss: 0.0382 - val_acc: 0.9882
Epoch 2/15
 - 10s - loss: 0.0272 - acc: 0.9898 - val_loss: 0.0361 - val_acc: 0.9886
Epoch 3/15
 - 10s - loss: 0.0224 - acc: 0.9903 - val_loss: 0.0368 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:06:53.325154
# F-Score(Ordinary) = 0.44, Recall: 0.926, Precision: 0.288
# F-Score(lvc) = 0.326, Recall: 0.966, Precision: 0.196
# F-Score(ireflv) = 0.452, Recall: 0.905, Precision: 0.302
# F-Score(id) = 0.517, Recall: 0.923, Precision: 0.359
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_42 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_42 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_42 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_42 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0702 - acc: 0.9846 - val_loss: 0.0379 - val_acc: 0.9885
Epoch 2/15
 - 10s - loss: 0.0272 - acc: 0.9899 - val_loss: 0.0371 - val_acc: 0.9883
Epoch 3/15
 - 10s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0376 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:07:15.899674
# F-Score(Ordinary) = 0.148, Recall: 0.946, Precision: 0.08
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.25, Recall: 1.0, Precision: 0.143
# F-Score(id) = 0.143, Recall: 0.867, Precision: 0.078
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_43 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_43 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_43 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_43 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0700 - acc: 0.9836 - val_loss: 0.0372 - val_acc: 0.9883
Epoch 2/15
 - 10s - loss: 0.0272 - acc: 0.9898 - val_loss: 0.0367 - val_acc: 0.9885
Epoch 3/15
 - 9s - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0359 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:07:38.293026
# F-Score(Ordinary) = 0.112, Recall: 0.963, Precision: 0.059
# F-Score(lvc) = 0.154, Recall: 0.923, Precision: 0.084
# F-Score(ireflv) = 0.147, Recall: 1.0, Precision: 0.079
# F-Score(id) = 0.047, Recall: 1.0, Precision: 0.024
********************
********************
# XP = Token(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 2017408
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_44 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_44 (Embedding)     (None, 4, 100)            2014200   
_________________________________________________________________
flatten_44 (Flatten)         (None, 400)               0         
_________________________________________________________________
dense_44 (Dense)             (None, 8)                 3208      
=================================================================
Total params: 2,017,408
Trainable params: 2,017,408
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0692 - acc: 0.9852 - val_loss: 0.0377 - val_acc: 0.9883
Epoch 2/15
 - 10s - loss: 0.0270 - acc: 0.9898 - val_loss: 0.0371 - val_acc: 0.9886
Epoch 3/15
 - 10s - loss: 0.0221 - acc: 0.9904 - val_loss: 0.0363 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:59.386873
# F-Score(Ordinary) = 0.136, Recall: 0.941, Precision: 0.073
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.187, Recall: 1.0, Precision: 0.103
# F-Score(id) = 0.122, Recall: 0.846, Precision: 0.066
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 64258
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_45 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_45 (Embedding)     (None, 4, 125)            60250     
_________________________________________________________________
flatten_45 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_45 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 64,258
Trainable params: 64,258
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.2308 - acc: 0.8993 - val_loss: 0.4564 - val_acc: 0.9783
Epoch 2/15
 - 0s - loss: 0.2824 - acc: 0.9743 - val_loss: 0.1676 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1414 - acc: 0.9742 - val_loss: 0.1124 - val_acc: 0.9783
Epoch 4/15
 - 0s - loss: 0.1038 - acc: 0.9748 - val_loss: 0.0941 - val_acc: 0.9783
Epoch 00004: early stopping
# Training time = 0:00:02.489565
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_46 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_46 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_46 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_46 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0665 - acc: 0.9855 - val_loss: 0.0371 - val_acc: 0.9880
Epoch 2/15
 - 10s - loss: 0.0270 - acc: 0.9898 - val_loss: 0.0365 - val_acc: 0.9885
Epoch 3/15
 - 10s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0374 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:06:38.641089
# F-Score(Ordinary) = 0.083, Recall: 0.95, Precision: 0.043
# F-Score(ireflv) = 0.146, Recall: 0.909, Precision: 0.079
# F-Score(id) = 0.102, Recall: 1.0, Precision: 0.054
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_47 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_47 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_47 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_47 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0673 - acc: 0.9855 - val_loss: 0.0371 - val_acc: 0.9884
Epoch 2/15
 - 10s - loss: 0.0269 - acc: 0.9897 - val_loss: 0.0358 - val_acc: 0.9886
Epoch 3/15
 - 10s - loss: 0.0222 - acc: 0.9902 - val_loss: 0.0368 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:07:24.933674
# F-Score(Ordinary) = 0.332, Recall: 0.946, Precision: 0.201
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.224, Recall: 0.941, Precision: 0.127
# F-Score(id) = 0.563, Recall: 0.944, Precision: 0.401
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_48 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_48 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_48 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_48 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0675 - acc: 0.9848 - val_loss: 0.0390 - val_acc: 0.9884
Epoch 2/15
 - 10s - loss: 0.0271 - acc: 0.9898 - val_loss: 0.0367 - val_acc: 0.9886
Epoch 3/15
 - 10s - loss: 0.0224 - acc: 0.9904 - val_loss: 0.0369 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:07:03.582648
# F-Score(Ordinary) = 0.246, Recall: 0.912, Precision: 0.142
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(ireflv) = 0.36, Recall: 0.829, Precision: 0.23
# F-Score(id) = 0.313, Recall: 1.0, Precision: 0.186
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_49 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_49 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_49 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_49 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0670 - acc: 0.9834 - val_loss: 0.0380 - val_acc: 0.9881
Epoch 2/15
 - 10s - loss: 0.0273 - acc: 0.9898 - val_loss: 0.0366 - val_acc: 0.9887
Epoch 3/15
 - 10s - loss: 0.0224 - acc: 0.9904 - val_loss: 0.0369 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:06:53.531431
# F-Score(Ordinary) = 0.287, Recall: 0.949, Precision: 0.169
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.422, Recall: 0.971, Precision: 0.27
# F-Score(id) = 0.35, Recall: 0.923, Precision: 0.216
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_50 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_50 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_50 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_50 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0661 - acc: 0.9859 - val_loss: 0.0382 - val_acc: 0.9880
Epoch 2/15
 - 10s - loss: 0.0273 - acc: 0.9897 - val_loss: 0.0364 - val_acc: 0.9883
Epoch 3/15
 - 10s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0373 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:07:38.463869
# F-Score(Ordinary) = 0.116, Recall: 0.931, Precision: 0.062
# F-Score(lvc) = 0.167, Recall: 1.0, Precision: 0.091
# F-Score(ireflv) = 0.184, Recall: 0.867, Precision: 0.103
# F-Score(id) = 0.012, Recall: 1.0, Precision: 0.006
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_51 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_51 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_51 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_51 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0671 - acc: 0.9852 - val_loss: 0.0374 - val_acc: 0.9879
Epoch 2/15
 - 10s - loss: 0.0269 - acc: 0.9897 - val_loss: 0.0359 - val_acc: 0.9886
Epoch 3/15
 - 10s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0365 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:07:04.261858
# F-Score(Ordinary) = 0.282, Recall: 0.912, Precision: 0.167
# F-Score(lvc) = 0.041, Recall: 0.75, Precision: 0.021
# F-Score(ireflv) = 0.282, Recall: 0.913, Precision: 0.167
# F-Score(id) = 0.445, Recall: 0.925, Precision: 0.293
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_52 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_52 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_52 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_52 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0669 - acc: 0.9848 - val_loss: 0.0384 - val_acc: 0.9880
Epoch 2/15
 - 10s - loss: 0.0270 - acc: 0.9898 - val_loss: 0.0362 - val_acc: 0.9886
Epoch 3/15
 - 10s - loss: 0.0223 - acc: 0.9903 - val_loss: 0.0372 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:06:54.057185
# F-Score(Ordinary) = 0.46, Recall: 0.924, Precision: 0.307
# F-Score(lvc) = 0.345, Recall: 0.968, Precision: 0.21
# F-Score(ireflv) = 0.459, Recall: 0.886, Precision: 0.31
# F-Score(id) = 0.549, Recall: 0.929, Precision: 0.389
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_53 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_53 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_53 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_53 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0671 - acc: 0.9839 - val_loss: 0.0382 - val_acc: 0.9885
Epoch 2/15
 - 10s - loss: 0.0271 - acc: 0.9898 - val_loss: 0.0373 - val_acc: 0.9883
Epoch 3/15
 - 10s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0379 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:37.355573
# F-Score(Ordinary) = 0.136, Recall: 0.941, Precision: 0.073
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.213, Recall: 1.0, Precision: 0.119
# F-Score(id) = 0.143, Recall: 0.867, Precision: 0.078
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_54 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_54 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_54 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_54 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0675 - acc: 0.9849 - val_loss: 0.0372 - val_acc: 0.9883
Epoch 2/15
 - 10s - loss: 0.0270 - acc: 0.9898 - val_loss: 0.0370 - val_acc: 0.9885
Epoch 3/15
 - 10s - loss: 0.0223 - acc: 0.9903 - val_loss: 0.0361 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:06:46.529632
# F-Score(Ordinary) = 0.124, Recall: 0.967, Precision: 0.066
# F-Score(lvc) = 0.177, Recall: 0.933, Precision: 0.098
# F-Score(ireflv) = 0.161, Recall: 1.0, Precision: 0.087
# F-Score(id) = 0.047, Recall: 1.0, Precision: 0.024
********************
********************
# XP = Token(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 2521758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_55 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_55 (Embedding)     (None, 4, 125)            2517750   
_________________________________________________________________
flatten_55 (Flatten)         (None, 500)               0         
_________________________________________________________________
dense_55 (Dense)             (None, 8)                 4008      
=================================================================
Total params: 2,521,758
Trainable params: 2,521,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0662 - acc: 0.9845 - val_loss: 0.0376 - val_acc: 0.9882
Epoch 2/15
 - 10s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0372 - val_acc: 0.9885
Epoch 3/15
 - 10s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0363 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:53.475089
# F-Score(Ordinary) = 0.148, Recall: 0.946, Precision: 0.08
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.174, Recall: 1.0, Precision: 0.095
# F-Score(id) = 0.143, Recall: 0.867, Precision: 0.078
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 77108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_56 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_56 (Embedding)     (None, 4, 150)            72300     
_________________________________________________________________
flatten_56 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_56 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 77,108
Trainable params: 77,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.1726 - acc: 0.8589 - val_loss: 0.4196 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.2560 - acc: 0.9743 - val_loss: 0.1511 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1298 - acc: 0.9745 - val_loss: 0.1056 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.0968 - acc: 0.9756 - val_loss: 0.0900 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:02.488192
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_57 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_57 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_57 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_57 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0654 - acc: 0.9851 - val_loss: 0.0372 - val_acc: 0.9881
Epoch 2/15
 - 10s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0368 - val_acc: 0.9885
Epoch 3/15
 - 10s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0378 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:06:33.231550
# F-Score(Ordinary) = 0.087, Recall: 0.952, Precision: 0.046
# F-Score(ireflv) = 0.159, Recall: 0.917, Precision: 0.087
# F-Score(id) = 0.102, Recall: 1.0, Precision: 0.054
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_58 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_58 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_58 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_58 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0645 - acc: 0.9851 - val_loss: 0.0372 - val_acc: 0.9884
Epoch 2/15
 - 10s - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0359 - val_acc: 0.9887
Epoch 3/15
 - 10s - loss: 0.0222 - acc: 0.9903 - val_loss: 0.0368 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:07:33.763963
# F-Score(Ordinary) = 0.338, Recall: 0.938, Precision: 0.206
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.21, Recall: 0.882, Precision: 0.119
# F-Score(id) = 0.581, Recall: 0.946, Precision: 0.419
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_59 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_59 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_59 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_59 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0652 - acc: 0.9852 - val_loss: 0.0389 - val_acc: 0.9884
Epoch 2/15
 - 10s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0366 - val_acc: 0.9886
Epoch 3/15
 - 10s - loss: 0.0221 - acc: 0.9905 - val_loss: 0.0368 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:50.944726
# F-Score(Ordinary) = 0.242, Recall: 0.91, Precision: 0.14
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(ireflv) = 0.362, Recall: 0.853, Precision: 0.23
# F-Score(id) = 0.303, Recall: 0.968, Precision: 0.18
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_60 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_60 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_60 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_60 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0645 - acc: 0.9861 - val_loss: 0.0379 - val_acc: 0.9881
Epoch 2/15
 - 10s - loss: 0.0271 - acc: 0.9898 - val_loss: 0.0365 - val_acc: 0.9885
Epoch 3/15
 - 10s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0368 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:07:21.395311
# F-Score(Ordinary) = 0.29, Recall: 0.926, Precision: 0.172
# F-Score(lvc) = 0.054, Recall: 0.8, Precision: 0.028
# F-Score(ireflv) = 0.41, Recall: 0.943, Precision: 0.262
# F-Score(id) = 0.365, Recall: 0.927, Precision: 0.228
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_61 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_61 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_61 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_61 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0645 - acc: 0.9855 - val_loss: 0.0384 - val_acc: 0.9878
Epoch 2/15
 - 10s - loss: 0.0271 - acc: 0.9898 - val_loss: 0.0366 - val_acc: 0.9883
Epoch 3/15
 - 10s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0375 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:07:27.596680
# F-Score(Ordinary) = 0.091, Recall: 0.913, Precision: 0.048
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.184, Recall: 0.867, Precision: 0.103
# F-Score(id) = 0.012, Recall: 1.0, Precision: 0.006
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_62 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_62 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_62 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_62 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0642 - acc: 0.9853 - val_loss: 0.0377 - val_acc: 0.9879
Epoch 2/15
 - 10s - loss: 0.0269 - acc: 0.9897 - val_loss: 0.0359 - val_acc: 0.9885
Epoch 3/15
 - 10s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0365 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:06:37.305600
# F-Score(Ordinary) = 0.303, Recall: 0.94, Precision: 0.181
# F-Score(lvc) = 0.027, Recall: 0.667, Precision: 0.014
# F-Score(ireflv) = 0.309, Recall: 1.0, Precision: 0.183
# F-Score(id) = 0.48, Recall: 0.931, Precision: 0.323
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_63 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_63 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_63 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_63 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0643 - acc: 0.9853 - val_loss: 0.0384 - val_acc: 0.9880
Epoch 2/15
 - 10s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0363 - val_acc: 0.9886
Epoch 3/15
 - 10s - loss: 0.0223 - acc: 0.9903 - val_loss: 0.0371 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:06:46.864998
# F-Score(Ordinary) = 0.455, Recall: 0.923, Precision: 0.302
# F-Score(lvc) = 0.343, Recall: 0.938, Precision: 0.21
# F-Score(ireflv) = 0.443, Recall: 0.902, Precision: 0.294
# F-Score(id) = 0.549, Recall: 0.929, Precision: 0.389
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_64 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_64 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_64 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_64 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0650 - acc: 0.9852 - val_loss: 0.0382 - val_acc: 0.9884
Epoch 2/15
 - 10s - loss: 0.0270 - acc: 0.9899 - val_loss: 0.0376 - val_acc: 0.9883
Epoch 3/15
 - 10s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0381 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:07:08.039638
# F-Score(Ordinary) = 0.124, Recall: 0.935, Precision: 0.066
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.213, Recall: 1.0, Precision: 0.119
# F-Score(id) = 0.122, Recall: 0.846, Precision: 0.066
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_65 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_65 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_65 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_65 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0644 - acc: 0.9852 - val_loss: 0.0374 - val_acc: 0.9882
Epoch 2/15
 - 10s - loss: 0.0268 - acc: 0.9899 - val_loss: 0.0373 - val_acc: 0.9883
Epoch 3/15
 - 10s - loss: 0.0224 - acc: 0.9903 - val_loss: 0.0364 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:07:17.078978
# F-Score(Ordinary) = 0.116, Recall: 0.964, Precision: 0.062
# F-Score(lvc) = 0.166, Recall: 0.929, Precision: 0.091
# F-Score(ireflv) = 0.147, Recall: 1.0, Precision: 0.079
# F-Score(id) = 0.047, Recall: 1.0, Precision: 0.024
********************
********************
# XP = Token(150) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 150
# POS = False
# Features = False
# Parameters = 3026108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_66 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_66 (Embedding)     (None, 4, 150)            3021300   
_________________________________________________________________
flatten_66 (Flatten)         (None, 600)               0         
_________________________________________________________________
dense_66 (Dense)             (None, 8)                 4808      
=================================================================
Total params: 3,026,108
Trainable params: 3,026,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0648 - acc: 0.9851 - val_loss: 0.0376 - val_acc: 0.9882
Epoch 2/15
 - 10s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0373 - val_acc: 0.9885
Epoch 3/15
 - 10s - loss: 0.0221 - acc: 0.9904 - val_loss: 0.0362 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:06:46.674225
# F-Score(Ordinary) = 0.151, Recall: 0.923, Precision: 0.082
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.187, Recall: 1.0, Precision: 0.103
# F-Score(id) = 0.152, Recall: 0.824, Precision: 0.084
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 89958
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_67 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_67 (Embedding)     (None, 4, 175)            84350     
_________________________________________________________________
flatten_67 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_67 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 89,958
Trainable params: 89,958
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.1129 - acc: 0.8838 - val_loss: 0.3667 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.2275 - acc: 0.9743 - val_loss: 0.1399 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1221 - acc: 0.9745 - val_loss: 0.1014 - val_acc: 0.9783
Epoch 4/15
 - 0s - loss: 0.0926 - acc: 0.9759 - val_loss: 0.0875 - val_acc: 0.9783
Epoch 00004: early stopping
# Training time = 0:00:02.507426
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_68 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_68 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_68 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_68 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0627 - acc: 0.9854 - val_loss: 0.0371 - val_acc: 0.9881
Epoch 2/15
 - 11s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0365 - val_acc: 0.9885
Epoch 3/15
 - 11s - loss: 0.0221 - acc: 0.9904 - val_loss: 0.0375 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:06:13.347855
# F-Score(Ordinary) = 0.087, Recall: 0.952, Precision: 0.046
# F-Score(ireflv) = 0.146, Recall: 0.909, Precision: 0.079
# F-Score(id) = 0.113, Recall: 1.0, Precision: 0.06
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_69 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_69 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_69 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_69 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0631 - acc: 0.9853 - val_loss: 0.0376 - val_acc: 0.9884
Epoch 2/15
 - 11s - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9887
Epoch 3/15
 - 11s - loss: 0.0222 - acc: 0.9903 - val_loss: 0.0368 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:06:15.008122
# F-Score(Ordinary) = 0.331, Recall: 0.926, Precision: 0.201
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.221, Recall: 0.842, Precision: 0.127
# F-Score(id) = 0.569, Recall: 0.944, Precision: 0.407
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_70 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_70 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_70 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_70 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0631 - acc: 0.9857 - val_loss: 0.0390 - val_acc: 0.9884
Epoch 2/15
 - 11s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0364 - val_acc: 0.9885
Epoch 3/15
 - 11s - loss: 0.0221 - acc: 0.9904 - val_loss: 0.0364 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:30.985114
# F-Score(Ordinary) = 0.236, Recall: 0.922, Precision: 0.135
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.365, Recall: 0.879, Precision: 0.23
# F-Score(id) = 0.294, Recall: 0.967, Precision: 0.174
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_71 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_71 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_71 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_71 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0631 - acc: 0.9856 - val_loss: 0.0381 - val_acc: 0.9882
Epoch 2/15
 - 11s - loss: 0.0270 - acc: 0.9898 - val_loss: 0.0368 - val_acc: 0.9885
Epoch 3/15
 - 11s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0371 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:06:50.509467
# F-Score(Ordinary) = 0.297, Recall: 0.939, Precision: 0.176
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.41, Recall: 0.943, Precision: 0.262
# F-Score(id) = 0.373, Recall: 0.929, Precision: 0.234
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_72 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_72 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_72 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_72 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0634 - acc: 0.9850 - val_loss: 0.0384 - val_acc: 0.9878
Epoch 2/15
 - 11s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0365 - val_acc: 0.9883
Epoch 3/15
 - 11s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0374 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:06:40.591467
# F-Score(Ordinary) = 0.1, Recall: 0.92, Precision: 0.053
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.21, Recall: 0.882, Precision: 0.119
# F-Score(id) = 0.012, Recall: 1.0, Precision: 0.006
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_73 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_73 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_73 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_73 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0627 - acc: 0.9852 - val_loss: 0.0377 - val_acc: 0.9879
Epoch 2/15
 - 11s - loss: 0.0267 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9886
Epoch 3/15
 - 11s - loss: 0.0222 - acc: 0.9903 - val_loss: 0.0368 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:07:04.971333
# F-Score(Ordinary) = 0.303, Recall: 0.929, Precision: 0.181
# F-Score(lvc) = 0.027, Recall: 0.667, Precision: 0.014
# F-Score(ireflv) = 0.26, Recall: 0.95, Precision: 0.151
# F-Score(id) = 0.507, Recall: 0.935, Precision: 0.347
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_74 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_74 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_74 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_74 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0637 - acc: 0.9835 - val_loss: 0.0385 - val_acc: 0.9879
Epoch 2/15
 - 11s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0363 - val_acc: 0.9885
Epoch 3/15
 - 11s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0374 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:07:02.237651
# F-Score(Ordinary) = 0.462, Recall: 0.918, Precision: 0.309
# F-Score(lvc) = 0.345, Recall: 0.968, Precision: 0.21
# F-Score(ireflv) = 0.465, Recall: 0.87, Precision: 0.317
# F-Score(id) = 0.549, Recall: 0.929, Precision: 0.389
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_75 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_75 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_75 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_75 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0638 - acc: 0.9854 - val_loss: 0.0385 - val_acc: 0.9884
Epoch 2/15
 - 11s - loss: 0.0269 - acc: 0.9899 - val_loss: 0.0376 - val_acc: 0.9882
Epoch 3/15
 - 11s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0380 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:07:07.845494
# F-Score(Ordinary) = 0.124, Recall: 0.935, Precision: 0.066
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.2, Recall: 1.0, Precision: 0.111
# F-Score(id) = 0.122, Recall: 0.846, Precision: 0.066
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_76 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_76 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_76 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_76 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0626 - acc: 0.9844 - val_loss: 0.0374 - val_acc: 0.9882
Epoch 2/15
 - 11s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0373 - val_acc: 0.9883
Epoch 3/15
 - 11s - loss: 0.0224 - acc: 0.9903 - val_loss: 0.0362 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:07:52.544331
# F-Score(Ordinary) = 0.12, Recall: 0.966, Precision: 0.064
# F-Score(lvc) = 0.189, Recall: 0.938, Precision: 0.105
# F-Score(ireflv) = 0.147, Recall: 1.0, Precision: 0.079
# F-Score(id) = 0.035, Recall: 1.0, Precision: 0.018
********************
********************
# XP = Token(175) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 175
# POS = False
# Features = False
# Parameters = 3530458
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_77 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_77 (Embedding)     (None, 4, 175)            3524850   
_________________________________________________________________
flatten_77 (Flatten)         (None, 700)               0         
_________________________________________________________________
dense_77 (Dense)             (None, 8)                 5608      
=================================================================
Total params: 3,530,458
Trainable params: 3,530,458
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 11s - loss: 0.0626 - acc: 0.9851 - val_loss: 0.0378 - val_acc: 0.9883
Epoch 2/15
 - 11s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0374 - val_acc: 0.9885
Epoch 3/15
 - 11s - loss: 0.0221 - acc: 0.9904 - val_loss: 0.0362 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:59.978791
# F-Score(Ordinary) = 0.178, Recall: 0.935, Precision: 0.098
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.25, Recall: 1.0, Precision: 0.143
# F-Score(id) = 0.162, Recall: 0.833, Precision: 0.09
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 102808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_78 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_78 (Embedding)     (None, 4, 200)            96400     
_________________________________________________________________
flatten_78 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_78 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 102,808
Trainable params: 102,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.0337 - acc: 0.8884 - val_loss: 0.3276 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.2054 - acc: 0.9743 - val_loss: 0.1280 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1142 - acc: 0.9750 - val_loss: 0.0962 - val_acc: 0.9783
Epoch 4/15
 - 0s - loss: 0.0879 - acc: 0.9767 - val_loss: 0.0847 - val_acc: 0.9813
Epoch 5/15
 - 0s - loss: 0.0736 - acc: 0.9811 - val_loss: 0.0784 - val_acc: 0.9833
Epoch 00005: early stopping
# Training time = 0:00:02.591320
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_79 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_79 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_79 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_79 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0618 - acc: 0.9848 - val_loss: 0.0373 - val_acc: 0.9881
Epoch 2/15
 - 12s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0370 - val_acc: 0.9886
Epoch 3/15
 - 12s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0379 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:06:31.559646
# F-Score(Ordinary) = 0.083, Recall: 0.95, Precision: 0.043
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.132, Recall: 0.9, Precision: 0.071
# F-Score(id) = 0.102, Recall: 1.0, Precision: 0.054
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_80 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_80 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_80 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_80 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0620 - acc: 0.9844 - val_loss: 0.0376 - val_acc: 0.9883
Epoch 2/15
 - 12s - loss: 0.0266 - acc: 0.9897 - val_loss: 0.0360 - val_acc: 0.9887
Epoch 3/15
 - 12s - loss: 0.0221 - acc: 0.9903 - val_loss: 0.0369 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:06:19.050632
# F-Score(Ordinary) = 0.343, Recall: 0.929, Precision: 0.211
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.257, Recall: 0.864, Precision: 0.151
# F-Score(id) = 0.575, Recall: 0.945, Precision: 0.413
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_81 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_81 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_81 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_81 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0622 - acc: 0.9846 - val_loss: 0.0392 - val_acc: 0.9884
Epoch 2/15
 - 12s - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0365 - val_acc: 0.9885
Epoch 3/15
 - 12s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0367 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:16.898117
# F-Score(Ordinary) = 0.25, Recall: 0.926, Precision: 0.144
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.365, Recall: 0.879, Precision: 0.23
# F-Score(id) = 0.328, Recall: 0.971, Precision: 0.198
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_82 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_82 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_82 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_82 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0616 - acc: 0.9847 - val_loss: 0.0382 - val_acc: 0.9881
Epoch 2/15
 - 12s - loss: 0.0270 - acc: 0.9898 - val_loss: 0.0369 - val_acc: 0.9885
Epoch 3/15
 - 12s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0374 - val_acc: 0.9882
Epoch 00003: early stopping
# Training time = 0:07:44.446082
# F-Score(Ordinary) = 0.3, Recall: 0.94, Precision: 0.178
# F-Score(lvc) = 0.081, Recall: 1.0, Precision: 0.042
# F-Score(ireflv) = 0.41, Recall: 0.943, Precision: 0.262
# F-Score(id) = 0.373, Recall: 0.929, Precision: 0.234
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_83 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_83 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_83 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_83 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0617 - acc: 0.9850 - val_loss: 0.0385 - val_acc: 0.9878
Epoch 2/15
 - 12s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0367 - val_acc: 0.9883
Epoch 3/15
 - 12s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0377 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:06:25.854467
# F-Score(Ordinary) = 0.087, Recall: 0.952, Precision: 0.046
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.186, Recall: 0.929, Precision: 0.103
# F-Score(id) = 0.024, Recall: 1.0, Precision: 0.012
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_84 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_84 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_84 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_84 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0620 - acc: 0.9854 - val_loss: 0.0376 - val_acc: 0.9878
Epoch 2/15
 - 12s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0359 - val_acc: 0.9886
Epoch 3/15
 - 12s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0367 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:49.985549
# F-Score(Ordinary) = 0.303, Recall: 0.929, Precision: 0.181
# F-Score(lvc) = 0.027, Recall: 0.667, Precision: 0.014
# F-Score(ireflv) = 0.272, Recall: 0.952, Precision: 0.159
# F-Score(id) = 0.5, Recall: 0.934, Precision: 0.341
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_85 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_85 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_85 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_85 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0621 - acc: 0.9853 - val_loss: 0.0385 - val_acc: 0.9880
Epoch 2/15
 - 12s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0364 - val_acc: 0.9886
Epoch 3/15
 - 12s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0375 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:07:03.288818
# F-Score(Ordinary) = 0.466, Recall: 0.925, Precision: 0.311
# F-Score(lvc) = 0.335, Recall: 0.967, Precision: 0.203
# F-Score(ireflv) = 0.477, Recall: 0.891, Precision: 0.325
# F-Score(id) = 0.555, Recall: 0.93, Precision: 0.395
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_86 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_86 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_86 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_86 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0619 - acc: 0.9847 - val_loss: 0.0384 - val_acc: 0.9884
Epoch 2/15
 - 12s - loss: 0.0268 - acc: 0.9899 - val_loss: 0.0376 - val_acc: 0.9882
Epoch 3/15
 - 12s - loss: 0.0221 - acc: 0.9904 - val_loss: 0.0380 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:34.213913
# F-Score(Ordinary) = 0.112, Recall: 0.929, Precision: 0.059
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.161, Recall: 1.0, Precision: 0.087
# F-Score(id) = 0.122, Recall: 0.846, Precision: 0.066
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_87 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_87 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_87 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_87 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0620 - acc: 0.9857 - val_loss: 0.0376 - val_acc: 0.9881
Epoch 2/15
 - 12s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0375 - val_acc: 0.9883
Epoch 3/15
 - 12s - loss: 0.0223 - acc: 0.9903 - val_loss: 0.0363 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:06:13.900962
# F-Score(Ordinary) = 0.104, Recall: 1.0, Precision: 0.055
# F-Score(lvc) = 0.178, Recall: 1.0, Precision: 0.098
# F-Score(ireflv) = 0.119, Recall: 1.0, Precision: 0.063
# F-Score(id) = 0.024, Recall: 1.0, Precision: 0.012
********************
********************
# XP = Token(200) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 200
# POS = False
# Features = False
# Parameters = 4034808
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_88 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_88 (Embedding)     (None, 4, 200)            4028400   
_________________________________________________________________
flatten_88 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_88 (Dense)             (None, 8)                 6408      
=================================================================
Total params: 4,034,808
Trainable params: 4,034,808
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 12s - loss: 0.0615 - acc: 0.9859 - val_loss: 0.0379 - val_acc: 0.9883
Epoch 2/15
 - 12s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0375 - val_acc: 0.9886
Epoch 3/15
 - 12s - loss: 0.0221 - acc: 0.9905 - val_loss: 0.0363 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:19.430762
# F-Score(Ordinary) = 0.193, Recall: 0.94, Precision: 0.108
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.238, Recall: 1.0, Precision: 0.135
# F-Score(id) = 0.22, Recall: 0.875, Precision: 0.126
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 115658
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_89 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_89 (Embedding)     (None, 4, 225)            108450    
_________________________________________________________________
flatten_89 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_89 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 115,658
Trainable params: 115,658
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 0.9567 - acc: 0.9503 - val_loss: 0.2671 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.1758 - acc: 0.9744 - val_loss: 0.1166 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1059 - acc: 0.9752 - val_loss: 0.0914 - val_acc: 0.9793
Epoch 00003: early stopping
# Training time = 0:00:02.353411
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_90 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_90 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_90 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_90 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0603 - acc: 0.9863 - val_loss: 0.0373 - val_acc: 0.9882
Epoch 2/15
 - 14s - loss: 0.0267 - acc: 0.9899 - val_loss: 0.0370 - val_acc: 0.9886
Epoch 3/15
 - 14s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0379 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:06:50.675408
# F-Score(Ordinary) = 0.087, Recall: 0.952, Precision: 0.046
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.119, Recall: 0.889, Precision: 0.063
# F-Score(id) = 0.124, Recall: 1.0, Precision: 0.066
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_91 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_91 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_91 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_91 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0607 - acc: 0.9859 - val_loss: 0.0378 - val_acc: 0.9884
Epoch 2/15
 - 14s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0360 - val_acc: 0.9887
Epoch 3/15
 - 14s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0368 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:07:02.535122
# F-Score(Ordinary) = 0.343, Recall: 0.92, Precision: 0.211
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.255, Recall: 0.826, Precision: 0.151
# F-Score(id) = 0.569, Recall: 0.944, Precision: 0.407
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_92 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_92 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_92 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_92 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0603 - acc: 0.9856 - val_loss: 0.0395 - val_acc: 0.9883
Epoch 2/15
 - 14s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0368 - val_acc: 0.9885
Epoch 3/15
 - 14s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0370 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:21.321779
# F-Score(Ordinary) = 0.24, Recall: 0.938, Precision: 0.137
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.375, Recall: 0.882, Precision: 0.238
# F-Score(id) = 0.296, Recall: 1.0, Precision: 0.174
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_93 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_93 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_93 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_93 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0605 - acc: 0.9860 - val_loss: 0.0382 - val_acc: 0.9879
Epoch 2/15
 - 14s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0368 - val_acc: 0.9885
Epoch 3/15
 - 14s - loss: 0.0220 - acc: 0.9905 - val_loss: 0.0372 - val_acc: 0.9881
Epoch 00003: early stopping
# Training time = 0:06:25.287596
# F-Score(Ordinary) = 0.331, Recall: 0.936, Precision: 0.201
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.41, Recall: 0.943, Precision: 0.262
# F-Score(id) = 0.431, Recall: 0.922, Precision: 0.281
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_94 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_94 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_94 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_94 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0610 - acc: 0.9859 - val_loss: 0.0387 - val_acc: 0.9877
Epoch 2/15
 - 14s - loss: 0.0269 - acc: 0.9897 - val_loss: 0.0367 - val_acc: 0.9882
Epoch 3/15
 - 14s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0378 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:07:19.121378
# F-Score(Ordinary) = 0.087, Recall: 0.952, Precision: 0.046
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.199, Recall: 0.933, Precision: 0.111
# F-Score(id) = 0.012, Recall: 1.0, Precision: 0.006
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_95 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_95 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_95 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_95 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0605 - acc: 0.9858 - val_loss: 0.0381 - val_acc: 0.9878
Epoch 2/15
 - 14s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0362 - val_acc: 0.9885
Epoch 3/15
 - 14s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0368 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:22.855537
# F-Score(Ordinary) = 0.303, Recall: 0.929, Precision: 0.181
# F-Score(lvc) = 0.014, Recall: 0.5, Precision: 0.007
# F-Score(ireflv) = 0.284, Recall: 0.955, Precision: 0.167
# F-Score(id) = 0.5, Recall: 0.934, Precision: 0.341
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_96 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_96 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_96 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_96 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0601 - acc: 0.9837 - val_loss: 0.0384 - val_acc: 0.9879
Epoch 2/15
 - 14s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0363 - val_acc: 0.9885
Epoch 3/15
 - 14s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0375 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:06:29.282856
# F-Score(Ordinary) = 0.476, Recall: 0.927, Precision: 0.32
# F-Score(lvc) = 0.335, Recall: 0.967, Precision: 0.203
# F-Score(ireflv) = 0.486, Recall: 0.894, Precision: 0.333
# F-Score(id) = 0.573, Recall: 0.932, Precision: 0.413
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_97 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_97 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_97 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_97 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0611 - acc: 0.9849 - val_loss: 0.0387 - val_acc: 0.9885
Epoch 2/15
 - 14s - loss: 0.0268 - acc: 0.9899 - val_loss: 0.0379 - val_acc: 0.9882
Epoch 3/15
 - 14s - loss: 0.0221 - acc: 0.9904 - val_loss: 0.0382 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:07:21.464931
# F-Score(Ordinary) = 0.12, Recall: 0.933, Precision: 0.064
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.187, Recall: 1.0, Precision: 0.103
# F-Score(id) = 0.133, Recall: 0.857, Precision: 0.072
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_98 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_98 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_98 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_98 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0602 - acc: 0.9847 - val_loss: 0.0378 - val_acc: 0.9882
Epoch 2/15
 - 14s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0378 - val_acc: 0.9883
Epoch 3/15
 - 14s - loss: 0.0223 - acc: 0.9903 - val_loss: 0.0365 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:06:20.636790
# F-Score(Ordinary) = 0.108, Recall: 1.0, Precision: 0.057
# F-Score(lvc) = 0.167, Recall: 1.0, Precision: 0.091
# F-Score(ireflv) = 0.147, Recall: 1.0, Precision: 0.079
# F-Score(id) = 0.024, Recall: 1.0, Precision: 0.012
********************
********************
# XP = Token(225) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 225
# POS = False
# Features = False
# Parameters = 4539158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_99 (InputLayer)        (None, 4)                 0         
_________________________________________________________________
embedding_99 (Embedding)     (None, 4, 225)            4531950   
_________________________________________________________________
flatten_99 (Flatten)         (None, 900)               0         
_________________________________________________________________
dense_99 (Dense)             (None, 8)                 7208      
=================================================================
Total params: 4,539,158
Trainable params: 4,539,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0606 - acc: 0.9858 - val_loss: 0.0379 - val_acc: 0.9883
Epoch 2/15
 - 14s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0376 - val_acc: 0.9885
Epoch 3/15
 - 14s - loss: 0.0221 - acc: 0.9905 - val_loss: 0.0363 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:06:30.175680
# F-Score(Ordinary) = 0.186, Recall: 0.938, Precision: 0.103
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.238, Recall: 1.0, Precision: 0.135
# F-Score(id) = 0.191, Recall: 0.857, Precision: 0.108
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 128508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_100 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_100 (Embedding)    (None, 4, 250)            120500    
_________________________________________________________________
flatten_100 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_100 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 128,508
Trainable params: 128,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 0.9805 - acc: 0.9007 - val_loss: 0.2772 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.1787 - acc: 0.9743 - val_loss: 0.1166 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1053 - acc: 0.9750 - val_loss: 0.0908 - val_acc: 0.9793
Epoch 00003: early stopping
# Training time = 0:00:02.344252
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_101 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_101 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_101 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_101 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0593 - acc: 0.9857 - val_loss: 0.0374 - val_acc: 0.9882
Epoch 2/15
 - 14s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0371 - val_acc: 0.9886
Epoch 3/15
 - 14s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0382 - val_acc: 0.9882
Epoch 00003: early stopping
# Training time = 0:07:37.276473
# F-Score(Ordinary) = 0.096, Recall: 0.957, Precision: 0.05
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.146, Recall: 0.909, Precision: 0.079
# F-Score(id) = 0.124, Recall: 1.0, Precision: 0.066
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_102 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_102 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_102 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_102 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0605 - acc: 0.9842 - val_loss: 0.0381 - val_acc: 0.9884
Epoch 2/15
 - 14s - loss: 0.0267 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9887
Epoch 3/15
 - 14s - loss: 0.0222 - acc: 0.9903 - val_loss: 0.0370 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:06:19.884342
# F-Score(Ordinary) = 0.353, Recall: 0.931, Precision: 0.217
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.28, Recall: 0.875, Precision: 0.167
# F-Score(id) = 0.575, Recall: 0.945, Precision: 0.413
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_103 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_103 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_103 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_103 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0593 - acc: 0.9862 - val_loss: 0.0396 - val_acc: 0.9882
Epoch 2/15
 - 14s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0367 - val_acc: 0.9886
Epoch 3/15
 - 14s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0370 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:50.925988
# F-Score(Ordinary) = 0.25, Recall: 0.94, Precision: 0.144
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.375, Recall: 0.882, Precision: 0.238
# F-Score(id) = 0.322, Recall: 1.0, Precision: 0.192
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_104 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_104 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_104 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_104 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0592 - acc: 0.9852 - val_loss: 0.0382 - val_acc: 0.9880
Epoch 2/15
 - 14s - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0369 - val_acc: 0.9885
Epoch 3/15
 - 14s - loss: 0.0220 - acc: 0.9905 - val_loss: 0.0374 - val_acc: 0.9879
Epoch 00003: early stopping
# Training time = 0:06:26.848618
# F-Score(Ordinary) = 0.307, Recall: 0.941, Precision: 0.183
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.429, Recall: 0.946, Precision: 0.278
# F-Score(id) = 0.365, Recall: 0.927, Precision: 0.228
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_105 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_105 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_105 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_105 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0596 - acc: 0.9853 - val_loss: 0.0387 - val_acc: 0.9878
Epoch 2/15
 - 14s - loss: 0.0269 - acc: 0.9897 - val_loss: 0.0367 - val_acc: 0.9883
Epoch 3/15
 - 14s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0375 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:07:54.218037
# F-Score(Ordinary) = 0.083, Recall: 0.95, Precision: 0.043
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.186, Recall: 0.929, Precision: 0.103
# F-Score(id) = 0.012, Recall: 1.0, Precision: 0.006
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_106 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_106 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_106 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_106 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0595 - acc: 0.9859 - val_loss: 0.0380 - val_acc: 0.9877
Epoch 2/15
 - 14s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0361 - val_acc: 0.9885
Epoch 3/15
 - 14s - loss: 0.0224 - acc: 0.9904 - val_loss: 0.0369 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:07:02.902833
# F-Score(Ordinary) = 0.322, Recall: 0.934, Precision: 0.195
# F-Score(lvc) = 0.027, Recall: 0.667, Precision: 0.014
# F-Score(ireflv) = 0.307, Recall: 0.958, Precision: 0.183
# F-Score(id) = 0.519, Recall: 0.938, Precision: 0.359
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_107 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_107 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_107 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_107 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0601 - acc: 0.9849 - val_loss: 0.0384 - val_acc: 0.9878
Epoch 2/15
 - 14s - loss: 0.0266 - acc: 0.9898 - val_loss: 0.0363 - val_acc: 0.9886
Epoch 3/15
 - 14s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0377 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:06:29.608495
# F-Score(Ordinary) = 0.484, Recall: 0.929, Precision: 0.327
# F-Score(lvc) = 0.335, Recall: 0.967, Precision: 0.203
# F-Score(ireflv) = 0.52, Recall: 0.902, Precision: 0.365
# F-Score(id) = 0.567, Recall: 0.932, Precision: 0.407
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_108 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_108 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_108 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_108 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0596 - acc: 0.9857 - val_loss: 0.0388 - val_acc: 0.9884
Epoch 2/15
 - 14s - loss: 0.0269 - acc: 0.9899 - val_loss: 0.0379 - val_acc: 0.9882
Epoch 3/15
 - 14s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0382 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:29.051086
# F-Score(Ordinary) = 0.12, Recall: 0.933, Precision: 0.064
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.174, Recall: 1.0, Precision: 0.095
# F-Score(id) = 0.143, Recall: 0.867, Precision: 0.078
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_109 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_109 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_109 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_109 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0597 - acc: 0.9853 - val_loss: 0.0381 - val_acc: 0.9884
Epoch 2/15
 - 14s - loss: 0.0268 - acc: 0.9899 - val_loss: 0.0380 - val_acc: 0.9883
Epoch 3/15
 - 14s - loss: 0.0225 - acc: 0.9903 - val_loss: 0.0364 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:06:22.714644
# F-Score(Ordinary) = 0.104, Recall: 0.96, Precision: 0.055
# F-Score(lvc) = 0.189, Recall: 0.938, Precision: 0.105
# F-Score(ireflv) = 0.105, Recall: 1.0, Precision: 0.056
# F-Score(id) = 0.024, Recall: 1.0, Precision: 0.012
********************
********************
# XP = Token(250) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 250
# POS = False
# Features = False
# Parameters = 5043508
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_110 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_110 (Embedding)    (None, 4, 250)            5035500   
_________________________________________________________________
flatten_110 (Flatten)        (None, 1000)              0         
_________________________________________________________________
dense_110 (Dense)            (None, 8)                 8008      
=================================================================
Total params: 5,043,508
Trainable params: 5,043,508
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 14s - loss: 0.0592 - acc: 0.9849 - val_loss: 0.0379 - val_acc: 0.9883
Epoch 2/15
 - 14s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0376 - val_acc: 0.9886
Epoch 3/15
 - 14s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0363 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:07:09.786681
# F-Score(Ordinary) = 0.222, Recall: 0.948, Precision: 0.126
# F-Score(lvc) = 0.143, Recall: 1.0, Precision: 0.077
# F-Score(ireflv) = 0.262, Recall: 1.0, Precision: 0.151
# F-Score(id) = 0.256, Recall: 0.893, Precision: 0.15
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 141358
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_111 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_111 (Embedding)    (None, 4, 275)            132550    
_________________________________________________________________
flatten_111 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_111 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 141,358
Trainable params: 141,358
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 0.9193 - acc: 0.9280 - val_loss: 0.2398 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.1613 - acc: 0.9744 - val_loss: 0.1099 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1007 - acc: 0.9754 - val_loss: 0.0884 - val_acc: 0.9803
Epoch 00003: early stopping
# Training time = 0:00:02.354244
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_112 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_112 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_112 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_112 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 15s - loss: 0.0586 - acc: 0.9858 - val_loss: 0.0376 - val_acc: 0.9882
Epoch 2/15
 - 15s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0372 - val_acc: 0.9886
Epoch 3/15
 - 15s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0381 - val_acc: 0.9882
Epoch 00003: early stopping
# Training time = 0:06:27.338753
# F-Score(Ordinary) = 0.092, Recall: 0.955, Precision: 0.048
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.132, Recall: 0.9, Precision: 0.071
# F-Score(id) = 0.124, Recall: 1.0, Precision: 0.066
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_113 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_113 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_113 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_113 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 15s - loss: 0.0591 - acc: 0.9854 - val_loss: 0.0382 - val_acc: 0.9883
Epoch 2/15
 - 15s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0361 - val_acc: 0.9887
Epoch 3/15
 - 15s - loss: 0.0223 - acc: 0.9903 - val_loss: 0.0367 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:06:59.415461
# F-Score(Ordinary) = 0.336, Recall: 0.909, Precision: 0.206
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.267, Recall: 0.833, Precision: 0.159
# F-Score(id) = 0.549, Recall: 0.929, Precision: 0.389
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_114 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_114 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_114 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_114 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 15s - loss: 0.0587 - acc: 0.9859 - val_loss: 0.0396 - val_acc: 0.9883
Epoch 2/15
 - 15s - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0369 - val_acc: 0.9885
Epoch 3/15
 - 15s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0371 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:06:25.058183
# F-Score(Ordinary) = 0.253, Recall: 0.941, Precision: 0.146
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.375, Recall: 0.882, Precision: 0.238
# F-Score(id) = 0.33, Recall: 1.0, Precision: 0.198
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_115 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_115 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_115 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_115 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 15s - loss: 0.0590 - acc: 0.9850 - val_loss: 0.0383 - val_acc: 0.9879
Epoch 2/15
 - 15s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0370 - val_acc: 0.9885
Epoch 3/15
 - 15s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0373 - val_acc: 0.9880
Epoch 00003: early stopping
# Training time = 0:06:27.484154
# F-Score(Ordinary) = 0.307, Recall: 0.941, Precision: 0.183
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.41, Recall: 0.943, Precision: 0.262
# F-Score(id) = 0.381, Recall: 0.93, Precision: 0.24
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_116 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_116 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_116 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_116 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 15s - loss: 0.0589 - acc: 0.9854 - val_loss: 0.0389 - val_acc: 0.9877
Epoch 2/15
 - 15s - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0368 - val_acc: 0.9883
Epoch 3/15
 - 15s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0375 - val_acc: 0.9884
Epoch 00003: early stopping
# Training time = 0:06:22.118837
# F-Score(Ordinary) = 0.092, Recall: 0.955, Precision: 0.048
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.199, Recall: 0.933, Precision: 0.111
# F-Score(id) = 0.024, Recall: 1.0, Precision: 0.012
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_117 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_117 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_117 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_117 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 15s - loss: 0.0590 - acc: 0.9857 - val_loss: 0.0380 - val_acc: 0.9878
Epoch 2/15
 - 15s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0359 - val_acc: 0.9886
Epoch 3/15
 - 15s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0366 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:06:49.071570
# F-Score(Ordinary) = 0.31, Recall: 0.953, Precision: 0.185
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(ireflv) = 0.286, Recall: 1.0, Precision: 0.167
# F-Score(id) = 0.507, Recall: 0.935, Precision: 0.347
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_118 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_118 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_118 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_118 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 15s - loss: 0.0584 - acc: 0.9860 - val_loss: 0.0388 - val_acc: 0.9878
Epoch 2/15
 - 15s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0365 - val_acc: 0.9884
Epoch 3/15
 - 15s - loss: 0.0223 - acc: 0.9904 - val_loss: 0.0378 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:06:27.469271
# F-Score(Ordinary) = 0.477, Recall: 0.933, Precision: 0.32
# F-Score(lvc) = 0.316, Recall: 0.964, Precision: 0.189
# F-Score(ireflv) = 0.486, Recall: 0.894, Precision: 0.333
# F-Score(id) = 0.587, Recall: 0.947, Precision: 0.425
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_119 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_119 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_119 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_119 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 15s - loss: 0.0589 - acc: 0.9854 - val_loss: 0.0388 - val_acc: 0.9884
Epoch 2/15
 - 15s - loss: 0.0267 - acc: 0.9899 - val_loss: 0.0379 - val_acc: 0.9882
Epoch 3/15
 - 15s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0383 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:23.829848
# F-Score(Ordinary) = 0.112, Recall: 0.929, Precision: 0.059
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.161, Recall: 1.0, Precision: 0.087
# F-Score(id) = 0.133, Recall: 0.857, Precision: 0.072
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_120 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_120 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_120 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_120 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 15s - loss: 0.0588 - acc: 0.9858 - val_loss: 0.0381 - val_acc: 0.9882
Epoch 2/15
 - 15s - loss: 0.0266 - acc: 0.9898 - val_loss: 0.0380 - val_acc: 0.9883
Epoch 3/15
 - 15s - loss: 0.0223 - acc: 0.9903 - val_loss: 0.0365 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:06:42.220756
# F-Score(Ordinary) = 0.112, Recall: 1.0, Precision: 0.059
# F-Score(lvc) = 0.201, Recall: 1.0, Precision: 0.112
# F-Score(ireflv) = 0.133, Recall: 1.0, Precision: 0.071
# F-Score(id) = 0.012, Recall: 1.0, Precision: 0.006
********************
********************
# XP = Token(275) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 275
# POS = False
# Features = False
# Parameters = 5547858
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_121 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_121 (Embedding)    (None, 4, 275)            5539050   
_________________________________________________________________
flatten_121 (Flatten)        (None, 1100)              0         
_________________________________________________________________
dense_121 (Dense)            (None, 8)                 8808      
=================================================================
Total params: 5,547,858
Trainable params: 5,547,858
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 15s - loss: 0.0589 - acc: 0.9857 - val_loss: 0.0381 - val_acc: 0.9883
Epoch 2/15
 - 15s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0376 - val_acc: 0.9886
Epoch 3/15
 - 15s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0362 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:06:46.557043
# F-Score(Ordinary) = 0.229, Recall: 0.95, Precision: 0.13
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.286, Recall: 1.0, Precision: 0.167
# F-Score(id) = 0.283, Recall: 0.903, Precision: 0.168
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 482
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 154208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_122 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_122 (Embedding)    (None, 4, 300)            144600    
_________________________________________________________________
flatten_122 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_122 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 154,208
Trainable params: 154,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 0.8918 - acc: 0.9151 - val_loss: 0.2271 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.1538 - acc: 0.9743 - val_loss: 0.1060 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.0966 - acc: 0.9757 - val_loss: 0.0864 - val_acc: 0.9793
Epoch 00003: early stopping
# Training time = 0:00:02.399485
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_123 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_123 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_123 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_123 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 16s - loss: 0.0580 - acc: 0.9854 - val_loss: 0.0376 - val_acc: 0.9884
Epoch 2/15
 - 16s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0372 - val_acc: 0.9886
Epoch 3/15
 - 16s - loss: 0.0223 - acc: 0.9905 - val_loss: 0.0381 - val_acc: 0.9883
Epoch 00003: early stopping
# Training time = 0:06:27.535452
# F-Score(Ordinary) = 0.087, Recall: 0.952, Precision: 0.046
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.132, Recall: 0.9, Precision: 0.071
# F-Score(id) = 0.113, Recall: 1.0, Precision: 0.06
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_124 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_124 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_124 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_124 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 16s - loss: 0.0584 - acc: 0.9858 - val_loss: 0.0383 - val_acc: 0.9884
Epoch 2/15
 - 16s - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0362 - val_acc: 0.9888
Epoch 3/15
 - 16s - loss: 0.0224 - acc: 0.9903 - val_loss: 0.0369 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:06:36.145364
# F-Score(Ordinary) = 0.342, Recall: 0.911, Precision: 0.211
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.267, Recall: 0.833, Precision: 0.159
# F-Score(id) = 0.567, Recall: 0.932, Precision: 0.407
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_125 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_125 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_125 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_125 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 16s - loss: 0.0579 - acc: 0.9858 - val_loss: 0.0396 - val_acc: 0.9883
Epoch 2/15
 - 16s - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0367 - val_acc: 0.9886
Epoch 3/15
 - 16s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0372 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:06:28.646305
# F-Score(Ordinary) = 0.257, Recall: 0.942, Precision: 0.149
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.365, Recall: 0.879, Precision: 0.23
# F-Score(id) = 0.347, Recall: 1.0, Precision: 0.21
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_126 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_126 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_126 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_126 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 16s - loss: 0.0582 - acc: 0.9847 - val_loss: 0.0386 - val_acc: 0.9878
Epoch 2/15
 - 16s - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0370 - val_acc: 0.9884
Epoch 3/15
 - 16s - loss: 0.0222 - acc: 0.9905 - val_loss: 0.0373 - val_acc: 0.9880
Epoch 00003: early stopping
# Training time = 0:06:51.248468
# F-Score(Ordinary) = 0.316, Recall: 0.943, Precision: 0.19
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.42, Recall: 0.944, Precision: 0.27
# F-Score(id) = 0.396, Recall: 0.933, Precision: 0.251
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_127 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_127 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_127 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_127 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 16s - loss: 0.0578 - acc: 0.9859 - val_loss: 0.0392 - val_acc: 0.9875
Epoch 2/15
 - 16s - loss: 0.0269 - acc: 0.9897 - val_loss: 0.0372 - val_acc: 0.9883
Epoch 3/15
 - 16s - loss: 0.0223 - acc: 0.9905 - val_loss: 0.0380 - val_acc: 0.9885
Epoch 00003: early stopping
# Training time = 0:06:26.539547
# F-Score(Ordinary) = 0.092, Recall: 0.955, Precision: 0.048
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.211, Recall: 0.938, Precision: 0.119
# F-Score(id) = 0.012, Recall: 1.0, Precision: 0.006
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_128 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_128 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_128 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_128 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 16s - loss: 0.0577 - acc: 0.9854 - val_loss: 0.0384 - val_acc: 0.9876
Epoch 2/15
 - 16s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0362 - val_acc: 0.9884
Epoch 3/15
 - 16s - loss: 0.0224 - acc: 0.9904 - val_loss: 0.0369 - val_acc: 0.9888
Epoch 00003: early stopping
# Training time = 0:06:27.604403
# F-Score(Ordinary) = 0.297, Recall: 0.939, Precision: 0.176
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.236, Recall: 0.944, Precision: 0.135
# F-Score(id) = 0.513, Recall: 0.937, Precision: 0.353
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_129 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_129 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_129 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_129 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 16s - loss: 0.0586 - acc: 0.9850 - val_loss: 0.0390 - val_acc: 0.9878
Epoch 2/15
 - 16s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0365 - val_acc: 0.9885
Epoch 3/15
 - 16s - loss: 0.0223 - acc: 0.9903 - val_loss: 0.0379 - val_acc: 0.9882
Epoch 00003: early stopping
# Training time = 0:06:24.420328
# F-Score(Ordinary) = 0.489, Recall: 0.929, Precision: 0.332
# F-Score(lvc) = 0.345, Recall: 0.968, Precision: 0.21
# F-Score(ireflv) = 0.494, Recall: 0.896, Precision: 0.341
# F-Score(id) = 0.59, Recall: 0.935, Precision: 0.431
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_130 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_130 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_130 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_130 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 16s - loss: 0.0584 - acc: 0.9857 - val_loss: 0.0389 - val_acc: 0.9885
Epoch 2/15
 - 16s - loss: 0.0268 - acc: 0.9899 - val_loss: 0.0378 - val_acc: 0.9882
Epoch 3/15
 - 16s - loss: 0.0222 - acc: 0.9904 - val_loss: 0.0379 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:07:03.166572
# F-Score(Ordinary) = 0.112, Recall: 0.929, Precision: 0.059
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.161, Recall: 1.0, Precision: 0.087
# F-Score(id) = 0.133, Recall: 0.857, Precision: 0.072
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_131 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_131 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_131 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_131 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 16s - loss: 0.0577 - acc: 0.9856 - val_loss: 0.0384 - val_acc: 0.9881
Epoch 2/15
 - 16s - loss: 0.0267 - acc: 0.9898 - val_loss: 0.0381 - val_acc: 0.9883
Epoch 3/15
 - 16s - loss: 0.0223 - acc: 0.9903 - val_loss: 0.0365 - val_acc: 0.9886
Epoch 00003: early stopping
# Training time = 0:06:25.482191
# F-Score(Ordinary) = 0.1, Recall: 1.0, Precision: 0.053
# F-Score(lvc) = 0.19, Recall: 1.0, Precision: 0.105
# F-Score(ireflv) = 0.091, Recall: 1.0, Precision: 0.048
# F-Score(id) = 0.024, Recall: 1.0, Precision: 0.012
********************
********************
# XP = Token(300) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 20142
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = False
# Token/Lemma emb = 300
# POS = False
# Features = False
# Parameters = 6052208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_132 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_132 (Embedding)    (None, 4, 300)            6042600   
_________________________________________________________________
flatten_132 (Flatten)        (None, 1200)              0         
_________________________________________________________________
dense_132 (Dense)            (None, 8)                 9608      
=================================================================
Total params: 6,052,208
Trainable params: 6,052,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 16s - loss: 0.0581 - acc: 0.9861 - val_loss: 0.0383 - val_acc: 0.9883
Epoch 2/15
 - 16s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0379 - val_acc: 0.9884
Epoch 3/15
 - 16s - loss: 0.0223 - acc: 0.9905 - val_loss: 0.0365 - val_acc: 0.9887
Epoch 00003: early stopping
# Training time = 0:06:27.821147
# F-Score(Ordinary) = 0.222, Recall: 0.948, Precision: 0.126
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.262, Recall: 1.0, Precision: 0.151
# F-Score(id) = 0.265, Recall: 0.897, Precision: 0.156
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 13558
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_133 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_133 (Embedding)    (None, 4, 25)             12750     
_________________________________________________________________
flatten_133 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_133 (Dense)            (None, 8)                 808       
=================================================================
Total params: 13,558
Trainable params: 13,558
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.6959 - acc: 0.8204 - val_loss: 1.1530 - val_acc: 0.9734
Epoch 2/15
 - 0s - loss: 0.7482 - acc: 0.9737 - val_loss: 0.4715 - val_acc: 0.9803
Epoch 3/15
 - 0s - loss: 0.3718 - acc: 0.9750 - val_loss: 0.2743 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.2360 - acc: 0.9747 - val_loss: 0.1849 - val_acc: 0.9793
Epoch 5/15
 - 0s - loss: 0.1711 - acc: 0.9747 - val_loss: 0.1407 - val_acc: 0.9793
Epoch 6/15
 - 0s - loss: 0.1367 - acc: 0.9748 - val_loss: 0.1157 - val_acc: 0.9793
Epoch 00006: early stopping
# Training time = 0:00:02.681421
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_134 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_134 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_134 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_134 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0918 - acc: 0.9817 - val_loss: 0.0351 - val_acc: 0.9887
Epoch 2/15
 - 9s - loss: 0.0270 - acc: 0.9897 - val_loss: 0.0304 - val_acc: 0.9893
Epoch 3/15
 - 9s - loss: 0.0221 - acc: 0.9904 - val_loss: 0.0301 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:06:08.683241
# F-Score(Ordinary) = 0.342, Recall: 0.958, Precision: 0.208
# F-Score(lvc) = 0.235, Recall: 1.0, Precision: 0.133
# F-Score(ireflv) = 0.539, Recall: 0.923, Precision: 0.381
# F-Score(id) = 0.251, Recall: 1.0, Precision: 0.144
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_135 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_135 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_135 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_135 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0939 - acc: 0.9791 - val_loss: 0.0343 - val_acc: 0.9890
Epoch 2/15
 - 9s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0303 - val_acc: 0.9894
Epoch 3/15
 - 9s - loss: 0.0220 - acc: 0.9904 - val_loss: 0.0296 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:06:04.432039
# F-Score(Ordinary) = 0.436, Recall: 0.939, Precision: 0.284
# F-Score(lvc) = 0.212, Recall: 1.0, Precision: 0.119
# F-Score(ireflv) = 0.398, Recall: 0.914, Precision: 0.254
# F-Score(id) = 0.607, Recall: 0.938, Precision: 0.449
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_136 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_136 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_136 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_136 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0933 - acc: 0.9806 - val_loss: 0.0355 - val_acc: 0.9887
Epoch 2/15
 - 9s - loss: 0.0270 - acc: 0.9898 - val_loss: 0.0303 - val_acc: 0.9894
Epoch 3/15
 - 9s - loss: 0.0220 - acc: 0.9906 - val_loss: 0.0299 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:06:32.727904
# F-Score(Ordinary) = 0.391, Recall: 0.939, Precision: 0.247
# F-Score(lvc) = 0.167, Recall: 1.0, Precision: 0.091
# F-Score(ireflv) = 0.538, Recall: 0.875, Precision: 0.389
# F-Score(id) = 0.432, Recall: 1.0, Precision: 0.275
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_137 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_137 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_137 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_137 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0911 - acc: 0.9823 - val_loss: 0.0352 - val_acc: 0.9888
Epoch 2/15
 - 10s - loss: 0.0271 - acc: 0.9898 - val_loss: 0.0305 - val_acc: 0.9894
Epoch 3/15
 - 9s - loss: 0.0221 - acc: 0.9905 - val_loss: 0.0301 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:06:25.501008
# F-Score(Ordinary) = 0.331, Recall: 0.936, Precision: 0.201
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.474, Recall: 0.872, Precision: 0.325
# F-Score(id) = 0.363, Recall: 1.0, Precision: 0.222
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_138 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_138 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_138 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_138 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0923 - acc: 0.9825 - val_loss: 0.0345 - val_acc: 0.9889
Epoch 2/15
 - 9s - loss: 0.0271 - acc: 0.9898 - val_loss: 0.0305 - val_acc: 0.9895
Epoch 3/15
 - 9s - loss: 0.0222 - acc: 0.9906 - val_loss: 0.0301 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:06:07.952161
# F-Score(Ordinary) = 0.351, Recall: 0.959, Precision: 0.215
# F-Score(lvc) = 0.409, Recall: 0.974, Precision: 0.259
# F-Score(ireflv) = 0.417, Recall: 0.919, Precision: 0.27
# F-Score(id) = 0.242, Recall: 1.0, Precision: 0.138
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_139 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_139 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_139 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_139 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0963 - acc: 0.9789 - val_loss: 0.0342 - val_acc: 0.9890
Epoch 2/15
 - 9s - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0296 - val_acc: 0.9896
Epoch 3/15
 - 9s - loss: 0.0220 - acc: 0.9904 - val_loss: 0.0296 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:06:18.843495
# F-Score(Ordinary) = 0.212, Recall: 0.963, Precision: 0.119
# F-Score(lvc) = 0.155, Recall: 1.0, Precision: 0.084
# F-Score(ireflv) = 0.316, Recall: 0.923, Precision: 0.19
# F-Score(id) = 0.175, Recall: 1.0, Precision: 0.096
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_140 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_140 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_140 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_140 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0914 - acc: 0.9760 - val_loss: 0.0347 - val_acc: 0.9890
Epoch 2/15
 - 9s - loss: 0.0268 - acc: 0.9898 - val_loss: 0.0302 - val_acc: 0.9893
Epoch 3/15
 - 9s - loss: 0.0220 - acc: 0.9904 - val_loss: 0.0301 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:06:04.520320
# F-Score(Ordinary) = 0.499, Recall: 0.949, Precision: 0.339
# F-Score(lvc) = 0.443, Recall: 0.976, Precision: 0.287
# F-Score(ireflv) = 0.552, Recall: 0.909, Precision: 0.397
# F-Score(id) = 0.504, Recall: 0.966, Precision: 0.341
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_141 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_141 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_141 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_141 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0935 - acc: 0.9822 - val_loss: 0.0345 - val_acc: 0.9890
Epoch 2/15
 - 9s - loss: 0.0267 - acc: 0.9900 - val_loss: 0.0306 - val_acc: 0.9896
Epoch 3/15
 - 9s - loss: 0.0220 - acc: 0.9905 - val_loss: 0.0303 - val_acc: 0.9896
Epoch 00003: early stopping
# Training time = 0:06:27.826093
# F-Score(Ordinary) = 0.31, Recall: 0.953, Precision: 0.185
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.542, Recall: 0.941, Precision: 0.381
# F-Score(id) = 0.259, Recall: 0.962, Precision: 0.15
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_142 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_142 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_142 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_142 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0927 - acc: 0.9816 - val_loss: 0.0346 - val_acc: 0.9890
Epoch 2/15
 - 9s - loss: 0.0270 - acc: 0.9897 - val_loss: 0.0302 - val_acc: 0.9895
Epoch 3/15
 - 9s - loss: 0.0221 - acc: 0.9904 - val_loss: 0.0296 - val_acc: 0.9896
Epoch 00003: early stopping
# Training time = 0:06:12.837226
# F-Score(Ordinary) = 0.248, Recall: 0.969, Precision: 0.142
# F-Score(lvc) = 0.265, Recall: 0.957, Precision: 0.154
# F-Score(ireflv) = 0.211, Recall: 0.938, Precision: 0.119
# F-Score(id) = 0.26, Recall: 1.0, Precision: 0.15
********************
********************
# XP = Lemma(25) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 25
# POS = False
# Features = False
# Parameters = 371083
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_143 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_143 (Embedding)    (None, 4, 25)             370275    
_________________________________________________________________
flatten_143 (Flatten)        (None, 100)               0         
_________________________________________________________________
dense_143 (Dense)            (None, 8)                 808       
=================================================================
Total params: 371,083
Trainable params: 371,083
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0907 - acc: 0.9812 - val_loss: 0.0344 - val_acc: 0.9888
Epoch 2/15
 - 9s - loss: 0.0266 - acc: 0.9899 - val_loss: 0.0304 - val_acc: 0.9894
Epoch 3/15
 - 9s - loss: 0.0219 - acc: 0.9905 - val_loss: 0.0297 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:06:07.479303
# F-Score(Ordinary) = 0.285, Recall: 0.973, Precision: 0.167
# F-Score(lvc) = 0.267, Recall: 1.0, Precision: 0.154
# F-Score(ireflv) = 0.282, Recall: 0.913, Precision: 0.167
# F-Score(id) = 0.305, Recall: 1.0, Precision: 0.18
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 27108
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_144 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_144 (Embedding)    (None, 4, 50)             25500     
_________________________________________________________________
flatten_144 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_144 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 27,108
Trainable params: 27,108
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.6184 - acc: 0.8286 - val_loss: 0.8999 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.5179 - acc: 0.9742 - val_loss: 0.2890 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.2272 - acc: 0.9744 - val_loss: 0.1605 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.1484 - acc: 0.9745 - val_loss: 0.1166 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:02.464955
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_145 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_145 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_145 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_145 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0775 - acc: 0.9833 - val_loss: 0.0330 - val_acc: 0.9889
Epoch 2/15
 - 10s - loss: 0.0255 - acc: 0.9900 - val_loss: 0.0298 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0301 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:06:49.608066
# F-Score(Ordinary) = 0.307, Recall: 0.952, Precision: 0.183
# F-Score(lvc) = 0.143, Recall: 1.0, Precision: 0.077
# F-Score(ireflv) = 0.539, Recall: 0.923, Precision: 0.381
# F-Score(id) = 0.223, Recall: 1.0, Precision: 0.126
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_146 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_146 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_146 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_146 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0780 - acc: 0.9823 - val_loss: 0.0323 - val_acc: 0.9892
Epoch 2/15
 - 9s - loss: 0.0254 - acc: 0.9899 - val_loss: 0.0302 - val_acc: 0.9895
Epoch 3/15
 - 9s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0299 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:06:05.323579
# F-Score(Ordinary) = 0.43, Recall: 0.931, Precision: 0.279
# F-Score(lvc) = 0.155, Recall: 1.0, Precision: 0.084
# F-Score(ireflv) = 0.415, Recall: 0.895, Precision: 0.27
# F-Score(id) = 0.613, Recall: 0.938, Precision: 0.455
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_147 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_147 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_147 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_147 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0766 - acc: 0.9840 - val_loss: 0.0338 - val_acc: 0.9891
Epoch 2/15
 - 9s - loss: 0.0256 - acc: 0.9900 - val_loss: 0.0302 - val_acc: 0.9894
Epoch 3/15
 - 10s - loss: 0.0214 - acc: 0.9906 - val_loss: 0.0303 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:06:11.119533
# F-Score(Ordinary) = 0.383, Recall: 0.938, Precision: 0.24
# F-Score(lvc) = 0.143, Recall: 1.0, Precision: 0.077
# F-Score(ireflv) = 0.53, Recall: 0.873, Precision: 0.381
# F-Score(id) = 0.432, Recall: 1.0, Precision: 0.275
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_148 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_148 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_148 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_148 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0767 - acc: 0.9839 - val_loss: 0.0330 - val_acc: 0.9892
Epoch 2/15
 - 10s - loss: 0.0256 - acc: 0.9899 - val_loss: 0.0300 - val_acc: 0.9894
Epoch 3/15
 - 10s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0300 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:06:05.987459
# F-Score(Ordinary) = 0.331, Recall: 0.926, Precision: 0.201
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.497, Recall: 0.863, Precision: 0.349
# F-Score(id) = 0.363, Recall: 1.0, Precision: 0.222
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_149 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_149 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_149 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_149 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0763 - acc: 0.9817 - val_loss: 0.0328 - val_acc: 0.9891
Epoch 2/15
 - 10s - loss: 0.0256 - acc: 0.9899 - val_loss: 0.0306 - val_acc: 0.9892
Epoch 3/15
 - 10s - loss: 0.0215 - acc: 0.9905 - val_loss: 0.0305 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:06:32.663513
# F-Score(Ordinary) = 0.291, Recall: 0.962, Precision: 0.172
# F-Score(lvc) = 0.375, Recall: 1.0, Precision: 0.231
# F-Score(ireflv) = 0.417, Recall: 0.919, Precision: 0.27
# F-Score(id) = 0.091, Recall: 1.0, Precision: 0.048
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_150 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_150 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_150 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_150 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0769 - acc: 0.9833 - val_loss: 0.0325 - val_acc: 0.9890
Epoch 2/15
 - 10s - loss: 0.0254 - acc: 0.9900 - val_loss: 0.0297 - val_acc: 0.9895
Epoch 3/15
 - 9s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0300 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:06:10.366253
# F-Score(Ordinary) = 0.208, Recall: 0.962, Precision: 0.117
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.26, Recall: 0.95, Precision: 0.151
# F-Score(id) = 0.25, Recall: 0.96, Precision: 0.144
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_151 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_151 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_151 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_151 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0769 - acc: 0.9837 - val_loss: 0.0331 - val_acc: 0.9890
Epoch 2/15
 - 9s - loss: 0.0254 - acc: 0.9900 - val_loss: 0.0299 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0213 - acc: 0.9905 - val_loss: 0.0302 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:06:05.899188
# F-Score(Ordinary) = 0.547, Recall: 0.934, Precision: 0.387
# F-Score(lvc) = 0.457, Recall: 0.956, Precision: 0.301
# F-Score(ireflv) = 0.618, Recall: 0.908, Precision: 0.468
# F-Score(id) = 0.563, Recall: 0.944, Precision: 0.401
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_152 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_152 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_152 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_152 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0780 - acc: 0.9840 - val_loss: 0.0327 - val_acc: 0.9895
Epoch 2/15
 - 9s - loss: 0.0255 - acc: 0.9900 - val_loss: 0.0304 - val_acc: 0.9894
Epoch 3/15
 - 9s - loss: 0.0214 - acc: 0.9905 - val_loss: 0.0305 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:06:05.386394
# F-Score(Ordinary) = 0.27, Recall: 0.932, Precision: 0.158
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.547, Recall: 0.925, Precision: 0.389
# F-Score(id) = 0.174, Recall: 0.941, Precision: 0.096
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_153 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_153 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_153 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_153 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0768 - acc: 0.9831 - val_loss: 0.0320 - val_acc: 0.9893
Epoch 2/15
 - 10s - loss: 0.0254 - acc: 0.9900 - val_loss: 0.0300 - val_acc: 0.9895
Epoch 3/15
 - 9s - loss: 0.0215 - acc: 0.9905 - val_loss: 0.0298 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:06:11.986176
# F-Score(Ordinary) = 0.282, Recall: 0.973, Precision: 0.165
# F-Score(lvc) = 0.318, Recall: 1.0, Precision: 0.189
# F-Score(ireflv) = 0.247, Recall: 0.9, Precision: 0.143
# F-Score(id) = 0.278, Recall: 1.0, Precision: 0.162
********************
********************
# XP = Lemma(50) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = False
# Features = False
# Parameters = 742158
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_154 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_154 (Embedding)    (None, 4, 50)             740550    
_________________________________________________________________
flatten_154 (Flatten)        (None, 200)               0         
_________________________________________________________________
dense_154 (Dense)            (None, 8)                 1608      
=================================================================
Total params: 742,158
Trainable params: 742,158
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 9s - loss: 0.0762 - acc: 0.9849 - val_loss: 0.0330 - val_acc: 0.9891
Epoch 2/15
 - 9s - loss: 0.0253 - acc: 0.9900 - val_loss: 0.0308 - val_acc: 0.9894
Epoch 3/15
 - 9s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0301 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:06:03.666757
# F-Score(Ordinary) = 0.248, Recall: 1.0, Precision: 0.142
# F-Score(lvc) = 0.256, Recall: 1.0, Precision: 0.147
# F-Score(ireflv) = 0.25, Recall: 1.0, Precision: 0.143
# F-Score(id) = 0.242, Recall: 1.0, Precision: 0.138
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 40658
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_155 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_155 (Embedding)    (None, 4, 75)             38250     
_________________________________________________________________
flatten_155 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_155 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 40,658
Trainable params: 40,658
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.4188 - acc: 0.6992 - val_loss: 0.6458 - val_acc: 0.9469
Epoch 2/15
 - 0s - loss: 0.3901 - acc: 0.9735 - val_loss: 0.2223 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1789 - acc: 0.9745 - val_loss: 0.1300 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.1228 - acc: 0.9746 - val_loss: 0.1002 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:03.964869
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_156 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_156 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_156 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_156 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0701 - acc: 0.9818 - val_loss: 0.0324 - val_acc: 0.9888
Epoch 2/15
 - 10s - loss: 0.0250 - acc: 0.9900 - val_loss: 0.0300 - val_acc: 0.9894
Epoch 3/15
 - 10s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0305 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:06:56.459455
# F-Score(Ordinary) = 0.277, Recall: 0.947, Precision: 0.162
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.556, Recall: 0.926, Precision: 0.397
# F-Score(id) = 0.134, Recall: 1.0, Precision: 0.072
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_157 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_157 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_157 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_157 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0695 - acc: 0.9844 - val_loss: 0.0315 - val_acc: 0.9893
Epoch 2/15
 - 10s - loss: 0.0249 - acc: 0.9900 - val_loss: 0.0302 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0300 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:06:11.479307
# F-Score(Ordinary) = 0.444, Recall: 0.941, Precision: 0.291
# F-Score(lvc) = 0.131, Recall: 1.0, Precision: 0.07
# F-Score(ireflv) = 0.436, Recall: 0.923, Precision: 0.286
# F-Score(id) = 0.64, Recall: 0.942, Precision: 0.485
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_158 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_158 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_158 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_158 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0699 - acc: 0.9840 - val_loss: 0.0334 - val_acc: 0.9892
Epoch 2/15
 - 10s - loss: 0.0251 - acc: 0.9900 - val_loss: 0.0300 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0303 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:06:06.462031
# F-Score(Ordinary) = 0.388, Recall: 0.939, Precision: 0.245
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.562, Recall: 0.881, Precision: 0.413
# F-Score(id) = 0.439, Recall: 1.0, Precision: 0.281
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_159 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_159 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_159 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_159 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0707 - acc: 0.9836 - val_loss: 0.0321 - val_acc: 0.9892
Epoch 2/15
 - 10s - loss: 0.0250 - acc: 0.9900 - val_loss: 0.0303 - val_acc: 0.9894
Epoch 3/15
 - 10s - loss: 0.0211 - acc: 0.9907 - val_loss: 0.0303 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:06:30.398419
# F-Score(Ordinary) = 0.328, Recall: 0.926, Precision: 0.199
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.48, Recall: 0.857, Precision: 0.333
# F-Score(id) = 0.371, Recall: 1.0, Precision: 0.228
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_160 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_160 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_160 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_160 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0701 - acc: 0.9827 - val_loss: 0.0322 - val_acc: 0.9891
Epoch 2/15
 - 10s - loss: 0.0251 - acc: 0.9900 - val_loss: 0.0308 - val_acc: 0.9892
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0308 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:06:04.574801
# F-Score(Ordinary) = 0.254, Recall: 0.955, Precision: 0.146
# F-Score(lvc) = 0.366, Recall: 1.0, Precision: 0.224
# F-Score(ireflv) = 0.357, Recall: 0.903, Precision: 0.222
# F-Score(id) = 0.047, Recall: 1.0, Precision: 0.024
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_161 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_161 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_161 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_161 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0697 - acc: 0.9850 - val_loss: 0.0318 - val_acc: 0.9893
Epoch 2/15
 - 10s - loss: 0.0249 - acc: 0.9900 - val_loss: 0.0296 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0300 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:06:28.230060
# F-Score(Ordinary) = 0.25, Recall: 0.926, Precision: 0.144
# F-Score(lvc) = 0.067, Recall: 0.833, Precision: 0.035
# F-Score(ireflv) = 0.284, Recall: 0.955, Precision: 0.167
# F-Score(id) = 0.357, Recall: 0.925, Precision: 0.222
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_162 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_162 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_162 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_162 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0695 - acc: 0.9838 - val_loss: 0.0325 - val_acc: 0.9890
Epoch 2/15
 - 10s - loss: 0.0249 - acc: 0.9901 - val_loss: 0.0300 - val_acc: 0.9894
Epoch 3/15
 - 10s - loss: 0.0211 - acc: 0.9905 - val_loss: 0.0308 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:06:16.741392
# F-Score(Ordinary) = 0.578, Recall: 0.934, Precision: 0.419
# F-Score(lvc) = 0.482, Recall: 0.958, Precision: 0.322
# F-Score(ireflv) = 0.653, Recall: 0.914, Precision: 0.508
# F-Score(id) = 0.596, Recall: 0.936, Precision: 0.437
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_163 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_163 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_163 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_163 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0691 - acc: 0.9836 - val_loss: 0.0322 - val_acc: 0.9894
Epoch 2/15
 - 10s - loss: 0.0249 - acc: 0.9901 - val_loss: 0.0308 - val_acc: 0.9892
Epoch 3/15
 - 10s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0310 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:06:07.119052
# F-Score(Ordinary) = 0.236, Recall: 0.922, Precision: 0.135
# F-Score(lvc) = 0.041, Recall: 1.0, Precision: 0.021
# F-Score(ireflv) = 0.506, Recall: 0.917, Precision: 0.349
# F-Score(id) = 0.133, Recall: 0.923, Precision: 0.072
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_164 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_164 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_164 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_164 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0696 - acc: 0.9823 - val_loss: 0.0317 - val_acc: 0.9895
Epoch 2/15
 - 10s - loss: 0.0250 - acc: 0.9900 - val_loss: 0.0303 - val_acc: 0.9894
Epoch 3/15
 - 10s - loss: 0.0213 - acc: 0.9906 - val_loss: 0.0299 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:06:10.764670
# F-Score(Ordinary) = 0.282, Recall: 0.973, Precision: 0.165
# F-Score(lvc) = 0.347, Recall: 1.0, Precision: 0.21
# F-Score(ireflv) = 0.247, Recall: 0.9, Precision: 0.143
# F-Score(id) = 0.251, Recall: 1.0, Precision: 0.144
********************
********************
# XP = Lemma(75) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 75
# POS = False
# Features = False
# Parameters = 1113233
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_165 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_165 (Embedding)    (None, 4, 75)             1110825   
_________________________________________________________________
flatten_165 (Flatten)        (None, 300)               0         
_________________________________________________________________
dense_165 (Dense)            (None, 8)                 2408      
=================================================================
Total params: 1,113,233
Trainable params: 1,113,233
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0696 - acc: 0.9831 - val_loss: 0.0328 - val_acc: 0.9891
Epoch 2/15
 - 10s - loss: 0.0250 - acc: 0.9900 - val_loss: 0.0309 - val_acc: 0.9894
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0301 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:06:05.125676
# F-Score(Ordinary) = 0.286, Recall: 0.986, Precision: 0.167
# F-Score(lvc) = 0.267, Recall: 1.0, Precision: 0.154
# F-Score(ireflv) = 0.272, Recall: 0.952, Precision: 0.159
# F-Score(id) = 0.313, Recall: 1.0, Precision: 0.186
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 54208
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_166 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_166 (Embedding)    (None, 4, 100)            51000     
_________________________________________________________________
flatten_166 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_166 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 54,208
Trainable params: 54,208
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.3020 - acc: 0.8273 - val_loss: 0.5347 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.3303 - acc: 0.9746 - val_loss: 0.1894 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1584 - acc: 0.9745 - val_loss: 0.1167 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.1122 - acc: 0.9754 - val_loss: 0.0919 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:02.492905
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_167 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_167 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_167 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_167 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0652 - acc: 0.9857 - val_loss: 0.0320 - val_acc: 0.9888
Epoch 2/15
 - 10s - loss: 0.0247 - acc: 0.9901 - val_loss: 0.0301 - val_acc: 0.9894
Epoch 3/15
 - 10s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0306 - val_acc: 0.9890
Epoch 00003: early stopping
# Training time = 0:06:08.051917
# F-Score(Ordinary) = 0.264, Recall: 0.944, Precision: 0.153
# F-Score(lvc) = 0.081, Recall: 1.0, Precision: 0.042
# F-Score(ireflv) = 0.571, Recall: 0.929, Precision: 0.413
# F-Score(id) = 0.102, Recall: 1.0, Precision: 0.054
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_168 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_168 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_168 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_168 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0655 - acc: 0.9834 - val_loss: 0.0316 - val_acc: 0.9893
Epoch 2/15
 - 10s - loss: 0.0247 - acc: 0.9900 - val_loss: 0.0302 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0210 - acc: 0.9906 - val_loss: 0.0300 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:06:10.449173
# F-Score(Ordinary) = 0.44, Recall: 0.926, Precision: 0.288
# F-Score(lvc) = 0.118, Recall: 1.0, Precision: 0.063
# F-Score(ireflv) = 0.431, Recall: 0.878, Precision: 0.286
# F-Score(id) = 0.64, Recall: 0.942, Precision: 0.485
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_169 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_169 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_169 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_169 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0653 - acc: 0.9852 - val_loss: 0.0332 - val_acc: 0.9891
Epoch 2/15
 - 10s - loss: 0.0248 - acc: 0.9901 - val_loss: 0.0301 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0305 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:06:05.084184
# F-Score(Ordinary) = 0.388, Recall: 0.939, Precision: 0.245
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.57, Recall: 0.883, Precision: 0.421
# F-Score(id) = 0.432, Recall: 1.0, Precision: 0.275
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_170 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_170 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_170 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_170 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0648 - acc: 0.9857 - val_loss: 0.0321 - val_acc: 0.9892
Epoch 2/15
 - 10s - loss: 0.0249 - acc: 0.9900 - val_loss: 0.0306 - val_acc: 0.9893
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9907 - val_loss: 0.0305 - val_acc: 0.9890
Epoch 00003: early stopping
# Training time = 0:06:28.450686
# F-Score(Ordinary) = 0.333, Recall: 0.918, Precision: 0.204
# F-Score(lvc) = 0.081, Recall: 1.0, Precision: 0.042
# F-Score(ireflv) = 0.494, Recall: 0.846, Precision: 0.349
# F-Score(id) = 0.379, Recall: 1.0, Precision: 0.234
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_171 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_171 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_171 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_171 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0648 - acc: 0.9854 - val_loss: 0.0317 - val_acc: 0.9892
Epoch 2/15
 - 10s - loss: 0.0248 - acc: 0.9900 - val_loss: 0.0310 - val_acc: 0.9890
Epoch 3/15
 - 10s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0308 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:06:09.959035
# F-Score(Ordinary) = 0.233, Recall: 0.951, Precision: 0.133
# F-Score(lvc) = 0.318, Recall: 1.0, Precision: 0.189
# F-Score(ireflv) = 0.346, Recall: 0.9, Precision: 0.214
# F-Score(id) = 0.047, Recall: 1.0, Precision: 0.024
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_172 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_172 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_172 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_172 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0657 - acc: 0.9836 - val_loss: 0.0318 - val_acc: 0.9892
Epoch 2/15
 - 10s - loss: 0.0248 - acc: 0.9900 - val_loss: 0.0298 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0302 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:06:08.632446
# F-Score(Ordinary) = 0.243, Recall: 0.924, Precision: 0.14
# F-Score(lvc) = 0.067, Recall: 0.833, Precision: 0.035
# F-Score(ireflv) = 0.224, Recall: 0.941, Precision: 0.127
# F-Score(id) = 0.381, Recall: 0.93, Precision: 0.24
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_173 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_173 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_173 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_173 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0657 - acc: 0.9848 - val_loss: 0.0322 - val_acc: 0.9890
Epoch 2/15
 - 10s - loss: 0.0247 - acc: 0.9902 - val_loss: 0.0299 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0307 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:06:11.097246
# F-Score(Ordinary) = 0.599, Recall: 0.932, Precision: 0.442
# F-Score(lvc) = 0.497, Recall: 0.96, Precision: 0.336
# F-Score(ireflv) = 0.657, Recall: 0.903, Precision: 0.516
# F-Score(id) = 0.635, Recall: 0.941, Precision: 0.479
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_174 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_174 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_174 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_174 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0663 - acc: 0.9845 - val_loss: 0.0319 - val_acc: 0.9895
Epoch 2/15
 - 10s - loss: 0.0247 - acc: 0.9902 - val_loss: 0.0308 - val_acc: 0.9893
Epoch 3/15
 - 10s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0311 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:06:06.437051
# F-Score(Ordinary) = 0.211, Recall: 0.929, Precision: 0.119
# F-Score(lvc) = 0.028, Recall: 1.0, Precision: 0.014
# F-Score(ireflv) = 0.5, Recall: 0.935, Precision: 0.341
# F-Score(id) = 0.08, Recall: 0.875, Precision: 0.042
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_175 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_175 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_175 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_175 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0655 - acc: 0.9842 - val_loss: 0.0313 - val_acc: 0.9894
Epoch 2/15
 - 10s - loss: 0.0247 - acc: 0.9901 - val_loss: 0.0303 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9905 - val_loss: 0.0298 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:06:06.870497
# F-Score(Ordinary) = 0.292, Recall: 0.974, Precision: 0.172
# F-Score(lvc) = 0.366, Recall: 1.0, Precision: 0.224
# F-Score(ireflv) = 0.234, Recall: 0.895, Precision: 0.135
# F-Score(id) = 0.269, Recall: 1.0, Precision: 0.156
********************
********************
# XP = Lemma(100) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 100
# POS = False
# Features = False
# Parameters = 1484308
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_176 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_176 (Embedding)    (None, 4, 100)            1481100   
_________________________________________________________________
flatten_176 (Flatten)        (None, 400)               0         
_________________________________________________________________
dense_176 (Dense)            (None, 8)                 3208      
=================================================================
Total params: 1,484,308
Trainable params: 1,484,308
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0645 - acc: 0.9857 - val_loss: 0.0327 - val_acc: 0.9891
Epoch 2/15
 - 10s - loss: 0.0247 - acc: 0.9901 - val_loss: 0.0310 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0302 - val_acc: 0.9896
Epoch 00003: early stopping
# Training time = 0:06:07.737089
# F-Score(Ordinary) = 0.3, Recall: 1.0, Precision: 0.176
# F-Score(lvc) = 0.277, Recall: 1.0, Precision: 0.161
# F-Score(ireflv) = 0.297, Recall: 1.0, Precision: 0.175
# F-Score(id) = 0.322, Recall: 1.0, Precision: 0.192
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 200
# Test = 17680
# Tokens vocabulary = 510
# POSs vocabulary = 38
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 67758
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_177 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_177 (Embedding)    (None, 4, 125)            63750     
_________________________________________________________________
flatten_177 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_177 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 67,758
Trainable params: 67,758
Non-trainable params: 0
_________________________________________________________________
None
Train on 9142 samples, validate on 1016 samples
Epoch 1/15
 - 0s - loss: 1.2381 - acc: 0.8893 - val_loss: 0.4637 - val_acc: 0.9793
Epoch 2/15
 - 0s - loss: 0.2864 - acc: 0.9743 - val_loss: 0.1626 - val_acc: 0.9793
Epoch 3/15
 - 0s - loss: 0.1396 - acc: 0.9743 - val_loss: 0.1044 - val_acc: 0.9793
Epoch 4/15
 - 0s - loss: 0.1013 - acc: 0.9755 - val_loss: 0.0843 - val_acc: 0.9793
Epoch 00004: early stopping
# Training time = 0:00:02.460258
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_178 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_178 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_178 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_178 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0619 - acc: 0.9850 - val_loss: 0.0319 - val_acc: 0.9888
Epoch 2/15
 - 10s - loss: 0.0247 - acc: 0.9901 - val_loss: 0.0301 - val_acc: 0.9894
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0306 - val_acc: 0.9890
Epoch 00003: early stopping
# Training time = 0:06:10.502284
# F-Score(Ordinary) = 0.256, Recall: 0.929, Precision: 0.149
# F-Score(lvc) = 0.068, Recall: 1.0, Precision: 0.035
# F-Score(ireflv) = 0.584, Recall: 0.915, Precision: 0.429
# F-Score(id) = 0.069, Recall: 1.0, Precision: 0.036
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_179 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_179 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_179 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_179 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0628 - acc: 0.9845 - val_loss: 0.0315 - val_acc: 0.9894
Epoch 2/15
 - 10s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0303 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0210 - acc: 0.9906 - val_loss: 0.0301 - val_acc: 0.9891
Epoch 00003: early stopping
# Training time = 0:06:09.064002
# F-Score(Ordinary) = 0.438, Recall: 0.933, Precision: 0.286
# F-Score(lvc) = 0.106, Recall: 1.0, Precision: 0.056
# F-Score(ireflv) = 0.434, Recall: 0.9, Precision: 0.286
# F-Score(id) = 0.64, Recall: 0.942, Precision: 0.485
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_180 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_180 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_180 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_180 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0623 - acc: 0.9848 - val_loss: 0.0335 - val_acc: 0.9892
Epoch 2/15
 - 10s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0304 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0211 - acc: 0.9907 - val_loss: 0.0306 - val_acc: 0.9893
Epoch 00003: early stopping
# Training time = 0:06:08.530657
# F-Score(Ordinary) = 0.388, Recall: 0.939, Precision: 0.245
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.585, Recall: 0.887, Precision: 0.437
# F-Score(id) = 0.425, Recall: 1.0, Precision: 0.269
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_181 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_181 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_181 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_181 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0630 - acc: 0.9844 - val_loss: 0.0319 - val_acc: 0.9893
Epoch 2/15
 - 10s - loss: 0.0247 - acc: 0.9900 - val_loss: 0.0306 - val_acc: 0.9892
Epoch 3/15
 - 10s - loss: 0.0210 - acc: 0.9907 - val_loss: 0.0304 - val_acc: 0.9890
Epoch 00003: early stopping
# Training time = 0:06:13.243216
# F-Score(Ordinary) = 0.357, Recall: 0.915, Precision: 0.222
# F-Score(lvc) = 0.093, Recall: 1.0, Precision: 0.049
# F-Score(ireflv) = 0.508, Recall: 0.836, Precision: 0.365
# F-Score(id) = 0.417, Recall: 1.0, Precision: 0.263
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_182 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_182 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_182 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_182 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0623 - acc: 0.9859 - val_loss: 0.0318 - val_acc: 0.9892
Epoch 2/15
 - 10s - loss: 0.0247 - acc: 0.9901 - val_loss: 0.0312 - val_acc: 0.9890
Epoch 3/15
 - 10s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0311 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:06:05.633876
# F-Score(Ordinary) = 0.215, Recall: 0.946, Precision: 0.121
# F-Score(lvc) = 0.318, Recall: 1.0, Precision: 0.189
# F-Score(ireflv) = 0.303, Recall: 0.885, Precision: 0.183
# F-Score(id) = 0.035, Recall: 1.0, Precision: 0.018
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_183 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_183 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_183 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_183 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0619 - acc: 0.9845 - val_loss: 0.0317 - val_acc: 0.9892
Epoch 2/15
 - 10s - loss: 0.0247 - acc: 0.9900 - val_loss: 0.0299 - val_acc: 0.9894
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0303 - val_acc: 0.9894
Epoch 00003: early stopping
# Training time = 0:06:12.913604
# F-Score(Ordinary) = 0.257, Recall: 0.942, Precision: 0.149
# F-Score(lvc) = 0.054, Recall: 1.0, Precision: 0.028
# F-Score(ireflv) = 0.236, Recall: 0.944, Precision: 0.135
# F-Score(id) = 0.411, Recall: 0.936, Precision: 0.263
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_184 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_184 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_184 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_184 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0620 - acc: 0.9854 - val_loss: 0.0321 - val_acc: 0.9891
Epoch 2/15
 - 10s - loss: 0.0245 - acc: 0.9902 - val_loss: 0.0299 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0211 - acc: 0.9906 - val_loss: 0.0309 - val_acc: 0.9892
Epoch 00003: early stopping
# Training time = 0:06:17.036122
# F-Score(Ordinary) = 0.614, Recall: 0.943, Precision: 0.455
# F-Score(lvc) = 0.52, Recall: 0.962, Precision: 0.357
# F-Score(ireflv) = 0.677, Recall: 0.931, Precision: 0.532
# F-Score(id) = 0.64, Recall: 0.942, Precision: 0.485
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_185 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_185 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_185 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_185 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0622 - acc: 0.9849 - val_loss: 0.0320 - val_acc: 0.9895
Epoch 2/15
 - 10s - loss: 0.0247 - acc: 0.9902 - val_loss: 0.0311 - val_acc: 0.9892
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9906 - val_loss: 0.0314 - val_acc: 0.9895
Epoch 00003: early stopping
# Training time = 0:06:10.706813
# F-Score(Ordinary) = 0.2, Recall: 0.907, Precision: 0.112
# F-Score(lvc) = 0.014, Recall: 1.0, Precision: 0.007
# F-Score(ireflv) = 0.497, Recall: 0.915, Precision: 0.341
# F-Score(id) = 0.058, Recall: 0.833, Precision: 0.03
********************
********************
# XP = Lemma(125) 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
# Train = 16092
# Test = 1788
# Tokens vocabulary = 14811
# POSs vocabulary = 236
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = False
# Features = False
# Parameters = 1855383
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_186 (InputLayer)       (None, 4)                 0         
_________________________________________________________________
embedding_186 (Embedding)    (None, 4, 125)            1851375   
_________________________________________________________________
flatten_186 (Flatten)        (None, 500)               0         
_________________________________________________________________
dense_186 (Dense)            (None, 8)                 4008      
=================================================================
Total params: 1,855,383
Trainable params: 1,855,383
Non-trainable params: 0
_________________________________________________________________
None
Train on 713107 samples, validate on 79235 samples
Epoch 1/15
 - 10s - loss: 0.0622 - acc: 0.9857 - val_loss: 0.0313 - val_acc: 0.9892
Epoch 2/15
 - 10s - loss: 0.0246 - acc: 0.9901 - val_loss: 0.0306 - val_acc: 0.9895
Epoch 3/15
 - 10s - loss: 0.0212 - acc: 0.9905 - val_loss: 0.0298 - val_acc: 0.9895
