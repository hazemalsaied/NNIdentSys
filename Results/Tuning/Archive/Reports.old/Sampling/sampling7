INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 4, 125)       1836625     input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 4, 56)        13160       input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 500)          0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 224)          0           embedding_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 724)          0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 256)          185600      concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 8)            2056        dropout_1[0][0]                  
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 712548 samples, validate on 79173 samples
Epoch 1/15
 - 32s - loss: 1.6682 - acc: 0.9844 - val_loss: 0.0852 - val_acc: 0.9864
Epoch 2/15
 - 32s - loss: 1.1475 - acc: 0.9885 - val_loss: 0.0973 - val_acc: 0.9886
Epoch 3/15
 - 32s - loss: 2.6205 - acc: 0.9890 - val_loss: 0.1444 - val_acc: 0.9878
Epoch 4/15
 - 32s - loss: 2.6321 - acc: 0.9886 - val_loss: 0.1880 - val_acc: 0.9888
Epoch 5/15
 - 32s - loss: 2.6322 - acc: 0.9896 - val_loss: 0.2064 - val_acc: 0.9878
Epoch 6/15
 - 32s - loss: 2.6272 - acc: 0.9890 - val_loss: 0.2166 - val_acc: 0.9878
Epoch 7/15
 - 32s - loss: 2.6266 - acc: 0.9899 - val_loss: 0.2993 - val_acc: 0.9872
Epoch 8/15
 - 32s - loss: 2.6455 - acc: 0.9897 - val_loss: 0.2608 - val_acc: 0.9883
Epoch 9/15
 - 32s - loss: 2.6429 - acc: 0.9902 - val_loss: 0.2726 - val_acc: 0.9886
Epoch 10/15
 - 32s - loss: 2.6279 - acc: 0.9906 - val_loss: 0.3277 - val_acc: 0.9884
Epoch 11/15
 - 32s - loss: 2.6204 - acc: 0.9907 - val_loss: 0.2609 - val_acc: 0.9891
Epoch 12/15
 - 32s - loss: 2.6501 - acc: 0.9910 - val_loss: 0.5839 - val_acc: 0.9888
Epoch 13/15
 - 32s - loss: 2.6518 - acc: 0.9908 - val_loss: 0.3613 - val_acc: 0.9893
Epoch 14/15
 - 32s - loss: 2.6282 - acc: 0.9907 - val_loss: 0.3687 - val_acc: 0.9881
Epoch 15/15
 - 32s - loss: 2.6345 - acc: 0.9913 - val_loss: 0.3653 - val_acc: 0.9884
# Training time = 0:09:52.687134
# F-Score(Ordinary) = 0.517, Recall: 0.448, Precision: 0.611
# F-Score(lvc) = 0.53, Recall: 0.925, Precision: 0.371
# F-Score(ireflv) = 0.805, Recall: 0.853, Precision: 0.762
# F-Score(id) = 0.403, Recall: 0.289, Precision: 0.668
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 4, 125)       1836625     input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 4, 56)        13160       input_4[0][0]                    
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 500)          0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 224)          0           embedding_4[0][0]                
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 724)          0           flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 256)          185600      concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 256)          0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 8)            2056        dropout_2[0][0]                  
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 712548 samples, validate on 79173 samples
Epoch 1/15
 - 32s - loss: 1.5206 - acc: 0.9839 - val_loss: 0.0725 - val_acc: 0.9868
Epoch 2/15
 - 32s - loss: 1.7617 - acc: 0.9887 - val_loss: 0.0930 - val_acc: 0.9880
Epoch 3/15
 - 32s - loss: 0.9277 - acc: 0.9888 - val_loss: 0.1055 - val_acc: 0.9876
Epoch 4/15
 - 32s - loss: 1.9779 - acc: 0.9889 - val_loss: 0.1425 - val_acc: 0.9885
Epoch 5/15
 - 32s - loss: 1.3334 - acc: 0.9890 - val_loss: 0.1933 - val_acc: 0.9874
Epoch 6/15
 - 32s - loss: 2.6345 - acc: 0.9888 - val_loss: 0.2874 - val_acc: 0.9890
Epoch 7/15
 - 32s - loss: 2.6308 - acc: 0.9892 - val_loss: 0.2145 - val_acc: 0.9886
Epoch 8/15
 - 32s - loss: 2.6432 - acc: 0.9900 - val_loss: 0.2551 - val_acc: 0.9885
Epoch 9/15
 - 32s - loss: 2.6294 - acc: 0.9898 - val_loss: 0.2613 - val_acc: 0.9871
Epoch 10/15
 - 32s - loss: 2.6245 - acc: 0.9894 - val_loss: 0.2768 - val_acc: 0.9878
Epoch 11/15
 - 32s - loss: 2.6296 - acc: 0.9907 - val_loss: 0.3738 - val_acc: 0.9888
Epoch 12/15
 - 32s - loss: 2.6250 - acc: 0.9904 - val_loss: 0.3209 - val_acc: 0.9890
Epoch 13/15
 - 32s - loss: 2.6399 - acc: 0.9911 - val_loss: 0.3240 - val_acc: 0.9881
Epoch 14/15
 - 32s - loss: 2.6529 - acc: 0.9908 - val_loss: 0.4091 - val_acc: 0.9884
Epoch 15/15
 - 32s - loss: 2.6508 - acc: 0.9910 - val_loss: 0.3392 - val_acc: 0.9887
# Training time = 0:09:36.759553
# F-Score(Ordinary) = 0.452, Recall: 0.357, Precision: 0.615
# F-Score(lvc) = 0.337, Recall: 0.284, Precision: 0.417
# F-Score(ireflv) = 0.759, Recall: 0.756, Precision: 0.762
# F-Score(id) = 0.371, Recall: 0.264, Precision: 0.622
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 4, 125)       1836625     input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 4, 56)        13160       input_6[0][0]                    
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 500)          0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 224)          0           embedding_6[0][0]                
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 724)          0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 256)          185600      concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 256)          0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 8)            2056        dropout_3[0][0]                  
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 712548 samples, validate on 79173 samples
Epoch 1/15
 - 32s - loss: 0.9996 - acc: 0.9835 - val_loss: 0.0850 - val_acc: 0.9846
Epoch 2/15
 - 32s - loss: 2.2797 - acc: 0.9889 - val_loss: 0.0929 - val_acc: 0.9870
Epoch 3/15
 - 32s - loss: 1.0242 - acc: 0.9893 - val_loss: 0.1015 - val_acc: 0.9883
Epoch 4/15
 - 32s - loss: 0.8224 - acc: 0.9895 - val_loss: 0.1331 - val_acc: 0.9875
Epoch 5/15
 - 32s - loss: 0.1098 - acc: 0.9890 - val_loss: 0.1275 - val_acc: 0.9885
Epoch 6/15
 - 32s - loss: 0.1395 - acc: 0.9890 - val_loss: 0.1702 - val_acc: 0.9872
Epoch 7/15
 - 32s - loss: 0.0651 - acc: 0.9902 - val_loss: 0.2596 - val_acc: 0.9883
Epoch 8/15
 - 32s - loss: 0.1637 - acc: 0.9903 - val_loss: 0.2237 - val_acc: 0.9872
Epoch 9/15
 - 32s - loss: 0.0860 - acc: 0.9909 - val_loss: 0.2640 - val_acc: 0.9874
Epoch 10/15
 - 32s - loss: 0.0749 - acc: 0.9899 - val_loss: 0.3469 - val_acc: 0.9877
Epoch 11/15
 - 32s - loss: 0.0847 - acc: 0.9901 - val_loss: 0.4723 - val_acc: 0.9884
Epoch 12/15
 - 32s - loss: 2.6669 - acc: 0.9911 - val_loss: 0.3213 - val_acc: 0.9880
Epoch 13/15
 - 32s - loss: 2.6496 - acc: 0.9914 - val_loss: 0.3196 - val_acc: 0.9885
Epoch 14/15
 - 32s - loss: 2.6620 - acc: 0.9915 - val_loss: 0.2848 - val_acc: 0.9837
Epoch 15/15
 - 32s - loss: 2.6388 - acc: 0.9910 - val_loss: 0.3405 - val_acc: 0.9887
# Training time = 0:09:39.464564
# F-Score(Ordinary) = 0.428, Recall: 0.357, Precision: 0.535
# F-Score(lvc) = 0.472, Recall: 0.913, Precision: 0.318
# F-Score(ireflv) = 0.759, Recall: 0.872, Precision: 0.672
# F-Score(id) = 0.313, Recall: 0.214, Precision: 0.585
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 4, 125)       1836625     input_7[0][0]                    
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 4, 56)        13160       input_8[0][0]                    
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 500)          0           embedding_7[0][0]                
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 224)          0           embedding_8[0][0]                
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 724)          0           flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 256)          185600      concatenate_4[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 256)          0           dense_7[0][0]                    
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 8)            2056        dropout_4[0][0]                  
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 712548 samples, validate on 79173 samples
Epoch 1/15
 - 32s - loss: 1.4473 - acc: 0.9841 - val_loss: 0.0692 - val_acc: 0.9870
Epoch 2/15
 - 32s - loss: 1.0733 - acc: 0.9879 - val_loss: 0.0861 - val_acc: 0.9884
Epoch 3/15
 - 32s - loss: 2.6133 - acc: 0.9890 - val_loss: 0.1076 - val_acc: 0.9872
Epoch 4/15
 - 32s - loss: 2.5057 - acc: 0.9886 - val_loss: 0.1274 - val_acc: 0.9883
Epoch 5/15
 - 32s - loss: 1.2998 - acc: 0.9891 - val_loss: 0.1968 - val_acc: 0.9883
Epoch 6/15
 - 32s - loss: 0.0832 - acc: 0.9889 - val_loss: 0.2810 - val_acc: 0.9878
Epoch 7/15
 - 32s - loss: 0.5923 - acc: 0.9890 - val_loss: 0.2794 - val_acc: 0.9882
Epoch 8/15
 - 32s - loss: 1.1873 - acc: 0.9900 - val_loss: 0.3052 - val_acc: 0.9881
Epoch 9/15
 - 32s - loss: 0.0687 - acc: 0.9904 - val_loss: 0.3559 - val_acc: 0.9889
Epoch 10/15
 - 32s - loss: 0.0834 - acc: 0.9901 - val_loss: 0.4915 - val_acc: 0.9875
Epoch 11/15
 - 32s - loss: 0.8639 - acc: 0.9903 - val_loss: 0.2885 - val_acc: 0.9884
Epoch 12/15
 - 32s - loss: 0.0870 - acc: 0.9906 - val_loss: 0.8015 - val_acc: 0.9878
Epoch 13/15
 - 32s - loss: 0.0888 - acc: 0.9912 - val_loss: 0.2956 - val_acc: 0.9890
Epoch 14/15
 - 32s - loss: 2.6633 - acc: 0.9912 - val_loss: 0.3406 - val_acc: 0.9879
Epoch 15/15
 - 32s - loss: 2.6586 - acc: 0.9912 - val_loss: 0.3286 - val_acc: 0.9888
# Training time = 0:09:37.467391
# F-Score(Ordinary) = 0.57, Recall: 0.553, Precision: 0.588
# F-Score(lvc) = 0.445, Recall: 0.595, Precision: 0.356
# F-Score(ireflv) = 0.836, Recall: 0.882, Precision: 0.795
# F-Score(id) = 0.483, Recall: 0.404, Precision: 0.601
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_10 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 4, 125)       1836625     input_9[0][0]                    
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 4, 56)        13160       input_10[0][0]                   
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 500)          0           embedding_9[0][0]                
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 224)          0           embedding_10[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 724)          0           flatten_9[0][0]                  
                                                                 flatten_10[0][0]                 
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 256)          185600      concatenate_5[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 256)          0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 8)            2056        dropout_5[0][0]                  
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 712548 samples, validate on 79173 samples
Epoch 1/15
 - 32s - loss: 1.4446 - acc: 0.9839 - val_loss: 0.0870 - val_acc: 0.9842
Epoch 2/15
 - 32s - loss: 0.9828 - acc: 0.9882 - val_loss: 0.0975 - val_acc: 0.9881
Epoch 3/15
 - 32s - loss: 1.7386 - acc: 0.9897 - val_loss: 0.1259 - val_acc: 0.9881
Epoch 4/15
 - 32s - loss: 0.5140 - acc: 0.9895 - val_loss: 0.1505 - val_acc: 0.9864
Epoch 5/15
 - 32s - loss: 0.1012 - acc: 0.9885 - val_loss: 0.1934 - val_acc: 0.9879
Epoch 6/15
 - 32s - loss: 0.1284 - acc: 0.9885 - val_loss: 0.3318 - val_acc: 0.9868
Epoch 7/15
 - 32s - loss: 0.0840 - acc: 0.9885 - val_loss: 0.1967 - val_acc: 0.9879
Epoch 8/15
 - 32s - loss: 0.0701 - acc: 0.9894 - val_loss: 0.4527 - val_acc: 0.9667
Epoch 9/15
 - 32s - loss: 0.0911 - acc: 0.9897 - val_loss: 0.2967 - val_acc: 0.9852
Epoch 10/15
 - 32s - loss: 2.6382 - acc: 0.9902 - val_loss: 0.3499 - val_acc: 0.9883
Epoch 11/15
 - 32s - loss: 2.6429 - acc: 0.9909 - val_loss: 0.3894 - val_acc: 0.9879
Epoch 12/15
 - 32s - loss: 2.6212 - acc: 0.9904 - val_loss: 0.3152 - val_acc: 0.9883
Epoch 13/15
 - 32s - loss: 2.6420 - acc: 0.9906 - val_loss: 0.3360 - val_acc: 0.9887
Epoch 14/15
 - 32s - loss: 2.6367 - acc: 0.9901 - val_loss: 0.3540 - val_acc: 0.9877
Epoch 15/15
 - 32s - loss: 2.6553 - acc: 0.9907 - val_loss: 0.4210 - val_acc: 0.9875
# Training time = 0:09:38.619051
# F-Score(Ordinary) = 0.508, Recall: 0.432, Precision: 0.615
# F-Score(lvc) = 0.415, Recall: 0.656, Precision: 0.303
# F-Score(ireflv) = 0.834, Recall: 0.788, Precision: 0.885
# F-Score(id) = 0.384, Recall: 0.276, Precision: 0.627
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 4, 125)       1836625     input_11[0][0]                   
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 4, 56)        13160       input_12[0][0]                   
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 500)          0           embedding_11[0][0]               
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 224)          0           embedding_12[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 724)          0           flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 256)          185600      concatenate_6[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 256)          0           dense_11[0][0]                   
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 8)            2056        dropout_6[0][0]                  
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 712548 samples, validate on 79173 samples
Epoch 1/15
 - 32s - loss: 1.7862 - acc: 0.9842 - val_loss: 0.0692 - val_acc: 0.9866
Epoch 2/15
 - 32s - loss: 1.4285 - acc: 0.9881 - val_loss: 0.0977 - val_acc: 0.9879
Epoch 3/15
 - 32s - loss: 1.0401 - acc: 0.9878 - val_loss: 0.1386 - val_acc: 0.9881
Epoch 4/15
 - 32s - loss: 0.2719 - acc: 0.9896 - val_loss: 0.1466 - val_acc: 0.9872
Epoch 5/15
 - 32s - loss: 0.0744 - acc: 0.9889 - val_loss: 0.1955 - val_acc: 0.9869
Epoch 6/15
 - 32s - loss: 0.9872 - acc: 0.9895 - val_loss: 0.1941 - val_acc: 0.9852
Epoch 7/15
 - 32s - loss: 0.0889 - acc: 0.9897 - val_loss: 0.2502 - val_acc: 0.9890
Epoch 8/15
 - 32s - loss: 2.2900 - acc: 0.9898 - val_loss: 0.2702 - val_acc: 0.9881
Epoch 9/15
 - 32s - loss: 0.0759 - acc: 0.9907 - val_loss: 0.3575 - val_acc: 0.9882
Epoch 10/15
 - 32s - loss: 0.9143 - acc: 0.9908 - val_loss: 0.3707 - val_acc: 0.9886
Epoch 11/15
 - 32s - loss: 0.0705 - acc: 0.9905 - val_loss: 0.3488 - val_acc: 0.9884
Epoch 12/15
 - 32s - loss: 0.0840 - acc: 0.9905 - val_loss: 0.3016 - val_acc: 0.9876
Epoch 13/15
 - 32s - loss: 2.6314 - acc: 0.9905 - val_loss: 0.3087 - val_acc: 0.9880
Epoch 14/15
 - 32s - loss: 2.6445 - acc: 0.9909 - val_loss: 0.2963 - val_acc: 0.9881
Epoch 15/15
 - 32s - loss: 2.6407 - acc: 0.9906 - val_loss: 0.3530 - val_acc: 0.9868
# Training time = 0:09:39.123986
# F-Score(Ordinary) = 0.068, Recall: 0.036, Precision: 0.597
# F-Score(lvc) = 0.453, Recall: 0.741, Precision: 0.326
# F-Score(ireflv) = 0.757, Recall: 0.736, Precision: 0.779
# F-Score(id) = 0.032, Recall: 0.016, Precision: 0.617
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_14 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 4, 125)       1836625     input_13[0][0]                   
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 4, 56)        13160       input_14[0][0]                   
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 500)          0           embedding_13[0][0]               
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 224)          0           embedding_14[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 724)          0           flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 256)          185600      concatenate_7[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 256)          0           dense_13[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 8)            2056        dropout_7[0][0]                  
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 712548 samples, validate on 79173 samples
Epoch 1/15
 - 33s - loss: 1.3304 - acc: 0.9835 - val_loss: 0.0689 - val_acc: 0.9871
Epoch 2/15
 - 33s - loss: 1.8048 - acc: 0.9878 - val_loss: 0.0895 - val_acc: 0.9867
Epoch 3/15
 - 32s - loss: 2.6183 - acc: 0.9884 - val_loss: 0.1311 - val_acc: 0.9855
Epoch 4/15
 - 32s - loss: 2.6424 - acc: 0.9882 - val_loss: 0.2061 - val_acc: 0.9886
Epoch 5/15
 - 32s - loss: 2.6280 - acc: 0.9887 - val_loss: 0.2312 - val_acc: 0.9881
Epoch 6/15
 - 32s - loss: 2.6409 - acc: 0.9877 - val_loss: 0.2810 - val_acc: 0.9869
Epoch 7/15
 - 32s - loss: 2.6312 - acc: 0.9892 - val_loss: 0.2615 - val_acc: 0.9862
Epoch 8/15
 - 32s - loss: 2.6207 - acc: 0.9896 - val_loss: 0.3121 - val_acc: 0.9882
Epoch 9/15
 - 32s - loss: 2.6421 - acc: 0.9900 - val_loss: 0.2607 - val_acc: 0.9875
Epoch 10/15
 - 32s - loss: 2.6408 - acc: 0.9898 - val_loss: 0.2691 - val_acc: 0.9879
Epoch 11/15
 - 32s - loss: 2.6225 - acc: 0.9903 - val_loss: 0.3081 - val_acc: 0.9882
Epoch 12/15
 - 32s - loss: 2.6288 - acc: 0.9907 - val_loss: 0.2881 - val_acc: 0.9873
Epoch 13/15
 - 32s - loss: 2.6625 - acc: 0.9912 - val_loss: 0.3478 - val_acc: 0.9886
Epoch 14/15
 - 32s - loss: 2.6388 - acc: 0.9910 - val_loss: 0.2990 - val_acc: 0.9884
Epoch 15/15
 - 32s - loss: 2.6369 - acc: 0.9905 - val_loss: 0.2846 - val_acc: 0.9881
# Training time = 0:09:38.445894
# F-Score(Ordinary) = 0.318, Recall: 0.222, Precision: 0.559
# F-Score(lvc) = 0.376, Recall: 0.842, Precision: 0.242
# F-Score(ireflv) = 0.802, Recall: 0.867, Precision: 0.746
# F-Score(id) = 0.211, Recall: 0.126, Precision: 0.642
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_15 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_16 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_15 (Embedding)        (None, 4, 125)       1836625     input_15[0][0]                   
__________________________________________________________________________________________________
embedding_16 (Embedding)        (None, 4, 56)        13160       input_16[0][0]                   
__________________________________________________________________________________________________
flatten_15 (Flatten)            (None, 500)          0           embedding_15[0][0]               
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 224)          0           embedding_16[0][0]               
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 724)          0           flatten_15[0][0]                 
                                                                 flatten_16[0][0]                 
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 256)          185600      concatenate_8[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 256)          0           dense_15[0][0]                   
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 8)            2056        dropout_8[0][0]                  
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 712548 samples, validate on 79173 samples
Epoch 1/15
 - 33s - loss: 1.6528 - acc: 0.9842 - val_loss: 0.0683 - val_acc: 0.9866
Epoch 2/15
 - 33s - loss: 1.5399 - acc: 0.9886 - val_loss: 0.0932 - val_acc: 0.9855
Epoch 3/15
 - 33s - loss: 2.5603 - acc: 0.9891 - val_loss: 0.1079 - val_acc: 0.9801
Epoch 4/15
 - 32s - loss: 0.5738 - acc: 0.9889 - val_loss: 0.1521 - val_acc: 0.9877
Epoch 5/15
 - 32s - loss: 0.0827 - acc: 0.9888 - val_loss: 0.1972 - val_acc: 0.9875
Epoch 6/15
 - 32s - loss: 0.0788 - acc: 0.9893 - val_loss: 0.2176 - val_acc: 0.9880
Epoch 7/15
 - 32s - loss: 0.0746 - acc: 0.9901 - val_loss: 0.2524 - val_acc: 0.9885
Epoch 8/15
 - 32s - loss: 0.0720 - acc: 0.9902 - val_loss: 0.2889 - val_acc: 0.9885
Epoch 9/15
 - 32s - loss: 0.0839 - acc: 0.9900 - val_loss: 0.4182 - val_acc: 0.9887
Epoch 10/15
 - 32s - loss: 0.0688 - acc: 0.9899 - val_loss: 0.3711 - val_acc: 0.9870
Epoch 11/15
 - 32s - loss: 0.0760 - acc: 0.9900 - val_loss: 0.3001 - val_acc: 0.9877
Epoch 12/15
 - 32s - loss: 2.6269 - acc: 0.9902 - val_loss: 0.3228 - val_acc: 0.9877
Epoch 13/15
 - 32s - loss: 2.6469 - acc: 0.9911 - val_loss: 0.3465 - val_acc: 0.9886
Epoch 14/15
 - 32s - loss: 2.6461 - acc: 0.9913 - val_loss: 0.3091 - val_acc: 0.9885
Epoch 15/15
 - 32s - loss: 2.6607 - acc: 0.9912 - val_loss: 0.3329 - val_acc: 0.9884
# Training time = 0:09:38.216910
# F-Score(Ordinary) = 0.306, Recall: 0.203, Precision: 0.629
# F-Score(lvc) = 0.107, Recall: 0.06, Precision: 0.47
# F-Score(ireflv) = 0.762, Recall: 0.706, Precision: 0.828
# F-Score(id) = 0.542, Recall: 0.516, Precision: 0.57
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_17 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_18 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_17 (Embedding)        (None, 4, 125)       1836625     input_17[0][0]                   
__________________________________________________________________________________________________
embedding_18 (Embedding)        (None, 4, 56)        13160       input_18[0][0]                   
__________________________________________________________________________________________________
flatten_17 (Flatten)            (None, 500)          0           embedding_17[0][0]               
__________________________________________________________________________________________________
flatten_18 (Flatten)            (None, 224)          0           embedding_18[0][0]               
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 724)          0           flatten_17[0][0]                 
                                                                 flatten_18[0][0]                 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 256)          185600      concatenate_9[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 256)          0           dense_17[0][0]                   
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 8)            2056        dropout_9[0][0]                  
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 712548 samples, validate on 79173 samples
Epoch 1/15
 - 33s - loss: 1.7950 - acc: 0.9824 - val_loss: 0.0831 - val_acc: 0.9875
Epoch 2/15
 - 33s - loss: 2.2766 - acc: 0.9886 - val_loss: 0.0865 - val_acc: 0.9861
Epoch 3/15
 - 33s - loss: 0.9198 - acc: 0.9889 - val_loss: 0.1014 - val_acc: 0.9859
Epoch 4/15
 - 32s - loss: 0.7608 - acc: 0.9894 - val_loss: 0.1511 - val_acc: 0.9879
Epoch 5/15
 - 32s - loss: 1.4118 - acc: 0.9891 - val_loss: 0.1800 - val_acc: 0.9882
Epoch 6/15
 - 32s - loss: 0.3729 - acc: 0.9893 - val_loss: 0.2143 - val_acc: 0.9887
Epoch 7/15
 - 32s - loss: 0.5693 - acc: 0.9903 - val_loss: 0.2215 - val_acc: 0.9886
Epoch 8/15
 - 32s - loss: 0.0687 - acc: 0.9897 - val_loss: 0.2180 - val_acc: 0.9875
Epoch 9/15
 - 32s - loss: 2.6211 - acc: 0.9899 - val_loss: 0.3692 - val_acc: 0.9880
Epoch 10/15
 - 32s - loss: 2.6188 - acc: 0.9901 - val_loss: 0.3754 - val_acc: 0.9873
Epoch 11/15
 - 32s - loss: 2.6265 - acc: 0.9903 - val_loss: 0.3484 - val_acc: 0.9880
Epoch 12/15
 - 32s - loss: 2.6242 - acc: 0.9909 - val_loss: 0.3470 - val_acc: 0.9873
Epoch 13/15
 - 32s - loss: 2.6289 - acc: 0.9906 - val_loss: 0.3215 - val_acc: 0.9875
Epoch 14/15
 - 32s - loss: 2.6167 - acc: 0.9904 - val_loss: 0.3805 - val_acc: 0.9882
Epoch 15/15
 - 32s - loss: 2.6317 - acc: 0.9906 - val_loss: 0.3762 - val_acc: 0.9872
# Training time = 0:09:39.676196
# F-Score(Ordinary) = 0.369, Recall: 0.26, Precision: 0.635
# F-Score(lvc) = 0.449, Recall: 0.688, Precision: 0.333
# F-Score(ireflv) = 0.816, Recall: 0.782, Precision: 0.852
# F-Score(id) = 0.243, Recall: 0.147, Precision: 0.684
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_19 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_20 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_19 (Embedding)        (None, 4, 125)       1836625     input_19[0][0]                   
__________________________________________________________________________________________________
embedding_20 (Embedding)        (None, 4, 56)        13160       input_20[0][0]                   
__________________________________________________________________________________________________
flatten_19 (Flatten)            (None, 500)          0           embedding_19[0][0]               
__________________________________________________________________________________________________
flatten_20 (Flatten)            (None, 224)          0           embedding_20[0][0]               
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 724)          0           flatten_19[0][0]                 
                                                                 flatten_20[0][0]                 
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 256)          185600      concatenate_10[0][0]             
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 256)          0           dense_19[0][0]                   
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 8)            2056        dropout_10[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 712548 samples, validate on 79173 samples
Epoch 1/15
 - 33s - loss: 2.0516 - acc: 0.9841 - val_loss: 0.0791 - val_acc: 0.9851
Epoch 2/15
 - 33s - loss: 1.4106 - acc: 0.9890 - val_loss: 0.0938 - val_acc: 0.9870
Epoch 3/15
 - 32s - loss: 2.0306 - acc: 0.9894 - val_loss: 0.1309 - val_acc: 0.9868
Epoch 4/15
 - 32s - loss: 1.1383 - acc: 0.9894 - val_loss: 0.1278 - val_acc: 0.9878
Epoch 5/15
 - 32s - loss: 1.7382 - acc: 0.9889 - val_loss: 0.2278 - val_acc: 0.9864
Epoch 6/15
 - 34s - loss: 1.7649 - acc: 0.9892 - val_loss: 0.1871 - val_acc: 0.9881
Epoch 7/15
 - 34s - loss: 0.9743 - acc: 0.9897 - val_loss: 0.1946 - val_acc: 0.9889
Epoch 8/15
 - 34s - loss: 2.2667 - acc: 0.9901 - val_loss: 0.1845 - val_acc: 0.9878
Epoch 9/15
 - 34s - loss: 0.3499 - acc: 0.9900 - val_loss: 0.2395 - val_acc: 0.9886
Epoch 10/15
 - 34s - loss: 2.6335 - acc: 0.9900 - val_loss: 0.2825 - val_acc: 0.9889
Epoch 11/15
 - 34s - loss: 2.6504 - acc: 0.9914 - val_loss: 0.2504 - val_acc: 0.9886
Epoch 12/15
 - 34s - loss: 2.6601 - acc: 0.9913 - val_loss: 0.2761 - val_acc: 0.9871
Epoch 13/15
 - 34s - loss: 2.6537 - acc: 0.9911 - val_loss: 0.4053 - val_acc: 0.9885
Epoch 14/15
 - 34s - loss: 2.6486 - acc: 0.9908 - val_loss: 0.2842 - val_acc: 0.9881
Epoch 15/15
 - 32s - loss: 2.6423 - acc: 0.9912 - val_loss: 0.4184 - val_acc: 0.9883
# Training time = 0:09:55.222999
# F-Score(Ordinary) = 0.158, Recall: 0.093, Precision: 0.508
# F-Score(lvc) = 0.166, Recall: 0.114, Precision: 0.311
# F-Score(ireflv) = 0.745, Recall: 0.878, Precision: 0.648
# F-Score(id) = 0.095, Recall: 0.052, Precision: 0.534
********************
