INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 4, 125)       1836625     input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 4, 56)        13160       input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 500)          0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 224)          0           embedding_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 724)          0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 256)          185600      concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 8)            2056        dropout_1[0][0]                  
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1028 - acc: 0.9622 - val_loss: 0.0727 - val_acc: 0.9675
Epoch 2/15
 - 5s - loss: 0.0527 - acc: 0.9720 - val_loss: 0.0724 - val_acc: 0.9666
Epoch 3/15
 - 5s - loss: 0.0448 - acc: 0.9744 - val_loss: 0.0757 - val_acc: 0.9672
Epoch 00003: early stopping
# Training time = 0:02:02.317852
# F-Score(Ordinary) = 0.534, Recall: 0.739, Precision: 0.418
# F-Score(ireflv) = 0.61, Recall: 0.714, Precision: 0.533
# F-Score(id) = 0.689, Recall: 0.758, Precision: 0.632
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 4, 125)       1836625     input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 4, 56)        13160       input_4[0][0]                    
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 500)          0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 224)          0           embedding_4[0][0]                
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 724)          0           flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 256)          185600      concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 256)          0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 8)            2056        dropout_2[0][0]                  
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1040 - acc: 0.9623 - val_loss: 0.0695 - val_acc: 0.9676
Epoch 2/15
 - 5s - loss: 0.0521 - acc: 0.9724 - val_loss: 0.0711 - val_acc: 0.9674
Epoch 3/15
 - 5s - loss: 0.0447 - acc: 0.9740 - val_loss: 0.0755 - val_acc: 0.9664
Epoch 00003: early stopping
# Training time = 0:00:45.938824
# F-Score(Ordinary) = 0.573, Recall: 0.516, Precision: 0.644
# F-Score(lvc) = 0.465, Recall: 0.367, Precision: 0.636
# F-Score(ireflv) = 0.739, Recall: 0.642, Precision: 0.869
# F-Score(id) = 0.487, Recall: 0.53, Precision: 0.451
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 4, 125)       1836625     input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 4, 56)        13160       input_6[0][0]                    
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 500)          0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 224)          0           embedding_6[0][0]                
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 724)          0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 256)          185600      concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 256)          0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 8)            2056        dropout_3[0][0]                  
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1044 - acc: 0.9627 - val_loss: 0.0720 - val_acc: 0.9673
Epoch 2/15
 - 5s - loss: 0.0520 - acc: 0.9724 - val_loss: 0.0714 - val_acc: 0.9679
Epoch 3/15
 - 5s - loss: 0.0445 - acc: 0.9743 - val_loss: 0.0752 - val_acc: 0.9674
Epoch 00003: early stopping
# Training time = 0:00:45.963158
# F-Score(Ordinary) = 0.658, Recall: 0.732, Precision: 0.597
# F-Score(lvc) = 0.371, Recall: 0.397, Precision: 0.348
# F-Score(ireflv) = 0.785, Recall: 0.809, Precision: 0.762
# F-Score(id) = 0.734, Recall: 0.896, Precision: 0.622
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 4, 125)       1836625     input_7[0][0]                    
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 4, 56)        13160       input_8[0][0]                    
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 500)          0           embedding_7[0][0]                
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 224)          0           embedding_8[0][0]                
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 724)          0           flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 256)          185600      concatenate_4[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 256)          0           dense_7[0][0]                    
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 8)            2056        dropout_4[0][0]                  
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1052 - acc: 0.9624 - val_loss: 0.0718 - val_acc: 0.9673
Epoch 2/15
 - 5s - loss: 0.0519 - acc: 0.9725 - val_loss: 0.0713 - val_acc: 0.9683
Epoch 3/15
 - 5s - loss: 0.0444 - acc: 0.9746 - val_loss: 0.0732 - val_acc: 0.9682
Epoch 00003: early stopping
# Training time = 0:00:46.470720
# F-Score(Ordinary) = 0.429, Recall: 0.524, Precision: 0.362
# F-Score(lvc) = 0.317, Recall: 0.296, Precision: 0.341
# F-Score(ireflv) = 0.798, Recall: 0.786, Precision: 0.811
# F-Score(id) = 0.107, Recall: 0.387, Precision: 0.062
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_10 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 4, 125)       1836625     input_9[0][0]                    
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 4, 56)        13160       input_10[0][0]                   
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 500)          0           embedding_9[0][0]                
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 224)          0           embedding_10[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 724)          0           flatten_9[0][0]                  
                                                                 flatten_10[0][0]                 
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 256)          185600      concatenate_5[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 256)          0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 8)            2056        dropout_5[0][0]                  
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1033 - acc: 0.9600 - val_loss: 0.0713 - val_acc: 0.9678
Epoch 2/15
 - 5s - loss: 0.0519 - acc: 0.9724 - val_loss: 0.0739 - val_acc: 0.9687
Epoch 3/15
 - 5s - loss: 0.0443 - acc: 0.9745 - val_loss: 0.0771 - val_acc: 0.9678
Epoch 00003: early stopping
# Training time = 0:00:46.443628
# F-Score(Ordinary) = 0.279, Recall: 0.833, Precision: 0.168
# F-Score(ireflv) = 0.711, Recall: 0.843, Precision: 0.615
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 4, 125)       1836625     input_11[0][0]                   
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 4, 56)        13160       input_12[0][0]                   
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 500)          0           embedding_11[0][0]               
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 224)          0           embedding_12[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 724)          0           flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 256)          185600      concatenate_6[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 256)          0           dense_11[0][0]                   
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 8)            2056        dropout_6[0][0]                  
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1028 - acc: 0.9606 - val_loss: 0.0720 - val_acc: 0.9678
Epoch 2/15
 - 5s - loss: 0.0520 - acc: 0.9725 - val_loss: 0.0712 - val_acc: 0.9676
Epoch 3/15
 - 5s - loss: 0.0445 - acc: 0.9748 - val_loss: 0.0728 - val_acc: 0.9681
Epoch 00003: early stopping
# Training time = 0:00:46.461638
# F-Score(Ordinary) = 0.239, Recall: 0.527, Precision: 0.154
# F-Score(lvc) = 0.481, Recall: 0.485, Precision: 0.477
# F-Score(id) = 0.01, Recall: 1.0, Precision: 0.005
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_14 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 4, 125)       1836625     input_13[0][0]                   
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 4, 56)        13160       input_14[0][0]                   
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 500)          0           embedding_13[0][0]               
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 224)          0           embedding_14[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 724)          0           flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 256)          185600      concatenate_7[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 256)          0           dense_13[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 8)            2056        dropout_7[0][0]                  
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1033 - acc: 0.9622 - val_loss: 0.0712 - val_acc: 0.9671
Epoch 2/15
 - 5s - loss: 0.0521 - acc: 0.9723 - val_loss: 0.0742 - val_acc: 0.9663
Epoch 3/15
 - 5s - loss: 0.0446 - acc: 0.9747 - val_loss: 0.0751 - val_acc: 0.9684
Epoch 00003: early stopping
# Training time = 0:00:46.565142
# F-Score(Ordinary) = 0.489, Recall: 0.716, Precision: 0.371
# F-Score(ireflv) = 0.741, Recall: 0.629, Precision: 0.902
# F-Score(id) = 0.44, Recall: 0.965, Precision: 0.285
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_15 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_16 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_15 (Embedding)        (None, 4, 125)       1836625     input_15[0][0]                   
__________________________________________________________________________________________________
embedding_16 (Embedding)        (None, 4, 56)        13160       input_16[0][0]                   
__________________________________________________________________________________________________
flatten_15 (Flatten)            (None, 500)          0           embedding_15[0][0]               
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 224)          0           embedding_16[0][0]               
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 724)          0           flatten_15[0][0]                 
                                                                 flatten_16[0][0]                 
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 256)          185600      concatenate_8[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 256)          0           dense_15[0][0]                   
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 8)            2056        dropout_8[0][0]                  
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1037 - acc: 0.9630 - val_loss: 0.0727 - val_acc: 0.9673
Epoch 2/15
 - 5s - loss: 0.0521 - acc: 0.9727 - val_loss: 0.0732 - val_acc: 0.9675
Epoch 3/15
 - 5s - loss: 0.0448 - acc: 0.9746 - val_loss: 0.0742 - val_acc: 0.9687
Epoch 00003: early stopping
# Training time = 0:00:47.164747
# F-Score(Ordinary) = 0, Recall: 0, Precision: 0
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_17 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_18 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_17 (Embedding)        (None, 4, 125)       1836625     input_17[0][0]                   
__________________________________________________________________________________________________
embedding_18 (Embedding)        (None, 4, 56)        13160       input_18[0][0]                   
__________________________________________________________________________________________________
flatten_17 (Flatten)            (None, 500)          0           embedding_17[0][0]               
__________________________________________________________________________________________________
flatten_18 (Flatten)            (None, 224)          0           embedding_18[0][0]               
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 724)          0           flatten_17[0][0]                 
                                                                 flatten_18[0][0]                 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 256)          185600      concatenate_9[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 256)          0           dense_17[0][0]                   
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 8)            2056        dropout_9[0][0]                  
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1062 - acc: 0.9588 - val_loss: 0.0733 - val_acc: 0.9670
Epoch 2/15
 - 5s - loss: 0.0522 - acc: 0.9728 - val_loss: 0.0698 - val_acc: 0.9686
Epoch 3/15
 - 5s - loss: 0.0450 - acc: 0.9745 - val_loss: 0.0734 - val_acc: 0.9680
Epoch 00003: early stopping
# Training time = 0:00:49.745141
# F-Score(Ordinary) = 0.415, Recall: 0.633, Precision: 0.309
# F-Score(ireflv) = 0.724, Recall: 0.609, Precision: 0.893
# F-Score(id) = 0.242, Recall: 0.737, Precision: 0.145
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_19 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_20 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_19 (Embedding)        (None, 4, 125)       1836625     input_19[0][0]                   
__________________________________________________________________________________________________
embedding_20 (Embedding)        (None, 4, 56)        13160       input_20[0][0]                   
__________________________________________________________________________________________________
flatten_19 (Flatten)            (None, 500)          0           embedding_19[0][0]               
__________________________________________________________________________________________________
flatten_20 (Flatten)            (None, 224)          0           embedding_20[0][0]               
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 724)          0           flatten_19[0][0]                 
                                                                 flatten_20[0][0]                 
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 256)          185600      concatenate_10[0][0]             
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 256)          0           dense_19[0][0]                   
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 8)            2056        dropout_10[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1036 - acc: 0.9621 - val_loss: 0.0713 - val_acc: 0.9672
Epoch 2/15
 - 5s - loss: 0.0518 - acc: 0.9721 - val_loss: 0.0697 - val_acc: 0.9686
Epoch 3/15
 - 5s - loss: 0.0443 - acc: 0.9748 - val_loss: 0.0720 - val_acc: 0.9684
Epoch 00003: early stopping
# Training time = 0:00:46.095117
# F-Score(Ordinary) = 0.365, Recall: 0.625, Precision: 0.257
# F-Score(lvc) = 0.014, Recall: 0.167, Precision: 0.008
# F-Score(ireflv) = 0.745, Recall: 0.643, Precision: 0.885
# F-Score(id) = 0.049, Recall: 0.5, Precision: 0.026
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_21 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_22 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_21 (Embedding)        (None, 4, 125)       1836625     input_21[0][0]                   
__________________________________________________________________________________________________
embedding_22 (Embedding)        (None, 4, 56)        13160       input_22[0][0]                   
__________________________________________________________________________________________________
flatten_21 (Flatten)            (None, 500)          0           embedding_21[0][0]               
__________________________________________________________________________________________________
flatten_22 (Flatten)            (None, 224)          0           embedding_22[0][0]               
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 724)          0           flatten_21[0][0]                 
                                                                 flatten_22[0][0]                 
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 256)          185600      concatenate_11[0][0]             
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 256)          0           dense_21[0][0]                   
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 8)            2056        dropout_11[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 4s - loss: 0.1031 - acc: 0.9627 - val_loss: 0.0747 - val_acc: 0.9662
Epoch 2/15
 - 4s - loss: 0.0525 - acc: 0.9722 - val_loss: 0.0697 - val_acc: 0.9687
Epoch 3/15
 - 4s - loss: 0.0446 - acc: 0.9743 - val_loss: 0.0744 - val_acc: 0.9676
Epoch 00003: early stopping
# Training time = 0:00:46.267292
# F-Score(Ordinary) = 0.607, Recall: 0.588, Precision: 0.626
# F-Score(lvc) = 0.35, Recall: 0.351, Precision: 0.348
# F-Score(ireflv) = 0.761, Recall: 0.667, Precision: 0.885
# F-Score(id) = 0.617, Recall: 0.634, Precision: 0.601
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_23 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_24 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_23 (Embedding)        (None, 4, 125)       1836625     input_23[0][0]                   
__________________________________________________________________________________________________
embedding_24 (Embedding)        (None, 4, 56)        13160       input_24[0][0]                   
__________________________________________________________________________________________________
flatten_23 (Flatten)            (None, 500)          0           embedding_23[0][0]               
__________________________________________________________________________________________________
flatten_24 (Flatten)            (None, 224)          0           embedding_24[0][0]               
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 724)          0           flatten_23[0][0]                 
                                                                 flatten_24[0][0]                 
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 256)          185600      concatenate_12[0][0]             
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 256)          0           dense_23[0][0]                   
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 8)            2056        dropout_12[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1035 - acc: 0.9601 - val_loss: 0.0710 - val_acc: 0.9682
Epoch 2/15
 - 5s - loss: 0.0522 - acc: 0.9723 - val_loss: 0.0740 - val_acc: 0.9664
Epoch 3/15
 - 4s - loss: 0.0453 - acc: 0.9737 - val_loss: 0.0762 - val_acc: 0.9672
Epoch 00003: early stopping
# Training time = 0:00:46.151639
# F-Score(Ordinary) = 0.607, Recall: 0.606, Precision: 0.609
# F-Score(lvc) = 0.535, Recall: 0.526, Precision: 0.545
# F-Score(ireflv) = 0.738, Recall: 0.65, Precision: 0.852
# F-Score(id) = 0.504, Recall: 0.572, Precision: 0.451
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_25 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_26 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_25 (Embedding)        (None, 4, 125)       1836625     input_25[0][0]                   
__________________________________________________________________________________________________
embedding_26 (Embedding)        (None, 4, 56)        13160       input_26[0][0]                   
__________________________________________________________________________________________________
flatten_25 (Flatten)            (None, 500)          0           embedding_25[0][0]               
__________________________________________________________________________________________________
flatten_26 (Flatten)            (None, 224)          0           embedding_26[0][0]               
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 724)          0           flatten_25[0][0]                 
                                                                 flatten_26[0][0]                 
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 256)          185600      concatenate_13[0][0]             
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 256)          0           dense_25[0][0]                   
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 8)            2056        dropout_13[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1052 - acc: 0.9596 - val_loss: 0.0741 - val_acc: 0.9676
Epoch 2/15
 - 5s - loss: 0.0524 - acc: 0.9721 - val_loss: 0.0722 - val_acc: 0.9680
Epoch 3/15
 - 5s - loss: 0.0446 - acc: 0.9750 - val_loss: 0.0729 - val_acc: 0.9671
Epoch 00003: early stopping
# Training time = 0:00:46.235480
# F-Score(Ordinary) = 0.601, Recall: 0.515, Precision: 0.72
# F-Score(lvc) = 0.41, Recall: 0.312, Precision: 0.598
# F-Score(ireflv) = 0.719, Recall: 0.613, Precision: 0.869
# F-Score(id) = 0.648, Recall: 0.638, Precision: 0.658
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_27 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_28 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_27 (Embedding)        (None, 4, 125)       1836625     input_27[0][0]                   
__________________________________________________________________________________________________
embedding_28 (Embedding)        (None, 4, 56)        13160       input_28[0][0]                   
__________________________________________________________________________________________________
flatten_27 (Flatten)            (None, 500)          0           embedding_27[0][0]               
__________________________________________________________________________________________________
flatten_28 (Flatten)            (None, 224)          0           embedding_28[0][0]               
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 724)          0           flatten_27[0][0]                 
                                                                 flatten_28[0][0]                 
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 256)          185600      concatenate_14[0][0]             
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 256)          0           dense_27[0][0]                   
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 8)            2056        dropout_14[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1048 - acc: 0.9620 - val_loss: 0.0725 - val_acc: 0.9669
Epoch 2/15
 - 4s - loss: 0.0523 - acc: 0.9725 - val_loss: 0.0720 - val_acc: 0.9683
Epoch 3/15
 - 4s - loss: 0.0447 - acc: 0.9746 - val_loss: 0.0805 - val_acc: 0.9675
Epoch 00003: early stopping
# Training time = 0:00:46.095568
# F-Score(Ordinary) = 0.548, Recall: 0.457, Precision: 0.685
# F-Score(lvc) = 0.598, Recall: 0.78, Precision: 0.485
# F-Score(ireflv) = 0.76, Recall: 0.661, Precision: 0.893
# F-Score(id) = 0.429, Recall: 0.313, Precision: 0.684
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_29 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_30 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_29 (Embedding)        (None, 4, 125)       1836625     input_29[0][0]                   
__________________________________________________________________________________________________
embedding_30 (Embedding)        (None, 4, 56)        13160       input_30[0][0]                   
__________________________________________________________________________________________________
flatten_29 (Flatten)            (None, 500)          0           embedding_29[0][0]               
__________________________________________________________________________________________________
flatten_30 (Flatten)            (None, 224)          0           embedding_30[0][0]               
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 724)          0           flatten_29[0][0]                 
                                                                 flatten_30[0][0]                 
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 256)          185600      concatenate_15[0][0]             
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 256)          0           dense_29[0][0]                   
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 8)            2056        dropout_15[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1033 - acc: 0.9630 - val_loss: 0.0682 - val_acc: 0.9680
Epoch 2/15
 - 5s - loss: 0.0519 - acc: 0.9722 - val_loss: 0.0706 - val_acc: 0.9676
Epoch 3/15
 - 5s - loss: 0.0447 - acc: 0.9742 - val_loss: 0.0766 - val_acc: 0.9679
Epoch 00003: early stopping
# Training time = 0:00:46.223610
# F-Score(Ordinary) = 0.482, Recall: 0.644, Precision: 0.385
# F-Score(lvc) = 0.314, Recall: 0.325, Precision: 0.303
# F-Score(ireflv) = 0.016, Recall: 0.25, Precision: 0.008
# F-Score(id) = 0.745, Recall: 0.886, Precision: 0.642
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_31 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_32 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_31 (Embedding)        (None, 4, 125)       1836625     input_31[0][0]                   
__________________________________________________________________________________________________
embedding_32 (Embedding)        (None, 4, 56)        13160       input_32[0][0]                   
__________________________________________________________________________________________________
flatten_31 (Flatten)            (None, 500)          0           embedding_31[0][0]               
__________________________________________________________________________________________________
flatten_32 (Flatten)            (None, 224)          0           embedding_32[0][0]               
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 724)          0           flatten_31[0][0]                 
                                                                 flatten_32[0][0]                 
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 256)          185600      concatenate_16[0][0]             
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 256)          0           dense_31[0][0]                   
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 8)            2056        dropout_16[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1029 - acc: 0.9630 - val_loss: 0.0704 - val_acc: 0.9682
Epoch 2/15
 - 4s - loss: 0.0521 - acc: 0.9726 - val_loss: 0.0727 - val_acc: 0.9674
Epoch 3/15
 - 4s - loss: 0.0447 - acc: 0.9744 - val_loss: 0.0796 - val_acc: 0.9686
Epoch 00003: early stopping
# Training time = 0:00:46.103805
# F-Score(Ordinary) = 0.379, Recall: 0.915, Precision: 0.239
# F-Score(id) = 0.69, Recall: 0.915, Precision: 0.554
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_33 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_34 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_33 (Embedding)        (None, 4, 125)       1836625     input_33[0][0]                   
__________________________________________________________________________________________________
embedding_34 (Embedding)        (None, 4, 56)        13160       input_34[0][0]                   
__________________________________________________________________________________________________
flatten_33 (Flatten)            (None, 500)          0           embedding_33[0][0]               
__________________________________________________________________________________________________
flatten_34 (Flatten)            (None, 224)          0           embedding_34[0][0]               
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 724)          0           flatten_33[0][0]                 
                                                                 flatten_34[0][0]                 
__________________________________________________________________________________________________
dense_33 (Dense)                (None, 256)          185600      concatenate_17[0][0]             
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 256)          0           dense_33[0][0]                   
__________________________________________________________________________________________________
dense_34 (Dense)                (None, 8)            2056        dropout_17[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1048 - acc: 0.9627 - val_loss: 0.0729 - val_acc: 0.9674
Epoch 2/15
 - 5s - loss: 0.0519 - acc: 0.9723 - val_loss: 0.0721 - val_acc: 0.9678
Epoch 3/15
 - 5s - loss: 0.0446 - acc: 0.9745 - val_loss: 0.0767 - val_acc: 0.9679
Epoch 00003: early stopping
# Training time = 0:00:46.266399
# F-Score(Ordinary) = 0.434, Recall: 0.621, Precision: 0.333
# F-Score(lvc) = 0.015, Recall: 0.5, Precision: 0.008
# F-Score(ireflv) = 0.611, Recall: 0.765, Precision: 0.508
# F-Score(id) = 0.491, Recall: 0.548, Precision: 0.446
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_35 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_36 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_35 (Embedding)        (None, 4, 125)       1836625     input_35[0][0]                   
__________________________________________________________________________________________________
embedding_36 (Embedding)        (None, 4, 56)        13160       input_36[0][0]                   
__________________________________________________________________________________________________
flatten_35 (Flatten)            (None, 500)          0           embedding_35[0][0]               
__________________________________________________________________________________________________
flatten_36 (Flatten)            (None, 224)          0           embedding_36[0][0]               
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 724)          0           flatten_35[0][0]                 
                                                                 flatten_36[0][0]                 
__________________________________________________________________________________________________
dense_35 (Dense)                (None, 256)          185600      concatenate_18[0][0]             
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, 256)          0           dense_35[0][0]                   
__________________________________________________________________________________________________
dense_36 (Dense)                (None, 8)            2056        dropout_18[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1050 - acc: 0.9625 - val_loss: 0.0760 - val_acc: 0.9674
Epoch 2/15
 - 5s - loss: 0.0526 - acc: 0.9720 - val_loss: 0.0721 - val_acc: 0.9683
Epoch 3/15
 - 5s - loss: 0.0446 - acc: 0.9745 - val_loss: 0.0788 - val_acc: 0.9678
Epoch 00003: early stopping
# Training time = 0:00:46.459003
# F-Score(Ordinary) = 0.291, Recall: 0.675, Precision: 0.186
# F-Score(ireflv) = 0.669, Recall: 0.667, Precision: 0.672
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_37 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_38 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_37 (Embedding)        (None, 4, 125)       1836625     input_37[0][0]                   
__________________________________________________________________________________________________
embedding_38 (Embedding)        (None, 4, 56)        13160       input_38[0][0]                   
__________________________________________________________________________________________________
flatten_37 (Flatten)            (None, 500)          0           embedding_37[0][0]               
__________________________________________________________________________________________________
flatten_38 (Flatten)            (None, 224)          0           embedding_38[0][0]               
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 724)          0           flatten_37[0][0]                 
                                                                 flatten_38[0][0]                 
__________________________________________________________________________________________________
dense_37 (Dense)                (None, 256)          185600      concatenate_19[0][0]             
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 256)          0           dense_37[0][0]                   
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 8)            2056        dropout_19[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 4s - loss: 0.1040 - acc: 0.9628 - val_loss: 0.0722 - val_acc: 0.9680
Epoch 2/15
 - 5s - loss: 0.0525 - acc: 0.9722 - val_loss: 0.0721 - val_acc: 0.9671
Epoch 3/15
 - 5s - loss: 0.0449 - acc: 0.9746 - val_loss: 0.0742 - val_acc: 0.9684
Epoch 00003: early stopping
# Training time = 0:00:46.365806
# F-Score(Ordinary) = 0.379, Recall: 0.804, Precision: 0.248
# F-Score(ireflv) = 0.045, Recall: 0.273, Precision: 0.025
# F-Score(id) = 0.675, Recall: 0.85, Precision: 0.56
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_39 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_40 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_39 (Embedding)        (None, 4, 125)       1836625     input_39[0][0]                   
__________________________________________________________________________________________________
embedding_40 (Embedding)        (None, 4, 56)        13160       input_40[0][0]                   
__________________________________________________________________________________________________
flatten_39 (Flatten)            (None, 500)          0           embedding_39[0][0]               
__________________________________________________________________________________________________
flatten_40 (Flatten)            (None, 224)          0           embedding_40[0][0]               
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 724)          0           flatten_39[0][0]                 
                                                                 flatten_40[0][0]                 
__________________________________________________________________________________________________
dense_39 (Dense)                (None, 256)          185600      concatenate_20[0][0]             
__________________________________________________________________________________________________
dropout_20 (Dropout)            (None, 256)          0           dense_39[0][0]                   
__________________________________________________________________________________________________
dense_40 (Dense)                (None, 8)            2056        dropout_20[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1045 - acc: 0.9627 - val_loss: 0.0726 - val_acc: 0.9676
Epoch 2/15
 - 5s - loss: 0.0527 - acc: 0.9716 - val_loss: 0.0753 - val_acc: 0.9672
Epoch 3/15
 - 5s - loss: 0.0447 - acc: 0.9745 - val_loss: 0.0776 - val_acc: 0.9684
Epoch 00003: early stopping
# Training time = 0:00:46.314134
# F-Score(Ordinary) = 0.551, Recall: 0.694, Precision: 0.456
# F-Score(ireflv) = 0.7, Recall: 0.586, Precision: 0.869
# F-Score(id) = 0.634, Recall: 0.858, Precision: 0.503
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_41 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_42 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_41 (Embedding)        (None, 4, 125)       1836625     input_41[0][0]                   
__________________________________________________________________________________________________
embedding_42 (Embedding)        (None, 4, 56)        13160       input_42[0][0]                   
__________________________________________________________________________________________________
flatten_41 (Flatten)            (None, 500)          0           embedding_41[0][0]               
__________________________________________________________________________________________________
flatten_42 (Flatten)            (None, 224)          0           embedding_42[0][0]               
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 724)          0           flatten_41[0][0]                 
                                                                 flatten_42[0][0]                 
__________________________________________________________________________________________________
dense_41 (Dense)                (None, 256)          185600      concatenate_21[0][0]             
__________________________________________________________________________________________________
dropout_21 (Dropout)            (None, 256)          0           dense_41[0][0]                   
__________________________________________________________________________________________________
dense_42 (Dense)                (None, 8)            2056        dropout_21[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1027 - acc: 0.9627 - val_loss: 0.0707 - val_acc: 0.9677
Epoch 2/15
 - 5s - loss: 0.0518 - acc: 0.9722 - val_loss: 0.0747 - val_acc: 0.9681
Epoch 3/15
 - 4s - loss: 0.0449 - acc: 0.9742 - val_loss: 0.0756 - val_acc: 0.9674
Epoch 00003: early stopping
# Training time = 0:00:46.047588
# F-Score(Ordinary) = 0.254, Recall: 0.605, Precision: 0.161
# F-Score(ireflv) = 0.584, Recall: 0.613, Precision: 0.557
# F-Score(id) = 0.03, Recall: 0.375, Precision: 0.016
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_43 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_44 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_43 (Embedding)        (None, 4, 125)       1836625     input_43[0][0]                   
__________________________________________________________________________________________________
embedding_44 (Embedding)        (None, 4, 56)        13160       input_44[0][0]                   
__________________________________________________________________________________________________
flatten_43 (Flatten)            (None, 500)          0           embedding_43[0][0]               
__________________________________________________________________________________________________
flatten_44 (Flatten)            (None, 224)          0           embedding_44[0][0]               
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 724)          0           flatten_43[0][0]                 
                                                                 flatten_44[0][0]                 
__________________________________________________________________________________________________
dense_43 (Dense)                (None, 256)          185600      concatenate_22[0][0]             
__________________________________________________________________________________________________
dropout_22 (Dropout)            (None, 256)          0           dense_43[0][0]                   
__________________________________________________________________________________________________
dense_44 (Dense)                (None, 8)            2056        dropout_22[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 4s - loss: 0.1041 - acc: 0.9606 - val_loss: 0.0684 - val_acc: 0.9680
Epoch 2/15
 - 5s - loss: 0.0520 - acc: 0.9728 - val_loss: 0.0740 - val_acc: 0.9673
Epoch 3/15
 - 5s - loss: 0.0443 - acc: 0.9750 - val_loss: 0.0733 - val_acc: 0.9688
Epoch 00003: early stopping
# Training time = 0:00:46.339108
# F-Score(Ordinary) = 0.288, Recall: 0.741, Precision: 0.179
# F-Score(lvc) = 0.323, Recall: 0.897, Precision: 0.197
# F-Score(ireflv) = 0.519, Recall: 0.762, Precision: 0.393
# F-Score(id) = 0.057, Recall: 0.375, Precision: 0.031
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_45 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_46 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_45 (Embedding)        (None, 4, 125)       1836625     input_45[0][0]                   
__________________________________________________________________________________________________
embedding_46 (Embedding)        (None, 4, 56)        13160       input_46[0][0]                   
__________________________________________________________________________________________________
flatten_45 (Flatten)            (None, 500)          0           embedding_45[0][0]               
__________________________________________________________________________________________________
flatten_46 (Flatten)            (None, 224)          0           embedding_46[0][0]               
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 724)          0           flatten_45[0][0]                 
                                                                 flatten_46[0][0]                 
__________________________________________________________________________________________________
dense_45 (Dense)                (None, 256)          185600      concatenate_23[0][0]             
__________________________________________________________________________________________________
dropout_23 (Dropout)            (None, 256)          0           dense_45[0][0]                   
__________________________________________________________________________________________________
dense_46 (Dense)                (None, 8)            2056        dropout_23[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1029 - acc: 0.9627 - val_loss: 0.0704 - val_acc: 0.9686
Epoch 2/15
 - 5s - loss: 0.0520 - acc: 0.9723 - val_loss: 0.0743 - val_acc: 0.9673
Epoch 3/15
 - 5s - loss: 0.0444 - acc: 0.9747 - val_loss: 0.0735 - val_acc: 0.9678
Epoch 00003: early stopping
# Training time = 0:00:49.484591
# F-Score(Ordinary) = 0.502, Recall: 0.587, Precision: 0.438
# F-Score(lvc) = 0.527, Recall: 0.481, Precision: 0.583
# F-Score(ireflv) = 0.742, Recall: 0.652, Precision: 0.861
# F-Score(id) = 0.029, Recall: 0.231, Precision: 0.016
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_47 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_48 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_47 (Embedding)        (None, 4, 125)       1836625     input_47[0][0]                   
__________________________________________________________________________________________________
embedding_48 (Embedding)        (None, 4, 56)        13160       input_48[0][0]                   
__________________________________________________________________________________________________
flatten_47 (Flatten)            (None, 500)          0           embedding_47[0][0]               
__________________________________________________________________________________________________
flatten_48 (Flatten)            (None, 224)          0           embedding_48[0][0]               
__________________________________________________________________________________________________
concatenate_24 (Concatenate)    (None, 724)          0           flatten_47[0][0]                 
                                                                 flatten_48[0][0]                 
__________________________________________________________________________________________________
dense_47 (Dense)                (None, 256)          185600      concatenate_24[0][0]             
__________________________________________________________________________________________________
dropout_24 (Dropout)            (None, 256)          0           dense_47[0][0]                   
__________________________________________________________________________________________________
dense_48 (Dense)                (None, 8)            2056        dropout_24[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1018 - acc: 0.9627 - val_loss: 0.0727 - val_acc: 0.9669
Epoch 2/15
 - 4s - loss: 0.0519 - acc: 0.9726 - val_loss: 0.0719 - val_acc: 0.9680
Epoch 3/15
 - 4s - loss: 0.0445 - acc: 0.9743 - val_loss: 0.0742 - val_acc: 0.9672
Epoch 00003: early stopping
# Training time = 0:00:46.545610
# F-Score(Ordinary) = 0.474, Recall: 0.547, Precision: 0.418
# F-Score(lvc) = 0.5, Recall: 0.467, Precision: 0.538
# F-Score(ireflv) = 0.693, Recall: 0.572, Precision: 0.877
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_49 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_50 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_49 (Embedding)        (None, 4, 125)       1836625     input_49[0][0]                   
__________________________________________________________________________________________________
embedding_50 (Embedding)        (None, 4, 56)        13160       input_50[0][0]                   
__________________________________________________________________________________________________
flatten_49 (Flatten)            (None, 500)          0           embedding_49[0][0]               
__________________________________________________________________________________________________
flatten_50 (Flatten)            (None, 224)          0           embedding_50[0][0]               
__________________________________________________________________________________________________
concatenate_25 (Concatenate)    (None, 724)          0           flatten_49[0][0]                 
                                                                 flatten_50[0][0]                 
__________________________________________________________________________________________________
dense_49 (Dense)                (None, 256)          185600      concatenate_25[0][0]             
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 256)          0           dense_49[0][0]                   
__________________________________________________________________________________________________
dense_50 (Dense)                (None, 8)            2056        dropout_25[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 4s - loss: 0.1024 - acc: 0.9634 - val_loss: 0.0699 - val_acc: 0.9683
Epoch 2/15
 - 4s - loss: 0.0517 - acc: 0.9721 - val_loss: 0.0716 - val_acc: 0.9681
Epoch 3/15
 - 4s - loss: 0.0441 - acc: 0.9748 - val_loss: 0.0742 - val_acc: 0.9683
Epoch 00003: early stopping
# Training time = 0:00:46.572393
# F-Score(Ordinary) = 0.501, Recall: 0.681, Precision: 0.396
# F-Score(ireflv) = 0.701, Recall: 0.599, Precision: 0.844
# F-Score(id) = 0.52, Recall: 0.83, Precision: 0.378
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_51 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_52 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_51 (Embedding)        (None, 4, 125)       1836625     input_51[0][0]                   
__________________________________________________________________________________________________
embedding_52 (Embedding)        (None, 4, 56)        13160       input_52[0][0]                   
__________________________________________________________________________________________________
flatten_51 (Flatten)            (None, 500)          0           embedding_51[0][0]               
__________________________________________________________________________________________________
flatten_52 (Flatten)            (None, 224)          0           embedding_52[0][0]               
__________________________________________________________________________________________________
concatenate_26 (Concatenate)    (None, 724)          0           flatten_51[0][0]                 
                                                                 flatten_52[0][0]                 
__________________________________________________________________________________________________
dense_51 (Dense)                (None, 256)          185600      concatenate_26[0][0]             
__________________________________________________________________________________________________
dropout_26 (Dropout)            (None, 256)          0           dense_51[0][0]                   
__________________________________________________________________________________________________
dense_52 (Dense)                (None, 8)            2056        dropout_26[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1029 - acc: 0.9632 - val_loss: 0.0719 - val_acc: 0.9685
Epoch 2/15
 - 5s - loss: 0.0520 - acc: 0.9727 - val_loss: 0.0693 - val_acc: 0.9684
Epoch 3/15
 - 5s - loss: 0.0447 - acc: 0.9749 - val_loss: 0.0739 - val_acc: 0.9678
Epoch 00003: early stopping
# Training time = 0:00:46.341684
# F-Score(Ordinary) = 0.022, Recall: 0.333, Precision: 0.011
# F-Score(lvc) = 0.058, Recall: 0.667, Precision: 0.03
# F-Score(ireflv) = 0.015, Recall: 0.111, Precision: 0.008
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_53 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_54 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_53 (Embedding)        (None, 4, 125)       1836625     input_53[0][0]                   
__________________________________________________________________________________________________
embedding_54 (Embedding)        (None, 4, 56)        13160       input_54[0][0]                   
__________________________________________________________________________________________________
flatten_53 (Flatten)            (None, 500)          0           embedding_53[0][0]               
__________________________________________________________________________________________________
flatten_54 (Flatten)            (None, 224)          0           embedding_54[0][0]               
__________________________________________________________________________________________________
concatenate_27 (Concatenate)    (None, 724)          0           flatten_53[0][0]                 
                                                                 flatten_54[0][0]                 
__________________________________________________________________________________________________
dense_53 (Dense)                (None, 256)          185600      concatenate_27[0][0]             
__________________________________________________________________________________________________
dropout_27 (Dropout)            (None, 256)          0           dense_53[0][0]                   
__________________________________________________________________________________________________
dense_54 (Dense)                (None, 8)            2056        dropout_27[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 4s - loss: 0.1034 - acc: 0.9605 - val_loss: 0.0726 - val_acc: 0.9676
Epoch 2/15
 - 4s - loss: 0.0520 - acc: 0.9724 - val_loss: 0.0719 - val_acc: 0.9679
Epoch 3/15
 - 5s - loss: 0.0448 - acc: 0.9744 - val_loss: 0.0793 - val_acc: 0.9681
Epoch 00003: early stopping
# Training time = 0:00:46.175343
# F-Score(Ordinary) = 0.013, Recall: 0.6, Precision: 0.007
# F-Score(id) = 0.03, Recall: 0.75, Precision: 0.016
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_55 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_56 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_55 (Embedding)        (None, 4, 125)       1836625     input_55[0][0]                   
__________________________________________________________________________________________________
embedding_56 (Embedding)        (None, 4, 56)        13160       input_56[0][0]                   
__________________________________________________________________________________________________
flatten_55 (Flatten)            (None, 500)          0           embedding_55[0][0]               
__________________________________________________________________________________________________
flatten_56 (Flatten)            (None, 224)          0           embedding_56[0][0]               
__________________________________________________________________________________________________
concatenate_28 (Concatenate)    (None, 724)          0           flatten_55[0][0]                 
                                                                 flatten_56[0][0]                 
__________________________________________________________________________________________________
dense_55 (Dense)                (None, 256)          185600      concatenate_28[0][0]             
__________________________________________________________________________________________________
dropout_28 (Dropout)            (None, 256)          0           dense_55[0][0]                   
__________________________________________________________________________________________________
dense_56 (Dense)                (None, 8)            2056        dropout_28[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1063 - acc: 0.9628 - val_loss: 0.0716 - val_acc: 0.9672
Epoch 2/15
 - 4s - loss: 0.0522 - acc: 0.9723 - val_loss: 0.0722 - val_acc: 0.9682
Epoch 3/15
 - 5s - loss: 0.0445 - acc: 0.9745 - val_loss: 0.0744 - val_acc: 0.9686
Epoch 00003: early stopping
# Training time = 0:00:46.183250
# F-Score(Ordinary) = 0.577, Recall: 0.606, Precision: 0.55
# F-Score(lvc) = 0.526, Recall: 0.478, Precision: 0.583
# F-Score(ireflv) = 0.724, Recall: 0.664, Precision: 0.795
# F-Score(id) = 0.445, Recall: 0.657, Precision: 0.337
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_57 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_58 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_57 (Embedding)        (None, 4, 125)       1836625     input_57[0][0]                   
__________________________________________________________________________________________________
embedding_58 (Embedding)        (None, 4, 56)        13160       input_58[0][0]                   
__________________________________________________________________________________________________
flatten_57 (Flatten)            (None, 500)          0           embedding_57[0][0]               
__________________________________________________________________________________________________
flatten_58 (Flatten)            (None, 224)          0           embedding_58[0][0]               
__________________________________________________________________________________________________
concatenate_29 (Concatenate)    (None, 724)          0           flatten_57[0][0]                 
                                                                 flatten_58[0][0]                 
__________________________________________________________________________________________________
dense_57 (Dense)                (None, 256)          185600      concatenate_29[0][0]             
__________________________________________________________________________________________________
dropout_29 (Dropout)            (None, 256)          0           dense_57[0][0]                   
__________________________________________________________________________________________________
dense_58 (Dense)                (None, 8)            2056        dropout_29[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1037 - acc: 0.9628 - val_loss: 0.0712 - val_acc: 0.9676
Epoch 2/15
 - 5s - loss: 0.0521 - acc: 0.9723 - val_loss: 0.0747 - val_acc: 0.9661
Epoch 3/15
 - 5s - loss: 0.0448 - acc: 0.9743 - val_loss: 0.0796 - val_acc: 0.9658
Epoch 00003: early stopping
# Training time = 0:00:46.421809
# F-Score(Ordinary) = 0.272, Recall: 0.332, Precision: 0.23
# F-Score(lvc) = 0.412, Recall: 0.308, Precision: 0.621
# F-Score(ireflv) = 0.145, Recall: 0.279, Precision: 0.098
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_59 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_60 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_59 (Embedding)        (None, 4, 125)       1836625     input_59[0][0]                   
__________________________________________________________________________________________________
embedding_60 (Embedding)        (None, 4, 56)        13160       input_60[0][0]                   
__________________________________________________________________________________________________
flatten_59 (Flatten)            (None, 500)          0           embedding_59[0][0]               
__________________________________________________________________________________________________
flatten_60 (Flatten)            (None, 224)          0           embedding_60[0][0]               
__________________________________________________________________________________________________
concatenate_30 (Concatenate)    (None, 724)          0           flatten_59[0][0]                 
                                                                 flatten_60[0][0]                 
__________________________________________________________________________________________________
dense_59 (Dense)                (None, 256)          185600      concatenate_30[0][0]             
__________________________________________________________________________________________________
dropout_30 (Dropout)            (None, 256)          0           dense_59[0][0]                   
__________________________________________________________________________________________________
dense_60 (Dense)                (None, 8)            2056        dropout_30[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.1031 - acc: 0.9634 - val_loss: 0.0726 - val_acc: 0.9663
Epoch 2/15
 - 5s - loss: 0.0519 - acc: 0.9726 - val_loss: 0.0735 - val_acc: 0.9671
Epoch 3/15
 - 5s - loss: 0.0447 - acc: 0.9746 - val_loss: 0.0776 - val_acc: 0.9675
Epoch 00003: early stopping
# Training time = 0:00:46.336739
# F-Score(Ordinary) = 0.543, Recall: 0.619, Precision: 0.483
# F-Score(lvc) = 0.481, Recall: 0.42, Precision: 0.561
# F-Score(ireflv) = 0.11, Recall: 0.348, Precision: 0.066
# F-Score(id) = 0.729, Recall: 0.833, Precision: 0.648
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_61 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_62 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_61 (Embedding)        (None, 4, 125)       1836625     input_61[0][0]                   
__________________________________________________________________________________________________
embedding_62 (Embedding)        (None, 4, 56)        13160       input_62[0][0]                   
__________________________________________________________________________________________________
flatten_61 (Flatten)            (None, 500)          0           embedding_61[0][0]               
__________________________________________________________________________________________________
flatten_62 (Flatten)            (None, 224)          0           embedding_62[0][0]               
__________________________________________________________________________________________________
concatenate_31 (Concatenate)    (None, 724)          0           flatten_61[0][0]                 
                                                                 flatten_62[0][0]                 
__________________________________________________________________________________________________
dense_61 (Dense)                (None, 256)          185600      concatenate_31[0][0]             
__________________________________________________________________________________________________
dropout_31 (Dropout)            (None, 256)          0           dense_61[0][0]                   
__________________________________________________________________________________________________
dense_62 (Dense)                (None, 8)            2056        dropout_31[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4730 - acc: 0.8109 - val_loss: 0.2481 - val_acc: 0.8673
Epoch 2/15
 - 1s - loss: 0.2299 - acc: 0.8623 - val_loss: 0.2350 - val_acc: 0.8641
Epoch 3/15
 - 1s - loss: 0.1943 - acc: 0.8700 - val_loss: 0.2246 - val_acc: 0.8665
Epoch 00003: early stopping
# Training time = 0:00:09.460101
# F-Score(Ordinary) = 0.135, Recall: 0.099, Precision: 0.215
# F-Score(lvc) = 0.089, Recall: 0.051, Precision: 0.341
# F-Score(ireflv) = 0.03, Recall: 0.154, Precision: 0.016
# F-Score(id) = 0.347, Recall: 0.603, Precision: 0.244
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_63 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_64 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_63 (Embedding)        (None, 4, 125)       1836625     input_63[0][0]                   
__________________________________________________________________________________________________
embedding_64 (Embedding)        (None, 4, 56)        13160       input_64[0][0]                   
__________________________________________________________________________________________________
flatten_63 (Flatten)            (None, 500)          0           embedding_63[0][0]               
__________________________________________________________________________________________________
flatten_64 (Flatten)            (None, 224)          0           embedding_64[0][0]               
__________________________________________________________________________________________________
concatenate_32 (Concatenate)    (None, 724)          0           flatten_63[0][0]                 
                                                                 flatten_64[0][0]                 
__________________________________________________________________________________________________
dense_63 (Dense)                (None, 256)          185600      concatenate_32[0][0]             
__________________________________________________________________________________________________
dropout_32 (Dropout)            (None, 256)          0           dense_63[0][0]                   
__________________________________________________________________________________________________
dense_64 (Dense)                (None, 8)            2056        dropout_32[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4785 - acc: 0.8123 - val_loss: 0.2433 - val_acc: 0.8665
Epoch 2/15
 - 1s - loss: 0.2279 - acc: 0.8621 - val_loss: 0.2256 - val_acc: 0.8700
Epoch 3/15
 - 1s - loss: 0.1976 - acc: 0.8703 - val_loss: 0.2207 - val_acc: 0.8700
Epoch 00003: early stopping
# Training time = 0:00:09.521509
# F-Score(Ordinary) = 0.076, Recall: 0.076, Precision: 0.076
# F-Score(lvc) = 0.048, Recall: 0.036, Precision: 0.076
# F-Score(ireflv) = 0.113, Recall: 0.1, Precision: 0.131
# F-Score(id) = 0.07, Recall: 0.875, Precision: 0.036
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_65 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_66 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_65 (Embedding)        (None, 4, 125)       1836625     input_65[0][0]                   
__________________________________________________________________________________________________
embedding_66 (Embedding)        (None, 4, 56)        13160       input_66[0][0]                   
__________________________________________________________________________________________________
flatten_65 (Flatten)            (None, 500)          0           embedding_65[0][0]               
__________________________________________________________________________________________________
flatten_66 (Flatten)            (None, 224)          0           embedding_66[0][0]               
__________________________________________________________________________________________________
concatenate_33 (Concatenate)    (None, 724)          0           flatten_65[0][0]                 
                                                                 flatten_66[0][0]                 
__________________________________________________________________________________________________
dense_65 (Dense)                (None, 256)          185600      concatenate_33[0][0]             
__________________________________________________________________________________________________
dropout_33 (Dropout)            (None, 256)          0           dense_65[0][0]                   
__________________________________________________________________________________________________
dense_66 (Dense)                (None, 8)            2056        dropout_33[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4838 - acc: 0.8120 - val_loss: 0.2442 - val_acc: 0.8679
Epoch 2/15
 - 1s - loss: 0.2269 - acc: 0.8643 - val_loss: 0.2254 - val_acc: 0.8703
Epoch 3/15
 - 1s - loss: 0.1948 - acc: 0.8713 - val_loss: 0.2238 - val_acc: 0.8673
Epoch 00003: early stopping
# Training time = 0:00:09.498157
# F-Score(Ordinary) = 0.179, Recall: 0.143, Precision: 0.239
# F-Score(lvc) = 0.095, Recall: 0.059, Precision: 0.25
# F-Score(ireflv) = 0.18, Recall: 0.254, Precision: 0.139
# F-Score(id) = 0.36, Recall: 0.475, Precision: 0.29
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_67 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_68 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_67 (Embedding)        (None, 4, 125)       1836625     input_67[0][0]                   
__________________________________________________________________________________________________
embedding_68 (Embedding)        (None, 4, 56)        13160       input_68[0][0]                   
__________________________________________________________________________________________________
flatten_67 (Flatten)            (None, 500)          0           embedding_67[0][0]               
__________________________________________________________________________________________________
flatten_68 (Flatten)            (None, 224)          0           embedding_68[0][0]               
__________________________________________________________________________________________________
concatenate_34 (Concatenate)    (None, 724)          0           flatten_67[0][0]                 
                                                                 flatten_68[0][0]                 
__________________________________________________________________________________________________
dense_67 (Dense)                (None, 256)          185600      concatenate_34[0][0]             
__________________________________________________________________________________________________
dropout_34 (Dropout)            (None, 256)          0           dense_67[0][0]                   
__________________________________________________________________________________________________
dense_68 (Dense)                (None, 8)            2056        dropout_34[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4822 - acc: 0.8080 - val_loss: 0.2444 - val_acc: 0.8656
Epoch 2/15
 - 1s - loss: 0.2281 - acc: 0.8609 - val_loss: 0.2270 - val_acc: 0.8688
Epoch 3/15
 - 1s - loss: 0.1946 - acc: 0.8711 - val_loss: 0.2210 - val_acc: 0.8721
Epoch 00003: early stopping
# Training time = 0:00:09.496391
# F-Score(Ordinary) = 0.025, Recall: 0.15, Precision: 0.013
# F-Score(lvc) = 0.047, Recall: 0.108, Precision: 0.03
# F-Score(id) = 0.02, Recall: 0.667, Precision: 0.01
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_69 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_70 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_69 (Embedding)        (None, 4, 125)       1836625     input_69[0][0]                   
__________________________________________________________________________________________________
embedding_70 (Embedding)        (None, 4, 56)        13160       input_70[0][0]                   
__________________________________________________________________________________________________
flatten_69 (Flatten)            (None, 500)          0           embedding_69[0][0]               
__________________________________________________________________________________________________
flatten_70 (Flatten)            (None, 224)          0           embedding_70[0][0]               
__________________________________________________________________________________________________
concatenate_35 (Concatenate)    (None, 724)          0           flatten_69[0][0]                 
                                                                 flatten_70[0][0]                 
__________________________________________________________________________________________________
dense_69 (Dense)                (None, 256)          185600      concatenate_35[0][0]             
__________________________________________________________________________________________________
dropout_35 (Dropout)            (None, 256)          0           dense_69[0][0]                   
__________________________________________________________________________________________________
dense_70 (Dense)                (None, 8)            2056        dropout_35[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4748 - acc: 0.8154 - val_loss: 0.2428 - val_acc: 0.8679
Epoch 2/15
 - 1s - loss: 0.2268 - acc: 0.8636 - val_loss: 0.2251 - val_acc: 0.8697
Epoch 3/15
 - 1s - loss: 0.1947 - acc: 0.8706 - val_loss: 0.2219 - val_acc: 0.8703
Epoch 00003: early stopping
# Training time = 0:00:09.478348
# F-Score(Ordinary) = 0.077, Recall: 0.101, Precision: 0.063
# F-Score(lvc) = 0.026, Recall: 0.087, Precision: 0.015
# F-Score(ireflv) = 0.128, Recall: 0.094, Precision: 0.197
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_71 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_72 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_71 (Embedding)        (None, 4, 125)       1836625     input_71[0][0]                   
__________________________________________________________________________________________________
embedding_72 (Embedding)        (None, 4, 56)        13160       input_72[0][0]                   
__________________________________________________________________________________________________
flatten_71 (Flatten)            (None, 500)          0           embedding_71[0][0]               
__________________________________________________________________________________________________
flatten_72 (Flatten)            (None, 224)          0           embedding_72[0][0]               
__________________________________________________________________________________________________
concatenate_36 (Concatenate)    (None, 724)          0           flatten_71[0][0]                 
                                                                 flatten_72[0][0]                 
__________________________________________________________________________________________________
dense_71 (Dense)                (None, 256)          185600      concatenate_36[0][0]             
__________________________________________________________________________________________________
dropout_36 (Dropout)            (None, 256)          0           dense_71[0][0]                   
__________________________________________________________________________________________________
dense_72 (Dense)                (None, 8)            2056        dropout_36[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4744 - acc: 0.8094 - val_loss: 0.2432 - val_acc: 0.8644
Epoch 2/15
 - 1s - loss: 0.2275 - acc: 0.8625 - val_loss: 0.2268 - val_acc: 0.8673
Epoch 3/15
 - 1s - loss: 0.1952 - acc: 0.8708 - val_loss: 0.2281 - val_acc: 0.8673
Epoch 00003: early stopping
# Training time = 0:00:09.452279
# F-Score(Ordinary) = 0.106, Recall: 0.075, Precision: 0.183
# F-Score(lvc) = 0.048, Recall: 0.029, Precision: 0.136
# F-Score(ireflv) = 0.085, Recall: 0.055, Precision: 0.189
# F-Score(id) = 0.313, Recall: 0.635, Precision: 0.207
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_73 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_74 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_73 (Embedding)        (None, 4, 125)       1836625     input_73[0][0]                   
__________________________________________________________________________________________________
embedding_74 (Embedding)        (None, 4, 56)        13160       input_74[0][0]                   
__________________________________________________________________________________________________
flatten_73 (Flatten)            (None, 500)          0           embedding_73[0][0]               
__________________________________________________________________________________________________
flatten_74 (Flatten)            (None, 224)          0           embedding_74[0][0]               
__________________________________________________________________________________________________
concatenate_37 (Concatenate)    (None, 724)          0           flatten_73[0][0]                 
                                                                 flatten_74[0][0]                 
__________________________________________________________________________________________________
dense_73 (Dense)                (None, 256)          185600      concatenate_37[0][0]             
__________________________________________________________________________________________________
dropout_37 (Dropout)            (None, 256)          0           dense_73[0][0]                   
__________________________________________________________________________________________________
dense_74 (Dense)                (None, 8)            2056        dropout_37[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4862 - acc: 0.8094 - val_loss: 0.2460 - val_acc: 0.8673
Epoch 2/15
 - 1s - loss: 0.2288 - acc: 0.8617 - val_loss: 0.2235 - val_acc: 0.8721
Epoch 3/15
 - 1s - loss: 0.1954 - acc: 0.8722 - val_loss: 0.2227 - val_acc: 0.8694
Epoch 00003: early stopping
# Training time = 0:00:09.519246
# F-Score(Ordinary) = 0.132, Recall: 0.099, Precision: 0.199
# F-Score(lvc) = 0.084, Recall: 0.049, Precision: 0.295
# F-Score(id) = 0.32, Recall: 0.449, Precision: 0.249
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_75 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_76 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_75 (Embedding)        (None, 4, 125)       1836625     input_75[0][0]                   
__________________________________________________________________________________________________
embedding_76 (Embedding)        (None, 4, 56)        13160       input_76[0][0]                   
__________________________________________________________________________________________________
flatten_75 (Flatten)            (None, 500)          0           embedding_75[0][0]               
__________________________________________________________________________________________________
flatten_76 (Flatten)            (None, 224)          0           embedding_76[0][0]               
__________________________________________________________________________________________________
concatenate_38 (Concatenate)    (None, 724)          0           flatten_75[0][0]                 
                                                                 flatten_76[0][0]                 
__________________________________________________________________________________________________
dense_75 (Dense)                (None, 256)          185600      concatenate_38[0][0]             
__________________________________________________________________________________________________
dropout_38 (Dropout)            (None, 256)          0           dense_75[0][0]                   
__________________________________________________________________________________________________
dense_76 (Dense)                (None, 8)            2056        dropout_38[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4810 - acc: 0.8142 - val_loss: 0.2418 - val_acc: 0.8653
Epoch 2/15
 - 1s - loss: 0.2264 - acc: 0.8630 - val_loss: 0.2222 - val_acc: 0.8676
Epoch 3/15
 - 1s - loss: 0.1953 - acc: 0.8718 - val_loss: 0.2209 - val_acc: 0.8688
Epoch 00003: early stopping
# Training time = 0:00:09.539933
# F-Score(Ordinary) = 0.064, Recall: 0.069, Precision: 0.06
# F-Score(lvc) = 0.098, Recall: 0.066, Precision: 0.189
# F-Score(id) = 0.021, Recall: 1.0, Precision: 0.01
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_77 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_78 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_77 (Embedding)        (None, 4, 125)       1836625     input_77[0][0]                   
__________________________________________________________________________________________________
embedding_78 (Embedding)        (None, 4, 56)        13160       input_78[0][0]                   
__________________________________________________________________________________________________
flatten_77 (Flatten)            (None, 500)          0           embedding_77[0][0]               
__________________________________________________________________________________________________
flatten_78 (Flatten)            (None, 224)          0           embedding_78[0][0]               
__________________________________________________________________________________________________
concatenate_39 (Concatenate)    (None, 724)          0           flatten_77[0][0]                 
                                                                 flatten_78[0][0]                 
__________________________________________________________________________________________________
dense_77 (Dense)                (None, 256)          185600      concatenate_39[0][0]             
__________________________________________________________________________________________________
dropout_39 (Dropout)            (None, 256)          0           dense_77[0][0]                   
__________________________________________________________________________________________________
dense_78 (Dense)                (None, 8)            2056        dropout_39[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4886 - acc: 0.8096 - val_loss: 0.2452 - val_acc: 0.8679
Epoch 2/15
 - 1s - loss: 0.2301 - acc: 0.8629 - val_loss: 0.2272 - val_acc: 0.8656
Epoch 3/15
 - 1s - loss: 0.1973 - acc: 0.8701 - val_loss: 0.2240 - val_acc: 0.8700
Epoch 00003: early stopping
# Training time = 0:00:09.496234
# F-Score(Ordinary) = 0.109, Recall: 0.114, Precision: 0.105
# F-Score(ireflv) = 0.148, Recall: 0.096, Precision: 0.32
# F-Score(id) = 0.07, Recall: 0.875, Precision: 0.036
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_79 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_80 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_79 (Embedding)        (None, 4, 125)       1836625     input_79[0][0]                   
__________________________________________________________________________________________________
embedding_80 (Embedding)        (None, 4, 56)        13160       input_80[0][0]                   
__________________________________________________________________________________________________
flatten_79 (Flatten)            (None, 500)          0           embedding_79[0][0]               
__________________________________________________________________________________________________
flatten_80 (Flatten)            (None, 224)          0           embedding_80[0][0]               
__________________________________________________________________________________________________
concatenate_40 (Concatenate)    (None, 724)          0           flatten_79[0][0]                 
                                                                 flatten_80[0][0]                 
__________________________________________________________________________________________________
dense_79 (Dense)                (None, 256)          185600      concatenate_40[0][0]             
__________________________________________________________________________________________________
dropout_40 (Dropout)            (None, 256)          0           dense_79[0][0]                   
__________________________________________________________________________________________________
dense_80 (Dense)                (None, 8)            2056        dropout_40[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4739 - acc: 0.8138 - val_loss: 0.2429 - val_acc: 0.8688
Epoch 2/15
 - 1s - loss: 0.2291 - acc: 0.8638 - val_loss: 0.2288 - val_acc: 0.8706
Epoch 3/15
 - 1s - loss: 0.1962 - acc: 0.8717 - val_loss: 0.2245 - val_acc: 0.8706
Epoch 00003: early stopping
# Training time = 0:00:09.528495
# F-Score(Ordinary) = 0.161, Recall: 0.138, Precision: 0.192
# F-Score(lvc) = 0.081, Recall: 0.051, Precision: 0.197
# F-Score(ireflv) = 0.093, Recall: 0.241, Precision: 0.057
# F-Score(id) = 0.377, Recall: 0.627, Precision: 0.269
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_81 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_82 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_81 (Embedding)        (None, 4, 125)       1836625     input_81[0][0]                   
__________________________________________________________________________________________________
embedding_82 (Embedding)        (None, 4, 56)        13160       input_82[0][0]                   
__________________________________________________________________________________________________
flatten_81 (Flatten)            (None, 500)          0           embedding_81[0][0]               
__________________________________________________________________________________________________
flatten_82 (Flatten)            (None, 224)          0           embedding_82[0][0]               
__________________________________________________________________________________________________
concatenate_41 (Concatenate)    (None, 724)          0           flatten_81[0][0]                 
                                                                 flatten_82[0][0]                 
__________________________________________________________________________________________________
dense_81 (Dense)                (None, 256)          185600      concatenate_41[0][0]             
__________________________________________________________________________________________________
dropout_41 (Dropout)            (None, 256)          0           dense_81[0][0]                   
__________________________________________________________________________________________________
dense_82 (Dense)                (None, 8)            2056        dropout_41[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4732 - acc: 0.8115 - val_loss: 0.2442 - val_acc: 0.8667
Epoch 2/15
 - 1s - loss: 0.2284 - acc: 0.8634 - val_loss: 0.2308 - val_acc: 0.8694
Epoch 3/15
 - 1s - loss: 0.1962 - acc: 0.8710 - val_loss: 0.2257 - val_acc: 0.8659
Epoch 00003: early stopping
# Training time = 0:00:09.451133
# F-Score(Ordinary) = 0.152, Recall: 0.124, Precision: 0.197
# F-Score(lvc) = 0.08, Recall: 0.048, Precision: 0.235
# F-Score(ireflv) = 0.045, Recall: 0.273, Precision: 0.025
# F-Score(id) = 0.424, Recall: 0.93, Precision: 0.275
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_83 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_84 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_83 (Embedding)        (None, 4, 125)       1836625     input_83[0][0]                   
__________________________________________________________________________________________________
embedding_84 (Embedding)        (None, 4, 56)        13160       input_84[0][0]                   
__________________________________________________________________________________________________
flatten_83 (Flatten)            (None, 500)          0           embedding_83[0][0]               
__________________________________________________________________________________________________
flatten_84 (Flatten)            (None, 224)          0           embedding_84[0][0]               
__________________________________________________________________________________________________
concatenate_42 (Concatenate)    (None, 724)          0           flatten_83[0][0]                 
                                                                 flatten_84[0][0]                 
__________________________________________________________________________________________________
dense_83 (Dense)                (None, 256)          185600      concatenate_42[0][0]             
__________________________________________________________________________________________________
dropout_42 (Dropout)            (None, 256)          0           dense_83[0][0]                   
__________________________________________________________________________________________________
dense_84 (Dense)                (None, 8)            2056        dropout_42[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4676 - acc: 0.8136 - val_loss: 0.2512 - val_acc: 0.8644
Epoch 2/15
 - 1s - loss: 0.2277 - acc: 0.8615 - val_loss: 0.2240 - val_acc: 0.8697
Epoch 3/15
 - 1s - loss: 0.1947 - acc: 0.8748 - val_loss: 0.2211 - val_acc: 0.8712
Epoch 00003: early stopping
# Training time = 0:00:09.505056
# F-Score(Ordinary) = 0.068, Recall: 0.058, Precision: 0.081
# F-Score(lvc) = 0.091, Recall: 0.055, Precision: 0.258
# F-Score(id) = 0.01, Recall: 1.0, Precision: 0.005
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_85 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_86 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_85 (Embedding)        (None, 4, 125)       1836625     input_85[0][0]                   
__________________________________________________________________________________________________
embedding_86 (Embedding)        (None, 4, 56)        13160       input_86[0][0]                   
__________________________________________________________________________________________________
flatten_85 (Flatten)            (None, 500)          0           embedding_85[0][0]               
__________________________________________________________________________________________________
flatten_86 (Flatten)            (None, 224)          0           embedding_86[0][0]               
__________________________________________________________________________________________________
concatenate_43 (Concatenate)    (None, 724)          0           flatten_85[0][0]                 
                                                                 flatten_86[0][0]                 
__________________________________________________________________________________________________
dense_85 (Dense)                (None, 256)          185600      concatenate_43[0][0]             
__________________________________________________________________________________________________
dropout_43 (Dropout)            (None, 256)          0           dense_85[0][0]                   
__________________________________________________________________________________________________
dense_86 (Dense)                (None, 8)            2056        dropout_43[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4827 - acc: 0.8100 - val_loss: 0.2494 - val_acc: 0.8641
Epoch 2/15
 - 1s - loss: 0.2293 - acc: 0.8637 - val_loss: 0.2268 - val_acc: 0.8682
Epoch 3/15
 - 1s - loss: 0.1954 - acc: 0.8709 - val_loss: 0.2273 - val_acc: 0.8688
Epoch 00003: early stopping
# Training time = 0:00:09.488375
# F-Score(Ordinary) = 0.042, Recall: 0.045, Precision: 0.04
# F-Score(lvc) = 0.053, Recall: 0.035, Precision: 0.106
# F-Score(id) = 0.031, Recall: 1.0, Precision: 0.016
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_87 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_88 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_87 (Embedding)        (None, 4, 125)       1836625     input_87[0][0]                   
__________________________________________________________________________________________________
embedding_88 (Embedding)        (None, 4, 56)        13160       input_88[0][0]                   
__________________________________________________________________________________________________
flatten_87 (Flatten)            (None, 500)          0           embedding_87[0][0]               
__________________________________________________________________________________________________
flatten_88 (Flatten)            (None, 224)          0           embedding_88[0][0]               
__________________________________________________________________________________________________
concatenate_44 (Concatenate)    (None, 724)          0           flatten_87[0][0]                 
                                                                 flatten_88[0][0]                 
__________________________________________________________________________________________________
dense_87 (Dense)                (None, 256)          185600      concatenate_44[0][0]             
__________________________________________________________________________________________________
dropout_44 (Dropout)            (None, 256)          0           dense_87[0][0]                   
__________________________________________________________________________________________________
dense_88 (Dense)                (None, 8)            2056        dropout_44[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4878 - acc: 0.8052 - val_loss: 0.2435 - val_acc: 0.8700
Epoch 2/15
 - 1s - loss: 0.2264 - acc: 0.8663 - val_loss: 0.2244 - val_acc: 0.8703
Epoch 3/15
 - 1s - loss: 0.1962 - acc: 0.8707 - val_loss: 0.2260 - val_acc: 0.8682
Epoch 00003: early stopping
# Training time = 0:00:09.564635
# F-Score(Ordinary) = 0.094, Recall: 0.136, Precision: 0.072
# F-Score(lvc) = 0.062, Recall: 0.074, Precision: 0.053
# F-Score(ireflv) = 0.174, Recall: 0.162, Precision: 0.189
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_89 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_90 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_89 (Embedding)        (None, 4, 125)       1836625     input_89[0][0]                   
__________________________________________________________________________________________________
embedding_90 (Embedding)        (None, 4, 56)        13160       input_90[0][0]                   
__________________________________________________________________________________________________
flatten_89 (Flatten)            (None, 500)          0           embedding_89[0][0]               
__________________________________________________________________________________________________
flatten_90 (Flatten)            (None, 224)          0           embedding_90[0][0]               
__________________________________________________________________________________________________
concatenate_45 (Concatenate)    (None, 724)          0           flatten_89[0][0]                 
                                                                 flatten_90[0][0]                 
__________________________________________________________________________________________________
dense_89 (Dense)                (None, 256)          185600      concatenate_45[0][0]             
__________________________________________________________________________________________________
dropout_45 (Dropout)            (None, 256)          0           dense_89[0][0]                   
__________________________________________________________________________________________________
dense_90 (Dense)                (None, 8)            2056        dropout_45[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4772 - acc: 0.8133 - val_loss: 0.2480 - val_acc: 0.8653
Epoch 2/15
 - 1s - loss: 0.2281 - acc: 0.8613 - val_loss: 0.2279 - val_acc: 0.8694
Epoch 3/15
 - 1s - loss: 0.1958 - acc: 0.8699 - val_loss: 0.2204 - val_acc: 0.8703
Epoch 00003: early stopping
# Training time = 0:00:09.518748
# F-Score(Ordinary) = 0.093, Recall: 0.815, Precision: 0.049
# F-Score(id) = 0.203, Recall: 0.917, Precision: 0.114
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_91 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_92 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_91 (Embedding)        (None, 4, 125)       1836625     input_91[0][0]                   
__________________________________________________________________________________________________
embedding_92 (Embedding)        (None, 4, 56)        13160       input_92[0][0]                   
__________________________________________________________________________________________________
flatten_91 (Flatten)            (None, 500)          0           embedding_91[0][0]               
__________________________________________________________________________________________________
flatten_92 (Flatten)            (None, 224)          0           embedding_92[0][0]               
__________________________________________________________________________________________________
concatenate_46 (Concatenate)    (None, 724)          0           flatten_91[0][0]                 
                                                                 flatten_92[0][0]                 
__________________________________________________________________________________________________
dense_91 (Dense)                (None, 256)          185600      concatenate_46[0][0]             
__________________________________________________________________________________________________
dropout_46 (Dropout)            (None, 256)          0           dense_91[0][0]                   
__________________________________________________________________________________________________
dense_92 (Dense)                (None, 8)            2056        dropout_46[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4749 - acc: 0.8160 - val_loss: 0.2540 - val_acc: 0.8644
Epoch 2/15
 - 1s - loss: 0.2308 - acc: 0.8621 - val_loss: 0.2280 - val_acc: 0.8721
Epoch 3/15
 - 1s - loss: 0.1965 - acc: 0.8712 - val_loss: 0.2202 - val_acc: 0.8700
Epoch 00003: early stopping
# Training time = 0:00:09.494519
# F-Score(Ordinary) = 0.168, Recall: 0.132, Precision: 0.23
# F-Score(lvc) = 0.081, Recall: 0.059, Precision: 0.129
# F-Score(ireflv) = 0.185, Recall: 0.117, Precision: 0.443
# F-Score(id) = 0.267, Recall: 0.938, Precision: 0.155
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_93 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_94 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_93 (Embedding)        (None, 4, 125)       1836625     input_93[0][0]                   
__________________________________________________________________________________________________
embedding_94 (Embedding)        (None, 4, 56)        13160       input_94[0][0]                   
__________________________________________________________________________________________________
flatten_93 (Flatten)            (None, 500)          0           embedding_93[0][0]               
__________________________________________________________________________________________________
flatten_94 (Flatten)            (None, 224)          0           embedding_94[0][0]               
__________________________________________________________________________________________________
concatenate_47 (Concatenate)    (None, 724)          0           flatten_93[0][0]                 
                                                                 flatten_94[0][0]                 
__________________________________________________________________________________________________
dense_93 (Dense)                (None, 256)          185600      concatenate_47[0][0]             
__________________________________________________________________________________________________
dropout_47 (Dropout)            (None, 256)          0           dense_93[0][0]                   
__________________________________________________________________________________________________
dense_94 (Dense)                (None, 8)            2056        dropout_47[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4826 - acc: 0.8106 - val_loss: 0.2543 - val_acc: 0.8632
Epoch 2/15
 - 1s - loss: 0.2270 - acc: 0.8641 - val_loss: 0.2288 - val_acc: 0.8662
Epoch 3/15
 - 1s - loss: 0.1960 - acc: 0.8708 - val_loss: 0.2223 - val_acc: 0.8697
Epoch 00003: early stopping
# Training time = 0:00:09.530997
# F-Score(Ordinary) = 0.124, Recall: 0.212, Precision: 0.087
# F-Score(ireflv) = 0.197, Recall: 0.169, Precision: 0.238
# F-Score(id) = 0.089, Recall: 0.9, Precision: 0.047
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_95 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_96 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_95 (Embedding)        (None, 4, 125)       1836625     input_95[0][0]                   
__________________________________________________________________________________________________
embedding_96 (Embedding)        (None, 4, 56)        13160       input_96[0][0]                   
__________________________________________________________________________________________________
flatten_95 (Flatten)            (None, 500)          0           embedding_95[0][0]               
__________________________________________________________________________________________________
flatten_96 (Flatten)            (None, 224)          0           embedding_96[0][0]               
__________________________________________________________________________________________________
concatenate_48 (Concatenate)    (None, 724)          0           flatten_95[0][0]                 
                                                                 flatten_96[0][0]                 
__________________________________________________________________________________________________
dense_95 (Dense)                (None, 256)          185600      concatenate_48[0][0]             
__________________________________________________________________________________________________
dropout_48 (Dropout)            (None, 256)          0           dense_95[0][0]                   
__________________________________________________________________________________________________
dense_96 (Dense)                (None, 8)            2056        dropout_48[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4910 - acc: 0.8143 - val_loss: 0.2453 - val_acc: 0.8665
Epoch 2/15
 - 1s - loss: 0.2297 - acc: 0.8660 - val_loss: 0.2243 - val_acc: 0.8697
Epoch 3/15
 - 1s - loss: 0.1968 - acc: 0.8732 - val_loss: 0.2198 - val_acc: 0.8667
Epoch 00003: early stopping
# Training time = 0:00:09.411875
# F-Score(Ordinary) = 0.136, Recall: 0.107, Precision: 0.188
# F-Score(lvc) = 0.07, Recall: 0.042, Precision: 0.212
# F-Score(ireflv) = 0.074, Recall: 0.357, Precision: 0.041
# F-Score(id) = 0.336, Recall: 0.495, Precision: 0.254
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_97 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_98 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_97 (Embedding)        (None, 4, 125)       1836625     input_97[0][0]                   
__________________________________________________________________________________________________
embedding_98 (Embedding)        (None, 4, 56)        13160       input_98[0][0]                   
__________________________________________________________________________________________________
flatten_97 (Flatten)            (None, 500)          0           embedding_97[0][0]               
__________________________________________________________________________________________________
flatten_98 (Flatten)            (None, 224)          0           embedding_98[0][0]               
__________________________________________________________________________________________________
concatenate_49 (Concatenate)    (None, 724)          0           flatten_97[0][0]                 
                                                                 flatten_98[0][0]                 
__________________________________________________________________________________________________
dense_97 (Dense)                (None, 256)          185600      concatenate_49[0][0]             
__________________________________________________________________________________________________
dropout_49 (Dropout)            (None, 256)          0           dense_97[0][0]                   
__________________________________________________________________________________________________
dense_98 (Dense)                (None, 8)            2056        dropout_49[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4820 - acc: 0.8110 - val_loss: 0.2487 - val_acc: 0.8659
Epoch 2/15
 - 1s - loss: 0.2291 - acc: 0.8636 - val_loss: 0.2220 - val_acc: 0.8700
Epoch 3/15
 - 1s - loss: 0.1968 - acc: 0.8698 - val_loss: 0.2230 - val_acc: 0.8685
Epoch 00003: early stopping
# Training time = 0:00:12.404717
# F-Score(Ordinary) = 0.15, Recall: 0.105, Precision: 0.26
# F-Score(lvc) = 0.073, Recall: 0.042, Precision: 0.258
# F-Score(ireflv) = 0.146, Recall: 0.112, Precision: 0.213
# F-Score(id) = 0.395, Recall: 0.785, Precision: 0.264
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_99 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_100 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_99 (Embedding)        (None, 4, 125)       1836625     input_99[0][0]                   
__________________________________________________________________________________________________
embedding_100 (Embedding)       (None, 4, 56)        13160       input_100[0][0]                  
__________________________________________________________________________________________________
flatten_99 (Flatten)            (None, 500)          0           embedding_99[0][0]               
__________________________________________________________________________________________________
flatten_100 (Flatten)           (None, 224)          0           embedding_100[0][0]              
__________________________________________________________________________________________________
concatenate_50 (Concatenate)    (None, 724)          0           flatten_99[0][0]                 
                                                                 flatten_100[0][0]                
__________________________________________________________________________________________________
dense_99 (Dense)                (None, 256)          185600      concatenate_50[0][0]             
__________________________________________________________________________________________________
dropout_50 (Dropout)            (None, 256)          0           dense_99[0][0]                   
__________________________________________________________________________________________________
dense_100 (Dense)               (None, 8)            2056        dropout_50[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4780 - acc: 0.8136 - val_loss: 0.2486 - val_acc: 0.8665
Epoch 2/15
 - 1s - loss: 0.2318 - acc: 0.8608 - val_loss: 0.2261 - val_acc: 0.8706
Epoch 3/15
 - 1s - loss: 0.1971 - acc: 0.8701 - val_loss: 0.2237 - val_acc: 0.8667
Epoch 00003: early stopping
# Training time = 0:00:09.491090
# F-Score(Ordinary) = 0.152, Recall: 0.106, Precision: 0.271
# F-Score(lvc) = 0.093, Recall: 0.056, Precision: 0.265
# F-Score(ireflv) = 0.14, Recall: 0.089, Precision: 0.328
# F-Score(id) = 0.333, Recall: 0.62, Precision: 0.228
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_101 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_102 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_101 (Embedding)       (None, 4, 125)       1836625     input_101[0][0]                  
__________________________________________________________________________________________________
embedding_102 (Embedding)       (None, 4, 56)        13160       input_102[0][0]                  
__________________________________________________________________________________________________
flatten_101 (Flatten)           (None, 500)          0           embedding_101[0][0]              
__________________________________________________________________________________________________
flatten_102 (Flatten)           (None, 224)          0           embedding_102[0][0]              
__________________________________________________________________________________________________
concatenate_51 (Concatenate)    (None, 724)          0           flatten_101[0][0]                
                                                                 flatten_102[0][0]                
__________________________________________________________________________________________________
dense_101 (Dense)               (None, 256)          185600      concatenate_51[0][0]             
__________________________________________________________________________________________________
dropout_51 (Dropout)            (None, 256)          0           dense_101[0][0]                  
__________________________________________________________________________________________________
dense_102 (Dense)               (None, 8)            2056        dropout_51[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4804 - acc: 0.8096 - val_loss: 0.2521 - val_acc: 0.8626
Epoch 2/15
 - 1s - loss: 0.2275 - acc: 0.8635 - val_loss: 0.2364 - val_acc: 0.8659
Epoch 3/15
 - 1s - loss: 0.1953 - acc: 0.8703 - val_loss: 0.2244 - val_acc: 0.8715
Epoch 00003: early stopping
# Training time = 0:00:09.502146
# F-Score(Ordinary) = 0.018, Recall: 1.0, Precision: 0.009
# F-Score(lvc) = 0.044, Recall: 0.75, Precision: 0.023
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_103 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_104 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_103 (Embedding)       (None, 4, 125)       1836625     input_103[0][0]                  
__________________________________________________________________________________________________
embedding_104 (Embedding)       (None, 4, 56)        13160       input_104[0][0]                  
__________________________________________________________________________________________________
flatten_103 (Flatten)           (None, 500)          0           embedding_103[0][0]              
__________________________________________________________________________________________________
flatten_104 (Flatten)           (None, 224)          0           embedding_104[0][0]              
__________________________________________________________________________________________________
concatenate_52 (Concatenate)    (None, 724)          0           flatten_103[0][0]                
                                                                 flatten_104[0][0]                
__________________________________________________________________________________________________
dense_103 (Dense)               (None, 256)          185600      concatenate_52[0][0]             
__________________________________________________________________________________________________
dropout_52 (Dropout)            (None, 256)          0           dense_103[0][0]                  
__________________________________________________________________________________________________
dense_104 (Dense)               (None, 8)            2056        dropout_52[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4836 - acc: 0.8076 - val_loss: 0.2509 - val_acc: 0.8650
Epoch 2/15
 - 1s - loss: 0.2292 - acc: 0.8601 - val_loss: 0.2279 - val_acc: 0.8718
Epoch 3/15
 - 1s - loss: 0.1969 - acc: 0.8698 - val_loss: 0.2196 - val_acc: 0.8673
Epoch 00003: early stopping
# Training time = 0:00:09.545477
# F-Score(Ordinary) = 0.127, Recall: 0.089, Precision: 0.219
# F-Score(lvc) = 0.075, Recall: 0.043, Precision: 0.303
# F-Score(ireflv) = 0.039, Recall: 0.1, Precision: 0.025
# F-Score(id) = 0.316, Recall: 0.382, Precision: 0.269
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_105 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_106 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_105 (Embedding)       (None, 4, 125)       1836625     input_105[0][0]                  
__________________________________________________________________________________________________
embedding_106 (Embedding)       (None, 4, 56)        13160       input_106[0][0]                  
__________________________________________________________________________________________________
flatten_105 (Flatten)           (None, 500)          0           embedding_105[0][0]              
__________________________________________________________________________________________________
flatten_106 (Flatten)           (None, 224)          0           embedding_106[0][0]              
__________________________________________________________________________________________________
concatenate_53 (Concatenate)    (None, 724)          0           flatten_105[0][0]                
                                                                 flatten_106[0][0]                
__________________________________________________________________________________________________
dense_105 (Dense)               (None, 256)          185600      concatenate_53[0][0]             
__________________________________________________________________________________________________
dropout_53 (Dropout)            (None, 256)          0           dense_105[0][0]                  
__________________________________________________________________________________________________
dense_106 (Dense)               (None, 8)            2056        dropout_53[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4726 - acc: 0.8192 - val_loss: 0.2422 - val_acc: 0.8682
Epoch 2/15
 - 1s - loss: 0.2271 - acc: 0.8623 - val_loss: 0.2286 - val_acc: 0.8670
Epoch 3/15
 - 1s - loss: 0.1960 - acc: 0.8667 - val_loss: 0.2217 - val_acc: 0.8670
Epoch 00003: early stopping
# Training time = 0:00:09.457614
# F-Score(Ordinary) = 0.087, Recall: 0.069, Precision: 0.116
# F-Score(lvc) = 0.064, Recall: 0.038, Precision: 0.205
# F-Score(ireflv) = 0.16, Recall: 0.429, Precision: 0.098
# F-Score(id) = 0.098, Recall: 0.909, Precision: 0.052
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_107 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_108 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_107 (Embedding)       (None, 4, 125)       1836625     input_107[0][0]                  
__________________________________________________________________________________________________
embedding_108 (Embedding)       (None, 4, 56)        13160       input_108[0][0]                  
__________________________________________________________________________________________________
flatten_107 (Flatten)           (None, 500)          0           embedding_107[0][0]              
__________________________________________________________________________________________________
flatten_108 (Flatten)           (None, 224)          0           embedding_108[0][0]              
__________________________________________________________________________________________________
concatenate_54 (Concatenate)    (None, 724)          0           flatten_107[0][0]                
                                                                 flatten_108[0][0]                
__________________________________________________________________________________________________
dense_107 (Dense)               (None, 256)          185600      concatenate_54[0][0]             
__________________________________________________________________________________________________
dropout_54 (Dropout)            (None, 256)          0           dense_107[0][0]                  
__________________________________________________________________________________________________
dense_108 (Dense)               (None, 8)            2056        dropout_54[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4722 - acc: 0.8129 - val_loss: 0.2438 - val_acc: 0.8670
Epoch 2/15
 - 1s - loss: 0.2281 - acc: 0.8619 - val_loss: 0.2224 - val_acc: 0.8706
Epoch 3/15
 - 1s - loss: 0.1946 - acc: 0.8711 - val_loss: 0.2217 - val_acc: 0.8667
Epoch 00003: early stopping
# Training time = 0:00:09.535483
# F-Score(Ordinary) = 0.106, Recall: 0.077, Precision: 0.174
# F-Score(lvc) = 0.042, Recall: 0.024, Precision: 0.159
# F-Score(ireflv) = 0.055, Recall: 0.085, Precision: 0.041
# F-Score(id) = 0.347, Recall: 0.505, Precision: 0.264
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_109 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_110 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_109 (Embedding)       (None, 4, 125)       1836625     input_109[0][0]                  
__________________________________________________________________________________________________
embedding_110 (Embedding)       (None, 4, 56)        13160       input_110[0][0]                  
__________________________________________________________________________________________________
flatten_109 (Flatten)           (None, 500)          0           embedding_109[0][0]              
__________________________________________________________________________________________________
flatten_110 (Flatten)           (None, 224)          0           embedding_110[0][0]              
__________________________________________________________________________________________________
concatenate_55 (Concatenate)    (None, 724)          0           flatten_109[0][0]                
                                                                 flatten_110[0][0]                
__________________________________________________________________________________________________
dense_109 (Dense)               (None, 256)          185600      concatenate_55[0][0]             
__________________________________________________________________________________________________
dropout_55 (Dropout)            (None, 256)          0           dense_109[0][0]                  
__________________________________________________________________________________________________
dense_110 (Dense)               (None, 8)            2056        dropout_55[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4709 - acc: 0.8149 - val_loss: 0.2478 - val_acc: 0.8665
Epoch 2/15
 - 1s - loss: 0.2278 - acc: 0.8635 - val_loss: 0.2282 - val_acc: 0.8685
Epoch 3/15
 - 1s - loss: 0.1941 - acc: 0.8733 - val_loss: 0.2234 - val_acc: 0.8703
Epoch 00003: early stopping
# Training time = 0:00:09.456836
# F-Score(Ordinary) = 0.207, Recall: 0.929, Precision: 0.116
# F-Score(ireflv) = 0.016, Recall: 0.5, Precision: 0.008
# F-Score(id) = 0.413, Recall: 0.944, Precision: 0.264
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_111 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_112 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_111 (Embedding)       (None, 4, 125)       1836625     input_111[0][0]                  
__________________________________________________________________________________________________
embedding_112 (Embedding)       (None, 4, 56)        13160       input_112[0][0]                  
__________________________________________________________________________________________________
flatten_111 (Flatten)           (None, 500)          0           embedding_111[0][0]              
__________________________________________________________________________________________________
flatten_112 (Flatten)           (None, 224)          0           embedding_112[0][0]              
__________________________________________________________________________________________________
concatenate_56 (Concatenate)    (None, 724)          0           flatten_111[0][0]                
                                                                 flatten_112[0][0]                
__________________________________________________________________________________________________
dense_111 (Dense)               (None, 256)          185600      concatenate_56[0][0]             
__________________________________________________________________________________________________
dropout_56 (Dropout)            (None, 256)          0           dense_111[0][0]                  
__________________________________________________________________________________________________
dense_112 (Dense)               (None, 8)            2056        dropout_56[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4735 - acc: 0.8194 - val_loss: 0.2508 - val_acc: 0.8676
Epoch 2/15
 - 1s - loss: 0.2292 - acc: 0.8629 - val_loss: 0.2251 - val_acc: 0.8709
Epoch 3/15
 - 1s - loss: 0.1956 - acc: 0.8703 - val_loss: 0.2205 - val_acc: 0.8703
Epoch 00003: early stopping
# Training time = 0:00:09.505492
# F-Score(Ordinary) = 0.188, Recall: 0.358, Precision: 0.128
# F-Score(lvc) = 0.087, Recall: 0.241, Precision: 0.053
# F-Score(ireflv) = 0.097, Recall: 0.141, Precision: 0.074
# F-Score(id) = 0.317, Recall: 0.621, Precision: 0.212
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_113 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_114 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_113 (Embedding)       (None, 4, 125)       1836625     input_113[0][0]                  
__________________________________________________________________________________________________
embedding_114 (Embedding)       (None, 4, 56)        13160       input_114[0][0]                  
__________________________________________________________________________________________________
flatten_113 (Flatten)           (None, 500)          0           embedding_113[0][0]              
__________________________________________________________________________________________________
flatten_114 (Flatten)           (None, 224)          0           embedding_114[0][0]              
__________________________________________________________________________________________________
concatenate_57 (Concatenate)    (None, 724)          0           flatten_113[0][0]                
                                                                 flatten_114[0][0]                
__________________________________________________________________________________________________
dense_113 (Dense)               (None, 256)          185600      concatenate_57[0][0]             
__________________________________________________________________________________________________
dropout_57 (Dropout)            (None, 256)          0           dense_113[0][0]                  
__________________________________________________________________________________________________
dense_114 (Dense)               (None, 8)            2056        dropout_57[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4770 - acc: 0.8117 - val_loss: 0.2485 - val_acc: 0.8667
Epoch 2/15
 - 1s - loss: 0.2299 - acc: 0.8624 - val_loss: 0.2248 - val_acc: 0.8700
Epoch 3/15
 - 1s - loss: 0.1968 - acc: 0.8705 - val_loss: 0.2204 - val_acc: 0.8715
Epoch 00003: early stopping
# Training time = 0:00:09.541824
# F-Score(Ordinary) = 0.252, Recall: 0.283, Precision: 0.228
# F-Score(ireflv) = 0.21, Recall: 0.148, Precision: 0.361
# F-Score(id) = 0.445, Recall: 0.905, Precision: 0.295
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_115 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_116 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_115 (Embedding)       (None, 4, 125)       1836625     input_115[0][0]                  
__________________________________________________________________________________________________
embedding_116 (Embedding)       (None, 4, 56)        13160       input_116[0][0]                  
__________________________________________________________________________________________________
flatten_115 (Flatten)           (None, 500)          0           embedding_115[0][0]              
__________________________________________________________________________________________________
flatten_116 (Flatten)           (None, 224)          0           embedding_116[0][0]              
__________________________________________________________________________________________________
concatenate_58 (Concatenate)    (None, 724)          0           flatten_115[0][0]                
                                                                 flatten_116[0][0]                
__________________________________________________________________________________________________
dense_115 (Dense)               (None, 256)          185600      concatenate_58[0][0]             
__________________________________________________________________________________________________
dropout_58 (Dropout)            (None, 256)          0           dense_115[0][0]                  
__________________________________________________________________________________________________
dense_116 (Dense)               (None, 8)            2056        dropout_58[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4894 - acc: 0.8110 - val_loss: 0.2439 - val_acc: 0.8667
Epoch 2/15
 - 1s - loss: 0.2302 - acc: 0.8623 - val_loss: 0.2234 - val_acc: 0.8679
Epoch 3/15
 - 1s - loss: 0.1976 - acc: 0.8695 - val_loss: 0.2227 - val_acc: 0.8673
Epoch 00003: early stopping
# Training time = 0:00:09.508485
# F-Score(Ordinary) = 0.108, Recall: 0.075, Precision: 0.192
# F-Score(lvc) = 0.083, Recall: 0.047, Precision: 0.333
# F-Score(ireflv) = 0.199, Recall: 0.158, Precision: 0.27
# F-Score(id) = 0.06, Recall: 1.0, Precision: 0.031
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_117 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_118 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_117 (Embedding)       (None, 4, 125)       1836625     input_117[0][0]                  
__________________________________________________________________________________________________
embedding_118 (Embedding)       (None, 4, 56)        13160       input_118[0][0]                  
__________________________________________________________________________________________________
flatten_117 (Flatten)           (None, 500)          0           embedding_117[0][0]              
__________________________________________________________________________________________________
flatten_118 (Flatten)           (None, 224)          0           embedding_118[0][0]              
__________________________________________________________________________________________________
concatenate_59 (Concatenate)    (None, 724)          0           flatten_117[0][0]                
                                                                 flatten_118[0][0]                
__________________________________________________________________________________________________
dense_117 (Dense)               (None, 256)          185600      concatenate_59[0][0]             
__________________________________________________________________________________________________
dropout_59 (Dropout)            (None, 256)          0           dense_117[0][0]                  
__________________________________________________________________________________________________
dense_118 (Dense)               (None, 8)            2056        dropout_59[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4825 - acc: 0.8160 - val_loss: 0.2477 - val_acc: 0.8653
Epoch 2/15
 - 1s - loss: 0.2283 - acc: 0.8655 - val_loss: 0.2258 - val_acc: 0.8682
Epoch 3/15
 - 1s - loss: 0.1957 - acc: 0.8697 - val_loss: 0.2204 - val_acc: 0.8703
Epoch 00003: early stopping
# Training time = 0:00:09.445028
# F-Score(Ordinary) = 0.21, Recall: 0.187, Precision: 0.239
# F-Score(lvc) = 0.097, Recall: 0.071, Precision: 0.152
# F-Score(ireflv) = 0.201, Recall: 0.166, Precision: 0.254
# F-Score(id) = 0.376, Recall: 0.533, Precision: 0.29
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 125
# POS = True
# POS emb = 56
# Features = False
# Parameters = 2037441
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_119 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
input_120 (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_119 (Embedding)       (None, 4, 125)       1836625     input_119[0][0]                  
__________________________________________________________________________________________________
embedding_120 (Embedding)       (None, 4, 56)        13160       input_120[0][0]                  
__________________________________________________________________________________________________
flatten_119 (Flatten)           (None, 500)          0           embedding_119[0][0]              
__________________________________________________________________________________________________
flatten_120 (Flatten)           (None, 224)          0           embedding_120[0][0]              
__________________________________________________________________________________________________
concatenate_60 (Concatenate)    (None, 724)          0           flatten_119[0][0]                
                                                                 flatten_120[0][0]                
__________________________________________________________________________________________________
dense_119 (Dense)               (None, 256)          185600      concatenate_60[0][0]             
__________________________________________________________________________________________________
dropout_60 (Dropout)            (None, 256)          0           dense_119[0][0]                  
__________________________________________________________________________________________________
dense_120 (Dense)               (None, 8)            2056        dropout_60[0][0]                 
==================================================================================================
Total params: 2,037,441
Trainable params: 2,037,441
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 0.4778 - acc: 0.8141 - val_loss: 0.2486 - val_acc: 0.8673
Epoch 2/15
 - 1s - loss: 0.2267 - acc: 0.8635 - val_loss: 0.2224 - val_acc: 0.8709
Epoch 3/15
 - 1s - loss: 0.1968 - acc: 0.8719 - val_loss: 0.2230 - val_acc: 0.8673
Epoch 00003: early stopping
# Training time = 0:00:12.318753
# F-Score(Ordinary) = 0.118, Recall: 0.083, Precision: 0.204
# F-Score(lvc) = 0.065, Recall: 0.037, Precision: 0.28
# F-Score(id) = 0.371, Recall: 0.622, Precision: 0.264
********************
