INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = True
# POS emb = 56
# Features = False
# Token weight matrix used# POS weight matrix used# Parameters = 3216216
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 4, 200)       2938600     input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 4, 56)        13160       input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 800)          0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 224)          0           embedding_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1024)         0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 256)          262400      concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 8)            2056        dropout_1[0][0]                  
==================================================================================================
Total params: 3,216,216
Trainable params: 3,216,216
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 393870), (1.0, 388780), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
[(0.0, 393870), (1.0, 393870), (2.0, 393870), (4.0, 393870), (5.0, 393870), (6.0, 393870), (7.0, 393870)]
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 2481381 samples, validate on 275709 samples
Epoch 1/15
 - 87s - loss: 0.0203 - acc: 0.9961 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 2/15
 - 88s - loss: 0.0174 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 88s - loss: 0.0174 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 88s - loss: 0.0180 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 88s - loss: 0.0180 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 88s - loss: 0.0188 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 88s - loss: 0.0251 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 88s - loss: 0.0254 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 88s - loss: 0.0258 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 88s - loss: 0.0263 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 88s - loss: 0.0264 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 88s - loss: 0.0268 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 88s - loss: 0.0272 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 88s - loss: 0.0306 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 88s - loss: 0.0329 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 9s - loss: 3.1349e-05 - acc: 1.0000
Epoch 2/15
 - 9s - loss: 1.2537e-07 - acc: 1.0000
Epoch 3/15
 - 9s - loss: 5.8580e-05 - acc: 1.0000
Epoch 4/15
 - 9s - loss: 1.7048e-06 - acc: 1.0000
Epoch 5/15
 - 9s - loss: 5.8580e-05 - acc: 1.0000
Epoch 6/15
 - 9s - loss: 5.8580e-05 - acc: 1.0000
Epoch 7/15
 - 9s - loss: 1.1704e-04 - acc: 1.0000
Epoch 8/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 9/15
 - 9s - loss: 5.8580e-05 - acc: 1.0000
Epoch 10/15
 - 9s - loss: 5.8580e-05 - acc: 1.0000
Epoch 11/15
 - 9s - loss: 5.8580e-05 - acc: 1.0000
Epoch 12/15
 - 9s - loss: 5.8588e-05 - acc: 1.0000
Epoch 13/15
 - 9s - loss: 1.1922e-07 - acc: 1.0000
Epoch 14/15
 - 9s - loss: 5.8580e-05 - acc: 1.0000
Epoch 15/15
 - 9s - loss: 5.8580e-05 - acc: 1.0000
# Training time = 0:25:38.106856
# F-Score(Ordinary) = 0.593, Recall: 0.531, Precision: 0.671
# F-Score(lvc) = 0.426, Recall: 0.364, Precision: 0.515
# F-Score(ireflv) = 0.747, Recall: 0.711, Precision: 0.787
# F-Score(id) = 0.578, Recall: 0.519, Precision: 0.653
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = True
# POS emb = 56
# Features = False
# Token weight matrix used# POS weight matrix used# Parameters = 3216216
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 4, 200)       2938600     input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 4, 56)        13160       input_4[0][0]                    
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 800)          0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 224)          0           embedding_4[0][0]                
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 1024)         0           flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 256)          262400      concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 256)          0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 8)            2056        dropout_2[0][0]                  
==================================================================================================
Total params: 3,216,216
Trainable params: 3,216,216
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 393870), (1.0, 388780), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
[(0.0, 393870), (1.0, 393870), (2.0, 393870), (4.0, 393870), (5.0, 393870), (6.0, 393870), (7.0, 393870)]
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 2481381 samples, validate on 275709 samples
Epoch 1/15
 - 88s - loss: 0.0203 - acc: 0.9961 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 2/15
 - 88s - loss: 0.0177 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 89s - loss: 0.0184 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 88s - loss: 0.0188 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 88s - loss: 0.0197 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 88s - loss: 0.0203 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 88s - loss: 0.0241 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 88s - loss: 0.0257 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 89s - loss: 0.0254 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 88s - loss: 0.0256 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 88s - loss: 0.0258 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 92s - loss: 0.0256 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 88s - loss: 0.0259 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 88s - loss: 0.0264 - acc: 0.9975 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 88s - loss: 0.0258 - acc: 0.9975 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 10s - loss: 9.4600e-05 - acc: 1.0000
Epoch 2/15
 - 10s - loss: 4.2744e-05 - acc: 1.0000
Epoch 3/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 4/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 5/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 6/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 7/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 8/15
 - 10s - loss: 1.1921e-07 - acc: 1.0000
Epoch 9/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 10/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 11/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 12/15
 - 9s - loss: 1.3540e-04 - acc: 1.0000
Epoch 13/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 14/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 15/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
# Training time = 0:25:40.797965
# F-Score(Ordinary) = 0.559, Recall: 0.604, Precision: 0.521
# F-Score(lvc) = 0.429, Recall: 0.844, Precision: 0.288
# F-Score(ireflv) = 0.763, Recall: 0.882, Precision: 0.672
# F-Score(id) = 0.478, Recall: 0.427, Precision: 0.544
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = True
# POS emb = 56
# Features = False
# Token weight matrix used# POS weight matrix used# Parameters = 3216216
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 4, 200)       2938600     input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 4, 56)        13160       input_6[0][0]                    
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 800)          0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 224)          0           embedding_6[0][0]                
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 1024)         0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 256)          262400      concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 256)          0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 8)            2056        dropout_3[0][0]                  
==================================================================================================
Total params: 3,216,216
Trainable params: 3,216,216
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 393870), (1.0, 388780), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
[(0.0, 393870), (1.0, 393870), (2.0, 393870), (4.0, 393870), (5.0, 393870), (6.0, 393870), (7.0, 393870)]
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 2481381 samples, validate on 275709 samples
Epoch 1/15
 - 87s - loss: 0.0202 - acc: 0.9961 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 2/15
 - 87s - loss: 0.0173 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 87s - loss: 0.0169 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 87s - loss: 0.0178 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 87s - loss: 0.0175 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 87s - loss: 0.0174 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 87s - loss: 0.0197 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 87s - loss: 0.0188 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 87s - loss: 0.0184 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 87s - loss: 0.0195 - acc: 0.9970 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 87s - loss: 0.0224 - acc: 0.9970 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 87s - loss: 0.0234 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 87s - loss: 0.0257 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 87s - loss: 0.0275 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 87s - loss: 0.0279 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 9s - loss: 6.6006e-04 - acc: 1.0000
Epoch 2/15
 - 9s - loss: 5.6674e-04 - acc: 1.0000
Epoch 3/15
 - 9s - loss: 1.5429e-04 - acc: 1.0000
Epoch 4/15
 - 9s - loss: 6.6619e-05 - acc: 1.0000
Epoch 5/15
 - 9s - loss: 5.8580e-05 - acc: 1.0000
Epoch 6/15
 - 9s - loss: 1.0937e-04 - acc: 1.0000
Epoch 7/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 8/15
 - 9s - loss: 3.6036e-05 - acc: 1.0000
Epoch 9/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 10/15
 - 9s - loss: 4.0895e-05 - acc: 1.0000
Epoch 11/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 12/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 13/15
 - 9s - loss: 2.3506e-05 - acc: 1.0000
Epoch 14/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 15/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
# Training time = 0:25:15.743380
# F-Score(Ordinary) = 0.679, Recall: 0.765, Precision: 0.611
# F-Score(lvc) = 0.512, Recall: 0.707, Precision: 0.402
# F-Score(ireflv) = 0.662, Recall: 0.585, Precision: 0.762
# F-Score(id) = 0.709, Recall: 0.911, Precision: 0.58
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = True
# POS emb = 56
# Features = False
# Token weight matrix used# POS weight matrix used# Parameters = 3216216
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 4, 200)       2938600     input_7[0][0]                    
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 4, 56)        13160       input_8[0][0]                    
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 800)          0           embedding_7[0][0]                
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 224)          0           embedding_8[0][0]                
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 1024)         0           flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 256)          262400      concatenate_4[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 256)          0           dense_7[0][0]                    
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 8)            2056        dropout_4[0][0]                  
==================================================================================================
Total params: 3,216,216
Trainable params: 3,216,216
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 393870), (1.0, 388780), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
[(0.0, 393870), (1.0, 393870), (2.0, 393870), (4.0, 393870), (5.0, 393870), (6.0, 393870), (7.0, 393870)]
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 2481381 samples, validate on 275709 samples
Epoch 1/15
 - 92s - loss: 0.0204 - acc: 0.9961 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 2/15
 - 92s - loss: 0.0172 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 92s - loss: 0.0174 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 92s - loss: 0.0177 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 92s - loss: 0.0176 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 92s - loss: 0.0178 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 92s - loss: 0.0175 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 92s - loss: 0.0191 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 92s - loss: 0.0198 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 92s - loss: 0.0219 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 92s - loss: 0.0268 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 92s - loss: 0.0278 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 92s - loss: 0.0281 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 92s - loss: 0.0278 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 92s - loss: 0.0273 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 10s - loss: 1.2094e-04 - acc: 1.0000
Epoch 2/15
 - 10s - loss: 2.4656e-05 - acc: 1.0000
Epoch 3/15
 - 10s - loss: 1.4681e-07 - acc: 1.0000
Epoch 4/15
 - 10s - loss: 1.2310e-07 - acc: 1.0000
Epoch 5/15
 - 10s - loss: 9.2113e-05 - acc: 1.0000
Epoch 6/15
 - 10s - loss: 1.1933e-07 - acc: 1.0000
Epoch 7/15
 - 10s - loss: 1.1923e-07 - acc: 1.0000
Epoch 8/15
 - 10s - loss: 1.1921e-07 - acc: 1.0000
Epoch 9/15
 - 10s - loss: 1.1921e-07 - acc: 1.0000
Epoch 10/15
 - 10s - loss: 1.1921e-07 - acc: 1.0000
Epoch 11/15
 - 10s - loss: 1.1921e-07 - acc: 1.0000
Epoch 12/15
 - 10s - loss: 4.5780e-05 - acc: 1.0000
Epoch 13/15
 - 10s - loss: 9.0752e-05 - acc: 1.0000
Epoch 14/15
 - 10s - loss: 4.5114e-05 - acc: 1.0000
Epoch 15/15
 - 10s - loss: 1.1921e-07 - acc: 1.0000
# Training time = 0:26:38.223963
# F-Score(Ordinary) = 0.627, Recall: 0.596, Precision: 0.662
# F-Score(lvc) = 0.591, Recall: 0.845, Precision: 0.455
# F-Score(ireflv) = 0.846, Recall: 0.884, Precision: 0.811
# F-Score(id) = 0.481, Recall: 0.389, Precision: 0.632
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = True
# POS emb = 56
# Features = False
# Token weight matrix used# POS weight matrix used# Parameters = 3216216
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_10 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 4, 200)       2938600     input_9[0][0]                    
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 4, 56)        13160       input_10[0][0]                   
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 800)          0           embedding_9[0][0]                
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 224)          0           embedding_10[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 1024)         0           flatten_9[0][0]                  
                                                                 flatten_10[0][0]                 
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 256)          262400      concatenate_5[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 256)          0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 8)            2056        dropout_5[0][0]                  
==================================================================================================
Total params: 3,216,216
Trainable params: 3,216,216
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 393870), (1.0, 388780), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
[(0.0, 393870), (1.0, 393870), (2.0, 393870), (4.0, 393870), (5.0, 393870), (6.0, 393870), (7.0, 393870)]
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 2481381 samples, validate on 275709 samples
Epoch 1/15
 - 87s - loss: 0.0202 - acc: 0.9961 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 2/15
 - 87s - loss: 0.0174 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 87s - loss: 0.0181 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 87s - loss: 0.0172 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 87s - loss: 0.0177 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 87s - loss: 0.0185 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 87s - loss: 0.0190 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 89s - loss: 0.0218 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 87s - loss: 0.0246 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 87s - loss: 0.0229 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 87s - loss: 0.0240 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 87s - loss: 0.0263 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 87s - loss: 0.0263 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 88s - loss: 0.0266 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 89s - loss: 0.0273 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 9s - loss: 2.9301e-04 - acc: 1.0000
Epoch 2/15
 - 9s - loss: 7.8134e-05 - acc: 1.0000
Epoch 3/15
 - 9s - loss: 3.6100e-05 - acc: 1.0000
Epoch 4/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 5/15
 - 9s - loss: 3.0318e-06 - acc: 1.0000
Epoch 6/15
 - 9s - loss: 6.5526e-06 - acc: 1.0000
Epoch 7/15
 - 9s - loss: 4.4352e-05 - acc: 1.0000
Epoch 8/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 9/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 10/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 11/15
 - 9s - loss: 4.4187e-05 - acc: 1.0000
Epoch 12/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 13/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 14/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 15/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
# Training time = 0:25:19.268152
# F-Score(Ordinary) = 0.62, Recall: 0.596, Precision: 0.647
# F-Score(lvc) = 0.591, Recall: 0.934, Precision: 0.432
# F-Score(ireflv) = 0.838, Recall: 0.897, Precision: 0.787
# F-Score(id) = 0.494, Recall: 0.397, Precision: 0.653
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = True
# POS emb = 56
# Features = False
# Token weight matrix used# POS weight matrix used# Parameters = 3216216
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 4, 200)       2938600     input_11[0][0]                   
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 4, 56)        13160       input_12[0][0]                   
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 800)          0           embedding_11[0][0]               
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 224)          0           embedding_12[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 1024)         0           flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 256)          262400      concatenate_6[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 256)          0           dense_11[0][0]                   
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 8)            2056        dropout_6[0][0]                  
==================================================================================================
Total params: 3,216,216
Trainable params: 3,216,216
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 393870), (1.0, 388780), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
[(0.0, 393870), (1.0, 393870), (2.0, 393870), (4.0, 393870), (5.0, 393870), (6.0, 393870), (7.0, 393870)]
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 2481381 samples, validate on 275709 samples
Epoch 1/15
 - 95s - loss: 0.0203 - acc: 0.9960 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 2/15
 - 96s - loss: 0.0173 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 96s - loss: 0.0180 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 96s - loss: 0.0182 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 96s - loss: 0.0193 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 96s - loss: 0.0195 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 96s - loss: 0.0213 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 96s - loss: 0.0229 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 96s - loss: 0.0240 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 95s - loss: 0.0269 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 95s - loss: 0.0273 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 96s - loss: 0.0270 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 96s - loss: 0.0280 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 96s - loss: 0.0279 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 95s - loss: 0.0273 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 10s - loss: 1.4900e-04 - acc: 1.0000
Epoch 2/15
 - 10s - loss: 2.5981e-04 - acc: 1.0000
Epoch 3/15
 - 10s - loss: 1.0276e-04 - acc: 1.0000
Epoch 4/15
 - 10s - loss: 2.0309e-04 - acc: 1.0000
Epoch 5/15
 - 10s - loss: 2.0013e-04 - acc: 1.0000
Epoch 6/15
 - 10s - loss: 4.9719e-05 - acc: 1.0000
Epoch 7/15
 - 10s - loss: 1.4759e-04 - acc: 1.0000
Epoch 8/15
 - 10s - loss: 9.7405e-05 - acc: 1.0000
Epoch 9/15
 - 10s - loss: 1.9231e-04 - acc: 1.0000
Epoch 10/15
 - 10s - loss: 4.7690e-05 - acc: 1.0000
Epoch 11/15
 - 10s - loss: 1.4162e-04 - acc: 1.0000
Epoch 12/15
 - 10s - loss: 1.3991e-04 - acc: 1.0000
Epoch 13/15
 - 10s - loss: 2.2930e-04 - acc: 1.0000
Epoch 14/15
 - 10s - loss: 4.5427e-05 - acc: 1.0000
Epoch 15/15
 - 10s - loss: 1.7926e-04 - acc: 1.0000
# Training time = 0:27:39.714723
# F-Score(Ordinary) = 0.622, Recall: 0.661, Precision: 0.588
# F-Score(lvc) = 0.503, Recall: 0.855, Precision: 0.356
# F-Score(ireflv) = 0.83, Recall: 0.912, Precision: 0.762
# F-Score(id) = 0.535, Recall: 0.481, Precision: 0.601
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = True
# POS emb = 56
# Features = False
# Token weight matrix used# POS weight matrix used# Parameters = 3216216
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_14 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 4, 200)       2938600     input_13[0][0]                   
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 4, 56)        13160       input_14[0][0]                   
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 800)          0           embedding_13[0][0]               
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 224)          0           embedding_14[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 1024)         0           flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 256)          262400      concatenate_7[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 256)          0           dense_13[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 8)            2056        dropout_7[0][0]                  
==================================================================================================
Total params: 3,216,216
Trainable params: 3,216,216
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 393870), (1.0, 388780), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
[(0.0, 393870), (1.0, 393870), (2.0, 393870), (4.0, 393870), (5.0, 393870), (6.0, 393870), (7.0, 393870)]
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 2481381 samples, validate on 275709 samples
Epoch 1/15
 - 87s - loss: 0.0203 - acc: 0.9961 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 2/15
 - 87s - loss: 0.0173 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 87s - loss: 0.0176 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 88s - loss: 0.0181 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 87s - loss: 0.0176 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 87s - loss: 0.0193 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 87s - loss: 0.0230 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 87s - loss: 0.0255 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 87s - loss: 0.0269 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 87s - loss: 0.0278 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 89s - loss: 0.0268 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 87s - loss: 0.0288 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 87s - loss: 0.0318 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 87s - loss: 0.0316 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 87s - loss: 0.0317 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 9s - loss: 4.8085e-05 - acc: 1.0000
Epoch 2/15
 - 9s - loss: 1.3286e-07 - acc: 1.0000
Epoch 3/15
 - 9s - loss: 1.2595e-07 - acc: 1.0000
Epoch 4/15
 - 9s - loss: 5.3980e-05 - acc: 1.0000
Epoch 5/15
 - 9s - loss: 1.1936e-07 - acc: 1.0000
Epoch 6/15
 - 9s - loss: 1.1924e-07 - acc: 1.0000
Epoch 7/15
 - 9s - loss: 5.3096e-05 - acc: 1.0000
Epoch 8/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 9/15
 - 9s - loss: 2.6325e-05 - acc: 1.0000
Epoch 10/15
 - 9s - loss: 5.1845e-05 - acc: 1.0000
Epoch 11/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 12/15
 - 9s - loss: 2.5655e-05 - acc: 1.0000
Epoch 13/15
 - 9s - loss: 5.0502e-05 - acc: 1.0000
Epoch 14/15
 - 9s - loss: 4.9624e-05 - acc: 1.0000
Epoch 15/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
# Training time = 0:25:23.438669
# F-Score(Ordinary) = 0.644, Recall: 0.691, Precision: 0.604
# F-Score(lvc) = 0.518, Recall: 0.785, Precision: 0.386
# F-Score(ireflv) = 0.807, Recall: 0.847, Precision: 0.77
# F-Score(id) = 0.569, Recall: 0.54, Precision: 0.601
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = True
# POS emb = 56
# Features = False
# Token weight matrix used# POS weight matrix used# Parameters = 3216216
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_15 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_16 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_15 (Embedding)        (None, 4, 200)       2938600     input_15[0][0]                   
__________________________________________________________________________________________________
embedding_16 (Embedding)        (None, 4, 56)        13160       input_16[0][0]                   
__________________________________________________________________________________________________
flatten_15 (Flatten)            (None, 800)          0           embedding_15[0][0]               
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 224)          0           embedding_16[0][0]               
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 1024)         0           flatten_15[0][0]                 
                                                                 flatten_16[0][0]                 
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 256)          262400      concatenate_8[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 256)          0           dense_15[0][0]                   
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 8)            2056        dropout_8[0][0]                  
==================================================================================================
Total params: 3,216,216
Trainable params: 3,216,216
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 393870), (1.0, 388780), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
[(0.0, 393870), (1.0, 393870), (2.0, 393870), (4.0, 393870), (5.0, 393870), (6.0, 393870), (7.0, 393870)]
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 2481381 samples, validate on 275709 samples
Epoch 1/15
 - 88s - loss: 0.0203 - acc: 0.9960 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 2/15
 - 88s - loss: 0.0176 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 88s - loss: 0.0176 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 88s - loss: 0.0178 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 88s - loss: 0.0186 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 88s - loss: 0.0204 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 88s - loss: 0.0199 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 88s - loss: 0.0217 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 88s - loss: 0.0242 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 88s - loss: 0.0244 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 88s - loss: 0.0253 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 88s - loss: 0.0252 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 88s - loss: 0.0260 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 88s - loss: 0.0272 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 88s - loss: 0.0289 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 9s - loss: 1.8840e-04 - acc: 1.0000
Epoch 2/15
 - 9s - loss: 4.9814e-05 - acc: 1.0000
Epoch 3/15
 - 9s - loss: 3.3019e-05 - acc: 1.0000
Epoch 4/15
 - 9s - loss: 6.4977e-05 - acc: 1.0000
Epoch 5/15
 - 9s - loss: 1.1984e-07 - acc: 1.0000
Epoch 6/15
 - 9s - loss: 1.1935e-07 - acc: 1.0000
Epoch 7/15
 - 9s - loss: 3.2283e-05 - acc: 1.0000
Epoch 8/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 9/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 10/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 11/15
 - 9s - loss: 3.2053e-05 - acc: 1.0000
Epoch 12/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 13/15
 - 9s - loss: 3.1823e-05 - acc: 1.0000
Epoch 14/15
 - 9s - loss: 6.2851e-05 - acc: 1.0000
Epoch 15/15
 - 9s - loss: 9.2603e-05 - acc: 1.0000
# Training time = 0:25:33.875946
# F-Score(Ordinary) = 0.627, Recall: 0.671, Precision: 0.588
# F-Score(lvc) = 0.438, Recall: 0.445, Precision: 0.432
# F-Score(ireflv) = 0.814, Recall: 0.885, Precision: 0.754
# F-Score(id) = 0.623, Recall: 0.688, Precision: 0.57
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = True
# POS emb = 56
# Features = False
# Token weight matrix used# POS weight matrix used# Parameters = 3216216
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_17 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_18 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_17 (Embedding)        (None, 4, 200)       2938600     input_17[0][0]                   
__________________________________________________________________________________________________
embedding_18 (Embedding)        (None, 4, 56)        13160       input_18[0][0]                   
__________________________________________________________________________________________________
flatten_17 (Flatten)            (None, 800)          0           embedding_17[0][0]               
__________________________________________________________________________________________________
flatten_18 (Flatten)            (None, 224)          0           embedding_18[0][0]               
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 1024)         0           flatten_17[0][0]                 
                                                                 flatten_18[0][0]                 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 256)          262400      concatenate_9[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 256)          0           dense_17[0][0]                   
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 8)            2056        dropout_9[0][0]                  
==================================================================================================
Total params: 3,216,216
Trainable params: 3,216,216
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 393870), (1.0, 388780), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
[(0.0, 393870), (1.0, 393870), (2.0, 393870), (4.0, 393870), (5.0, 393870), (6.0, 393870), (7.0, 393870)]
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 2481381 samples, validate on 275709 samples
Epoch 1/15
 - 87s - loss: 0.0204 - acc: 0.9960 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 2/15
 - 87s - loss: 0.0173 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 87s - loss: 0.0185 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 87s - loss: 0.0168 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 87s - loss: 0.0174 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 87s - loss: 0.0188 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 87s - loss: 0.0206 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 88s - loss: 0.0185 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 87s - loss: 0.0228 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 87s - loss: 0.0234 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 87s - loss: 0.0269 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 87s - loss: 0.0271 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 87s - loss: 0.0266 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 87s - loss: 0.0273 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 87s - loss: 0.0283 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 9s - loss: 1.7079e-07 - acc: 1.0000
Epoch 2/15
 - 9s - loss: 1.5234e-07 - acc: 1.0000
Epoch 3/15
 - 9s - loss: 1.8955e-05 - acc: 1.0000
Epoch 4/15
 - 9s - loss: 9.9926e-06 - acc: 1.0000
Epoch 5/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 6/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 7/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 8/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 9/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 10/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 11/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 12/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 13/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 14/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
Epoch 15/15
 - 9s - loss: 1.1921e-07 - acc: 1.0000
# Training time = 0:25:12.945064
# F-Score(Ordinary) = 0.632, Recall: 0.697, Precision: 0.577
# F-Score(lvc) = 0.551, Recall: 0.962, Precision: 0.386
# F-Score(ireflv) = 0.74, Recall: 0.895, Precision: 0.631
# F-Score(id) = 0.566, Recall: 0.519, Precision: 0.622
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = True
# POS emb = 56
# Features = False
# Token weight matrix used# POS weight matrix used# Parameters = 3216216
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_19 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_20 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_19 (Embedding)        (None, 4, 200)       2938600     input_19[0][0]                   
__________________________________________________________________________________________________
embedding_20 (Embedding)        (None, 4, 56)        13160       input_20[0][0]                   
__________________________________________________________________________________________________
flatten_19 (Flatten)            (None, 800)          0           embedding_19[0][0]               
__________________________________________________________________________________________________
flatten_20 (Flatten)            (None, 224)          0           embedding_20[0][0]               
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 1024)         0           flatten_19[0][0]                 
                                                                 flatten_20[0][0]                 
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 256)          262400      concatenate_10[0][0]             
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 256)          0           dense_19[0][0]                   
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 8)            2056        dropout_10[0][0]                 
==================================================================================================
Total params: 3,216,216
Trainable params: 3,216,216
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 393870), (1.0, 388780), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
[(0.0, 393870), (1.0, 393870), (2.0, 393870), (4.0, 393870), (5.0, 393870), (6.0, 393870), (7.0, 393870)]
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 2481381 samples, validate on 275709 samples
Epoch 1/15
 - 91s - loss: 0.0204 - acc: 0.9960 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 2/15
 - 91s - loss: 0.0175 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 91s - loss: 0.0178 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 91s - loss: 0.0174 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 91s - loss: 0.0182 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 91s - loss: 0.0209 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 91s - loss: 0.0230 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 91s - loss: 0.0260 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 95s - loss: 0.0265 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 90s - loss: 0.0268 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 91s - loss: 0.0281 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 91s - loss: 0.0318 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 92s - loss: 0.0315 - acc: 0.9974 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 91s - loss: 0.0316 - acc: 0.9975 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 92s - loss: 0.0321 - acc: 0.9975 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 10s - loss: 2.6131e-04 - acc: 1.0000
Epoch 2/15
 - 10s - loss: 1.1704e-04 - acc: 1.0000
Epoch 3/15
 - 10s - loss: 1.1704e-04 - acc: 1.0000
Epoch 4/15
 - 10s - loss: 6.2301e-04 - acc: 1.0000
Epoch 5/15
 - 10s - loss: 5.8580e-05 - acc: 1.0000
Epoch 6/15
 - 10s - loss: 9.6637e-05 - acc: 1.0000
Epoch 7/15
 - 10s - loss: 9.6406e-05 - acc: 1.0000
Epoch 8/15
 - 10s - loss: 2.1310e-04 - acc: 1.0000
Epoch 9/15
 - 10s - loss: 9.5949e-05 - acc: 1.0000
Epoch 10/15
 - 10s - loss: 3.2957e-04 - acc: 1.0000
Epoch 11/15
 - 10s - loss: 2.3396e-04 - acc: 1.0000
Epoch 12/15
 - 10s - loss: 1.9065e-04 - acc: 1.0000
Epoch 13/15
 - 10s - loss: 5.8580e-05 - acc: 1.0000
Epoch 14/15
 - 10s - loss: 1.3134e-04 - acc: 1.0000
Epoch 15/15
 - 10s - loss: 3.6433e-04 - acc: 1.0000
# Training time = 0:26:23.619131
# F-Score(Ordinary) = 0.662, Recall: 0.699, Precision: 0.629
# F-Score(lvc) = 0.545, Recall: 0.927, Precision: 0.386
# F-Score(ireflv) = 0.779, Recall: 0.764, Precision: 0.795
# F-Score(id) = 0.6, Recall: 0.564, Precision: 0.642
********************
