INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 4, 48)        705264      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 4, 24)        5640        input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 192)          0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 96)           0           embedding_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 288)          0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 24)           6936        concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24)           0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 8)            200         dropout_1[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.8132 - acc: 0.9390 - val_loss: 0.1499 - val_acc: 0.9576
Epoch 2/15
 - 5s - loss: 0.5649 - acc: 0.9629 - val_loss: 0.1002 - val_acc: 0.9616
Epoch 3/15
 - 5s - loss: 0.4286 - acc: 0.9678 - val_loss: 0.1066 - val_acc: 0.9609
Epoch 4/15
 - 5s - loss: 0.2935 - acc: 0.9693 - val_loss: 0.1110 - val_acc: 0.9635
Epoch 5/15
 - 5s - loss: 0.3571 - acc: 0.9715 - val_loss: 0.1094 - val_acc: 0.9648
Epoch 6/15
 - 5s - loss: 0.2660 - acc: 0.9727 - val_loss: 0.1210 - val_acc: 0.9642
Epoch 7/15
 - 5s - loss: 0.3353 - acc: 0.9732 - val_loss: 0.1256 - val_acc: 0.9650
Epoch 8/15
 - 5s - loss: 0.1605 - acc: 0.9740 - val_loss: 0.1362 - val_acc: 0.9624
Epoch 9/15
 - 5s - loss: 0.3605 - acc: 0.9744 - val_loss: 0.1369 - val_acc: 0.9652
Epoch 10/15
 - 5s - loss: 0.1830 - acc: 0.9748 - val_loss: 0.1473 - val_acc: 0.9659
Epoch 11/15
 - 5s - loss: 0.0992 - acc: 0.9751 - val_loss: 0.1325 - val_acc: 0.9639
Epoch 12/15
 - 5s - loss: 0.2816 - acc: 0.9755 - val_loss: 0.1383 - val_acc: 0.9646
Epoch 13/15
 - 5s - loss: 0.0734 - acc: 0.9756 - val_loss: 0.1577 - val_acc: 0.9656
Epoch 14/15
 - 5s - loss: 0.0500 - acc: 0.9762 - val_loss: 0.1451 - val_acc: 0.9659
Epoch 15/15
 - 5s - loss: 0.0437 - acc: 0.9759 - val_loss: 0.1522 - val_acc: 0.9654
# Training time = 0:01:39.960152
# F-Score(Ordinary) = 0.586, Recall: 0.487, Precision: 0.734
# F-Score(lvc) = 0.438, Recall: 0.353, Precision: 0.576
# F-Score(ireflv) = 0.712, Recall: 0.592, Precision: 0.893
# F-Score(id) = 0.574, Recall: 0.489, Precision: 0.694
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 4, 48)        705264      input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 4, 24)        5640        input_4[0][0]                    
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 192)          0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 96)           0           embedding_4[0][0]                
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 288)          0           flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 24)           6936        concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24)           0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 8)            200         dropout_2[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.1468 - acc: 0.9295 - val_loss: 0.1156 - val_acc: 0.9590
Epoch 2/15
 - 5s - loss: 1.6538 - acc: 0.9629 - val_loss: 0.0979 - val_acc: 0.9633
Epoch 3/15
 - 5s - loss: 0.4163 - acc: 0.9669 - val_loss: 0.1025 - val_acc: 0.9625
Epoch 4/15
 - 5s - loss: 0.4994 - acc: 0.9693 - val_loss: 0.1043 - val_acc: 0.9639
Epoch 5/15
 - 5s - loss: 0.2614 - acc: 0.9715 - val_loss: 0.1145 - val_acc: 0.9648
Epoch 6/15
 - 5s - loss: 0.1901 - acc: 0.9730 - val_loss: 0.1176 - val_acc: 0.9636
Epoch 7/15
 - 5s - loss: 0.1318 - acc: 0.9740 - val_loss: 0.1256 - val_acc: 0.9640
Epoch 8/15
 - 5s - loss: 0.0919 - acc: 0.9740 - val_loss: 0.1272 - val_acc: 0.9647
Epoch 9/15
 - 5s - loss: 0.0754 - acc: 0.9745 - val_loss: 0.1303 - val_acc: 0.9635
Epoch 10/15
 - 5s - loss: 0.0466 - acc: 0.9745 - val_loss: 0.1463 - val_acc: 0.9620
Epoch 11/15
 - 5s - loss: 0.0461 - acc: 0.9749 - val_loss: 0.1471 - val_acc: 0.9639
Epoch 12/15
 - 5s - loss: 0.0585 - acc: 0.9749 - val_loss: 0.1511 - val_acc: 0.9637
Epoch 13/15
 - 5s - loss: 0.0431 - acc: 0.9755 - val_loss: 0.1649 - val_acc: 0.9639
Epoch 14/15
 - 5s - loss: 0.0436 - acc: 0.9755 - val_loss: 0.1811 - val_acc: 0.9645
Epoch 15/15
 - 5s - loss: 0.0422 - acc: 0.9758 - val_loss: 0.1672 - val_acc: 0.9632
# Training time = 0:01:32.687029
# F-Score(Ordinary) = 0.524, Recall: 0.404, Precision: 0.745
# F-Score(lvc) = 0.411, Recall: 0.317, Precision: 0.583
# F-Score(ireflv) = 0.723, Recall: 0.6, Precision: 0.91
# F-Score(id) = 0.461, Recall: 0.343, Precision: 0.705
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 4, 48)        705264      input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 4, 24)        5640        input_6[0][0]                    
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 192)          0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 96)           0           embedding_6[0][0]                
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 288)          0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 24)           6936        concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24)           0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 8)            200         dropout_3[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.6780 - acc: 0.9363 - val_loss: 0.1095 - val_acc: 0.9577
Epoch 2/15
 - 5s - loss: 0.8655 - acc: 0.9616 - val_loss: 0.1096 - val_acc: 0.9589
Epoch 3/15
 - 5s - loss: 0.2945 - acc: 0.9670 - val_loss: 0.1184 - val_acc: 0.9637
Epoch 4/15
 - 5s - loss: 0.5085 - acc: 0.9698 - val_loss: 0.1108 - val_acc: 0.9637
Epoch 5/15
 - 5s - loss: 0.2108 - acc: 0.9712 - val_loss: 0.1374 - val_acc: 0.9641
Epoch 6/15
 - 5s - loss: 0.0795 - acc: 0.9721 - val_loss: 0.1314 - val_acc: 0.9664
Epoch 7/15
 - 5s - loss: 0.0534 - acc: 0.9733 - val_loss: 0.1369 - val_acc: 0.9660
Epoch 8/15
 - 5s - loss: 0.0473 - acc: 0.9739 - val_loss: 0.1373 - val_acc: 0.9654
Epoch 9/15
 - 5s - loss: 0.1691 - acc: 0.9739 - val_loss: 0.1665 - val_acc: 0.9647
Epoch 10/15
 - 5s - loss: 0.0950 - acc: 0.9745 - val_loss: 0.1837 - val_acc: 0.9641
Epoch 11/15
 - 5s - loss: 0.0501 - acc: 0.9747 - val_loss: 0.1579 - val_acc: 0.9637
Epoch 12/15
 - 5s - loss: 0.0688 - acc: 0.9752 - val_loss: 0.1814 - val_acc: 0.9634
Epoch 13/15
 - 5s - loss: 0.0410 - acc: 0.9755 - val_loss: 0.2075 - val_acc: 0.9645
Epoch 14/15
 - 5s - loss: 0.0414 - acc: 0.9757 - val_loss: 0.1948 - val_acc: 0.9639
Epoch 15/15
 - 5s - loss: 0.0404 - acc: 0.9758 - val_loss: 0.2123 - val_acc: 0.9635
# Training time = 0:01:31.093886
# F-Score(Ordinary) = 0.448, Recall: 0.325, Precision: 0.723
# F-Score(lvc) = 0.402, Recall: 0.319, Precision: 0.545
# F-Score(ireflv) = 0.671, Recall: 0.537, Precision: 0.893
# F-Score(id) = 0.35, Recall: 0.235, Precision: 0.689
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 4, 48)        705264      input_7[0][0]                    
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 4, 24)        5640        input_8[0][0]                    
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 192)          0           embedding_7[0][0]                
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 96)           0           embedding_8[0][0]                
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 288)          0           flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 24)           6936        concatenate_4[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24)           0           dense_7[0][0]                    
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 8)            200         dropout_4[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.6559 - acc: 0.9131 - val_loss: 0.1158 - val_acc: 0.9588
Epoch 2/15
 - 5s - loss: 1.0187 - acc: 0.9623 - val_loss: 0.1023 - val_acc: 0.9643
Epoch 3/15
 - 5s - loss: 0.4712 - acc: 0.9681 - val_loss: 0.1076 - val_acc: 0.9638
Epoch 4/15
 - 5s - loss: 0.6501 - acc: 0.9706 - val_loss: 0.1180 - val_acc: 0.9648
Epoch 5/15
 - 5s - loss: 0.3701 - acc: 0.9720 - val_loss: 0.1110 - val_acc: 0.9638
Epoch 6/15
 - 5s - loss: 0.2442 - acc: 0.9725 - val_loss: 0.1203 - val_acc: 0.9645
Epoch 7/15
 - 5s - loss: 0.0747 - acc: 0.9733 - val_loss: 0.1275 - val_acc: 0.9644
Epoch 8/15
 - 5s - loss: 0.0817 - acc: 0.9737 - val_loss: 0.1363 - val_acc: 0.9646
Epoch 9/15
 - 5s - loss: 0.0476 - acc: 0.9741 - val_loss: 0.1456 - val_acc: 0.9654
Epoch 10/15
 - 5s - loss: 0.0444 - acc: 0.9748 - val_loss: 0.1563 - val_acc: 0.9659
Epoch 11/15
 - 5s - loss: 0.0439 - acc: 0.9750 - val_loss: 0.1517 - val_acc: 0.9654
Epoch 12/15
 - 5s - loss: 0.0419 - acc: 0.9752 - val_loss: 0.1731 - val_acc: 0.9629
Epoch 13/15
 - 5s - loss: 0.0412 - acc: 0.9754 - val_loss: 0.1660 - val_acc: 0.9641
Epoch 14/15
 - 5s - loss: 0.0402 - acc: 0.9755 - val_loss: 0.1790 - val_acc: 0.9656
Epoch 15/15
 - 5s - loss: 0.0400 - acc: 0.9758 - val_loss: 0.1903 - val_acc: 0.9637
# Training time = 0:01:30.879030
# F-Score(Ordinary) = 0.467, Recall: 0.349, Precision: 0.705
# F-Score(lvc) = 0.523, Recall: 0.531, Precision: 0.515
# F-Score(ireflv) = 0.747, Recall: 0.692, Precision: 0.811
# F-Score(id) = 0.339, Recall: 0.222, Precision: 0.725
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_10 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 4, 48)        705264      input_9[0][0]                    
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 4, 24)        5640        input_10[0][0]                   
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 192)          0           embedding_9[0][0]                
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 96)           0           embedding_10[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 288)          0           flatten_9[0][0]                  
                                                                 flatten_10[0][0]                 
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 24)           6936        concatenate_5[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24)           0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 8)            200         dropout_5[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.3774 - acc: 0.9228 - val_loss: 0.1228 - val_acc: 0.9529
Epoch 2/15
 - 5s - loss: 0.5475 - acc: 0.9583 - val_loss: 0.0981 - val_acc: 0.9607
Epoch 3/15
 - 5s - loss: 0.5575 - acc: 0.9639 - val_loss: 0.0982 - val_acc: 0.9635
Epoch 4/15
 - 5s - loss: 0.3312 - acc: 0.9671 - val_loss: 0.1035 - val_acc: 0.9636
Epoch 5/15
 - 5s - loss: 0.1732 - acc: 0.9694 - val_loss: 0.1133 - val_acc: 0.9628
Epoch 6/15
 - 5s - loss: 0.0912 - acc: 0.9708 - val_loss: 0.1173 - val_acc: 0.9654
Epoch 7/15
 - 5s - loss: 0.1255 - acc: 0.9714 - val_loss: 0.1232 - val_acc: 0.9645
Epoch 8/15
 - 5s - loss: 0.0500 - acc: 0.9728 - val_loss: 0.1317 - val_acc: 0.9642
Epoch 9/15
 - 5s - loss: 0.1747 - acc: 0.9735 - val_loss: 0.1278 - val_acc: 0.9622
Epoch 10/15
 - 5s - loss: 0.0445 - acc: 0.9738 - val_loss: 0.1392 - val_acc: 0.9644
Epoch 11/15
 - 5s - loss: 0.0424 - acc: 0.9744 - val_loss: 0.1437 - val_acc: 0.9646
Epoch 12/15
 - 5s - loss: 0.0422 - acc: 0.9746 - val_loss: 0.1394 - val_acc: 0.9644
Epoch 13/15
 - 5s - loss: 0.0428 - acc: 0.9751 - val_loss: 0.1646 - val_acc: 0.9652
Epoch 14/15
 - 5s - loss: 0.0407 - acc: 0.9749 - val_loss: 0.1508 - val_acc: 0.9630
Epoch 15/15
 - 5s - loss: 0.0405 - acc: 0.9752 - val_loss: 0.1701 - val_acc: 0.9652
# Training time = 0:01:31.045384
# F-Score(Ordinary) = 0.574, Recall: 0.468, Precision: 0.74
# F-Score(lvc) = 0.5, Recall: 0.429, Precision: 0.598
# F-Score(ireflv) = 0.711, Recall: 0.602, Precision: 0.869
# F-Score(id) = 0.511, Recall: 0.398, Precision: 0.715
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 4, 48)        705264      input_11[0][0]                   
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 4, 24)        5640        input_12[0][0]                   
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 192)          0           embedding_11[0][0]               
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 96)           0           embedding_12[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 288)          0           flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 24)           6936        concatenate_6[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24)           0           dense_11[0][0]                   
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 8)            200         dropout_6[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.7998 - acc: 0.9227 - val_loss: 0.1115 - val_acc: 0.9578
Epoch 2/15
 - 5s - loss: 0.9473 - acc: 0.9617 - val_loss: 0.1021 - val_acc: 0.9617
Epoch 3/15
 - 5s - loss: 0.3602 - acc: 0.9672 - val_loss: 0.0983 - val_acc: 0.9629
Epoch 4/15
 - 5s - loss: 0.3849 - acc: 0.9689 - val_loss: 0.1023 - val_acc: 0.9620
Epoch 5/15
 - 5s - loss: 0.4103 - acc: 0.9706 - val_loss: 0.1100 - val_acc: 0.9633
Epoch 6/15
 - 5s - loss: 0.3970 - acc: 0.9715 - val_loss: 0.1159 - val_acc: 0.9635
Epoch 7/15
 - 5s - loss: 0.1838 - acc: 0.9730 - val_loss: 0.1157 - val_acc: 0.9639
Epoch 8/15
 - 5s - loss: 0.2489 - acc: 0.9735 - val_loss: 0.1318 - val_acc: 0.9629
Epoch 9/15
 - 5s - loss: 0.0663 - acc: 0.9741 - val_loss: 0.1385 - val_acc: 0.9638
Epoch 10/15
 - 5s - loss: 0.1699 - acc: 0.9747 - val_loss: 0.1702 - val_acc: 0.9645
Epoch 11/15
 - 5s - loss: 0.0479 - acc: 0.9747 - val_loss: 0.1376 - val_acc: 0.9640
Epoch 12/15
 - 5s - loss: 0.1848 - acc: 0.9750 - val_loss: 0.1413 - val_acc: 0.9648
Epoch 13/15
 - 5s - loss: 0.0592 - acc: 0.9752 - val_loss: 0.1590 - val_acc: 0.9657
Epoch 14/15
 - 5s - loss: 0.0461 - acc: 0.9757 - val_loss: 0.1399 - val_acc: 0.9646
Epoch 15/15
 - 5s - loss: 0.0450 - acc: 0.9759 - val_loss: 0.1518 - val_acc: 0.9647
# Training time = 0:01:30.666894
# F-Score(Ordinary) = 0.553, Recall: 0.441, Precision: 0.74
# F-Score(lvc) = 0.439, Recall: 0.342, Precision: 0.614
# F-Score(ireflv) = 0.732, Recall: 0.624, Precision: 0.885
# F-Score(id) = 0.502, Recall: 0.393, Precision: 0.694
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_14 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 4, 48)        705264      input_13[0][0]                   
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 4, 24)        5640        input_14[0][0]                   
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 192)          0           embedding_13[0][0]               
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 96)           0           embedding_14[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 288)          0           flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 24)           6936        concatenate_7[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24)           0           dense_13[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 8)            200         dropout_7[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.6369 - acc: 0.9324 - val_loss: 0.1120 - val_acc: 0.9562
Epoch 2/15
 - 5s - loss: 1.2067 - acc: 0.9630 - val_loss: 0.1014 - val_acc: 0.9602
Epoch 3/15
 - 5s - loss: 0.6781 - acc: 0.9667 - val_loss: 0.1025 - val_acc: 0.9628
Epoch 4/15
 - 5s - loss: 0.4203 - acc: 0.9690 - val_loss: 0.1129 - val_acc: 0.9642
Epoch 5/15
 - 5s - loss: 0.3436 - acc: 0.9708 - val_loss: 0.1088 - val_acc: 0.9655
Epoch 6/15
 - 5s - loss: 0.2790 - acc: 0.9720 - val_loss: 0.1154 - val_acc: 0.9642
Epoch 7/15
 - 5s - loss: 0.3874 - acc: 0.9727 - val_loss: 0.1148 - val_acc: 0.9638
Epoch 8/15
 - 5s - loss: 0.2212 - acc: 0.9733 - val_loss: 0.1387 - val_acc: 0.9640
Epoch 9/15
 - 5s - loss: 0.1128 - acc: 0.9736 - val_loss: 0.1354 - val_acc: 0.9642
Epoch 10/15
 - 5s - loss: 0.0545 - acc: 0.9744 - val_loss: 0.1410 - val_acc: 0.9657
Epoch 11/15
 - 5s - loss: 0.0454 - acc: 0.9744 - val_loss: 0.1324 - val_acc: 0.9647
Epoch 12/15
 - 5s - loss: 0.0769 - acc: 0.9750 - val_loss: 0.1816 - val_acc: 0.9645
Epoch 13/15
 - 5s - loss: 0.0444 - acc: 0.9749 - val_loss: 0.1438 - val_acc: 0.9651
Epoch 14/15
 - 5s - loss: 0.0455 - acc: 0.9750 - val_loss: 0.1533 - val_acc: 0.9654
Epoch 15/15
 - 5s - loss: 0.1381 - acc: 0.9751 - val_loss: 0.1650 - val_acc: 0.9633
# Training time = 0:01:31.070048
# F-Score(Ordinary) = 0.5, Recall: 0.394, Precision: 0.685
# F-Score(lvc) = 0.594, Recall: 0.857, Precision: 0.455
# F-Score(ireflv) = 0.736, Recall: 0.673, Precision: 0.811
# F-Score(id) = 0.361, Recall: 0.243, Precision: 0.705
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_15 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_16 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_15 (Embedding)        (None, 4, 48)        705264      input_15[0][0]                   
__________________________________________________________________________________________________
embedding_16 (Embedding)        (None, 4, 24)        5640        input_16[0][0]                   
__________________________________________________________________________________________________
flatten_15 (Flatten)            (None, 192)          0           embedding_15[0][0]               
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 96)           0           embedding_16[0][0]               
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 288)          0           flatten_15[0][0]                 
                                                                 flatten_16[0][0]                 
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 24)           6936        concatenate_8[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24)           0           dense_15[0][0]                   
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 8)            200         dropout_8[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.6525 - acc: 0.9299 - val_loss: 0.1095 - val_acc: 0.9582
Epoch 2/15
 - 5s - loss: 0.8814 - acc: 0.9623 - val_loss: 0.1052 - val_acc: 0.9617
Epoch 3/15
 - 5s - loss: 0.8121 - acc: 0.9676 - val_loss: 0.1008 - val_acc: 0.9625
Epoch 4/15
 - 5s - loss: 0.4143 - acc: 0.9700 - val_loss: 0.1049 - val_acc: 0.9623
Epoch 5/15
 - 5s - loss: 0.3603 - acc: 0.9717 - val_loss: 0.1083 - val_acc: 0.9647
Epoch 6/15
 - 5s - loss: 0.3541 - acc: 0.9730 - val_loss: 0.1083 - val_acc: 0.9645
Epoch 7/15
 - 5s - loss: 0.3577 - acc: 0.9733 - val_loss: 0.1241 - val_acc: 0.9646
Epoch 8/15
 - 5s - loss: 0.2826 - acc: 0.9738 - val_loss: 0.1381 - val_acc: 0.9662
Epoch 9/15
 - 5s - loss: 0.3912 - acc: 0.9740 - val_loss: 0.1425 - val_acc: 0.9645
Epoch 10/15
 - 5s - loss: 0.1856 - acc: 0.9747 - val_loss: 0.1473 - val_acc: 0.9652
Epoch 11/15
 - 5s - loss: 0.1981 - acc: 0.9753 - val_loss: 0.1453 - val_acc: 0.9647
Epoch 12/15
 - 5s - loss: 0.0883 - acc: 0.9748 - val_loss: 0.1556 - val_acc: 0.9649
Epoch 13/15
 - 5s - loss: 0.0599 - acc: 0.9754 - val_loss: 0.1533 - val_acc: 0.9653
Epoch 14/15
 - 5s - loss: 0.0434 - acc: 0.9756 - val_loss: 0.1628 - val_acc: 0.9650
Epoch 15/15
 - 5s - loss: 0.4344 - acc: 0.9759 - val_loss: 0.1644 - val_acc: 0.9646
# Training time = 0:01:31.243513
# F-Score(Ordinary) = 0.412, Recall: 0.289, Precision: 0.72
# F-Score(lvc) = 0.445, Recall: 0.372, Precision: 0.553
# F-Score(ireflv) = 0.746, Recall: 0.654, Precision: 0.869
# F-Score(id) = 0.284, Recall: 0.178, Precision: 0.694
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_17 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_18 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_17 (Embedding)        (None, 4, 48)        705264      input_17[0][0]                   
__________________________________________________________________________________________________
embedding_18 (Embedding)        (None, 4, 24)        5640        input_18[0][0]                   
__________________________________________________________________________________________________
flatten_17 (Flatten)            (None, 192)          0           embedding_17[0][0]               
__________________________________________________________________________________________________
flatten_18 (Flatten)            (None, 96)           0           embedding_18[0][0]               
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 288)          0           flatten_17[0][0]                 
                                                                 flatten_18[0][0]                 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 24)           6936        concatenate_9[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24)           0           dense_17[0][0]                   
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 8)            200         dropout_9[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.3992 - acc: 0.9221 - val_loss: 0.1178 - val_acc: 0.9569
Epoch 2/15
 - 5s - loss: 0.8941 - acc: 0.9635 - val_loss: 0.1052 - val_acc: 0.9612
Epoch 3/15
 - 5s - loss: 0.7849 - acc: 0.9681 - val_loss: 0.1103 - val_acc: 0.9632
Epoch 4/15
 - 5s - loss: 0.4138 - acc: 0.9700 - val_loss: 0.1142 - val_acc: 0.9640
Epoch 5/15
 - 5s - loss: 0.2710 - acc: 0.9705 - val_loss: 0.1268 - val_acc: 0.9644
Epoch 6/15
 - 5s - loss: 0.3243 - acc: 0.9714 - val_loss: 0.1180 - val_acc: 0.9622
Epoch 7/15
 - 5s - loss: 0.2894 - acc: 0.9727 - val_loss: 0.1370 - val_acc: 0.9640
Epoch 8/15
 - 5s - loss: 0.3424 - acc: 0.9732 - val_loss: 0.1359 - val_acc: 0.9635
Epoch 9/15
 - 5s - loss: 0.1371 - acc: 0.9737 - val_loss: 0.1559 - val_acc: 0.9645
Epoch 10/15
 - 5s - loss: 0.0905 - acc: 0.9742 - val_loss: 0.1573 - val_acc: 0.9634
Epoch 11/15
 - 5s - loss: 0.0607 - acc: 0.9747 - val_loss: 0.1586 - val_acc: 0.9648
Epoch 12/15
 - 5s - loss: 0.3156 - acc: 0.9747 - val_loss: 0.1553 - val_acc: 0.9642
Epoch 13/15
 - 5s - loss: 0.0473 - acc: 0.9750 - val_loss: 0.1715 - val_acc: 0.9640
Epoch 14/15
 - 5s - loss: 0.1506 - acc: 0.9753 - val_loss: 0.1648 - val_acc: 0.9638
Epoch 15/15
 - 5s - loss: 0.0421 - acc: 0.9756 - val_loss: 0.1781 - val_acc: 0.9645
# Training time = 0:01:33.140903
# F-Score(Ordinary) = 0.595, Recall: 0.501, Precision: 0.734
# F-Score(lvc) = 0.536, Recall: 0.491, Precision: 0.591
# F-Score(ireflv) = 0.694, Recall: 0.568, Precision: 0.893
# F-Score(id) = 0.543, Recall: 0.444, Precision: 0.699
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_19 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_20 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_19 (Embedding)        (None, 4, 48)        705264      input_19[0][0]                   
__________________________________________________________________________________________________
embedding_20 (Embedding)        (None, 4, 24)        5640        input_20[0][0]                   
__________________________________________________________________________________________________
flatten_19 (Flatten)            (None, 192)          0           embedding_19[0][0]               
__________________________________________________________________________________________________
flatten_20 (Flatten)            (None, 96)           0           embedding_20[0][0]               
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 288)          0           flatten_19[0][0]                 
                                                                 flatten_20[0][0]                 
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 24)           6936        concatenate_10[0][0]             
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24)           0           dense_19[0][0]                   
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 8)            200         dropout_10[0][0]                 
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.2900 - acc: 0.9156 - val_loss: 0.1124 - val_acc: 0.9589
Epoch 2/15
 - 5s - loss: 1.1785 - acc: 0.9624 - val_loss: 0.1048 - val_acc: 0.9620
Epoch 3/15
 - 5s - loss: 0.6144 - acc: 0.9658 - val_loss: 0.1064 - val_acc: 0.9621
Epoch 4/15
 - 5s - loss: 0.3032 - acc: 0.9686 - val_loss: 0.1116 - val_acc: 0.9622
Epoch 5/15
 - 5s - loss: 0.5605 - acc: 0.9706 - val_loss: 0.1208 - val_acc: 0.9635
Epoch 6/15
 - 5s - loss: 0.3786 - acc: 0.9717 - val_loss: 0.1234 - val_acc: 0.9642
Epoch 7/15
 - 5s - loss: 0.1164 - acc: 0.9722 - val_loss: 0.1364 - val_acc: 0.9638
Epoch 8/15
 - 5s - loss: 0.0795 - acc: 0.9734 - val_loss: 0.1447 - val_acc: 0.9648
Epoch 9/15
 - 5s - loss: 0.0507 - acc: 0.9736 - val_loss: 0.1415 - val_acc: 0.9650
Epoch 10/15
 - 5s - loss: 0.0485 - acc: 0.9741 - val_loss: 0.1590 - val_acc: 0.9636
Epoch 11/15
 - 5s - loss: 0.0460 - acc: 0.9744 - val_loss: 0.1799 - val_acc: 0.9651
Epoch 12/15
 - 5s - loss: 0.0452 - acc: 0.9747 - val_loss: 0.1873 - val_acc: 0.9643
Epoch 13/15
 - 5s - loss: 0.0428 - acc: 0.9753 - val_loss: 0.1544 - val_acc: 0.9637
Epoch 14/15
 - 5s - loss: 0.0558 - acc: 0.9753 - val_loss: 0.1863 - val_acc: 0.9640
Epoch 15/15
 - 5s - loss: 0.0489 - acc: 0.9753 - val_loss: 0.1757 - val_acc: 0.9639
# Training time = 0:01:31.076847
# F-Score(Ordinary) = 0.483, Recall: 0.361, Precision: 0.729
# F-Score(lvc) = 0.45, Recall: 0.361, Precision: 0.598
# F-Score(ireflv) = 0.727, Recall: 0.634, Precision: 0.852
# F-Score(id) = 0.375, Recall: 0.257, Precision: 0.694
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_21 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_22 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_21 (Embedding)        (None, 4, 48)        705264      input_21[0][0]                   
__________________________________________________________________________________________________
embedding_22 (Embedding)        (None, 4, 24)        5640        input_22[0][0]                   
__________________________________________________________________________________________________
flatten_21 (Flatten)            (None, 192)          0           embedding_21[0][0]               
__________________________________________________________________________________________________
flatten_22 (Flatten)            (None, 96)           0           embedding_22[0][0]               
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 288)          0           flatten_21[0][0]                 
                                                                 flatten_22[0][0]                 
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 24)           6936        concatenate_11[0][0]             
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 24)           0           dense_21[0][0]                   
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 8)            200         dropout_11[0][0]                 
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 1.5695 - acc: 0.7668 - val_loss: 0.3588 - val_acc: 0.8381
Epoch 2/15
 - 1s - loss: 1.1004 - acc: 0.8451 - val_loss: 0.2972 - val_acc: 0.8520
Epoch 3/15
 - 1s - loss: 0.7450 - acc: 0.8575 - val_loss: 0.2769 - val_acc: 0.8567
Epoch 4/15
 - 1s - loss: 0.4804 - acc: 0.8644 - val_loss: 0.2678 - val_acc: 0.8597
Epoch 5/15
 - 1s - loss: 0.3681 - acc: 0.8676 - val_loss: 0.2639 - val_acc: 0.8597
Epoch 6/15
 - 1s - loss: 0.2846 - acc: 0.8702 - val_loss: 0.2638 - val_acc: 0.8611
Epoch 7/15
 - 1s - loss: 0.2420 - acc: 0.8723 - val_loss: 0.2633 - val_acc: 0.8623
Epoch 8/15
 - 1s - loss: 0.2650 - acc: 0.8724 - val_loss: 0.2649 - val_acc: 0.8626
Epoch 9/15
 - 1s - loss: 0.2274 - acc: 0.8751 - val_loss: 0.2687 - val_acc: 0.8641
Epoch 10/15
 - 1s - loss: 0.2126 - acc: 0.8758 - val_loss: 0.2722 - val_acc: 0.8653
Epoch 11/15
 - 1s - loss: 0.2260 - acc: 0.8769 - val_loss: 0.2758 - val_acc: 0.8641
Epoch 12/15
 - 1s - loss: 0.2078 - acc: 0.8766 - val_loss: 0.2748 - val_acc: 0.8650
Epoch 13/15
 - 1s - loss: 0.2040 - acc: 0.8781 - val_loss: 0.2774 - val_acc: 0.8653
Epoch 14/15
 - 1s - loss: 0.2117 - acc: 0.8781 - val_loss: 0.2828 - val_acc: 0.8656
Epoch 15/15
 - 1s - loss: 0.2003 - acc: 0.8782 - val_loss: 0.2906 - val_acc: 0.8647
# Training time = 0:00:15.946488
# F-Score(Ordinary) = 0.148, Recall: 0.092, Precision: 0.38
# F-Score(lvc) = 0.08, Recall: 0.045, Precision: 0.379
# F-Score(ireflv) = 0.178, Recall: 0.119, Precision: 0.352
# F-Score(id) = 0.265, Recall: 0.208, Precision: 0.368
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_23 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_24 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_23 (Embedding)        (None, 4, 48)        705264      input_23[0][0]                   
__________________________________________________________________________________________________
embedding_24 (Embedding)        (None, 4, 24)        5640        input_24[0][0]                   
__________________________________________________________________________________________________
flatten_23 (Flatten)            (None, 192)          0           embedding_23[0][0]               
__________________________________________________________________________________________________
flatten_24 (Flatten)            (None, 96)           0           embedding_24[0][0]               
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 288)          0           flatten_23[0][0]                 
                                                                 flatten_24[0][0]                 
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 24)           6936        concatenate_12[0][0]             
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 24)           0           dense_23[0][0]                   
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 8)            200         dropout_12[0][0]                 
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 1.7280 - acc: 0.7479 - val_loss: 0.3476 - val_acc: 0.8429
Epoch 2/15
 - 1s - loss: 1.1023 - acc: 0.8508 - val_loss: 0.2940 - val_acc: 0.8541
Epoch 3/15
 - 1s - loss: 0.7772 - acc: 0.8613 - val_loss: 0.2743 - val_acc: 0.8579
Epoch 4/15
 - 1s - loss: 0.5998 - acc: 0.8672 - val_loss: 0.2675 - val_acc: 0.8606
Epoch 5/15
 - 1s - loss: 0.4653 - acc: 0.8705 - val_loss: 0.2637 - val_acc: 0.8600
Epoch 6/15
 - 1s - loss: 0.4484 - acc: 0.8712 - val_loss: 0.2628 - val_acc: 0.8608
Epoch 7/15
 - 1s - loss: 0.4344 - acc: 0.8729 - val_loss: 0.2625 - val_acc: 0.8623
Epoch 8/15
 - 1s - loss: 0.3956 - acc: 0.8736 - val_loss: 0.2649 - val_acc: 0.8629
Epoch 9/15
 - 1s - loss: 0.3634 - acc: 0.8743 - val_loss: 0.2670 - val_acc: 0.8617
Epoch 10/15
 - 1s - loss: 0.2492 - acc: 0.8752 - val_loss: 0.2689 - val_acc: 0.8614
Epoch 11/15
 - 1s - loss: 0.2281 - acc: 0.8758 - val_loss: 0.2678 - val_acc: 0.8635
Epoch 12/15
 - 1s - loss: 0.2487 - acc: 0.8767 - val_loss: 0.2719 - val_acc: 0.8629
Epoch 13/15
 - 1s - loss: 0.2614 - acc: 0.8771 - val_loss: 0.2747 - val_acc: 0.8623
Epoch 14/15
 - 1s - loss: 0.2141 - acc: 0.8775 - val_loss: 0.2775 - val_acc: 0.8617
Epoch 15/15
 - 1s - loss: 0.2037 - acc: 0.8780 - val_loss: 0.2789 - val_acc: 0.8608
# Training time = 0:00:15.849819
# F-Score(Ordinary) = 0.165, Recall: 0.105, Precision: 0.391
# F-Score(lvc) = 0.072, Recall: 0.041, Precision: 0.295
# F-Score(ireflv) = 0.164, Recall: 0.106, Precision: 0.369
# F-Score(id) = 0.354, Recall: 0.294, Precision: 0.446
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_25 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_26 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_25 (Embedding)        (None, 4, 48)        705264      input_25[0][0]                   
__________________________________________________________________________________________________
embedding_26 (Embedding)        (None, 4, 24)        5640        input_26[0][0]                   
__________________________________________________________________________________________________
flatten_25 (Flatten)            (None, 192)          0           embedding_25[0][0]               
__________________________________________________________________________________________________
flatten_26 (Flatten)            (None, 96)           0           embedding_26[0][0]               
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 288)          0           flatten_25[0][0]                 
                                                                 flatten_26[0][0]                 
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 24)           6936        concatenate_13[0][0]             
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 24)           0           dense_25[0][0]                   
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 8)            200         dropout_13[0][0]                 
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 1.6555 - acc: 0.7557 - val_loss: 0.3454 - val_acc: 0.8446
Epoch 2/15
 - 1s - loss: 1.0733 - acc: 0.8477 - val_loss: 0.2931 - val_acc: 0.8591
Epoch 3/15
 - 1s - loss: 0.5590 - acc: 0.8623 - val_loss: 0.2694 - val_acc: 0.8597
Epoch 4/15
 - 1s - loss: 0.7939 - acc: 0.8671 - val_loss: 0.2677 - val_acc: 0.8603
Epoch 5/15
 - 1s - loss: 0.4914 - acc: 0.8706 - val_loss: 0.2634 - val_acc: 0.8614
Epoch 6/15
 - 1s - loss: 0.3870 - acc: 0.8729 - val_loss: 0.2650 - val_acc: 0.8608
Epoch 7/15
 - 1s - loss: 0.2714 - acc: 0.8728 - val_loss: 0.2643 - val_acc: 0.8611
Epoch 8/15
 - 1s - loss: 0.2908 - acc: 0.8742 - val_loss: 0.2643 - val_acc: 0.8623
Epoch 9/15
 - 1s - loss: 0.2239 - acc: 0.8750 - val_loss: 0.2658 - val_acc: 0.8626
Epoch 10/15
 - 1s - loss: 0.2233 - acc: 0.8763 - val_loss: 0.2675 - val_acc: 0.8626
Epoch 11/15
 - 1s - loss: 0.2340 - acc: 0.8764 - val_loss: 0.2681 - val_acc: 0.8626
Epoch 12/15
 - 1s - loss: 0.2964 - acc: 0.8771 - val_loss: 0.2693 - val_acc: 0.8635
Epoch 13/15
 - 1s - loss: 0.2106 - acc: 0.8783 - val_loss: 0.2732 - val_acc: 0.8647
Epoch 14/15
 - 1s - loss: 0.2043 - acc: 0.8789 - val_loss: 0.2744 - val_acc: 0.8659
Epoch 15/15
 - 1s - loss: 0.2083 - acc: 0.8790 - val_loss: 0.2779 - val_acc: 0.8641
# Training time = 0:00:15.777531
# F-Score(Ordinary) = 0.128, Recall: 0.078, Precision: 0.347
# F-Score(lvc) = 0.071, Recall: 0.039, Precision: 0.341
# F-Score(ireflv) = 0.127, Recall: 0.08, Precision: 0.303
# F-Score(id) = 0.244, Recall: 0.186, Precision: 0.352
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_27 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_28 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_27 (Embedding)        (None, 4, 48)        705264      input_27[0][0]                   
__________________________________________________________________________________________________
embedding_28 (Embedding)        (None, 4, 24)        5640        input_28[0][0]                   
__________________________________________________________________________________________________
flatten_27 (Flatten)            (None, 192)          0           embedding_27[0][0]               
__________________________________________________________________________________________________
flatten_28 (Flatten)            (None, 96)           0           embedding_28[0][0]               
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 288)          0           flatten_27[0][0]                 
                                                                 flatten_28[0][0]                 
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 24)           6936        concatenate_14[0][0]             
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 24)           0           dense_27[0][0]                   
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 8)            200         dropout_14[0][0]                 
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 1.4329 - acc: 0.7315 - val_loss: 0.3784 - val_acc: 0.8381
Epoch 2/15
 - 1s - loss: 1.0972 - acc: 0.8442 - val_loss: 0.3011 - val_acc: 0.8535
Epoch 3/15
 - 1s - loss: 0.6796 - acc: 0.8593 - val_loss: 0.2780 - val_acc: 0.8582
Epoch 4/15
 - 1s - loss: 0.5094 - acc: 0.8659 - val_loss: 0.2693 - val_acc: 0.8611
Epoch 5/15
 - 1s - loss: 0.3424 - acc: 0.8696 - val_loss: 0.2657 - val_acc: 0.8620
Epoch 6/15
 - 1s - loss: 0.3251 - acc: 0.8700 - val_loss: 0.2651 - val_acc: 0.8617
Epoch 7/15
 - 1s - loss: 0.2609 - acc: 0.8730 - val_loss: 0.2643 - val_acc: 0.8623
Epoch 8/15
 - 1s - loss: 0.2420 - acc: 0.8746 - val_loss: 0.2649 - val_acc: 0.8635
Epoch 9/15
 - 1s - loss: 0.2224 - acc: 0.8753 - val_loss: 0.2677 - val_acc: 0.8635
Epoch 10/15
 - 1s - loss: 0.2538 - acc: 0.8759 - val_loss: 0.2680 - val_acc: 0.8629
Epoch 11/15
 - 1s - loss: 0.2118 - acc: 0.8766 - val_loss: 0.2689 - val_acc: 0.8635
Epoch 12/15
 - 1s - loss: 0.2623 - acc: 0.8778 - val_loss: 0.2759 - val_acc: 0.8638
Epoch 13/15
 - 1s - loss: 0.2064 - acc: 0.8780 - val_loss: 0.2743 - val_acc: 0.8635
Epoch 14/15
 - 1s - loss: 0.2041 - acc: 0.8780 - val_loss: 0.2731 - val_acc: 0.8635
Epoch 15/15
 - 1s - loss: 0.2166 - acc: 0.8788 - val_loss: 0.2744 - val_acc: 0.8632
# Training time = 0:00:15.906677
# F-Score(Ordinary) = 0.13, Recall: 0.08, Precision: 0.349
# F-Score(lvc) = 0.077, Recall: 0.043, Precision: 0.326
# F-Score(ireflv) = 0.145, Recall: 0.093, Precision: 0.328
# F-Score(id) = 0.276, Recall: 0.231, Precision: 0.342
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_29 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_30 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_29 (Embedding)        (None, 4, 48)        705264      input_29[0][0]                   
__________________________________________________________________________________________________
embedding_30 (Embedding)        (None, 4, 24)        5640        input_30[0][0]                   
__________________________________________________________________________________________________
flatten_29 (Flatten)            (None, 192)          0           embedding_29[0][0]               
__________________________________________________________________________________________________
flatten_30 (Flatten)            (None, 96)           0           embedding_30[0][0]               
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 288)          0           flatten_29[0][0]                 
                                                                 flatten_30[0][0]                 
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 24)           6936        concatenate_15[0][0]             
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 24)           0           dense_29[0][0]                   
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 8)            200         dropout_15[0][0]                 
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 1.4814 - acc: 0.7451 - val_loss: 0.3891 - val_acc: 0.8405
Epoch 2/15
 - 1s - loss: 0.8875 - acc: 0.8405 - val_loss: 0.2993 - val_acc: 0.8517
Epoch 3/15
 - 1s - loss: 1.0049 - acc: 0.8549 - val_loss: 0.2846 - val_acc: 0.8541
Epoch 4/15
 - 1s - loss: 0.7185 - acc: 0.8588 - val_loss: 0.2762 - val_acc: 0.8576
Epoch 5/15
 - 1s - loss: 0.4494 - acc: 0.8651 - val_loss: 0.2709 - val_acc: 0.8588
Epoch 6/15
 - 1s - loss: 0.3168 - acc: 0.8681 - val_loss: 0.2671 - val_acc: 0.8597
Epoch 7/15
 - 1s - loss: 0.3008 - acc: 0.8705 - val_loss: 0.2652 - val_acc: 0.8626
Epoch 8/15
 - 1s - loss: 0.2384 - acc: 0.8725 - val_loss: 0.2668 - val_acc: 0.8620
Epoch 9/15
 - 1s - loss: 0.2432 - acc: 0.8736 - val_loss: 0.2643 - val_acc: 0.8626
Epoch 10/15
 - 1s - loss: 0.2178 - acc: 0.8744 - val_loss: 0.2664 - val_acc: 0.8644
Epoch 11/15
 - 1s - loss: 0.2132 - acc: 0.8757 - val_loss: 0.2691 - val_acc: 0.8644
Epoch 12/15
 - 1s - loss: 0.2193 - acc: 0.8767 - val_loss: 0.2685 - val_acc: 0.8647
Epoch 13/15
 - 1s - loss: 0.2114 - acc: 0.8776 - val_loss: 0.2694 - val_acc: 0.8644
Epoch 14/15
 - 1s - loss: 0.2060 - acc: 0.8777 - val_loss: 0.2783 - val_acc: 0.8641
Epoch 15/15
 - 1s - loss: 0.2007 - acc: 0.8784 - val_loss: 0.2769 - val_acc: 0.8644
# Training time = 0:00:15.897227
# F-Score(Ordinary) = 0.192, Recall: 0.121, Precision: 0.472
# F-Score(lvc) = 0.107, Recall: 0.062, Precision: 0.371
# F-Score(ireflv) = 0.246, Recall: 0.156, Precision: 0.59
# F-Score(id) = 0.24, Recall: 0.166, Precision: 0.43
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_31 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_32 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_31 (Embedding)        (None, 4, 48)        705264      input_31[0][0]                   
__________________________________________________________________________________________________
embedding_32 (Embedding)        (None, 4, 24)        5640        input_32[0][0]                   
__________________________________________________________________________________________________
flatten_31 (Flatten)            (None, 192)          0           embedding_31[0][0]               
__________________________________________________________________________________________________
flatten_32 (Flatten)            (None, 96)           0           embedding_32[0][0]               
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 288)          0           flatten_31[0][0]                 
                                                                 flatten_32[0][0]                 
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 24)           6936        concatenate_16[0][0]             
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 24)           0           dense_31[0][0]                   
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 8)            200         dropout_16[0][0]                 
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 1.7663 - acc: 0.7502 - val_loss: 0.3538 - val_acc: 0.8461
Epoch 2/15
 - 1s - loss: 0.8631 - acc: 0.8477 - val_loss: 0.2820 - val_acc: 0.8558
Epoch 3/15
 - 1s - loss: 0.8405 - acc: 0.8605 - val_loss: 0.2766 - val_acc: 0.8594
Epoch 4/15
 - 1s - loss: 0.5102 - acc: 0.8674 - val_loss: 0.2678 - val_acc: 0.8611
Epoch 5/15
 - 1s - loss: 0.4833 - acc: 0.8705 - val_loss: 0.2634 - val_acc: 0.8623
Epoch 6/15
 - 1s - loss: 0.3896 - acc: 0.8714 - val_loss: 0.2629 - val_acc: 0.8653
Epoch 7/15
 - 1s - loss: 0.3696 - acc: 0.8734 - val_loss: 0.2627 - val_acc: 0.8641
Epoch 8/15
 - 1s - loss: 0.4722 - acc: 0.8741 - val_loss: 0.2684 - val_acc: 0.8635
Epoch 9/15
 - 1s - loss: 0.2618 - acc: 0.8754 - val_loss: 0.2670 - val_acc: 0.8650
Epoch 10/15
 - 1s - loss: 0.3407 - acc: 0.8762 - val_loss: 0.2677 - val_acc: 0.8647
Epoch 11/15
 - 1s - loss: 0.2489 - acc: 0.8771 - val_loss: 0.2706 - val_acc: 0.8644
Epoch 12/15
 - 1s - loss: 0.2624 - acc: 0.8774 - val_loss: 0.2734 - val_acc: 0.8644
Epoch 13/15
 - 1s - loss: 0.2082 - acc: 0.8779 - val_loss: 0.2803 - val_acc: 0.8644
Epoch 14/15
 - 1s - loss: 0.2225 - acc: 0.8787 - val_loss: 0.2807 - val_acc: 0.8641
Epoch 15/15
 - 1s - loss: 0.2082 - acc: 0.8787 - val_loss: 0.2821 - val_acc: 0.8644
# Training time = 0:00:15.813159
# F-Score(Ordinary) = 0.148, Recall: 0.089, Precision: 0.434
# F-Score(lvc) = 0.056, Recall: 0.031, Precision: 0.326
# F-Score(ireflv) = 0.218, Recall: 0.137, Precision: 0.525
# F-Score(id) = 0.331, Recall: 0.273, Precision: 0.42
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_33 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_34 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_33 (Embedding)        (None, 4, 48)        705264      input_33[0][0]                   
__________________________________________________________________________________________________
embedding_34 (Embedding)        (None, 4, 24)        5640        input_34[0][0]                   
__________________________________________________________________________________________________
flatten_33 (Flatten)            (None, 192)          0           embedding_33[0][0]               
__________________________________________________________________________________________________
flatten_34 (Flatten)            (None, 96)           0           embedding_34[0][0]               
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 288)          0           flatten_33[0][0]                 
                                                                 flatten_34[0][0]                 
__________________________________________________________________________________________________
dense_33 (Dense)                (None, 24)           6936        concatenate_17[0][0]             
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 24)           0           dense_33[0][0]                   
__________________________________________________________________________________________________
dense_34 (Dense)                (None, 8)            200         dropout_17[0][0]                 
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 1.6690 - acc: 0.7463 - val_loss: 0.3530 - val_acc: 0.8420
Epoch 2/15
 - 1s - loss: 1.2132 - acc: 0.8479 - val_loss: 0.2887 - val_acc: 0.8555
Epoch 3/15
 - 1s - loss: 0.9927 - acc: 0.8625 - val_loss: 0.2747 - val_acc: 0.8582
Epoch 4/15
 - 1s - loss: 0.5730 - acc: 0.8670 - val_loss: 0.2705 - val_acc: 0.8567
Epoch 5/15
 - 1s - loss: 0.4899 - acc: 0.8706 - val_loss: 0.2669 - val_acc: 0.8594
Epoch 6/15
 - 1s - loss: 0.5244 - acc: 0.8723 - val_loss: 0.2668 - val_acc: 0.8620
Epoch 7/15
 - 1s - loss: 0.4817 - acc: 0.8742 - val_loss: 0.2653 - val_acc: 0.8629
Epoch 8/15
 - 1s - loss: 0.3879 - acc: 0.8748 - val_loss: 0.2676 - val_acc: 0.8617
Epoch 9/15
 - 1s - loss: 0.4109 - acc: 0.8755 - val_loss: 0.2686 - val_acc: 0.8641
Epoch 10/15
 - 1s - loss: 0.3069 - acc: 0.8764 - val_loss: 0.2731 - val_acc: 0.8614
Epoch 11/15
 - 1s - loss: 0.3098 - acc: 0.8765 - val_loss: 0.2754 - val_acc: 0.8620
Epoch 12/15
 - 1s - loss: 0.2700 - acc: 0.8774 - val_loss: 0.2800 - val_acc: 0.8632
Epoch 13/15
 - 1s - loss: 0.2422 - acc: 0.8777 - val_loss: 0.2793 - val_acc: 0.8635
Epoch 14/15
 - 1s - loss: 0.2108 - acc: 0.8779 - val_loss: 0.2858 - val_acc: 0.8644
Epoch 15/15
 - 1s - loss: 0.3516 - acc: 0.8788 - val_loss: 0.2849 - val_acc: 0.8653
# Training time = 0:00:15.868004
# F-Score(Ordinary) = 0.151, Recall: 0.094, Precision: 0.396
# F-Score(lvc) = 0.065, Recall: 0.036, Precision: 0.333
# F-Score(ireflv) = 0.193, Recall: 0.121, Precision: 0.467
# F-Score(id) = 0.353, Recall: 0.348, Precision: 0.358
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_35 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_36 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_35 (Embedding)        (None, 4, 48)        705264      input_35[0][0]                   
__________________________________________________________________________________________________
embedding_36 (Embedding)        (None, 4, 24)        5640        input_36[0][0]                   
__________________________________________________________________________________________________
flatten_35 (Flatten)            (None, 192)          0           embedding_35[0][0]               
__________________________________________________________________________________________________
flatten_36 (Flatten)            (None, 96)           0           embedding_36[0][0]               
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 288)          0           flatten_35[0][0]                 
                                                                 flatten_36[0][0]                 
__________________________________________________________________________________________________
dense_35 (Dense)                (None, 24)           6936        concatenate_18[0][0]             
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, 24)           0           dense_35[0][0]                   
__________________________________________________________________________________________________
dense_36 (Dense)                (None, 8)            200         dropout_18[0][0]                 
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 1.3812 - acc: 0.7301 - val_loss: 0.4405 - val_acc: 0.8320
Epoch 2/15
 - 1s - loss: 0.9864 - acc: 0.8388 - val_loss: 0.3385 - val_acc: 0.8496
Epoch 3/15
 - 1s - loss: 0.5906 - acc: 0.8568 - val_loss: 0.2873 - val_acc: 0.8585
Epoch 4/15
 - 1s - loss: 0.4596 - acc: 0.8625 - val_loss: 0.2741 - val_acc: 0.8608
Epoch 5/15
 - 1s - loss: 0.4369 - acc: 0.8674 - val_loss: 0.2694 - val_acc: 0.8617
Epoch 6/15
 - 1s - loss: 0.2862 - acc: 0.8703 - val_loss: 0.2672 - val_acc: 0.8632
Epoch 7/15
 - 1s - loss: 0.2527 - acc: 0.8731 - val_loss: 0.2677 - val_acc: 0.8641
Epoch 8/15
 - 1s - loss: 0.2371 - acc: 0.8735 - val_loss: 0.2690 - val_acc: 0.8641
Epoch 9/15
 - 1s - loss: 0.2306 - acc: 0.8760 - val_loss: 0.2703 - val_acc: 0.8647
Epoch 10/15
 - 1s - loss: 0.2241 - acc: 0.8760 - val_loss: 0.2725 - val_acc: 0.8650
Epoch 11/15
 - 1s - loss: 0.2364 - acc: 0.8777 - val_loss: 0.2772 - val_acc: 0.8647
Epoch 12/15
 - 1s - loss: 0.2098 - acc: 0.8775 - val_loss: 0.2783 - val_acc: 0.8653
Epoch 13/15
 - 1s - loss: 0.2069 - acc: 0.8783 - val_loss: 0.2793 - val_acc: 0.8650
Epoch 14/15
 - 1s - loss: 0.2081 - acc: 0.8787 - val_loss: 0.2816 - val_acc: 0.8653
Epoch 15/15
 - 1s - loss: 0.2047 - acc: 0.8788 - val_loss: 0.2951 - val_acc: 0.8650
# Training time = 0:00:15.796053
# F-Score(Ordinary) = 0.158, Recall: 0.1, Precision: 0.374
# F-Score(lvc) = 0.076, Recall: 0.043, Precision: 0.333
# F-Score(ireflv) = 0.163, Recall: 0.108, Precision: 0.328
# F-Score(id) = 0.36, Recall: 0.328, Precision: 0.399
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_37 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_38 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_37 (Embedding)        (None, 4, 48)        705264      input_37[0][0]                   
__________________________________________________________________________________________________
embedding_38 (Embedding)        (None, 4, 24)        5640        input_38[0][0]                   
__________________________________________________________________________________________________
flatten_37 (Flatten)            (None, 192)          0           embedding_37[0][0]               
__________________________________________________________________________________________________
flatten_38 (Flatten)            (None, 96)           0           embedding_38[0][0]               
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 288)          0           flatten_37[0][0]                 
                                                                 flatten_38[0][0]                 
__________________________________________________________________________________________________
dense_37 (Dense)                (None, 24)           6936        concatenate_19[0][0]             
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 24)           0           dense_37[0][0]                   
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 8)            200         dropout_19[0][0]                 
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 1.6405 - acc: 0.7108 - val_loss: 0.3486 - val_acc: 0.8443
Epoch 2/15
 - 1s - loss: 1.0623 - acc: 0.8488 - val_loss: 0.2988 - val_acc: 0.8538
Epoch 3/15
 - 1s - loss: 0.6928 - acc: 0.8604 - val_loss: 0.2865 - val_acc: 0.8567
Epoch 4/15
 - 1s - loss: 0.5958 - acc: 0.8656 - val_loss: 0.2746 - val_acc: 0.8588
Epoch 5/15
 - 1s - loss: 0.4487 - acc: 0.8679 - val_loss: 0.2697 - val_acc: 0.8585
Epoch 6/15
 - 1s - loss: 0.3609 - acc: 0.8698 - val_loss: 0.2678 - val_acc: 0.8603
Epoch 7/15
 - 1s - loss: 0.3050 - acc: 0.8714 - val_loss: 0.2675 - val_acc: 0.8620
Epoch 8/15
 - 1s - loss: 0.2803 - acc: 0.8724 - val_loss: 0.2680 - val_acc: 0.8626
Epoch 9/15
 - 1s - loss: 0.2390 - acc: 0.8744 - val_loss: 0.2684 - val_acc: 0.8614
Epoch 10/15
 - 1s - loss: 0.2367 - acc: 0.8758 - val_loss: 0.2707 - val_acc: 0.8638
Epoch 11/15
 - 1s - loss: 0.2236 - acc: 0.8761 - val_loss: 0.2710 - val_acc: 0.8617
Epoch 12/15
 - 1s - loss: 0.2176 - acc: 0.8772 - val_loss: 0.2732 - val_acc: 0.8635
Epoch 13/15
 - 1s - loss: 0.2158 - acc: 0.8778 - val_loss: 0.2789 - val_acc: 0.8632
Epoch 14/15
 - 1s - loss: 0.2097 - acc: 0.8782 - val_loss: 0.2780 - val_acc: 0.8629
Epoch 15/15
 - 1s - loss: 0.2075 - acc: 0.8784 - val_loss: 0.2804 - val_acc: 0.8626
# Training time = 0:00:15.789825
# F-Score(Ordinary) = 0.13, Recall: 0.079, Precision: 0.351
# F-Score(lvc) = 0.044, Recall: 0.024, Precision: 0.242
# F-Score(ireflv) = 0.167, Recall: 0.104, Precision: 0.426
# F-Score(id) = 0.411, Recall: 0.504, Precision: 0.347
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_39 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_40 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_39 (Embedding)        (None, 4, 48)        705264      input_39[0][0]                   
__________________________________________________________________________________________________
embedding_40 (Embedding)        (None, 4, 24)        5640        input_40[0][0]                   
__________________________________________________________________________________________________
flatten_39 (Flatten)            (None, 192)          0           embedding_39[0][0]               
__________________________________________________________________________________________________
flatten_40 (Flatten)            (None, 96)           0           embedding_40[0][0]               
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 288)          0           flatten_39[0][0]                 
                                                                 flatten_40[0][0]                 
__________________________________________________________________________________________________
dense_39 (Dense)                (None, 24)           6936        concatenate_20[0][0]             
__________________________________________________________________________________________________
dropout_20 (Dropout)            (None, 24)           0           dense_39[0][0]                   
__________________________________________________________________________________________________
dense_40 (Dense)                (None, 8)            200         dropout_20[0][0]                 
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 30526 samples, validate on 3392 samples
Epoch 1/15
 - 1s - loss: 1.7984 - acc: 0.7287 - val_loss: 0.3443 - val_acc: 0.8464
Epoch 2/15
 - 1s - loss: 1.0992 - acc: 0.8474 - val_loss: 0.2989 - val_acc: 0.8517
Epoch 3/15
 - 1s - loss: 0.6955 - acc: 0.8604 - val_loss: 0.2795 - val_acc: 0.8591
Epoch 4/15
 - 1s - loss: 0.5508 - acc: 0.8632 - val_loss: 0.2744 - val_acc: 0.8594
Epoch 5/15
 - 1s - loss: 0.4224 - acc: 0.8672 - val_loss: 0.2700 - val_acc: 0.8617
Epoch 6/15
 - 1s - loss: 0.3185 - acc: 0.8701 - val_loss: 0.2658 - val_acc: 0.8626
Epoch 7/15
 - 1s - loss: 0.3066 - acc: 0.8719 - val_loss: 0.2659 - val_acc: 0.8629
Epoch 8/15
 - 1s - loss: 0.2821 - acc: 0.8730 - val_loss: 0.2677 - val_acc: 0.8617
Epoch 9/15
 - 1s - loss: 0.2377 - acc: 0.8745 - val_loss: 0.2671 - val_acc: 0.8629
Epoch 10/15
 - 1s - loss: 0.2679 - acc: 0.8740 - val_loss: 0.2703 - val_acc: 0.8635
Epoch 11/15
 - 1s - loss: 0.3007 - acc: 0.8755 - val_loss: 0.2708 - val_acc: 0.8644
Epoch 12/15
 - 1s - loss: 0.2117 - acc: 0.8771 - val_loss: 0.2721 - val_acc: 0.8641
Epoch 13/15
 - 1s - loss: 0.2115 - acc: 0.8774 - val_loss: 0.2754 - val_acc: 0.8635
Epoch 14/15
 - 1s - loss: 0.2066 - acc: 0.8778 - val_loss: 0.2741 - val_acc: 0.8641
Epoch 15/15
 - 1s - loss: 0.2062 - acc: 0.8784 - val_loss: 0.2793 - val_acc: 0.8632
# Training time = 0:00:15.835685
# F-Score(Ordinary) = 0.159, Recall: 0.1, Precision: 0.387
# F-Score(lvc) = 0.078, Recall: 0.044, Precision: 0.311
# F-Score(ireflv) = 0.178, Recall: 0.111, Precision: 0.451
# F-Score(id) = 0.317, Recall: 0.273, Precision: 0.378
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_41 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_42 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_41 (Embedding)        (None, 4, 48)        705264      input_41[0][0]                   
__________________________________________________________________________________________________
embedding_42 (Embedding)        (None, 4, 24)        5640        input_42[0][0]                   
__________________________________________________________________________________________________
flatten_41 (Flatten)            (None, 192)          0           embedding_41[0][0]               
__________________________________________________________________________________________________
flatten_42 (Flatten)            (None, 96)           0           embedding_42[0][0]               
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 288)          0           flatten_41[0][0]                 
                                                                 flatten_42[0][0]                 
__________________________________________________________________________________________________
dense_41 (Dense)                (None, 24)           6936        concatenate_21[0][0]             
__________________________________________________________________________________________________
dropout_21 (Dropout)            (None, 24)           0           dense_41[0][0]                   
__________________________________________________________________________________________________
dense_42 (Dense)                (None, 8)            200         dropout_21[0][0]                 
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
