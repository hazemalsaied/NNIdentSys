INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 4, 48)        705264      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 4, 24)        5640        input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 192)          0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 96)           0           embedding_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 288)          0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 24)           6936        concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24)           0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 8)            200         dropout_1[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.8132 - acc: 0.9390 - val_loss: 0.1499 - val_acc: 0.9576
Epoch 2/15
 - 5s - loss: 0.5649 - acc: 0.9629 - val_loss: 0.1002 - val_acc: 0.9616
Epoch 3/15
 - 5s - loss: 0.4286 - acc: 0.9678 - val_loss: 0.1066 - val_acc: 0.9609
Epoch 4/15
 - 5s - loss: 0.2935 - acc: 0.9693 - val_loss: 0.1110 - val_acc: 0.9635
Epoch 5/15
 - 5s - loss: 0.3571 - acc: 0.9715 - val_loss: 0.1094 - val_acc: 0.9648
Epoch 6/15
 - 5s - loss: 0.2660 - acc: 0.9727 - val_loss: 0.1210 - val_acc: 0.9642
Epoch 7/15
 - 5s - loss: 0.3353 - acc: 0.9732 - val_loss: 0.1256 - val_acc: 0.9650
Epoch 8/15
 - 5s - loss: 0.1605 - acc: 0.9740 - val_loss: 0.1362 - val_acc: 0.9624
Epoch 9/15
 - 5s - loss: 0.3605 - acc: 0.9744 - val_loss: 0.1369 - val_acc: 0.9652
Epoch 10/15
 - 5s - loss: 0.1830 - acc: 0.9748 - val_loss: 0.1473 - val_acc: 0.9659
Epoch 11/15
 - 5s - loss: 0.0992 - acc: 0.9751 - val_loss: 0.1325 - val_acc: 0.9639
Epoch 12/15
 - 5s - loss: 0.2816 - acc: 0.9755 - val_loss: 0.1383 - val_acc: 0.9645
Epoch 13/15
 - 5s - loss: 0.0734 - acc: 0.9756 - val_loss: 0.1566 - val_acc: 0.9654
Epoch 14/15
 - 5s - loss: 0.0506 - acc: 0.9761 - val_loss: 0.1441 - val_acc: 0.9644
Epoch 15/15
 - 5s - loss: 0.0445 - acc: 0.9760 - val_loss: 0.1517 - val_acc: 0.9658
Epoch 1/15
 - 1s - loss: 0.1608 - acc: 0.9582
Epoch 2/15
 - 1s - loss: 0.0893 - acc: 0.9672
Epoch 3/15
 - 1s - loss: 0.0671 - acc: 0.9709
Epoch 4/15
 - 1s - loss: 0.0563 - acc: 0.9724
Epoch 5/15
 - 1s - loss: 0.0519 - acc: 0.9732
Epoch 6/15
 - 1s - loss: 0.0496 - acc: 0.9749
Epoch 7/15
 - 1s - loss: 0.0496 - acc: 0.9750
Epoch 8/15
 - 1s - loss: 0.0488 - acc: 0.9764
Epoch 9/15
 - 1s - loss: 0.0484 - acc: 0.9755
Epoch 10/15
 - 1s - loss: 0.0473 - acc: 0.9764
Epoch 11/15
 - 1s - loss: 0.0487 - acc: 0.9769
Epoch 12/15
 - 1s - loss: 0.0482 - acc: 0.9763
Epoch 13/15
 - 1s - loss: 0.0456 - acc: 0.9768
Epoch 14/15
 - 1s - loss: 0.0428 - acc: 0.9780
Epoch 15/15
 - 1s - loss: 0.0430 - acc: 0.9778
# Training time = 0:01:48.712788
# F-Score(Ordinary) = 0.526, Recall: 0.412, Precision: 0.727
# F-Score(lvc) = 0.28, Recall: 0.182, Precision: 0.598
# F-Score(ireflv) = 0.721, Recall: 0.616, Precision: 0.869
# F-Score(id) = 0.686, Recall: 0.705, Precision: 0.668
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 4, 48)        705264      input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 4, 24)        5640        input_4[0][0]                    
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 192)          0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 96)           0           embedding_4[0][0]                
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 288)          0           flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 24)           6936        concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24)           0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 8)            200         dropout_2[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.1468 - acc: 0.9295 - val_loss: 0.1156 - val_acc: 0.9590
Epoch 2/15
 - 5s - loss: 1.6538 - acc: 0.9629 - val_loss: 0.0979 - val_acc: 0.9633
Epoch 3/15
 - 5s - loss: 0.4163 - acc: 0.9669 - val_loss: 0.1025 - val_acc: 0.9625
Epoch 4/15
 - 5s - loss: 0.4994 - acc: 0.9693 - val_loss: 0.1043 - val_acc: 0.9639
Epoch 5/15
 - 5s - loss: 0.2614 - acc: 0.9715 - val_loss: 0.1145 - val_acc: 0.9648
Epoch 6/15
 - 5s - loss: 0.1901 - acc: 0.9730 - val_loss: 0.1176 - val_acc: 0.9636
Epoch 7/15
 - 5s - loss: 0.1318 - acc: 0.9740 - val_loss: 0.1256 - val_acc: 0.9640
Epoch 8/15
 - 5s - loss: 0.0919 - acc: 0.9740 - val_loss: 0.1272 - val_acc: 0.9647
Epoch 9/15
 - 5s - loss: 0.0754 - acc: 0.9745 - val_loss: 0.1303 - val_acc: 0.9635
Epoch 10/15
 - 5s - loss: 0.0466 - acc: 0.9745 - val_loss: 0.1463 - val_acc: 0.9620
Epoch 11/15
 - 5s - loss: 0.0461 - acc: 0.9749 - val_loss: 0.1475 - val_acc: 0.9638
Epoch 12/15
 - 5s - loss: 0.0590 - acc: 0.9749 - val_loss: 0.1477 - val_acc: 0.9638
Epoch 13/15
 - 5s - loss: 0.0431 - acc: 0.9754 - val_loss: 0.1527 - val_acc: 0.9633
Epoch 14/15
 - 5s - loss: 0.0433 - acc: 0.9754 - val_loss: 0.1691 - val_acc: 0.9648
Epoch 15/15
 - 5s - loss: 0.0421 - acc: 0.9759 - val_loss: 0.1578 - val_acc: 0.9630
Epoch 1/15
 - 1s - loss: 0.1344 - acc: 0.9592
Epoch 2/15
 - 1s - loss: 0.0914 - acc: 0.9641
Epoch 3/15
 - 1s - loss: 0.0698 - acc: 0.9695
Epoch 4/15
 - 1s - loss: 0.0535 - acc: 0.9717
Epoch 5/15
 - 1s - loss: 0.0494 - acc: 0.9736
Epoch 6/15
 - 1s - loss: 0.0495 - acc: 0.9748
Epoch 7/15
 - 1s - loss: 0.0467 - acc: 0.9753
Epoch 8/15
 - 1s - loss: 0.0467 - acc: 0.9762
Epoch 9/15
 - 1s - loss: 0.0436 - acc: 0.9765
Epoch 10/15
 - 1s - loss: 0.0437 - acc: 0.9771
Epoch 11/15
 - 1s - loss: 0.0442 - acc: 0.9769
Epoch 12/15
 - 1s - loss: 0.0454 - acc: 0.9763
Epoch 13/15
 - 1s - loss: 0.0437 - acc: 0.9770
Epoch 14/15
 - 1s - loss: 0.0463 - acc: 0.9775
Epoch 15/15
 - 1s - loss: 0.0419 - acc: 0.9775
# Training time = 0:01:40.368329
# F-Score(Ordinary) = 0.556, Recall: 0.441, Precision: 0.752
# F-Score(lvc) = 0.345, Recall: 0.238, Precision: 0.621
# F-Score(ireflv) = 0.727, Recall: 0.598, Precision: 0.926
# F-Score(id) = 0.621, Recall: 0.572, Precision: 0.679
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 4, 48)        705264      input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 4, 24)        5640        input_6[0][0]                    
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 192)          0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 96)           0           embedding_6[0][0]                
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 288)          0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 24)           6936        concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24)           0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 8)            200         dropout_3[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.6780 - acc: 0.9363 - val_loss: 0.1095 - val_acc: 0.9577
Epoch 2/15
 - 5s - loss: 0.8655 - acc: 0.9616 - val_loss: 0.1096 - val_acc: 0.9589
Epoch 3/15
 - 5s - loss: 0.2945 - acc: 0.9670 - val_loss: 0.1184 - val_acc: 0.9637
Epoch 4/15
 - 5s - loss: 0.5085 - acc: 0.9698 - val_loss: 0.1108 - val_acc: 0.9637
Epoch 5/15
 - 5s - loss: 0.2108 - acc: 0.9712 - val_loss: 0.1374 - val_acc: 0.9641
Epoch 6/15
 - 5s - loss: 0.0790 - acc: 0.9721 - val_loss: 0.1314 - val_acc: 0.9664
Epoch 7/15
 - 5s - loss: 0.0535 - acc: 0.9732 - val_loss: 0.1370 - val_acc: 0.9661
Epoch 8/15
 - 5s - loss: 0.0474 - acc: 0.9738 - val_loss: 0.1371 - val_acc: 0.9649
Epoch 9/15
 - 5s - loss: 0.1829 - acc: 0.9739 - val_loss: 0.1703 - val_acc: 0.9647
Epoch 10/15
 - 5s - loss: 0.1141 - acc: 0.9746 - val_loss: 0.1751 - val_acc: 0.9638
Epoch 11/15
 - 5s - loss: 0.0448 - acc: 0.9748 - val_loss: 0.1538 - val_acc: 0.9638
Epoch 12/15
 - 5s - loss: 0.0798 - acc: 0.9751 - val_loss: 0.1636 - val_acc: 0.9637
Epoch 13/15
 - 5s - loss: 0.0417 - acc: 0.9754 - val_loss: 0.1874 - val_acc: 0.9649
Epoch 14/15
 - 5s - loss: 0.0406 - acc: 0.9756 - val_loss: 0.2033 - val_acc: 0.9648
Epoch 15/15
 - 5s - loss: 0.0406 - acc: 0.9758 - val_loss: 0.1995 - val_acc: 0.9617
Epoch 1/15
 - 1s - loss: 0.1636 - acc: 0.9592
Epoch 2/15
 - 1s - loss: 0.0995 - acc: 0.9666
Epoch 3/15
 - 1s - loss: 0.0839 - acc: 0.9698
Epoch 4/15
 - 1s - loss: 0.0697 - acc: 0.9733
Epoch 5/15
 - 1s - loss: 0.0656 - acc: 0.9743
Epoch 6/15
 - 1s - loss: 0.0518 - acc: 0.9752
Epoch 7/15
 - 1s - loss: 0.0459 - acc: 0.9759
Epoch 8/15
 - 1s - loss: 0.0447 - acc: 0.9763
Epoch 9/15
 - 1s - loss: 0.0448 - acc: 0.9763
Epoch 10/15
 - 1s - loss: 0.0427 - acc: 0.9765
Epoch 11/15
 - 1s - loss: 0.0436 - acc: 0.9777
Epoch 12/15
 - 1s - loss: 0.0431 - acc: 0.9770
Epoch 13/15
 - 1s - loss: 0.0427 - acc: 0.9779
Epoch 14/15
 - 1s - loss: 0.0428 - acc: 0.9775
Epoch 15/15
 - 1s - loss: 0.0427 - acc: 0.9779
# Training time = 0:01:40.261931
# F-Score(Ordinary) = 0.421, Recall: 0.298, Precision: 0.718
# F-Score(lvc) = 0.45, Recall: 0.426, Precision: 0.477
# F-Score(ireflv) = 0.722, Recall: 0.61, Precision: 0.885
# F-Score(id) = 0.292, Recall: 0.183, Precision: 0.715
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 4, 48)        705264      input_7[0][0]                    
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 4, 24)        5640        input_8[0][0]                    
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 192)          0           embedding_7[0][0]                
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 96)           0           embedding_8[0][0]                
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 288)          0           flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 24)           6936        concatenate_4[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24)           0           dense_7[0][0]                    
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 8)            200         dropout_4[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.6559 - acc: 0.9131 - val_loss: 0.1158 - val_acc: 0.9588
Epoch 2/15
 - 5s - loss: 1.0187 - acc: 0.9623 - val_loss: 0.1023 - val_acc: 0.9643
Epoch 3/15
 - 5s - loss: 0.4712 - acc: 0.9682 - val_loss: 0.1076 - val_acc: 0.9638
Epoch 4/15
 - 5s - loss: 0.6501 - acc: 0.9706 - val_loss: 0.1180 - val_acc: 0.9648
Epoch 5/15
 - 5s - loss: 0.3701 - acc: 0.9720 - val_loss: 0.1110 - val_acc: 0.9638
Epoch 6/15
 - 5s - loss: 0.2442 - acc: 0.9725 - val_loss: 0.1203 - val_acc: 0.9645
Epoch 7/15
 - 5s - loss: 0.0747 - acc: 0.9733 - val_loss: 0.1275 - val_acc: 0.9645
Epoch 8/15
 - 5s - loss: 0.0817 - acc: 0.9737 - val_loss: 0.1375 - val_acc: 0.9649
Epoch 9/15
 - 5s - loss: 0.0474 - acc: 0.9742 - val_loss: 0.1462 - val_acc: 0.9657
Epoch 10/15
 - 5s - loss: 0.0443 - acc: 0.9748 - val_loss: 0.1585 - val_acc: 0.9657
Epoch 11/15
 - 5s - loss: 0.0453 - acc: 0.9750 - val_loss: 0.1404 - val_acc: 0.9651
Epoch 12/15
 - 5s - loss: 0.0426 - acc: 0.9750 - val_loss: 0.1837 - val_acc: 0.9643
Epoch 13/15
 - 5s - loss: 0.0418 - acc: 0.9751 - val_loss: 0.1535 - val_acc: 0.9644
Epoch 14/15
 - 5s - loss: 0.0399 - acc: 0.9758 - val_loss: 0.1886 - val_acc: 0.9656
Epoch 15/15
 - 5s - loss: 0.0397 - acc: 0.9760 - val_loss: 0.1714 - val_acc: 0.9640
Epoch 1/15
 - 1s - loss: 0.1688 - acc: 0.9615
Epoch 2/15
 - 1s - loss: 0.0917 - acc: 0.9665
Epoch 3/15
 - 1s - loss: 0.0682 - acc: 0.9704
Epoch 4/15
 - 1s - loss: 0.0528 - acc: 0.9729
Epoch 5/15
 - 1s - loss: 0.0510 - acc: 0.9735
Epoch 6/15
 - 1s - loss: 0.0516 - acc: 0.9752
Epoch 7/15
 - 1s - loss: 0.0458 - acc: 0.9758
Epoch 8/15
 - 1s - loss: 0.0440 - acc: 0.9762
Epoch 9/15
 - 1s - loss: 0.0457 - acc: 0.9764
Epoch 10/15
 - 1s - loss: 0.0451 - acc: 0.9761
Epoch 11/15
 - 1s - loss: 0.0432 - acc: 0.9772
Epoch 12/15
 - 1s - loss: 0.0439 - acc: 0.9773
Epoch 13/15
 - 1s - loss: 0.0423 - acc: 0.9771
Epoch 14/15
 - 1s - loss: 0.0414 - acc: 0.9777
Epoch 15/15
 - 1s - loss: 0.0432 - acc: 0.9784
# Training time = 0:01:40.355635
# F-Score(Ordinary) = 0.395, Recall: 0.273, Precision: 0.718
# F-Score(lvc) = 0.492, Recall: 0.5, Precision: 0.485
# F-Score(ireflv) = 0.71, Recall: 0.608, Precision: 0.852
# F-Score(id) = 0.263, Recall: 0.161, Precision: 0.731
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_10 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 4, 48)        705264      input_9[0][0]                    
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 4, 24)        5640        input_10[0][0]                   
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 192)          0           embedding_9[0][0]                
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 96)           0           embedding_10[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 288)          0           flatten_9[0][0]                  
                                                                 flatten_10[0][0]                 
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 24)           6936        concatenate_5[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24)           0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 8)            200         dropout_5[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.3774 - acc: 0.9228 - val_loss: 0.1228 - val_acc: 0.9529
Epoch 2/15
 - 5s - loss: 0.5475 - acc: 0.9583 - val_loss: 0.0981 - val_acc: 0.9607
Epoch 3/15
 - 5s - loss: 0.5575 - acc: 0.9639 - val_loss: 0.0982 - val_acc: 0.9635
Epoch 4/15
 - 5s - loss: 0.3312 - acc: 0.9671 - val_loss: 0.1035 - val_acc: 0.9636
Epoch 5/15
 - 5s - loss: 0.1732 - acc: 0.9694 - val_loss: 0.1133 - val_acc: 0.9628
Epoch 6/15
 - 5s - loss: 0.0912 - acc: 0.9708 - val_loss: 0.1173 - val_acc: 0.9654
Epoch 7/15
 - 5s - loss: 0.1255 - acc: 0.9714 - val_loss: 0.1232 - val_acc: 0.9645
Epoch 8/15
 - 5s - loss: 0.0500 - acc: 0.9728 - val_loss: 0.1317 - val_acc: 0.9642
Epoch 9/15
 - 5s - loss: 0.1747 - acc: 0.9735 - val_loss: 0.1278 - val_acc: 0.9622
Epoch 10/15
 - 5s - loss: 0.0445 - acc: 0.9738 - val_loss: 0.1392 - val_acc: 0.9644
Epoch 11/15
 - 5s - loss: 0.0424 - acc: 0.9744 - val_loss: 0.1437 - val_acc: 0.9646
Epoch 12/15
 - 5s - loss: 0.0422 - acc: 0.9746 - val_loss: 0.1386 - val_acc: 0.9643
Epoch 13/15
 - 5s - loss: 0.0419 - acc: 0.9752 - val_loss: 0.1851 - val_acc: 0.9659
Epoch 14/15
 - 5s - loss: 0.0404 - acc: 0.9751 - val_loss: 0.1510 - val_acc: 0.9631
Epoch 15/15
 - 5s - loss: 0.0405 - acc: 0.9752 - val_loss: 0.1744 - val_acc: 0.9651
Epoch 1/15
 - 1s - loss: 0.1688 - acc: 0.9591
Epoch 2/15
 - 1s - loss: 0.0787 - acc: 0.9661
Epoch 3/15
 - 1s - loss: 0.0654 - acc: 0.9709
Epoch 4/15
 - 1s - loss: 0.0534 - acc: 0.9729
Epoch 5/15
 - 1s - loss: 0.0564 - acc: 0.9738
Epoch 6/15
 - 1s - loss: 0.0481 - acc: 0.9745
Epoch 7/15
 - 1s - loss: 0.0455 - acc: 0.9760
Epoch 8/15
 - 1s - loss: 0.0453 - acc: 0.9764
Epoch 9/15
 - 1s - loss: 0.0496 - acc: 0.9757
Epoch 10/15
 - 1s - loss: 0.0427 - acc: 0.9767
Epoch 11/15
 - 1s - loss: 0.0422 - acc: 0.9773
Epoch 12/15
 - 1s - loss: 0.0417 - acc: 0.9777
Epoch 13/15
 - 1s - loss: 0.0423 - acc: 0.9772
Epoch 14/15
 - 1s - loss: 0.0411 - acc: 0.9780
Epoch 15/15
 - 1s - loss: 0.0423 - acc: 0.9778
# Training time = 0:01:40.414528
# F-Score(Ordinary) = 0.619, Recall: 0.546, Precision: 0.714
# F-Score(lvc) = 0.422, Recall: 0.344, Precision: 0.545
# F-Score(ireflv) = 0.764, Recall: 0.677, Precision: 0.877
# F-Score(id) = 0.654, Recall: 0.618, Precision: 0.694
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 4, 48)        705264      input_11[0][0]                   
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 4, 24)        5640        input_12[0][0]                   
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 192)          0           embedding_11[0][0]               
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 96)           0           embedding_12[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 288)          0           flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 24)           6936        concatenate_6[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24)           0           dense_11[0][0]                   
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 8)            200         dropout_6[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.7998 - acc: 0.9227 - val_loss: 0.1115 - val_acc: 0.9578
Epoch 2/15
 - 5s - loss: 0.9473 - acc: 0.9617 - val_loss: 0.1021 - val_acc: 0.9617
Epoch 3/15
 - 5s - loss: 0.3602 - acc: 0.9672 - val_loss: 0.0983 - val_acc: 0.9630
Epoch 4/15
 - 5s - loss: 0.3849 - acc: 0.9689 - val_loss: 0.1030 - val_acc: 0.9612
Epoch 5/15
 - 5s - loss: 0.4109 - acc: 0.9705 - val_loss: 0.1096 - val_acc: 0.9636
Epoch 6/15
 - 5s - loss: 0.3970 - acc: 0.9714 - val_loss: 0.1160 - val_acc: 0.9636
Epoch 7/15
 - 5s - loss: 0.1837 - acc: 0.9729 - val_loss: 0.1187 - val_acc: 0.9641
Epoch 8/15
 - 5s - loss: 0.2484 - acc: 0.9737 - val_loss: 0.1314 - val_acc: 0.9633
Epoch 9/15
 - 5s - loss: 0.0690 - acc: 0.9739 - val_loss: 0.1400 - val_acc: 0.9642
Epoch 10/15
 - 5s - loss: 0.1746 - acc: 0.9744 - val_loss: 0.1522 - val_acc: 0.9644
Epoch 11/15
 - 5s - loss: 0.0479 - acc: 0.9745 - val_loss: 0.1471 - val_acc: 0.9646
Epoch 12/15
 - 5s - loss: 0.1177 - acc: 0.9752 - val_loss: 0.1469 - val_acc: 0.9639
Epoch 13/15
 - 5s - loss: 0.0576 - acc: 0.9753 - val_loss: 0.1501 - val_acc: 0.9654
Epoch 14/15
 - 5s - loss: 0.0454 - acc: 0.9756 - val_loss: 0.1507 - val_acc: 0.9651
Epoch 15/15
 - 5s - loss: 0.0433 - acc: 0.9757 - val_loss: 0.1523 - val_acc: 0.9649
Epoch 1/15
 - 1s - loss: 0.1723 - acc: 0.9621
Epoch 2/15
 - 1s - loss: 0.0969 - acc: 0.9661
Epoch 3/15
 - 1s - loss: 0.0704 - acc: 0.9706
Epoch 4/15
 - 1s - loss: 0.0556 - acc: 0.9726
Epoch 5/15
 - 1s - loss: 0.0527 - acc: 0.9741
Epoch 6/15
 - 1s - loss: 0.0498 - acc: 0.9746
Epoch 7/15
 - 1s - loss: 0.0474 - acc: 0.9758
Epoch 8/15
 - 1s - loss: 0.0459 - acc: 0.9767
Epoch 9/15
 - 1s - loss: 0.0455 - acc: 0.9765
Epoch 10/15
 - 1s - loss: 0.0447 - acc: 0.9767
Epoch 11/15
 - 1s - loss: 0.0444 - acc: 0.9774
Epoch 12/15
 - 1s - loss: 0.0447 - acc: 0.9771
Epoch 13/15
 - 1s - loss: 0.0449 - acc: 0.9775
Epoch 14/15
 - 1s - loss: 0.0439 - acc: 0.9778
Epoch 15/15
 - 1s - loss: 0.0451 - acc: 0.9773
# Training time = 0:01:40.333644
# F-Score(Ordinary) = 0.505, Recall: 0.388, Precision: 0.72
# F-Score(lvc) = 0.312, Recall: 0.214, Precision: 0.576
# F-Score(ireflv) = 0.679, Recall: 0.538, Precision: 0.918
# F-Score(id) = 0.549, Recall: 0.474, Precision: 0.653
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_14 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 4, 48)        705264      input_13[0][0]                   
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 4, 24)        5640        input_14[0][0]                   
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 192)          0           embedding_13[0][0]               
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 96)           0           embedding_14[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 288)          0           flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 24)           6936        concatenate_7[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24)           0           dense_13[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 8)            200         dropout_7[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.6369 - acc: 0.9324 - val_loss: 0.1120 - val_acc: 0.9562
Epoch 2/15
 - 5s - loss: 1.2067 - acc: 0.9630 - val_loss: 0.1014 - val_acc: 0.9602
Epoch 3/15
 - 5s - loss: 0.6781 - acc: 0.9667 - val_loss: 0.1025 - val_acc: 0.9628
Epoch 4/15
 - 5s - loss: 0.4203 - acc: 0.9690 - val_loss: 0.1129 - val_acc: 0.9642
Epoch 5/15
 - 5s - loss: 0.3436 - acc: 0.9708 - val_loss: 0.1088 - val_acc: 0.9655
Epoch 6/15
 - 5s - loss: 0.2790 - acc: 0.9720 - val_loss: 0.1154 - val_acc: 0.9642
Epoch 7/15
 - 5s - loss: 0.3874 - acc: 0.9727 - val_loss: 0.1148 - val_acc: 0.9638
Epoch 8/15
 - 5s - loss: 0.2212 - acc: 0.9733 - val_loss: 0.1387 - val_acc: 0.9640
Epoch 9/15
 - 5s - loss: 0.1128 - acc: 0.9736 - val_loss: 0.1354 - val_acc: 0.9642
Epoch 10/15
 - 5s - loss: 0.0545 - acc: 0.9744 - val_loss: 0.1410 - val_acc: 0.9657
Epoch 11/15
 - 5s - loss: 0.0454 - acc: 0.9744 - val_loss: 0.1324 - val_acc: 0.9647
Epoch 12/15
 - 5s - loss: 0.0769 - acc: 0.9750 - val_loss: 0.1816 - val_acc: 0.9645
Epoch 13/15
 - 5s - loss: 0.0444 - acc: 0.9749 - val_loss: 0.1438 - val_acc: 0.9651
Epoch 14/15
 - 5s - loss: 0.0455 - acc: 0.9750 - val_loss: 0.1533 - val_acc: 0.9654
Epoch 15/15
 - 5s - loss: 0.1381 - acc: 0.9751 - val_loss: 0.1650 - val_acc: 0.9633
Epoch 1/15
 - 1s - loss: 0.1744 - acc: 0.9567
Epoch 2/15
 - 1s - loss: 0.0793 - acc: 0.9663
Epoch 3/15
 - 1s - loss: 0.0717 - acc: 0.9696
Epoch 4/15
 - 1s - loss: 0.0587 - acc: 0.9720
Epoch 5/15
 - 1s - loss: 0.0533 - acc: 0.9718
Epoch 6/15
 - 1s - loss: 0.0498 - acc: 0.9742
Epoch 7/15
 - 1s - loss: 0.0473 - acc: 0.9753
Epoch 8/15
 - 1s - loss: 0.0457 - acc: 0.9758
Epoch 9/15
 - 1s - loss: 0.0467 - acc: 0.9759
Epoch 10/15
 - 1s - loss: 0.0455 - acc: 0.9764
Epoch 11/15
 - 1s - loss: 0.0440 - acc: 0.9768
Epoch 12/15
 - 1s - loss: 0.0452 - acc: 0.9763
Epoch 13/15
 - 1s - loss: 0.0432 - acc: 0.9771
Epoch 14/15
 - 1s - loss: 0.0434 - acc: 0.9771
Epoch 15/15
 - 1s - loss: 0.0436 - acc: 0.9778
