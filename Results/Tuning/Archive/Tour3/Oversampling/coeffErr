INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
/home/halsaied/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using Theano backend.
Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:
/tmp/try_flags_N88mYc.c:4:10: fatal error: cudnn.h: No such file or directory
 #include <cudnn.h>
          ^~~~~~~~~
compilation terminated.

Preallocating 10619/11178 Mb (0.950000) on cuda
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:03:00.0)
/home/halsaied/NNIdenSys/src/vocabulary.py:328: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if item in corpusTokens:
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.4--2.7.14-64/tmp4u6wUE and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.4--2.7.14-64/tmpsyJLRu). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.4--2.7.14-64/tmp4u6wUE and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.4--2.7.14-64/tmpsyJLRu). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 4, 50)        734650      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 4, 25)        5875        input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 200)          0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 100)          0           embedding_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 24)           7224        concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24)           0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 8)            200         dropout_1[0][0]                  
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 148.85279259051362, 4.0: 636.1550917596257, 5.0: 475.61877858488026, 6.0: 633.49558050645, 7.0: 757660.7142857143}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:54.231507
# F-Score(Ordinary) = 0.399, Recall: 0.285, Precision: 0.667
# F-Score(lvc) = 0.171, Recall: 0.103, Precision: 0.508
# F-Score(ireflv) = 0.716, Recall: 0.626, Precision: 0.836
# F-Score(id) = 0.569, Recall: 0.522, Precision: 0.627
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 4, 50)        734650      input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 4, 25)        5875        input_4[0][0]                    
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 200)          0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 100)          0           embedding_4[0][0]                
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 300)          0           flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 24)           7224        concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24)           0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 8)            200         dropout_2[0][0]                  
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 148.85279259051362, 4.0: 636.1550917596257, 5.0: 475.61877858488026, 6.0: 633.49558050645, 7.0: 757660.7142857143}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:51.492732
# F-Score(Ordinary) = 0.579, Recall: 0.515, Precision: 0.662
# F-Score(lvc) = 0.403, Recall: 0.352, Precision: 0.47
# F-Score(ireflv) = 0.7, Recall: 0.586, Precision: 0.869
# F-Score(id) = 0.584, Recall: 0.55, Precision: 0.622
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 4, 50)        734650      input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 4, 25)        5875        input_6[0][0]                    
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 200)          0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 100)          0           embedding_6[0][0]                
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 300)          0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 24)           7224        concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24)           0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 8)            200         dropout_3[0][0]                  
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 148.85279259051362, 4.0: 636.1550917596257, 5.0: 475.61877858488026, 6.0: 633.49558050645, 7.0: 757660.7142857143}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:54.009701
# F-Score(Ordinary) = 0.595, Recall: 0.526, Precision: 0.685
# F-Score(lvc) = 0.407, Recall: 0.379, Precision: 0.439
# F-Score(ireflv) = 0.734, Recall: 0.623, Precision: 0.893
# F-Score(id) = 0.582, Recall: 0.512, Precision: 0.674
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 4, 50)        734650      input_7[0][0]                    
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 4, 25)        5875        input_8[0][0]                    
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 200)          0           embedding_7[0][0]                
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 100)          0           embedding_8[0][0]                
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 300)          0           flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 24)           7224        concatenate_4[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24)           0           dense_7[0][0]                    
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 8)            200         dropout_4[0][0]                  
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 148.85279259051362, 4.0: 636.1550917596257, 5.0: 475.61877858488026, 6.0: 633.49558050645, 7.0: 757660.7142857143}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:51.236184
# F-Score(Ordinary) = 0.49, Recall: 0.382, Precision: 0.682
# F-Score(lvc) = 0.349, Recall: 0.264, Precision: 0.515
# F-Score(ireflv) = 0.723, Recall: 0.632, Precision: 0.844
# F-Score(id) = 0.446, Recall: 0.337, Precision: 0.658
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_10 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 4, 50)        734650      input_9[0][0]                    
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 4, 25)        5875        input_10[0][0]                   
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 200)          0           embedding_9[0][0]                
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 100)          0           embedding_10[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 300)          0           flatten_9[0][0]                  
                                                                 flatten_10[0][0]                 
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 24)           7224        concatenate_5[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24)           0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 8)            200         dropout_5[0][0]                  
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 148.85279259051362, 4.0: 636.1550917596257, 5.0: 475.61877858488026, 6.0: 633.49558050645, 7.0: 757660.7142857143}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:51.366356
# F-Score(Ordinary) = 0.656, Recall: 0.653, Precision: 0.658
# F-Score(lvc) = 0.472, Recall: 0.5, Precision: 0.447
# F-Score(ireflv) = 0.737, Recall: 0.681, Precision: 0.803
# F-Score(id) = 0.651, Recall: 0.66, Precision: 0.642
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 4, 50)        734650      input_11[0][0]                   
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 4, 25)        5875        input_12[0][0]                   
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 200)          0           embedding_11[0][0]               
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 100)          0           embedding_12[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 300)          0           flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 24)           7224        concatenate_6[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24)           0           dense_11[0][0]                   
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 8)            200         dropout_6[0][0]                  
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 297.70558518102723, 4.0: 1272.3101835192515, 5.0: 951.2375571697605, 6.0: 1266.9911610129, 7.0: 1515321.4285714286}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:49.034747
# F-Score(Ordinary) = 0.49, Recall: 0.395, Precision: 0.647
# F-Score(lvc) = 0.324, Recall: 0.264, Precision: 0.417
# F-Score(ireflv) = 0.673, Recall: 0.571, Precision: 0.82
# F-Score(id) = 0.469, Recall: 0.364, Precision: 0.658
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_14 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 4, 50)        734650      input_13[0][0]                   
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 4, 25)        5875        input_14[0][0]                   
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 200)          0           embedding_13[0][0]               
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 100)          0           embedding_14[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 300)          0           flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 24)           7224        concatenate_7[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24)           0           dense_13[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 8)            200         dropout_7[0][0]                  
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 297.70558518102723, 4.0: 1272.3101835192515, 5.0: 951.2375571697605, 6.0: 1266.9911610129, 7.0: 1515321.4285714286}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:46.773699
# F-Score(Ordinary) = 0.492, Recall: 0.402, Precision: 0.635
# F-Score(lvc) = 0.337, Recall: 0.29, Precision: 0.402
# F-Score(ireflv) = 0.689, Recall: 0.582, Precision: 0.844
# F-Score(id) = 0.444, Recall: 0.346, Precision: 0.622
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_15 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_16 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_15 (Embedding)        (None, 4, 50)        734650      input_15[0][0]                   
__________________________________________________________________________________________________
embedding_16 (Embedding)        (None, 4, 25)        5875        input_16[0][0]                   
__________________________________________________________________________________________________
flatten_15 (Flatten)            (None, 200)          0           embedding_15[0][0]               
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 100)          0           embedding_16[0][0]               
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 300)          0           flatten_15[0][0]                 
                                                                 flatten_16[0][0]                 
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 24)           7224        concatenate_8[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24)           0           dense_15[0][0]                   
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 8)            200         dropout_8[0][0]                  
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 297.70558518102723, 4.0: 1272.3101835192515, 5.0: 951.2375571697605, 6.0: 1266.9911610129, 7.0: 1515321.4285714286}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:04:01.320143
# F-Score(Ordinary) = 0.607, Recall: 0.582, Precision: 0.633
# F-Score(lvc) = 0.409, Recall: 0.409, Precision: 0.409
# F-Score(ireflv) = 0.697, Recall: 0.606, Precision: 0.82
# F-Score(id) = 0.618, Recall: 0.624, Precision: 0.611
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_17 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_18 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_17 (Embedding)        (None, 4, 50)        734650      input_17[0][0]                   
__________________________________________________________________________________________________
embedding_18 (Embedding)        (None, 4, 25)        5875        input_18[0][0]                   
__________________________________________________________________________________________________
flatten_17 (Flatten)            (None, 200)          0           embedding_17[0][0]               
__________________________________________________________________________________________________
flatten_18 (Flatten)            (None, 100)          0           embedding_18[0][0]               
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 300)          0           flatten_17[0][0]                 
                                                                 flatten_18[0][0]                 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 24)           7224        concatenate_9[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24)           0           dense_17[0][0]                   
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 8)            200         dropout_9[0][0]                  
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 297.70558518102723, 4.0: 1272.3101835192515, 5.0: 951.2375571697605, 6.0: 1266.9911610129, 7.0: 1515321.4285714286}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:45.651899
# F-Score(Ordinary) = 0.531, Recall: 0.441, Precision: 0.667
# F-Score(lvc) = 0.439, Recall: 0.439, Precision: 0.439
# F-Score(ireflv) = 0.713, Recall: 0.597, Precision: 0.885
# F-Score(id) = 0.436, Recall: 0.334, Precision: 0.627
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_19 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_20 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_19 (Embedding)        (None, 4, 50)        734650      input_19[0][0]                   
__________________________________________________________________________________________________
embedding_20 (Embedding)        (None, 4, 25)        5875        input_20[0][0]                   
__________________________________________________________________________________________________
flatten_19 (Flatten)            (None, 200)          0           embedding_19[0][0]               
__________________________________________________________________________________________________
flatten_20 (Flatten)            (None, 100)          0           embedding_20[0][0]               
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 300)          0           flatten_19[0][0]                 
                                                                 flatten_20[0][0]                 
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 24)           7224        concatenate_10[0][0]             
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24)           0           dense_19[0][0]                   
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 8)            200         dropout_10[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 297.70558518102723, 4.0: 1272.3101835192515, 5.0: 951.2375571697605, 6.0: 1266.9911610129, 7.0: 1515321.4285714286}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:41.883927
# F-Score(Ordinary) = 0.591, Recall: 0.555, Precision: 0.631
# F-Score(lvc) = 0.398, Recall: 0.403, Precision: 0.394
# F-Score(ireflv) = 0.705, Recall: 0.606, Precision: 0.844
# F-Score(id) = 0.587, Recall: 0.565, Precision: 0.611
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_21 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_22 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_21 (Embedding)        (None, 4, 50)        734650      input_21[0][0]                   
__________________________________________________________________________________________________
embedding_22 (Embedding)        (None, 4, 25)        5875        input_22[0][0]                   
__________________________________________________________________________________________________
flatten_21 (Flatten)            (None, 200)          0           embedding_21[0][0]               
__________________________________________________________________________________________________
flatten_22 (Flatten)            (None, 100)          0           embedding_22[0][0]               
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 300)          0           flatten_21[0][0]                 
                                                                 flatten_22[0][0]                 
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 24)           7224        concatenate_11[0][0]             
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 24)           0           dense_21[0][0]                   
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 8)            200         dropout_11[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 446.5583777715408, 4.0: 1908.4652752788775, 5.0: 1426.856335754641, 6.0: 1900.48674151935, 7.0: 2272982.1428571427}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:40.442907
# F-Score(Ordinary) = 0.396, Recall: 0.287, Precision: 0.638
# F-Score(lvc) = 0.157, Recall: 0.096, Precision: 0.417
# F-Score(ireflv) = 0.663, Recall: 0.532, Precision: 0.877
# F-Score(id) = 0.565, Recall: 0.529, Precision: 0.606
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_23 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_24 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_23 (Embedding)        (None, 4, 50)        734650      input_23[0][0]                   
__________________________________________________________________________________________________
embedding_24 (Embedding)        (None, 4, 25)        5875        input_24[0][0]                   
__________________________________________________________________________________________________
flatten_23 (Flatten)            (None, 200)          0           embedding_23[0][0]               
__________________________________________________________________________________________________
flatten_24 (Flatten)            (None, 100)          0           embedding_24[0][0]               
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 300)          0           flatten_23[0][0]                 
                                                                 flatten_24[0][0]                 
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 24)           7224        concatenate_12[0][0]             
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 24)           0           dense_23[0][0]                   
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 8)            200         dropout_12[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 446.5583777715408, 4.0: 1908.4652752788775, 5.0: 1426.856335754641, 6.0: 1900.48674151935, 7.0: 2272982.1428571427}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:46.655291
# F-Score(Ordinary) = 0.482, Recall: 0.454, Precision: 0.515
# F-Score(lvc) = 0.377, Recall: 0.448, Precision: 0.326
# F-Score(ireflv) = 0.715, Recall: 0.798, Precision: 0.648
# F-Score(id) = 0.4, Recall: 0.324, Precision: 0.523
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_25 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_26 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_25 (Embedding)        (None, 4, 50)        734650      input_25[0][0]                   
__________________________________________________________________________________________________
embedding_26 (Embedding)        (None, 4, 25)        5875        input_26[0][0]                   
__________________________________________________________________________________________________
flatten_25 (Flatten)            (None, 200)          0           embedding_25[0][0]               
__________________________________________________________________________________________________
flatten_26 (Flatten)            (None, 100)          0           embedding_26[0][0]               
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 300)          0           flatten_25[0][0]                 
                                                                 flatten_26[0][0]                 
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 24)           7224        concatenate_13[0][0]             
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 24)           0           dense_25[0][0]                   
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 8)            200         dropout_13[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 446.5583777715408, 4.0: 1908.4652752788775, 5.0: 1426.856335754641, 6.0: 1900.48674151935, 7.0: 2272982.1428571427}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:43.895339
# F-Score(Ordinary) = 0.564, Recall: 0.501, Precision: 0.647
# F-Score(lvc) = 0.467, Recall: 0.61, Precision: 0.379
# F-Score(ireflv) = 0.669, Recall: 0.54, Precision: 0.877
# F-Score(id) = 0.502, Recall: 0.414, Precision: 0.637
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_27 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_28 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_27 (Embedding)        (None, 4, 50)        734650      input_27[0][0]                   
__________________________________________________________________________________________________
embedding_28 (Embedding)        (None, 4, 25)        5875        input_28[0][0]                   
__________________________________________________________________________________________________
flatten_27 (Flatten)            (None, 200)          0           embedding_27[0][0]               
__________________________________________________________________________________________________
flatten_28 (Flatten)            (None, 100)          0           embedding_28[0][0]               
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 300)          0           flatten_27[0][0]                 
                                                                 flatten_28[0][0]                 
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 24)           7224        concatenate_14[0][0]             
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 24)           0           dense_27[0][0]                   
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 8)            200         dropout_14[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 446.5583777715408, 4.0: 1908.4652752788775, 5.0: 1426.856335754641, 6.0: 1900.48674151935, 7.0: 2272982.1428571427}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:49.806291
# F-Score(Ordinary) = 0.342, Recall: 0.233, Precision: 0.649
# F-Score(lvc) = 0.453, Recall: 0.487, Precision: 0.424
# F-Score(ireflv) = 0.699, Recall: 0.6, Precision: 0.836
# F-Score(id) = 0.208, Recall: 0.125, Precision: 0.622
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_29 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_30 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_29 (Embedding)        (None, 4, 50)        734650      input_29[0][0]                   
__________________________________________________________________________________________________
embedding_30 (Embedding)        (None, 4, 25)        5875        input_30[0][0]                   
__________________________________________________________________________________________________
flatten_29 (Flatten)            (None, 200)          0           embedding_29[0][0]               
__________________________________________________________________________________________________
flatten_30 (Flatten)            (None, 100)          0           embedding_30[0][0]               
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 300)          0           flatten_29[0][0]                 
                                                                 flatten_30[0][0]                 
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 24)           7224        concatenate_15[0][0]             
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 24)           0           dense_29[0][0]                   
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 8)            200         dropout_15[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 446.5583777715408, 4.0: 1908.4652752788775, 5.0: 1426.856335754641, 6.0: 1900.48674151935, 7.0: 2272982.1428571427}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:48.873121
# F-Score(Ordinary) = 0.63, Recall: 0.613, Precision: 0.649
# F-Score(lvc) = 0.469, Recall: 0.514, Precision: 0.432
# F-Score(ireflv) = 0.662, Recall: 0.538, Precision: 0.861
# F-Score(id) = 0.661, Recall: 0.713, Precision: 0.617
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_31 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_32 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_31 (Embedding)        (None, 4, 50)        734650      input_31[0][0]                   
__________________________________________________________________________________________________
embedding_32 (Embedding)        (None, 4, 25)        5875        input_32[0][0]                   
__________________________________________________________________________________________________
flatten_31 (Flatten)            (None, 200)          0           embedding_31[0][0]               
__________________________________________________________________________________________________
flatten_32 (Flatten)            (None, 100)          0           embedding_32[0][0]               
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 300)          0           flatten_31[0][0]                 
                                                                 flatten_32[0][0]                 
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 24)           7224        concatenate_16[0][0]             
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 24)           0           dense_31[0][0]                   
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 8)            200         dropout_16[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 535.870053325849, 4.0: 2290.158330334653, 5.0: 1712.227602905569, 6.0: 2280.58408982322, 7.0: 2727578.5714285714}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:48.576200
# F-Score(Ordinary) = 0.304, Recall: 0.2, Precision: 0.633
# F-Score(lvc) = 0.094, Recall: 0.053, Precision: 0.424
# F-Score(ireflv) = 0.665, Recall: 0.548, Precision: 0.844
# F-Score(id) = 0.646, Recall: 0.706, Precision: 0.596
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_33 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_34 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_33 (Embedding)        (None, 4, 50)        734650      input_33[0][0]                   
__________________________________________________________________________________________________
embedding_34 (Embedding)        (None, 4, 25)        5875        input_34[0][0]                   
__________________________________________________________________________________________________
flatten_33 (Flatten)            (None, 200)          0           embedding_33[0][0]               
__________________________________________________________________________________________________
flatten_34 (Flatten)            (None, 100)          0           embedding_34[0][0]               
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 300)          0           flatten_33[0][0]                 
                                                                 flatten_34[0][0]                 
__________________________________________________________________________________________________
dense_33 (Dense)                (None, 24)           7224        concatenate_17[0][0]             
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 24)           0           dense_33[0][0]                   
__________________________________________________________________________________________________
dense_34 (Dense)                (None, 8)            200         dropout_17[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 535.870053325849, 4.0: 2290.158330334653, 5.0: 1712.227602905569, 6.0: 2280.58408982322, 7.0: 2727578.5714285714}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:48.209680
# F-Score(Ordinary) = 0.377, Recall: 0.268, Precision: 0.635
# F-Score(lvc) = 0.364, Recall: 0.338, Precision: 0.394
# F-Score(ireflv) = 0.687, Recall: 0.583, Precision: 0.836
# F-Score(id) = 0.257, Recall: 0.163, Precision: 0.617
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_35 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_36 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_35 (Embedding)        (None, 4, 50)        734650      input_35[0][0]                   
__________________________________________________________________________________________________
embedding_36 (Embedding)        (None, 4, 25)        5875        input_36[0][0]                   
__________________________________________________________________________________________________
flatten_35 (Flatten)            (None, 200)          0           embedding_35[0][0]               
__________________________________________________________________________________________________
flatten_36 (Flatten)            (None, 100)          0           embedding_36[0][0]               
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 300)          0           flatten_35[0][0]                 
                                                                 flatten_36[0][0]                 
__________________________________________________________________________________________________
dense_35 (Dense)                (None, 24)           7224        concatenate_18[0][0]             
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, 24)           0           dense_35[0][0]                   
__________________________________________________________________________________________________
dense_36 (Dense)                (None, 8)            200         dropout_18[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 535.870053325849, 4.0: 2290.158330334653, 5.0: 1712.227602905569, 6.0: 2280.58408982322, 7.0: 2727578.5714285714}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:52.000127
# F-Score(Ordinary) = 0.618, Recall: 0.647, Precision: 0.591
# F-Score(lvc) = 0.406, Recall: 0.691, Precision: 0.288
# F-Score(ireflv) = 0.729, Recall: 0.646, Precision: 0.836
# F-Score(id) = 0.629, Recall: 0.626, Precision: 0.632
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_37 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_38 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_37 (Embedding)        (None, 4, 50)        734650      input_37[0][0]                   
__________________________________________________________________________________________________
embedding_38 (Embedding)        (None, 4, 25)        5875        input_38[0][0]                   
__________________________________________________________________________________________________
flatten_37 (Flatten)            (None, 200)          0           embedding_37[0][0]               
__________________________________________________________________________________________________
flatten_38 (Flatten)            (None, 100)          0           embedding_38[0][0]               
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 300)          0           flatten_37[0][0]                 
                                                                 flatten_38[0][0]                 
__________________________________________________________________________________________________
dense_37 (Dense)                (None, 24)           7224        concatenate_19[0][0]             
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 24)           0           dense_37[0][0]                   
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 8)            200         dropout_19[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 535.870053325849, 4.0: 2290.158330334653, 5.0: 1712.227602905569, 6.0: 2280.58408982322, 7.0: 2727578.5714285714}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:44.826556
# F-Score(Ordinary) = 0.498, Recall: 0.392, Precision: 0.68
# F-Score(lvc) = 0.427, Recall: 0.396, Precision: 0.462
# F-Score(ireflv) = 0.736, Recall: 0.626, Precision: 0.893
# F-Score(id) = 0.384, Recall: 0.275, Precision: 0.637
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_39 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_40 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_39 (Embedding)        (None, 4, 50)        734650      input_39[0][0]                   
__________________________________________________________________________________________________
embedding_40 (Embedding)        (None, 4, 25)        5875        input_40[0][0]                   
__________________________________________________________________________________________________
flatten_39 (Flatten)            (None, 200)          0           embedding_39[0][0]               
__________________________________________________________________________________________________
flatten_40 (Flatten)            (None, 100)          0           embedding_40[0][0]               
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 300)          0           flatten_39[0][0]                 
                                                                 flatten_40[0][0]                 
__________________________________________________________________________________________________
dense_39 (Dense)                (None, 24)           7224        concatenate_20[0][0]             
__________________________________________________________________________________________________
dropout_20 (Dropout)            (None, 24)           0           dense_39[0][0]                   
__________________________________________________________________________________________________
dense_40 (Dense)                (None, 8)            200         dropout_20[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 535.870053325849, 4.0: 2290.158330334653, 5.0: 1712.227602905569, 6.0: 2280.58408982322, 7.0: 2727578.5714285714}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:45.995767
# F-Score(Ordinary) = 0.527, Recall: 0.467, Precision: 0.604
# F-Score(lvc) = 0.472, Recall: 0.73, Precision: 0.348
# F-Score(ireflv) = 0.696, Recall: 0.623, Precision: 0.787
# F-Score(id) = 0.437, Recall: 0.335, Precision: 0.627
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_41 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_42 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_41 (Embedding)        (None, 4, 50)        734650      input_41[0][0]                   
__________________________________________________________________________________________________
embedding_42 (Embedding)        (None, 4, 25)        5875        input_42[0][0]                   
__________________________________________________________________________________________________
flatten_41 (Flatten)            (None, 200)          0           embedding_41[0][0]               
__________________________________________________________________________________________________
flatten_42 (Flatten)            (None, 100)          0           embedding_42[0][0]               
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 300)          0           flatten_41[0][0]                 
                                                                 flatten_42[0][0]                 
__________________________________________________________________________________________________
dense_41 (Dense)                (None, 24)           7224        concatenate_21[0][0]             
__________________________________________________________________________________________________
dropout_21 (Dropout)            (None, 24)           0           dense_41[0][0]                   
__________________________________________________________________________________________________
dense_42 (Dense)                (None, 8)            200         dropout_21[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 684.7228459163625, 4.0: 2926.313422094279, 5.0: 2187.8463814904494, 6.0: 2914.07967032967, 7.0: 3485239.285714286}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:39.066865
# F-Score(Ordinary) = 0.433, Recall: 0.326, Precision: 0.647
# F-Score(lvc) = 0.166, Recall: 0.107, Precision: 0.371
# F-Score(ireflv) = 0.656, Recall: 0.527, Precision: 0.869
# F-Score(id) = 0.61, Recall: 0.564, Precision: 0.663
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_43 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_44 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_43 (Embedding)        (None, 4, 50)        734650      input_43[0][0]                   
__________________________________________________________________________________________________
embedding_44 (Embedding)        (None, 4, 25)        5875        input_44[0][0]                   
__________________________________________________________________________________________________
flatten_43 (Flatten)            (None, 200)          0           embedding_43[0][0]               
__________________________________________________________________________________________________
flatten_44 (Flatten)            (None, 100)          0           embedding_44[0][0]               
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 300)          0           flatten_43[0][0]                 
                                                                 flatten_44[0][0]                 
__________________________________________________________________________________________________
dense_43 (Dense)                (None, 24)           7224        concatenate_22[0][0]             
__________________________________________________________________________________________________
dropout_22 (Dropout)            (None, 24)           0           dense_43[0][0]                   
__________________________________________________________________________________________________
dense_44 (Dense)                (None, 8)            200         dropout_22[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 684.7228459163625, 4.0: 2926.313422094279, 5.0: 2187.8463814904494, 6.0: 2914.07967032967, 7.0: 3485239.285714286}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:43.369212
# F-Score(Ordinary) = 0.46, Recall: 0.363, Precision: 0.626
# F-Score(lvc) = 0.375, Recall: 0.387, Precision: 0.364
# F-Score(ireflv) = 0.686, Recall: 0.567, Precision: 0.869
# F-Score(id) = 0.361, Recall: 0.257, Precision: 0.611
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_45 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_46 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_45 (Embedding)        (None, 4, 50)        734650      input_45[0][0]                   
__________________________________________________________________________________________________
embedding_46 (Embedding)        (None, 4, 25)        5875        input_46[0][0]                   
__________________________________________________________________________________________________
flatten_45 (Flatten)            (None, 200)          0           embedding_45[0][0]               
__________________________________________________________________________________________________
flatten_46 (Flatten)            (None, 100)          0           embedding_46[0][0]               
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 300)          0           flatten_45[0][0]                 
                                                                 flatten_46[0][0]                 
__________________________________________________________________________________________________
dense_45 (Dense)                (None, 24)           7224        concatenate_23[0][0]             
__________________________________________________________________________________________________
dropout_23 (Dropout)            (None, 24)           0           dense_45[0][0]                   
__________________________________________________________________________________________________
dense_46 (Dense)                (None, 8)            200         dropout_23[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 684.7228459163625, 4.0: 2926.313422094279, 5.0: 2187.8463814904494, 6.0: 2914.07967032967, 7.0: 3485239.285714286}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:49.708976
# F-Score(Ordinary) = 0.437, Recall: 0.348, Precision: 0.586
# F-Score(lvc) = 0.404, Recall: 0.783, Precision: 0.273
# F-Score(ireflv) = 0.728, Recall: 0.64, Precision: 0.844
# F-Score(id) = 0.325, Recall: 0.22, Precision: 0.622
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_47 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_48 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_47 (Embedding)        (None, 4, 50)        734650      input_47[0][0]                   
__________________________________________________________________________________________________
embedding_48 (Embedding)        (None, 4, 25)        5875        input_48[0][0]                   
__________________________________________________________________________________________________
flatten_47 (Flatten)            (None, 200)          0           embedding_47[0][0]               
__________________________________________________________________________________________________
flatten_48 (Flatten)            (None, 100)          0           embedding_48[0][0]               
__________________________________________________________________________________________________
concatenate_24 (Concatenate)    (None, 300)          0           flatten_47[0][0]                 
                                                                 flatten_48[0][0]                 
__________________________________________________________________________________________________
dense_47 (Dense)                (None, 24)           7224        concatenate_24[0][0]             
__________________________________________________________________________________________________
dropout_24 (Dropout)            (None, 24)           0           dense_47[0][0]                   
__________________________________________________________________________________________________
dense_48 (Dense)                (None, 8)            200         dropout_24[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 684.7228459163625, 4.0: 2926.313422094279, 5.0: 2187.8463814904494, 6.0: 2914.07967032967, 7.0: 3485239.285714286}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:39.889179
# F-Score(Ordinary) = 0.467, Recall: 0.359, Precision: 0.667
# F-Score(lvc) = 0.45, Recall: 0.454, Precision: 0.447
# F-Score(ireflv) = 0.737, Recall: 0.644, Precision: 0.861
# F-Score(id) = 0.343, Recall: 0.233, Precision: 0.648
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_49 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_50 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_49 (Embedding)        (None, 4, 50)        734650      input_49[0][0]                   
__________________________________________________________________________________________________
embedding_50 (Embedding)        (None, 4, 25)        5875        input_50[0][0]                   
__________________________________________________________________________________________________
flatten_49 (Flatten)            (None, 200)          0           embedding_49[0][0]               
__________________________________________________________________________________________________
flatten_50 (Flatten)            (None, 100)          0           embedding_50[0][0]               
__________________________________________________________________________________________________
concatenate_25 (Concatenate)    (None, 300)          0           flatten_49[0][0]                 
                                                                 flatten_50[0][0]                 
__________________________________________________________________________________________________
dense_49 (Dense)                (None, 24)           7224        concatenate_25[0][0]             
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 24)           0           dense_49[0][0]                   
__________________________________________________________________________________________________
dense_50 (Dense)                (None, 8)            200         dropout_25[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 684.7228459163625, 4.0: 2926.313422094279, 5.0: 2187.8463814904494, 6.0: 2914.07967032967, 7.0: 3485239.285714286}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:47.568148
# F-Score(Ordinary) = 0.623, Recall: 0.635, Precision: 0.611
# F-Score(lvc) = 0.476, Recall: 0.568, Precision: 0.409
# F-Score(ireflv) = 0.723, Recall: 0.632, Precision: 0.844
# F-Score(id) = 0.608, Recall: 0.645, Precision: 0.575
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_51 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_52 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_51 (Embedding)        (None, 4, 50)        734650      input_51[0][0]                   
__________________________________________________________________________________________________
embedding_52 (Embedding)        (None, 4, 25)        5875        input_52[0][0]                   
__________________________________________________________________________________________________
flatten_51 (Flatten)            (None, 200)          0           embedding_51[0][0]               
__________________________________________________________________________________________________
flatten_52 (Flatten)            (None, 100)          0           embedding_52[0][0]               
__________________________________________________________________________________________________
concatenate_26 (Concatenate)    (None, 300)          0           flatten_51[0][0]                 
                                                                 flatten_52[0][0]                 
__________________________________________________________________________________________________
dense_51 (Dense)                (None, 24)           7224        concatenate_26[0][0]             
__________________________________________________________________________________________________
dropout_26 (Dropout)            (None, 24)           0           dense_51[0][0]                   
__________________________________________________________________________________________________
dense_52 (Dense)                (None, 8)            200         dropout_26[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 833.5756385068762, 4.0: 3562.4685138539044, 5.0: 2663.4651600753295, 6.0: 3547.57525083612, 7.0: 4242900.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:42.722238
# F-Score(Ordinary) = 0.371, Recall: 0.273, Precision: 0.577
# F-Score(lvc) = 0.092, Recall: 0.057, Precision: 0.242
# F-Score(ireflv) = 0.652, Recall: 0.531, Precision: 0.844
# F-Score(id) = 0.599, Recall: 0.602, Precision: 0.596
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_53 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_54 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_53 (Embedding)        (None, 4, 50)        734650      input_53[0][0]                   
__________________________________________________________________________________________________
embedding_54 (Embedding)        (None, 4, 25)        5875        input_54[0][0]                   
__________________________________________________________________________________________________
flatten_53 (Flatten)            (None, 200)          0           embedding_53[0][0]               
__________________________________________________________________________________________________
flatten_54 (Flatten)            (None, 100)          0           embedding_54[0][0]               
__________________________________________________________________________________________________
concatenate_27 (Concatenate)    (None, 300)          0           flatten_53[0][0]                 
                                                                 flatten_54[0][0]                 
__________________________________________________________________________________________________
dense_53 (Dense)                (None, 24)           7224        concatenate_27[0][0]             
__________________________________________________________________________________________________
dropout_27 (Dropout)            (None, 24)           0           dense_53[0][0]                   
__________________________________________________________________________________________________
dense_54 (Dense)                (None, 8)            200         dropout_27[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 833.5756385068762, 4.0: 3562.4685138539044, 5.0: 2663.4651600753295, 6.0: 3547.57525083612, 7.0: 4242900.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:47.596547
# F-Score(Ordinary) = 0.439, Recall: 0.337, Precision: 0.631
# F-Score(lvc) = 0.458, Recall: 0.667, Precision: 0.348
# F-Score(ireflv) = 0.776, Recall: 0.758, Precision: 0.795
# F-Score(id) = 0.312, Recall: 0.203, Precision: 0.674
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_55 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_56 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_55 (Embedding)        (None, 4, 50)        734650      input_55[0][0]                   
__________________________________________________________________________________________________
embedding_56 (Embedding)        (None, 4, 25)        5875        input_56[0][0]                   
__________________________________________________________________________________________________
flatten_55 (Flatten)            (None, 200)          0           embedding_55[0][0]               
__________________________________________________________________________________________________
flatten_56 (Flatten)            (None, 100)          0           embedding_56[0][0]               
__________________________________________________________________________________________________
concatenate_28 (Concatenate)    (None, 300)          0           flatten_55[0][0]                 
                                                                 flatten_56[0][0]                 
__________________________________________________________________________________________________
dense_55 (Dense)                (None, 24)           7224        concatenate_28[0][0]             
__________________________________________________________________________________________________
dropout_28 (Dropout)            (None, 24)           0           dense_55[0][0]                   
__________________________________________________________________________________________________
dense_56 (Dense)                (None, 8)            200         dropout_28[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 833.5756385068762, 4.0: 3562.4685138539044, 5.0: 2663.4651600753295, 6.0: 3547.57525083612, 7.0: 4242900.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:42.417573
# F-Score(Ordinary) = 0.378, Recall: 0.268, Precision: 0.64
# F-Score(lvc) = 0.474, Recall: 0.614, Precision: 0.386
# F-Score(ireflv) = 0.744, Recall: 0.665, Precision: 0.844
# F-Score(id) = 0.245, Recall: 0.151, Precision: 0.648
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_57 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_58 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_57 (Embedding)        (None, 4, 50)        734650      input_57[0][0]                   
__________________________________________________________________________________________________
embedding_58 (Embedding)        (None, 4, 25)        5875        input_58[0][0]                   
__________________________________________________________________________________________________
flatten_57 (Flatten)            (None, 200)          0           embedding_57[0][0]               
__________________________________________________________________________________________________
flatten_58 (Flatten)            (None, 100)          0           embedding_58[0][0]               
__________________________________________________________________________________________________
concatenate_29 (Concatenate)    (None, 300)          0           flatten_57[0][0]                 
                                                                 flatten_58[0][0]                 
__________________________________________________________________________________________________
dense_57 (Dense)                (None, 24)           7224        concatenate_29[0][0]             
__________________________________________________________________________________________________
dropout_29 (Dropout)            (None, 24)           0           dense_57[0][0]                   
__________________________________________________________________________________________________
dense_58 (Dense)                (None, 8)            200         dropout_29[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 833.5756385068762, 4.0: 3562.4685138539044, 5.0: 2663.4651600753295, 6.0: 3547.57525083612, 7.0: 4242900.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:40.871658
# F-Score(Ordinary) = 0.563, Recall: 0.497, Precision: 0.649
# F-Score(lvc) = 0.486, Recall: 0.532, Precision: 0.447
# F-Score(ireflv) = 0.702, Recall: 0.593, Precision: 0.861
# F-Score(id) = 0.471, Recall: 0.39, Precision: 0.596
********************
********************
# XP = FR: 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 50
# POS = True
# POS emb = 25
# Features = False
Deep model(Non compositional)
# Parameters = 747949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_59 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_60 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_59 (Embedding)        (None, 4, 50)        734650      input_59[0][0]                   
__________________________________________________________________________________________________
embedding_60 (Embedding)        (None, 4, 25)        5875        input_60[0][0]                   
__________________________________________________________________________________________________
flatten_59 (Flatten)            (None, 200)          0           embedding_59[0][0]               
__________________________________________________________________________________________________
flatten_60 (Flatten)            (None, 100)          0           embedding_60[0][0]               
__________________________________________________________________________________________________
concatenate_30 (Concatenate)    (None, 300)          0           flatten_59[0][0]                 
                                                                 flatten_60[0][0]                 
__________________________________________________________________________________________________
dense_59 (Dense)                (None, 24)           7224        concatenate_30[0][0]             
__________________________________________________________________________________________________
dropout_30 (Dropout)            (None, 24)           0           dense_59[0][0]                   
__________________________________________________________________________________________________
dense_60 (Dense)                (None, 8)            200         dropout_30[0][0]                 
==================================================================================================
Total params: 747,949
Trainable params: 747,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
class_weight{0.0: 0.2911783840762915, 1.0: 0.3061502805421506, 2.0: 833.5756385068762, 4.0: 3562.4685138539044, 5.0: 2663.4651600753295, 6.0: 3547.57525083612, 7.0: 4242900.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:03:40.303151
# F-Score(Ordinary) = 0.536, Recall: 0.487, Precision: 0.595
# F-Score(lvc) = 0.343, Recall: 0.372, Precision: 0.318
# F-Score(ireflv) = 0.675, Recall: 0.567, Precision: 0.836
# F-Score(id) = 0.525, Recall: 0.462, Precision: 0.606
********************
