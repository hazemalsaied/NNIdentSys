INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
********************
# XP = FR: Init selvio
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
[1196, 1593, 13152, 1, 11515, 5090, 1191, 180]
TransitionType.MARK_AS_LVC  :  3.53
TransitionType.MARK_AS_ID  :  4.7
TransitionType.SHIFT  :  38.78
TransitionType.MARK_AS_OTH  :  0.0
TransitionType.REDUCE  :  33.95
TransitionType.MERGE  :  15.01
TransitionType.MARK_AS_IREFLV  :  3.51
None  :  0.53
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = True
# POS emb = 15
# Features = False
Deep model(Non compositional)
# Token weight matrix used# POS weight matrix used# Parameters = 3703508
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 4, 250)       3673250     input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 4, 15)        3525        input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 1000)         0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 60)           0           embedding_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1060)         0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 25)           26525       concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 25)           0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 8)            208         dropout_1[0][0]                  
==================================================================================================
Total params: 3,703,508
Trainable params: 3,703,508
Non-trainable params: 0
__________________________________________________________________________________________________
None
3507 importatnt sents of 16091
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adagrad, learning rate = 0.02
# Training time = 0:23:36.862090
# F-Score(Ordinary) = 0.757, Recall: 0.879, Precision: 0.664
# F-Score(lvc) = 0.627, Recall: 0.889, Precision: 0.485
# F-Score(ireflv) = 0.82, Recall: 0.82, Precision: 0.82
# F-Score(id) = 0.789, Recall: 0.924, Precision: 0.689
********************
********************
# XP = FR: Init selvio
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
[1196, 1593, 13152, 1, 11515, 5090, 1191, 180]
TransitionType.MARK_AS_LVC  :  3.53
TransitionType.MARK_AS_ID  :  4.7
TransitionType.SHIFT  :  38.78
TransitionType.MARK_AS_OTH  :  0.0
TransitionType.REDUCE  :  33.95
TransitionType.MERGE  :  15.01
TransitionType.MARK_AS_IREFLV  :  3.51
None  :  0.53
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = True
# POS emb = 15
# Features = False
Deep model(Non compositional)
# Token weight matrix used# POS weight matrix used# Parameters = 3703508
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 4, 250)       3673250     input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 4, 15)        3525        input_4[0][0]                    
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 1000)         0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 60)           0           embedding_4[0][0]                
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 1060)         0           flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 25)           26525       concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 25)           0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 8)            208         dropout_2[0][0]                  
==================================================================================================
Total params: 3,703,508
Trainable params: 3,703,508
Non-trainable params: 0
__________________________________________________________________________________________________
None
3507 importatnt sents of 16091
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adagrad, learning rate = 0.02
# Training time = 0:23:28.910561
# F-Score(Ordinary) = 0.735, Recall: 0.784, Precision: 0.691
# F-Score(lvc) = 0.56, Recall: 0.613, Precision: 0.515
# F-Score(ireflv) = 0.82, Recall: 0.757, Precision: 0.893
# F-Score(id) = 0.783, Recall: 0.935, Precision: 0.674
********************
********************
# XP = FR: Init selvio
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
[1196, 1593, 13152, 1, 11515, 5090, 1191, 180]
TransitionType.MARK_AS_LVC  :  3.53
TransitionType.MARK_AS_ID  :  4.7
TransitionType.SHIFT  :  38.78
TransitionType.MARK_AS_OTH  :  0.0
TransitionType.REDUCE  :  33.95
TransitionType.MERGE  :  15.01
TransitionType.MARK_AS_IREFLV  :  3.51
None  :  0.53
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = True
# POS emb = 15
# Features = False
Deep model(Non compositional)
# Token weight matrix used# POS weight matrix used# Parameters = 3703508
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 4, 250)       3673250     input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 4, 15)        3525        input_6[0][0]                    
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 1000)         0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 60)           0           embedding_6[0][0]                
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 1060)         0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 25)           26525       concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 25)           0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 8)            208         dropout_3[0][0]                  
==================================================================================================
Total params: 3,703,508
Trainable params: 3,703,508
Non-trainable params: 0
__________________________________________________________________________________________________
None
3507 importatnt sents of 16091
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adagrad, learning rate = 0.02
# Training time = 0:23:46.203438
# F-Score(Ordinary) = 0.753, Recall: 0.88, Precision: 0.658
# F-Score(lvc) = 0.641, Recall: 0.892, Precision: 0.5
# F-Score(ireflv) = 0.82, Recall: 0.82, Precision: 0.82
# F-Score(id) = 0.773, Recall: 0.928, Precision: 0.663
********************
********************
# XP = FR: Init selvio
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
[1196, 1593, 13152, 1, 11515, 5090, 1191, 180]
TransitionType.MARK_AS_LVC  :  3.53
TransitionType.MARK_AS_ID  :  4.7
TransitionType.SHIFT  :  38.78
TransitionType.MARK_AS_OTH  :  0.0
TransitionType.REDUCE  :  33.95
TransitionType.MERGE  :  15.01
TransitionType.MARK_AS_IREFLV  :  3.51
None  :  0.53
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = True
# POS emb = 15
# Features = False
Deep model(Non compositional)
# Token weight matrix used# POS weight matrix used# Parameters = 3703508
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 4, 250)       3673250     input_7[0][0]                    
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 4, 15)        3525        input_8[0][0]                    
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 1000)         0           embedding_7[0][0]                
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 60)           0           embedding_8[0][0]                
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 1060)         0           flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 25)           26525       concatenate_4[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 25)           0           dense_7[0][0]                    
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 8)            208         dropout_4[0][0]                  
==================================================================================================
Total params: 3,703,508
Trainable params: 3,703,508
Non-trainable params: 0
__________________________________________________________________________________________________
None
3507 importatnt sents of 16091
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adagrad, learning rate = 0.02
# Training time = 0:23:40.943618
# F-Score(Ordinary) = 0.757, Recall: 0.889, Precision: 0.66
# F-Score(lvc) = 0.61, Recall: 0.897, Precision: 0.462
# F-Score(ireflv) = 0.842, Recall: 0.832, Precision: 0.852
# F-Score(id) = 0.783, Recall: 0.935, Precision: 0.674
********************
********************
# XP = FR: Init selvio
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
[1196, 1593, 13152, 1, 11515, 5090, 1191, 180]
TransitionType.MARK_AS_LVC  :  3.53
TransitionType.MARK_AS_ID  :  4.7
TransitionType.SHIFT  :  38.78
TransitionType.MARK_AS_OTH  :  0.0
TransitionType.REDUCE  :  33.95
TransitionType.MERGE  :  15.01
TransitionType.MARK_AS_IREFLV  :  3.51
None  :  0.53
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 250
# POS = True
# POS emb = 15
# Features = False
Deep model(Non compositional)
# Token weight matrix used# POS weight matrix used# Parameters = 3703508
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_10 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 4, 250)       3673250     input_9[0][0]                    
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 4, 15)        3525        input_10[0][0]                   
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 1000)         0           embedding_9[0][0]                
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 60)           0           embedding_10[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 1060)         0           flatten_9[0][0]                  
                                                                 flatten_10[0][0]                 
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 25)           26525       concatenate_5[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 25)           0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 8)            208         dropout_5[0][0]                  
==================================================================================================
Total params: 3,703,508
Trainable params: 3,703,508
Non-trainable params: 0
__________________________________________________________________________________________________
None
3507 importatnt sents of 16091
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adagrad, learning rate = 0.02
# Training time = 0:23:39.145357
# F-Score(Ordinary) = 0.76, Recall: 0.892, Precision: 0.662
# F-Score(lvc) = 0.644, Recall: 0.882, Precision: 0.508
# F-Score(ireflv) = 0.826, Recall: 0.833, Precision: 0.82
# F-Score(id) = 0.784, Recall: 0.949, Precision: 0.668
********************
********************
# XP = FR: Init fauconnier
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
[1196, 1593, 13152, 1, 11515, 5090, 1191, 180]
TransitionType.MARK_AS_LVC  :  3.53
TransitionType.MARK_AS_ID  :  4.7
TransitionType.SHIFT  :  38.78
TransitionType.MARK_AS_OTH  :  0.0
TransitionType.REDUCE  :  33.95
TransitionType.MERGE  :  15.01
TransitionType.MARK_AS_IREFLV  :  3.51
None  :  0.53
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = True
# POS emb = 15
# Features = False
Deep model(Non compositional)
# Token weight matrix used# POS weight matrix used# Parameters = 2963858
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 4, 200)       2938600     input_11[0][0]                   
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 4, 15)        3525        input_12[0][0]                   
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 800)          0           embedding_11[0][0]               
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 60)           0           embedding_12[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 860)          0           flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 25)           21525       concatenate_6[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 25)           0           dense_11[0][0]                   
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 8)            208         dropout_6[0][0]                  
==================================================================================================
Total params: 2,963,858
Trainable params: 2,963,858
Non-trainable params: 0
__________________________________________________________________________________________________
None
3507 importatnt sents of 16091
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adagrad, learning rate = 0.02
# Training time = 0:21:59.360729
# F-Score(Ordinary) = 0.74, Recall: 0.849, Precision: 0.655
# F-Score(lvc) = 0.595, Recall: 0.771, Precision: 0.485
# F-Score(ireflv) = 0.808, Recall: 0.822, Precision: 0.795
# F-Score(id) = 0.783, Recall: 0.917, Precision: 0.684
********************
********************
# XP = FR: Init fauconnier
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
[1196, 1593, 13152, 1, 11515, 5090, 1191, 180]
TransitionType.MARK_AS_LVC  :  3.53
TransitionType.MARK_AS_ID  :  4.7
TransitionType.SHIFT  :  38.78
TransitionType.MARK_AS_OTH  :  0.0
TransitionType.REDUCE  :  33.95
TransitionType.MERGE  :  15.01
TransitionType.MARK_AS_IREFLV  :  3.51
None  :  0.53
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = True
# POS emb = 15
# Features = False
Deep model(Non compositional)
# Token weight matrix used# POS weight matrix used# Parameters = 2963858
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_14 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 4, 200)       2938600     input_13[0][0]                   
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 4, 15)        3525        input_14[0][0]                   
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 800)          0           embedding_13[0][0]               
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 60)           0           embedding_14[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 860)          0           flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 25)           21525       concatenate_7[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 25)           0           dense_13[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 8)            208         dropout_7[0][0]                  
==================================================================================================
Total params: 2,963,858
Trainable params: 2,963,858
Non-trainable params: 0
__________________________________________________________________________________________________
None
3507 importatnt sents of 16091
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adagrad, learning rate = 0.02
# Training time = 0:22:02.390137
# F-Score(Ordinary) = 0.748, Recall: 0.884, Precision: 0.649
# F-Score(lvc) = 0.607, Recall: 0.884, Precision: 0.462
# F-Score(ireflv) = 0.83, Recall: 0.84, Precision: 0.82
# F-Score(id) = 0.775, Recall: 0.921, Precision: 0.668
********************
********************
# XP = FR: Init fauconnier
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
[1196, 1593, 13152, 1, 11515, 5090, 1191, 180]
TransitionType.MARK_AS_LVC  :  3.53
TransitionType.MARK_AS_ID  :  4.7
TransitionType.SHIFT  :  38.78
TransitionType.MARK_AS_OTH  :  0.0
TransitionType.REDUCE  :  33.95
TransitionType.MERGE  :  15.01
TransitionType.MARK_AS_IREFLV  :  3.51
None  :  0.53
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = True
# POS emb = 15
# Features = False
Deep model(Non compositional)
# Token weight matrix used# POS weight matrix used# Parameters = 2963858
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_15 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_16 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_15 (Embedding)        (None, 4, 200)       2938600     input_15[0][0]                   
__________________________________________________________________________________________________
embedding_16 (Embedding)        (None, 4, 15)        3525        input_16[0][0]                   
__________________________________________________________________________________________________
flatten_15 (Flatten)            (None, 800)          0           embedding_15[0][0]               
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 60)           0           embedding_16[0][0]               
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 860)          0           flatten_15[0][0]                 
                                                                 flatten_16[0][0]                 
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 25)           21525       concatenate_8[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 25)           0           dense_15[0][0]                   
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 8)            208         dropout_8[0][0]                  
==================================================================================================
Total params: 2,963,858
Trainable params: 2,963,858
Non-trainable params: 0
__________________________________________________________________________________________________
None
3507 importatnt sents of 16091
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adagrad, learning rate = 0.02
# Training time = 0:22:55.210112
# F-Score(Ordinary) = 0.735, Recall: 0.866, Precision: 0.638
# F-Score(lvc) = 0.6, Recall: 0.808, Precision: 0.477
# F-Score(ireflv) = 0.805, Recall: 0.833, Precision: 0.779
# F-Score(id) = 0.77, Recall: 0.927, Precision: 0.658
********************
********************
# XP = FR: Init fauconnier
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
[1196, 1593, 13152, 1, 11515, 5090, 1191, 180]
TransitionType.MARK_AS_LVC  :  3.53
TransitionType.MARK_AS_ID  :  4.7
TransitionType.SHIFT  :  38.78
TransitionType.MARK_AS_OTH  :  0.0
TransitionType.REDUCE  :  33.95
TransitionType.MERGE  :  15.01
TransitionType.MARK_AS_IREFLV  :  3.51
None  :  0.53
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = True
# POS emb = 15
# Features = False
Deep model(Non compositional)
# Token weight matrix used# POS weight matrix used# Parameters = 2963858
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_17 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_18 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_17 (Embedding)        (None, 4, 200)       2938600     input_17[0][0]                   
__________________________________________________________________________________________________
embedding_18 (Embedding)        (None, 4, 15)        3525        input_18[0][0]                   
__________________________________________________________________________________________________
flatten_17 (Flatten)            (None, 800)          0           embedding_17[0][0]               
__________________________________________________________________________________________________
flatten_18 (Flatten)            (None, 60)           0           embedding_18[0][0]               
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 860)          0           flatten_17[0][0]                 
                                                                 flatten_18[0][0]                 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 25)           21525       concatenate_9[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 25)           0           dense_17[0][0]                   
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 8)            208         dropout_9[0][0]                  
==================================================================================================
Total params: 2,963,858
Trainable params: 2,963,858
Non-trainable params: 0
__________________________________________________________________________________________________
None
3507 importatnt sents of 16091
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adagrad, learning rate = 0.02
# Training time = 0:22:09.391079
# F-Score(Ordinary) = 0.749, Recall: 0.889, Precision: 0.647
# F-Score(lvc) = 0.617, Recall: 0.899, Precision: 0.47
# F-Score(ireflv) = 0.822, Recall: 0.832, Precision: 0.811
# F-Score(id) = 0.776, Recall: 0.934, Precision: 0.663
********************
********************
# XP = FR: Init fauconnier
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
[1196, 1593, 13152, 1, 11515, 5090, 1191, 180]
TransitionType.MARK_AS_LVC  :  3.53
TransitionType.MARK_AS_ID  :  4.7
TransitionType.SHIFT  :  38.78
TransitionType.MARK_AS_OTH  :  0.0
TransitionType.REDUCE  :  33.95
TransitionType.MERGE  :  15.01
TransitionType.MARK_AS_IREFLV  :  3.51
None  :  0.53
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = True
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = True
# POS emb = 15
# Features = False
Deep model(Non compositional)
# Token weight matrix used# POS weight matrix used# Parameters = 2963858
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_19 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_20 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_19 (Embedding)        (None, 4, 200)       2938600     input_19[0][0]                   
__________________________________________________________________________________________________
embedding_20 (Embedding)        (None, 4, 15)        3525        input_20[0][0]                   
__________________________________________________________________________________________________
flatten_19 (Flatten)            (None, 800)          0           embedding_19[0][0]               
__________________________________________________________________________________________________
flatten_20 (Flatten)            (None, 60)           0           embedding_20[0][0]               
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 860)          0           flatten_19[0][0]                 
                                                                 flatten_20[0][0]                 
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 25)           21525       concatenate_10[0][0]             
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 25)           0           dense_19[0][0]                   
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 8)            208         dropout_10[0][0]                 
==================================================================================================
Total params: 2,963,858
Trainable params: 2,963,858
Non-trainable params: 0
__________________________________________________________________________________________________
None
3507 importatnt sents of 16091
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adagrad, learning rate = 0.02
# Training time = 0:21:56.982026
# F-Score(Ordinary) = 0.739, Recall: 0.867, Precision: 0.644
# F-Score(lvc) = 0.597, Recall: 0.87, Precision: 0.455
# F-Score(ireflv) = 0.822, Recall: 0.832, Precision: 0.811
# F-Score(id) = 0.766, Recall: 0.896, Precision: 0.668
********************
