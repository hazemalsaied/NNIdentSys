INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
Debug enabled
********************
# XP = FR: Lemma(30) POS(15) Dense 25 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 200, Test = 200
Training started# Tokens vocabulary = 491
# POSs vocabulary = 39
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 491
# POS vocabulary = 39
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 20048
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 4, 30)        14730       input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 4, 15)        585         input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 120)          0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 60)           0           embedding_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 180)          0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 25)           4525        concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 25)           0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 8)            208         dropout_1[0][0]                  
==================================================================================================
Total params: 20,048
Trainable params: 20,048
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 3141
data size after sampling = 9270
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:00:30.424628
# F-Score(Ordinary) = 0.366, Recall: 0.472, Precision: 0.298
# F-Score(lvc) = 0.182, Recall: 0.214, Precision: 0.158
# F-Score(ireflv) = 0.529, Recall: 0.563, Precision: 0.5
# F-Score(id) = 0.308, Recall: 0.667, Precision: 0.2
********************
Debug enabled
********************
# XP = FR: Lemma(30) POS(15) Dense 75 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 200, Test = 200
Training started# Tokens vocabulary = 491
# POSs vocabulary = 39
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 491
# POS vocabulary = 39
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 29498
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 4, 30)        14730       input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 4, 15)        585         input_4[0][0]                    
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 120)          0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 60)           0           embedding_4[0][0]                
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 180)          0           flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 75)           13575       concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 75)           0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 8)            608         dropout_2[0][0]                  
==================================================================================================
Total params: 29,498
Trainable params: 29,498
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 3141
data size after sampling = 9270
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:00:17.124599
# F-Score(Ordinary) = 0.39, Recall: 0.364, Precision: 0.421
# F-Score(lvc) = 0.154, Recall: 0.121, Precision: 0.211
# F-Score(ireflv) = 0.619, Recall: 0.542, Precision: 0.722
# F-Score(id) = 0.276, Recall: 0.444, Precision: 0.2
********************
Debug enabled
********************
# XP = FR: Lemma(30) POS(15) Dense 125 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 200, Test = 200
Training started# Tokens vocabulary = 491
# POSs vocabulary = 39
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 491
# POS vocabulary = 39
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 38948
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 4, 30)        14730       input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 4, 15)        585         input_6[0][0]                    
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 120)          0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 60)           0           embedding_6[0][0]                
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 180)          0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 125)          22625       concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 125)          0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 8)            1008        dropout_3[0][0]                  
==================================================================================================
Total params: 38,948
Trainable params: 38,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 3141
data size after sampling = 9270
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:00:17.027987
# F-Score(Ordinary) = 0.318, Recall: 0.34, Precision: 0.298
# F-Score(lvc) = 0.14, Recall: 0.125, Precision: 0.158
# F-Score(ireflv) = 0.5, Recall: 0.571, Precision: 0.444
# F-Score(id) = 0.25, Recall: 0.333, Precision: 0.2
********************
Debug enabled
********************
# XP = FR: Lemma(30) POS(15) Dense 250 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 200, Test = 200
Training started# Tokens vocabulary = 491
# POSs vocabulary = 39
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 491
# POS vocabulary = 39
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 62573
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 4, 30)        14730       input_7[0][0]                    
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 4, 15)        585         input_8[0][0]                    
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 120)          0           embedding_7[0][0]                
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 60)           0           embedding_8[0][0]                
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 180)          0           flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 250)          45250       concatenate_4[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 250)          0           dense_7[0][0]                    
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 8)            2008        dropout_4[0][0]                  
==================================================================================================
Total params: 62,573
Trainable params: 62,573
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 3141
data size after sampling = 9270
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:00:17.283587
# F-Score(Ordinary) = 0.353, Recall: 0.281, Precision: 0.474
# F-Score(lvc) = 0.174, Recall: 0.148, Precision: 0.211
# F-Score(ireflv) = 0.651, Recall: 0.56, Precision: 0.778
# F-Score(id) = 0.187, Recall: 0.136, Precision: 0.3
********************
Debug enabled
********************
# XP = FR: Lemma(30) POS(25) Dense 25 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 200, Test = 200
Training started# Tokens vocabulary = 491
# POSs vocabulary = 39
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 491
# POS vocabulary = 39
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 55
# Features = False
Deep model(Non compositional)
# Parameters = 21438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_10 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 4, 30)        14730       input_9[0][0]                    
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 4, 25)        975         input_10[0][0]                   
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 120)          0           embedding_9[0][0]                
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 100)          0           embedding_10[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 220)          0           flatten_9[0][0]                  
                                                                 flatten_10[0][0]                 
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 25)           5525        concatenate_5[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 25)           0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 8)            208         dropout_5[0][0]                  
==================================================================================================
Total params: 21,438
Trainable params: 21,438
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 3141
data size after sampling = 9270
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:00:16.961375
# F-Score(Ordinary) = 0.364, Recall: 0.429, Precision: 0.316
# F-Score(lvc) = 0.17, Recall: 0.143, Precision: 0.211
# F-Score(ireflv) = 0.462, Recall: 0.75, Precision: 0.333
# F-Score(id) = 0.308, Recall: 0.667, Precision: 0.2
********************
Debug enabled
********************
# XP = FR: Lemma(30) POS(25) Dense 75 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 200, Test = 200
Training started# Tokens vocabulary = 491
# POSs vocabulary = 39
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 491
# POS vocabulary = 39
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 55
# Features = False
Deep model(Non compositional)
# Parameters = 32888
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 4, 30)        14730       input_11[0][0]                   
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 4, 25)        975         input_12[0][0]                   
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 120)          0           embedding_11[0][0]               
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 100)          0           embedding_12[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 220)          0           flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 75)           16575       concatenate_6[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 75)           0           dense_11[0][0]                   
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 8)            608         dropout_6[0][0]                  
==================================================================================================
Total params: 32,888
Trainable params: 32,888
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 3141
data size after sampling = 9270
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:00:16.992693
# F-Score(Ordinary) = 0.36, Recall: 0.305, Precision: 0.439
# F-Score(lvc) = 0.167, Recall: 0.138, Precision: 0.211
# F-Score(ireflv) = 0.622, Recall: 0.519, Precision: 0.778
# F-Score(id) = 0.217, Recall: 0.192, Precision: 0.25
********************
Debug enabled
********************
# XP = FR: Lemma(30) POS(25) Dense 125 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 200, Test = 200
Training started# Tokens vocabulary = 491
# POSs vocabulary = 39
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 491
# POS vocabulary = 39
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 55
# Features = False
Deep model(Non compositional)
# Parameters = 44338
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_14 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 4, 30)        14730       input_13[0][0]                   
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 4, 25)        975         input_14[0][0]                   
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 120)          0           embedding_13[0][0]               
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 100)          0           embedding_14[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 220)          0           flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 125)          27625       concatenate_7[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 125)          0           dense_13[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 8)            1008        dropout_7[0][0]                  
==================================================================================================
Total params: 44,338
Trainable params: 44,338
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 3141
data size after sampling = 9270
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:00:17.096460
# F-Score(Ordinary) = 0.403, Recall: 0.333, Precision: 0.509
# F-Score(lvc) = 0.131, Recall: 0.095, Precision: 0.211
# F-Score(ireflv) = 0.653, Recall: 0.516, Precision: 0.889
# F-Score(id) = 0.235, Recall: 0.286, Precision: 0.2
********************
Debug enabled
********************
# XP = FR: Lemma(30) POS(25) Dense 250 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 200, Test = 200
Training started# Tokens vocabulary = 491
# POSs vocabulary = 39
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 491
# POS vocabulary = 39
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 55
# Features = False
Deep model(Non compositional)
# Parameters = 72963
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_15 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_16 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_15 (Embedding)        (None, 4, 30)        14730       input_15[0][0]                   
__________________________________________________________________________________________________
embedding_16 (Embedding)        (None, 4, 25)        975         input_16[0][0]                   
__________________________________________________________________________________________________
flatten_15 (Flatten)            (None, 120)          0           embedding_15[0][0]               
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 100)          0           embedding_16[0][0]               
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 220)          0           flatten_15[0][0]                 
                                                                 flatten_16[0][0]                 
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 250)          55250       concatenate_8[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 250)          0           dense_15[0][0]                   
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 8)            2008        dropout_8[0][0]                  
==================================================================================================
Total params: 72,963
Trainable params: 72,963
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 3141
data size after sampling = 9270
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:00:19.080220
# F-Score(Ordinary) = 0.339, Recall: 0.259, Precision: 0.491
# F-Score(lvc) = 0.138, Recall: 0.103, Precision: 0.211
# F-Score(ireflv) = 0.612, Recall: 0.484, Precision: 0.833
# F-Score(id) = 0.172, Recall: 0.132, Precision: 0.25
********************
Debug enabled
********************
# XP = FR: Lemma(30) POS(35) Dense 25 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 200, Test = 200
Training started# Tokens vocabulary = 491
# POSs vocabulary = 39
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 491
# POS vocabulary = 39
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 65
# Features = False
Deep model(Non compositional)
# Parameters = 22828
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_17 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_18 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_17 (Embedding)        (None, 4, 30)        14730       input_17[0][0]                   
__________________________________________________________________________________________________
embedding_18 (Embedding)        (None, 4, 35)        1365        input_18[0][0]                   
__________________________________________________________________________________________________
flatten_17 (Flatten)            (None, 120)          0           embedding_17[0][0]               
__________________________________________________________________________________________________
flatten_18 (Flatten)            (None, 140)          0           embedding_18[0][0]               
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 260)          0           flatten_17[0][0]                 
                                                                 flatten_18[0][0]                 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 25)           6525        concatenate_9[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 25)           0           dense_17[0][0]                   
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 8)            208         dropout_9[0][0]                  
==================================================================================================
Total params: 22,828
Trainable params: 22,828
Non-trainable paINFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
********************
# XP = FR: Lemma(30) POS(15) Dense 25 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 449048
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 4, 30)        440790      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 4, 15)        3525        input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 120)          0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 60)           0           embedding_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 180)          0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 25)           4525        concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 25)           0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 8)            208         dropout_1[0][0]                  
==================================================================================================
Total params: 449,048
Trainable params: 449,048
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:18:56.310270
# F-Score(Ordinary) = 0.722, Recall: 0.883, Precision: 0.611
# F-Score(lvc) = 0.62, Recall: 0.912, Precision: 0.47
# F-Score(ireflv) = 0.836, Recall: 0.939, Precision: 0.754
# F-Score(id) = 0.702, Recall: 0.825, Precision: 0.611
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 25 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 449048
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 4, 30)        440790      input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 4, 15)        3525        input_4[0][0]                    
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 120)          0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 60)           0           embedding_4[0][0]                
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 180)          0           flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 25)           4525        concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 25)           0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 8)            208         dropout_2[0][0]                  
==================================================================================================
Total params: 449,048
Trainable params: 449,048
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:18:47.599961
# F-Score(Ordinary) = 0.726, Recall: 0.903, Precision: 0.606
# F-Score(lvc) = 0.555, Recall: 0.898, Precision: 0.402
# F-Score(ireflv) = 0.822, Recall: 0.851, Precision: 0.795
# F-Score(id) = 0.756, Recall: 0.953, Precision: 0.627
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 25 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 449048
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 4, 30)        440790      input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 4, 15)        3525        input_6[0][0]                    
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 120)          0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 60)           0           embedding_6[0][0]                
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 180)          0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 25)           4525        concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 25)           0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 8)            208         dropout_3[0][0]                  
==================================================================================================
Total params: 449,048
Trainable params: 449,048
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:18:47.339797
# F-Score(Ordinary) = 0.661, Recall: 0.667, Precision: 0.655
# F-Score(lvc) = 0.579, Recall: 0.719, Precision: 0.485
# F-Score(ireflv) = 0.815, Recall: 0.856, Precision: 0.779
# F-Score(id) = 0.616, Recall: 0.556, Precision: 0.689
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 25 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 449048
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 4, 30)        440790      input_7[0][0]                    
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 4, 15)        3525        input_8[0][0]                    
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 120)          0           embedding_7[0][0]                
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 60)           0           embedding_8[0][0]                
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 180)          0           flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 25)           4525        concatenate_4[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 25)           0           dense_7[0][0]                    
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 8)            208         dropout_4[0][0]                  
==================================================================================================
Total params: 449,048
Trainable params: 449,048
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:18:48.117392
# F-Score(Ordinary) = 0.744, Recall: 0.857, Precision: 0.658
# F-Score(lvc) = 0.581, Recall: 0.782, Precision: 0.462
# F-Score(ireflv) = 0.855, Recall: 0.866, Precision: 0.844
# F-Score(id) = 0.761, Recall: 0.884, Precision: 0.668
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 25 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 449048
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_10 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 4, 30)        440790      input_9[0][0]                    
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 4, 15)        3525        input_10[0][0]                   
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 120)          0           embedding_9[0][0]                
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 60)           0           embedding_10[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 180)          0           flatten_9[0][0]                  
                                                                 flatten_10[0][0]                 
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 25)           4525        concatenate_5[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 25)           0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 8)            208         dropout_5[0][0]                  
==================================================================================================
Total params: 449,048
Trainable params: 449,048
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:18:49.107031
# F-Score(Ordinary) = 0.721, Recall: 0.842, Precision: 0.631
# F-Score(lvc) = 0.561, Recall: 0.859, Precision: 0.417
# F-Score(ireflv) = 0.842, Recall: 0.856, Precision: 0.828
# F-Score(id) = 0.728, Recall: 0.824, Precision: 0.653
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 75 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 458498
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 4, 30)        440790      input_11[0][0]                   
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 4, 15)        3525        input_12[0][0]                   
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 120)          0           embedding_11[0][0]               
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 60)           0           embedding_12[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 180)          0           flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 75)           13575       concatenate_6[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 75)           0           dense_11[0][0]                   
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 8)            608         dropout_6[0][0]                  
==================================================================================================
Total params: 458,498
Trainable params: 458,498
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:19:05.304888
# F-Score(Ordinary) = 0.608, Recall: 0.547, Precision: 0.685
# F-Score(lvc) = 0.537, Recall: 0.591, Precision: 0.492
# F-Score(ireflv) = 0.818, Recall: 0.825, Precision: 0.811
# F-Score(id) = 0.506, Recall: 0.401, Precision: 0.684
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 75 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 458498
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_14 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 4, 30)        440790      input_13[0][0]                   
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 4, 15)        3525        input_14[0][0]                   
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 120)          0           embedding_13[0][0]               
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 60)           0           embedding_14[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 180)          0           flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 75)           13575       concatenate_7[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 75)           0           dense_13[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 8)            608         dropout_7[0][0]                  
==================================================================================================
Total params: 458,498
Trainable params: 458,498
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:18:54.682945
# F-Score(Ordinary) = 0.539, Recall: 0.434, Precision: 0.711
# F-Score(lvc) = 0.357, Recall: 0.264, Precision: 0.553
# F-Score(ireflv) = 0.704, Recall: 0.612, Precision: 0.828
# F-Score(id) = 0.541, Recall: 0.45, Precision: 0.679
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 75 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 458498
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_15 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_16 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_15 (Embedding)        (None, 4, 30)        440790      input_15[0][0]                   
__________________________________________________________________________________________________
embedding_16 (Embedding)        (None, 4, 15)        3525        input_16[0][0]                   
__________________________________________________________________________________________________
flatten_15 (Flatten)            (None, 120)          0           embedding_15[0][0]               
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 60)           0           embedding_16[0][0]               
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 180)          0           flatten_15[0][0]                 
                                                                 flatten_16[0][0]                 
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 75)           13575       concatenate_8[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 75)           0           dense_15[0][0]                   
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 8)            608         dropout_8[0][0]                  
==================================================================================================
Total params: 458,498
Trainable params: 458,498
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:18:50.771941
# F-Score(Ordinary) = 0.607, Recall: 0.527, Precision: 0.716
# F-Score(lvc) = 0.617, Recall: 0.805, Precision: 0.5
# F-Score(ireflv) = 0.832, Recall: 0.853, Precision: 0.811
# F-Score(id) = 0.485, Recall: 0.357, Precision: 0.756
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 75 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 458498
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_17 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_18 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_17 (Embedding)        (None, 4, 30)        440790      input_17[0][0]                   
__________________________________________________________________________________________________
embedding_18 (Embedding)        (None, 4, 15)        3525        input_18[0][0]                   
__________________________________________________________________________________________________
flatten_17 (Flatten)            (None, 120)          0           embedding_17[0][0]               
__________________________________________________________________________________________________
flatten_18 (Flatten)            (None, 60)           0           embedding_18[0][0]               
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 180)          0           flatten_17[0][0]                 
                                                                 flatten_18[0][0]                 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 75)           13575       concatenate_9[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 75)           0           dense_17[0][0]                   
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 8)            608         dropout_9[0][0]                  
==================================================================================================
Total params: 458,498
Trainable params: 458,498
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:19:16.465570
# F-Score(Ordinary) = 0.6, Recall: 0.521, Precision: 0.709
# F-Score(lvc) = 0.561, Recall: 0.626, Precision: 0.508
# F-Score(ireflv) = 0.828, Recall: 0.846, Precision: 0.811
# F-Score(id) = 0.446, Recall: 0.335, Precision: 0.668
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 75 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 458498
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_19 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_20 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_19 (Embedding)        (None, 4, 30)        440790      input_19[0][0]                   
__________________________________________________________________________________________________
embedding_20 (Embedding)        (None, 4, 15)        3525        input_20[0][0]                   
__________________________________________________________________________________________________
flatten_19 (Flatten)            (None, 120)          0           embedding_19[0][0]               
__________________________________________________________________________________________________
flatten_20 (Flatten)            (None, 60)           0           embedding_20[0][0]               
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 180)          0           flatten_19[0][0]                 
                                                                 flatten_20[0][0]                 
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 75)           13575       concatenate_10[0][0]             
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 75)           0           dense_19[0][0]                   
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 8)            608         dropout_10[0][0]                 
==================================================================================================
Total params: 458,498
Trainable params: 458,498
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:19:23.277655
# F-Score(Ordinary) = 0.606, Recall: 0.525, Precision: 0.718
# F-Score(lvc) = 0.603, Recall: 0.759, Precision: 0.5
# F-Score(ireflv) = 0.722, Recall: 0.61, Precision: 0.885
# F-Score(id) = 0.499, Recall: 0.388, Precision: 0.699
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 125 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 467948
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_21 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_22 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_21 (Embedding)        (None, 4, 30)        440790      input_21[0][0]                   
__________________________________________________________________________________________________
embedding_22 (Embedding)        (None, 4, 15)        3525        input_22[0][0]                   
__________________________________________________________________________________________________
flatten_21 (Flatten)            (None, 120)          0           embedding_21[0][0]               
__________________________________________________________________________________________________
flatten_22 (Flatten)            (None, 60)           0           embedding_22[0][0]               
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 180)          0           flatten_21[0][0]                 
                                                                 flatten_22[0][0]                 
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 125)          22625       concatenate_11[0][0]             
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 125)          0           dense_21[0][0]                   
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 8)            1008        dropout_11[0][0]                 
==================================================================================================
Total params: 467,948
Trainable params: 467,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:19:13.784097
# F-Score(Ordinary) = 0.588, Recall: 0.486, Precision: 0.743
# F-Score(lvc) = 0.631, Recall: 0.878, Precision: 0.492
# F-Score(ireflv) = 0.849, Recall: 0.846, Precision: 0.852
# F-Score(id) = 0.415, Recall: 0.29, Precision: 0.731
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 125 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 467948
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_23 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_24 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_23 (Embedding)        (None, 4, 30)        440790      input_23[0][0]                   
__________________________________________________________________________________________________
embedding_24 (Embedding)        (None, 4, 15)        3525        input_24[0][0]                   
__________________________________________________________________________________________________
flatten_23 (Flatten)            (None, 120)          0           embedding_23[0][0]               
__________________________________________________________________________________________________
flatten_24 (Flatten)            (None, 60)           0           embedding_24[0][0]               
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 180)          0           flatten_23[0][0]                 
                                                                 flatten_24[0][0]                 
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 125)          22625       concatenate_12[0][0]             
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 125)          0           dense_23[0][0]                   
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 8)            1008        dropout_12[0][0]                 
==================================================================================================
Total params: 467,948
Trainable params: 467,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:19:15.897043
# F-Score(Ordinary) = 0.541, Recall: 0.427, Precision: 0.738
# F-Score(lvc) = 0.591, Recall: 0.845, Precision: 0.455
# F-Score(ireflv) = 0.842, Recall: 0.856, Precision: 0.828
# F-Score(id) = 0.376, Recall: 0.25, Precision: 0.756
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 125 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 467948
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_25 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_26 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_25 (Embedding)        (None, 4, 30)        440790      input_25[0][0]                   
__________________________________________________________________________________________________
embedding_26 (Embedding)        (None, 4, 15)        3525        input_26[0][0]                   
__________________________________________________________________________________________________
flatten_25 (Flatten)            (None, 120)          0           embedding_25[0][0]               
__________________________________________________________________________________________________
flatten_26 (Flatten)            (None, 60)           0           embedding_26[0][0]               
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 180)          0           flatten_25[0][0]                 
                                                                 flatten_26[0][0]                 
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 125)          22625       concatenate_13[0][0]             
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 125)          0           dense_25[0][0]                   
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 8)            1008        dropout_13[0][0]                 
==================================================================================================
Total params: 467,948
Trainable params: 467,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:18:56.807914
# F-Score(Ordinary) = 0.548, Recall: 0.451, Precision: 0.698
# F-Score(lvc) = 0.315, Recall: 0.217, Precision: 0.576
# F-Score(ireflv) = 0.803, Recall: 0.803, Precision: 0.803
# F-Score(id) = 0.621, Recall: 0.584, Precision: 0.663
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 125 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 467948
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_27 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_28 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_27 (Embedding)        (None, 4, 30)        440790      input_27[0][0]                   
__________________________________________________________________________________________________
embedding_28 (Embedding)        (None, 4, 15)        3525        input_28[0][0]                   
__________________________________________________________________________________________________
flatten_27 (Flatten)            (None, 120)          0           embedding_27[0][0]               
__________________________________________________________________________________________________
flatten_28 (Flatten)            (None, 60)           0           embedding_28[0][0]               
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 180)          0           flatten_27[0][0]                 
                                                                 flatten_28[0][0]                 
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 125)          22625       concatenate_14[0][0]             
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 125)          0           dense_27[0][0]                   
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 8)            1008        dropout_14[0][0]                 
==================================================================================================
Total params: 467,948
Trainable params: 467,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:18:59.636775
# F-Score(Ordinary) = 0.579, Recall: 0.485, Precision: 0.718
# F-Score(lvc) = 0.593, Recall: 0.805, Precision: 0.47
# F-Score(ireflv) = 0.818, Recall: 0.825, Precision: 0.811
# F-Score(id) = 0.426, Recall: 0.301, Precision: 0.725
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 125 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 467948
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_29 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_30 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_29 (Embedding)        (None, 4, 30)        440790      input_29[0][0]                   
__________________________________________________________________________________________________
embedding_30 (Embedding)        (None, 4, 15)        3525        input_30[0][0]                   
__________________________________________________________________________________________________
flatten_29 (Flatten)            (None, 120)          0           embedding_29[0][0]               
__________________________________________________________________________________________________
flatten_30 (Flatten)            (None, 60)           0           embedding_30[0][0]               
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 180)          0           flatten_29[0][0]                 
                                                                 flatten_30[0][0]                 
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 125)          22625       concatenate_15[0][0]             
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 125)          0           dense_29[0][0]                   
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 8)            1008        dropout_15[0][0]                 
==================================================================================================
Total params: 467,948
Trainable params: 467,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:19:00.388182
# F-Score(Ordinary) = 0.624, Recall: 0.544, Precision: 0.732
# F-Score(lvc) = 0.526, Recall: 0.565, Precision: 0.492
# F-Score(ireflv) = 0.841, Recall: 0.837, Precision: 0.844
# F-Score(id) = 0.5, Recall: 0.383, Precision: 0.72
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 250 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 491573
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_31 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_32 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_31 (Embedding)        (None, 4, 30)        440790      input_31[0][0]                   
__________________________________________________________________________________________________
embedding_32 (Embedding)        (None, 4, 15)        3525        input_32[0][0]                   
__________________________________________________________________________________________________
flatten_31 (Flatten)            (None, 120)          0           embedding_31[0][0]               
__________________________________________________________________________________________________
flatten_32 (Flatten)            (None, 60)           0           embedding_32[0][0]               
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 180)          0           flatten_31[0][0]                 
                                                                 flatten_32[0][0]                 
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 250)          45250       concatenate_16[0][0]             
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 250)          0           dense_31[0][0]                   
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 8)            2008        dropout_16[0][0]                 
==================================================================================================
Total params: 491,573
Trainable params: 491,573
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:19:05.149425
# F-Score(Ordinary) = 0.676, Recall: 0.649, Precision: 0.705
# F-Score(lvc) = 0.589, Recall: 0.813, Precision: 0.462
# F-Score(ireflv) = 0.828, Recall: 0.828, Precision: 0.828
# F-Score(id) = 0.578, Recall: 0.483, Precision: 0.72
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 250 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 491573
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_33 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_34 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_33 (Embedding)        (None, 4, 30)        440790      input_33[0][0]                   
__________________________________________________________________________________________________
embedding_34 (Embedding)        (None, 4, 15)        3525        input_34[0][0]                   
__________________________________________________________________________________________________
flatten_33 (Flatten)            (None, 120)          0           embedding_33[0][0]               
__________________________________________________________________________________________________
flatten_34 (Flatten)            (None, 60)           0           embedding_34[0][0]               
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 180)          0           flatten_33[0][0]                 
                                                                 flatten_34[0][0]                 
__________________________________________________________________________________________________
dense_33 (Dense)                (None, 250)          45250       concatenate_17[0][0]             
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 250)          0           dense_33[0][0]                   
__________________________________________________________________________________________________
dense_34 (Dense)                (None, 8)            2008        dropout_17[0][0]                 
==================================================================================================
Total params: 491,573
Trainable params: 491,573
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:19:05.298038
# F-Score(Ordinary) = 0.573, Recall: 0.479, Precision: 0.714
# F-Score(lvc) = 0.589, Recall: 0.813, Precision: 0.462
# F-Score(ireflv) = 0.736, Recall: 0.652, Precision: 0.844
# F-Score(id) = 0.428, Recall: 0.309, Precision: 0.694
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 250 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 491573
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_35 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_36 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_35 (Embedding)        (None, 4, 30)        440790      input_35[0][0]                   
__________________________________________________________________________________________________
embedding_36 (Embedding)        (None, 4, 15)        3525        input_36[0][0]                   
__________________________________________________________________________________________________
flatten_35 (Flatten)            (None, 120)          0           embedding_35[0][0]               
__________________________________________________________________________________________________
flatten_36 (Flatten)            (None, 60)           0           embedding_36[0][0]               
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 180)          0           flatten_35[0][0]                 
                                                                 flatten_36[0][0]                 
__________________________________________________________________________________________________
dense_35 (Dense)                (None, 250)          45250       concatenate_18[0][0]             
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, 250)          0           dense_35[0][0]                   
__________________________________________________________________________________________________
dense_36 (Dense)                (None, 8)            2008        dropout_18[0][0]                 
==================================================================================================
Total params: 491,573
Trainable params: 491,573
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:19:13.765260
# F-Score(Ordinary) = 0.568, Recall: 0.472, Precision: 0.714
# F-Score(lvc) = 0.456, Recall: 0.425, Precision: 0.492
# F-Score(ireflv) = 0.818, Recall: 0.825, Precision: 0.811
# F-Score(id) = 0.463, Recall: 0.342, Precision: 0.715
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 250 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 491573
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_37 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_38 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_37 (Embedding)        (None, 4, 30)        440790      input_37[0][0]                   
__________________________________________________________________________________________________
embedding_38 (Embedding)        (None, 4, 15)        3525        input_38[0][0]                   
__________________________________________________________________________________________________
flatten_37 (Flatten)            (None, 120)          0           embedding_37[0][0]               
__________________________________________________________________________________________________
flatten_38 (Flatten)            (None, 60)           0           embedding_38[0][0]               
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 180)          0           flatten_37[0][0]                 
                                                                 flatten_38[0][0]                 
__________________________________________________________________________________________________
dense_37 (Dense)                (None, 250)          45250       concatenate_19[0][0]             
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 250)          0           dense_37[0][0]                   
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 8)            2008        dropout_19[0][0]                 
==================================================================================================
Total params: 491,573
Trainable params: 491,573
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:19:05.956058
# F-Score(Ordinary) = 0.595, Recall: 0.505, Precision: 0.723
# F-Score(lvc) = 0.53, Recall: 0.522, Precision: 0.538
# F-Score(ireflv) = 0.834, Recall: 0.867, Precision: 0.803
# F-Score(id) = 0.473, Recall: 0.354, Precision: 0.715
********************
********************
# XP = FR: Lemma(30) POS(15) Dense 250 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 45
# Features = False
Deep model(Non compositional)
# Parameters = 491573
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_39 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_40 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_39 (Embedding)        (None, 4, 30)        440790      input_39[0][0]                   
__________________________________________________________________________________________________
embedding_40 (Embedding)        (None, 4, 15)        3525        input_40[0][0]                   
__________________________________________________________________________________________________
flatten_39 (Flatten)            (None, 120)          0           embedding_39[0][0]               
__________________________________________________________________________________________________
flatten_40 (Flatten)            (None, 60)           0           embedding_40[0][0]               
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 180)          0           flatten_39[0][0]                 
                                                                 flatten_40[0][0]                 
__________________________________________________________________________________________________
dense_39 (Dense)                (None, 250)          45250       concatenate_20[0][0]             
__________________________________________________________________________________________________
dropout_20 (Dropout)            (None, 250)          0           dense_39[0][0]                   
__________________________________________________________________________________________________
dense_40 (Dense)                (None, 8)            2008        dropout_20[0][0]                 
==================================================================================================
Total params: 491,573
Trainable params: 491,573
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 212145
data size after sampling = 728574
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 4.0: 10.0, 5.0: 10.0, 6.0: 10.0, 7.0: 10.0}
# Network optimizer = adam, learning rate = 0.001
Training over validation data# Training time = 0:19:13.362473
# F-Score(Ordinary) = 0.59, Recall: 0.498, Precision: 0.723
# F-Score(lvc) = 0.467, Recall: 0.397, Precision: 0.568
# F-Score(ireflv) = 0.787, Recall: 0.772, Precision: 0.803
# F-Score(id) = 0.518, Recall: 0.41, Precision: 0.705
********************
********************
# XP = FR: Lemma(30) POS(25) Dense 25 
********************
********************
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091, Test = 1788
Training started# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = True
# Emb = 55
# Features = False
Deep model(Non compositional)
