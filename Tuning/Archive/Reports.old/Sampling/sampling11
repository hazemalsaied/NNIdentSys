INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 4, 48)        705264      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 4, 24)        5640        input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 192)          0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 96)           0           embedding_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 288)          0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 24)           6936        concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24)           0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 8)            200         dropout_1[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 104082), (1.0, 98992), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
(212145,)
(728574,)
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 655716 samples, validate on 72858 samples
Epoch 1/15
 - 17s - loss: 0.0793 - acc: 0.9821 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 2/15
 - 17s - loss: 0.0448 - acc: 0.9906 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 17s - loss: 0.0423 - acc: 0.9912 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 17s - loss: 0.0409 - acc: 0.9915 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 17s - loss: 0.0403 - acc: 0.9916 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 17s - loss: 0.0397 - acc: 0.9919 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 17s - loss: 0.0394 - acc: 0.9919 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 17s - loss: 0.0389 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 17s - loss: 0.0386 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 17s - loss: 0.0384 - acc: 0.9922 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 17s - loss: 0.0384 - acc: 0.9922 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 17s - loss: 0.0383 - acc: 0.9922 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 17s - loss: 0.0381 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 17s - loss: 0.0382 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 17s - loss: 0.0378 - acc: 0.9924 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 2s - loss: 1.9349e-05 - acc: 1.0000
Epoch 2/15
 - 2s - loss: 5.3458e-06 - acc: 1.0000
Epoch 3/15
 - 2s - loss: 3.3592e-06 - acc: 1.0000
Epoch 4/15
 - 2s - loss: 8.9231e-07 - acc: 1.0000
Epoch 5/15
 - 2s - loss: 6.7462e-07 - acc: 1.0000
Epoch 6/15
 - 2s - loss: 8.9545e-05 - acc: 1.0000
Epoch 7/15
 - 2s - loss: 2.5866e-07 - acc: 1.0000
Epoch 8/15
 - 2s - loss: 8.7157e-05 - acc: 1.0000
Epoch 9/15
 - 2s - loss: 1.2624e-04 - acc: 1.0000
Epoch 10/15
 - 2s - loss: 1.3682e-07 - acc: 1.0000
Epoch 11/15
 - 2s - loss: 1.2859e-07 - acc: 1.0000
Epoch 12/15
 - 2s - loss: 4.1054e-05 - acc: 1.0000
Epoch 13/15
 - 2s - loss: 7.9769e-05 - acc: 1.0000
Epoch 14/15
 - 2s - loss: 7.7367e-05 - acc: 1.0000
Epoch 15/15
 - 2s - loss: 3.7932e-05 - acc: 1.0000
# Training time = 0:05:12.291897
# F-Score(Ordinary) = 0.627, Recall: 0.619, Precision: 0.635
# F-Score(lvc) = 0.482, Recall: 0.522, Precision: 0.447
# F-Score(ireflv) = 0.803, Recall: 0.821, Precision: 0.787
# F-Score(id) = 0.575, Recall: 0.531, Precision: 0.627
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 4, 48)        705264      input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 4, 24)        5640        input_4[0][0]                    
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 192)          0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 96)           0           embedding_4[0][0]                
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 288)          0           flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 24)           6936        concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24)           0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 8)            200         dropout_2[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 104082), (1.0, 98992), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
(212145,)
(728574,)
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 655716 samples, validate on 72858 samples
Epoch 1/15
 - 17s - loss: 0.0806 - acc: 0.9824 - val_loss: 2.3842e-07 - val_acc: 1.0000
Epoch 2/15
 - 17s - loss: 0.0449 - acc: 0.9906 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 17s - loss: 0.0423 - acc: 0.9912 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 17s - loss: 0.0411 - acc: 0.9915 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 17s - loss: 0.0403 - acc: 0.9916 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 17s - loss: 0.0397 - acc: 0.9918 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 17s - loss: 0.0394 - acc: 0.9919 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 17s - loss: 0.0391 - acc: 0.9920 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 17s - loss: 0.0389 - acc: 0.9920 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 17s - loss: 0.0387 - acc: 0.9920 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 17s - loss: 0.0387 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 17s - loss: 0.0385 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 17s - loss: 0.0383 - acc: 0.9922 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 17s - loss: 0.0381 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 17s - loss: 0.0381 - acc: 0.9922 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 2s - loss: 2.5432e-05 - acc: 1.0000
Epoch 2/15
 - 2s - loss: 6.3667e-06 - acc: 1.0000
Epoch 3/15
 - 2s - loss: 7.2372e-06 - acc: 1.0000
Epoch 4/15
 - 2s - loss: 1.4124e-05 - acc: 1.0000
Epoch 5/15
 - 2s - loss: 5.8172e-05 - acc: 1.0000
Epoch 6/15
 - 2s - loss: 3.1525e-07 - acc: 1.0000
Epoch 7/15
 - 2s - loss: 7.8823e-06 - acc: 1.0000
Epoch 8/15
 - 2s - loss: 3.2939e-07 - acc: 1.0000
Epoch 9/15
 - 2s - loss: 2.5057e-06 - acc: 1.0000
Epoch 10/15
 - 2s - loss: 5.5284e-05 - acc: 1.0000
Epoch 11/15
 - 2s - loss: 1.5627e-07 - acc: 1.0000
Epoch 12/15
 - 2s - loss: 2.1499e-07 - acc: 1.0000
Epoch 13/15
 - 2s - loss: 5.3820e-05 - acc: 1.0000
Epoch 14/15
 - 2s - loss: 1.7871e-07 - acc: 1.0000
Epoch 15/15
 - 2s - loss: 1.2628e-07 - acc: 1.0000
# Training time = 0:05:03.813244
# F-Score(Ordinary) = 0.675, Recall: 0.724, Precision: 0.633
# F-Score(lvc) = 0.538, Recall: 0.618, Precision: 0.477
# F-Score(ireflv) = 0.8, Recall: 0.797, Precision: 0.803
# F-Score(id) = 0.646, Recall: 0.699, Precision: 0.601
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 4, 48)        705264      input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 4, 24)        5640        input_6[0][0]                    
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 192)          0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 96)           0           embedding_6[0][0]                
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 288)          0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 24)           6936        concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24)           0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 8)            200         dropout_3[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 104082), (1.0, 98992), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
(212145,)
(728574,)
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 655716 samples, validate on 72858 samples
Epoch 1/15
 - 17s - loss: 0.0811 - acc: 0.9820 - val_loss: 1.0729e-06 - val_acc: 1.0000
Epoch 2/15
 - 17s - loss: 0.0451 - acc: 0.9906 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 17s - loss: 0.0423 - acc: 0.9913 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 17s - loss: 0.0410 - acc: 0.9915 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 17s - loss: 0.0403 - acc: 0.9917 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 17s - loss: 0.0398 - acc: 0.9918 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 17s - loss: 0.0392 - acc: 0.9920 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 17s - loss: 0.0389 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 17s - loss: 0.0388 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 17s - loss: 0.0386 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 17s - loss: 0.0383 - acc: 0.9922 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 17s - loss: 0.0383 - acc: 0.9922 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 17s - loss: 0.0380 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 17s - loss: 0.0379 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 17s - loss: 0.0379 - acc: 0.9924 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 2s - loss: 2.2255e-04 - acc: 1.0000
Epoch 2/15
 - 2s - loss: 6.4465e-05 - acc: 1.0000
Epoch 3/15
 - 2s - loss: 9.4230e-05 - acc: 1.0000
Epoch 4/15
 - 2s - loss: 1.9843e-05 - acc: 1.0000
Epoch 5/15
 - 2s - loss: 3.8057e-06 - acc: 1.0000
Epoch 6/15
 - 2s - loss: 8.4304e-05 - acc: 1.0000
Epoch 7/15
 - 2s - loss: 5.4270e-07 - acc: 1.0000
Epoch 8/15
 - 2s - loss: 2.7535e-07 - acc: 1.0000
Epoch 9/15
 - 2s - loss: 8.1584e-05 - acc: 1.0000
Epoch 10/15
 - 2s - loss: 3.5550e-07 - acc: 1.0000
Epoch 11/15
 - 2s - loss: 2.6765e-07 - acc: 1.0000
Epoch 12/15
 - 2s - loss: 1.5244e-07 - acc: 1.0000
Epoch 13/15
 - 2s - loss: 1.4317e-07 - acc: 1.0000
Epoch 14/15
 - 2s - loss: 1.3237e-07 - acc: 1.0000
Epoch 15/15
 - 2s - loss: 1.1965e-07 - acc: 1.0000
# Training time = 0:05:03.595355
# F-Score(Ordinary) = 0.721, Recall: 0.827, Precision: 0.64
# F-Score(lvc) = 0.573, Recall: 0.753, Precision: 0.462
# F-Score(ireflv) = 0.821, Recall: 0.815, Precision: 0.828
# F-Score(id) = 0.731, Recall: 0.865, Precision: 0.632
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 4, 48)        705264      input_7[0][0]                    
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 4, 24)        5640        input_8[0][0]                    
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 192)          0           embedding_7[0][0]                
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 96)           0           embedding_8[0][0]                
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 288)          0           flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 24)           6936        concatenate_4[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24)           0           dense_7[0][0]                    
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 8)            200         dropout_4[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 104082), (1.0, 98992), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
(212145,)
(728574,)
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 655716 samples, validate on 72858 samples
Epoch 1/15
 - 17s - loss: 0.0811 - acc: 0.9821 - val_loss: 3.5763e-07 - val_acc: 1.0000
Epoch 2/15
 - 17s - loss: 0.0448 - acc: 0.9906 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 17s - loss: 0.0423 - acc: 0.9911 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 17s - loss: 0.0411 - acc: 0.9914 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 17s - loss: 0.0403 - acc: 0.9916 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 17s - loss: 0.0397 - acc: 0.9918 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 17s - loss: 0.0392 - acc: 0.9919 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 17s - loss: 0.0391 - acc: 0.9919 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 17s - loss: 0.0387 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 17s - loss: 0.0386 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 18s - loss: 0.0384 - acc: 0.9922 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 17s - loss: 0.0383 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 17s - loss: 0.0381 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 17s - loss: 0.0380 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 17s - loss: 0.0380 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 2s - loss: 3.3501e-05 - acc: 1.0000
Epoch 2/15
 - 2s - loss: 2.4076e-05 - acc: 1.0000
Epoch 3/15
 - 2s - loss: 1.6363e-06 - acc: 1.0000
Epoch 4/15
 - 2s - loss: 3.1390e-07 - acc: 1.0000
Epoch 5/15
 - 2s - loss: 3.0877e-06 - acc: 1.0000
Epoch 6/15
 - 2s - loss: 1.0198e-04 - acc: 1.0000
Epoch 7/15
 - 2s - loss: 5.8991e-05 - acc: 1.0000
Epoch 8/15
 - 2s - loss: 3.5094e-07 - acc: 1.0000
Epoch 9/15
 - 2s - loss: 1.5681e-07 - acc: 1.0000
Epoch 10/15
 - 2s - loss: 1.5738e-07 - acc: 1.0000
Epoch 11/15
 - 2s - loss: 6.4174e-05 - acc: 1.0000
Epoch 12/15
 - 2s - loss: 1.5397e-06 - acc: 1.0000
Epoch 13/15
 - 2s - loss: 2.1753e-07 - acc: 1.0000
Epoch 14/15
 - 2s - loss: 1.1950e-07 - acc: 1.0000
Epoch 15/15
 - 2s - loss: 1.3719e-05 - acc: 1.0000
# Training time = 0:05:04.433801
# F-Score(Ordinary) = 0.648, Recall: 0.695, Precision: 0.606
# F-Score(lvc) = 0.577, Recall: 0.841, Precision: 0.439
# F-Score(ireflv) = 0.816, Recall: 0.813, Precision: 0.82
# F-Score(id) = 0.532, Recall: 0.525, Precision: 0.539
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_10 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 4, 48)        705264      input_9[0][0]                    
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 4, 24)        5640        input_10[0][0]                   
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 192)          0           embedding_9[0][0]                
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 96)           0           embedding_10[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 288)          0           flatten_9[0][0]                  
                                                                 flatten_10[0][0]                 
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 24)           6936        concatenate_5[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24)           0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 8)            200         dropout_5[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 104082), (1.0, 98992), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
(212145,)
(728574,)
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 655716 samples, validate on 72858 samples
Epoch 1/15
 - 17s - loss: 0.0818 - acc: 0.9820 - val_loss: 2.3842e-07 - val_acc: 1.0000
Epoch 2/15
 - 17s - loss: 0.0452 - acc: 0.9907 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 17s - loss: 0.0427 - acc: 0.9912 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 17s - loss: 0.0413 - acc: 0.9914 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 17s - loss: 0.0403 - acc: 0.9917 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 17s - loss: 0.0401 - acc: 0.9917 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 17s - loss: 0.0396 - acc: 0.9919 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 17s - loss: 0.0393 - acc: 0.9920 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 17s - loss: 0.0389 - acc: 0.9920 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 17s - loss: 0.0387 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 17s - loss: 0.0387 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 17s - loss: 0.0385 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 17s - loss: 0.0383 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 17s - loss: 0.0382 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 17s - loss: 0.0380 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 2s - loss: 3.4346e-04 - acc: 0.9999
Epoch 2/15
 - 2s - loss: 2.5139e-04 - acc: 0.9999
Epoch 3/15
 - 2s - loss: 3.3889e-04 - acc: 0.9999
Epoch 4/15
 - 2s - loss: 3.7282e-04 - acc: 0.9999
Epoch 5/15
 - 2s - loss: 9.1042e-05 - acc: 1.0000
Epoch 6/15
 - 2s - loss: 1.3676e-04 - acc: 1.0000
Epoch 7/15
 - 2s - loss: 4.3979e-05 - acc: 1.0000
Epoch 8/15
 - 2s - loss: 2.5366e-04 - acc: 0.9999
Epoch 9/15
 - 2s - loss: 1.2114e-04 - acc: 1.0000
Epoch 10/15
 - 2s - loss: 1.5557e-04 - acc: 0.9999
Epoch 11/15
 - 2s - loss: 7.5469e-05 - acc: 1.0000
Epoch 12/15
 - 2s - loss: 1.4557e-04 - acc: 0.9999
Epoch 13/15
 - 2s - loss: 2.0605e-04 - acc: 0.9999
Epoch 14/15
 - 2s - loss: 1.3005e-04 - acc: 0.9999
Epoch 15/15
 - 2s - loss: 1.8454e-04 - acc: 0.9999
# Training time = 0:05:04.341185
# F-Score(Ordinary) = 0.717, Recall: 0.78, Precision: 0.664
# F-Score(lvc) = 0.538, Recall: 0.562, Precision: 0.515
# F-Score(ireflv) = 0.826, Recall: 0.858, Precision: 0.795
# F-Score(id) = 0.741, Recall: 0.857, Precision: 0.653
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 4, 48)        705264      input_11[0][0]                   
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 4, 24)        5640        input_12[0][0]                   
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 192)          0           embedding_11[0][0]               
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 96)           0           embedding_12[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 288)          0           flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 24)           6936        concatenate_6[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24)           0           dense_11[0][0]                   
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 8)            200         dropout_6[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 104082), (1.0, 98992), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
(212145,)
(728574,)
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 655716 samples, validate on 72858 samples
Epoch 1/15
 - 17s - loss: 0.0808 - acc: 0.9818 - val_loss: 4.7684e-07 - val_acc: 1.0000
Epoch 2/15
 - 17s - loss: 0.0449 - acc: 0.9906 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 17s - loss: 0.0425 - acc: 0.9911 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 17s - loss: 0.0413 - acc: 0.9914 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 17s - loss: 0.0406 - acc: 0.9916 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 17s - loss: 0.0400 - acc: 0.9918 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 17s - loss: 0.0397 - acc: 0.9918 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 17s - loss: 0.0392 - acc: 0.9920 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 17s - loss: 0.0391 - acc: 0.9920 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 17s - loss: 0.0389 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 17s - loss: 0.0387 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 17s - loss: 0.0385 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 17s - loss: 0.0384 - acc: 0.9922 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 17s - loss: 0.0382 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 17s - loss: 0.0381 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 2s - loss: 1.6057e-04 - acc: 1.0000
Epoch 2/15
 - 2s - loss: 7.4845e-05 - acc: 1.0000
Epoch 3/15
 - 2s - loss: 1.3485e-04 - acc: 1.0000
Epoch 4/15
 - 2s - loss: 1.1478e-06 - acc: 1.0000
Epoch 5/15
 - 2s - loss: 7.8207e-07 - acc: 1.0000
Epoch 6/15
 - 2s - loss: 6.6093e-05 - acc: 1.0000
Epoch 7/15
 - 2s - loss: 1.2976e-04 - acc: 1.0000
Epoch 8/15
 - 2s - loss: 1.8616e-07 - acc: 1.0000
Epoch 9/15
 - 2s - loss: 1.8150e-07 - acc: 1.0000
Epoch 10/15
 - 2s - loss: 6.4020e-05 - acc: 1.0000
Epoch 11/15
 - 2s - loss: 6.3196e-05 - acc: 1.0000
Epoch 12/15
 - 2s - loss: 1.3007e-07 - acc: 1.0000
Epoch 13/15
 - 2s - loss: 1.2394e-04 - acc: 1.0000
Epoch 14/15
 - 2s - loss: 1.2105e-07 - acc: 1.0000
Epoch 15/15
 - 2s - loss: 6.1005e-05 - acc: 1.0000
# Training time = 0:05:03.831320
# F-Score(Ordinary) = 0.65, Recall: 0.618, Precision: 0.687
# F-Score(lvc) = 0.563, Recall: 0.741, Precision: 0.455
# F-Score(ireflv) = 0.832, Recall: 0.853, Precision: 0.811
# F-Score(id) = 0.54, Recall: 0.443, Precision: 0.689
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_14 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 4, 48)        705264      input_13[0][0]                   
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 4, 24)        5640        input_14[0][0]                   
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 192)          0           embedding_13[0][0]               
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 96)           0           embedding_14[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 288)          0           flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 24)           6936        concatenate_7[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24)           0           dense_13[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 8)            200         dropout_7[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 104082), (1.0, 98992), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
(212145,)
(728574,)
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 655716 samples, validate on 72858 samples
Epoch 1/15
 - 17s - loss: 0.0822 - acc: 0.9815 - val_loss: 3.5763e-07 - val_acc: 1.0000
Epoch 2/15
 - 17s - loss: 0.0453 - acc: 0.9905 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 17s - loss: 0.0428 - acc: 0.9911 - val_loss: 2.3842e-07 - val_acc: 1.0000
Epoch 4/15
 - 17s - loss: 0.0414 - acc: 0.9914 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 17s - loss: 0.0406 - acc: 0.9916 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 17s - loss: 0.0399 - acc: 0.9917 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 17s - loss: 0.0394 - acc: 0.9919 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 17s - loss: 0.0393 - acc: 0.9919 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 17s - loss: 0.0392 - acc: 0.9920 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 17s - loss: 0.0388 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 17s - loss: 0.0387 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 17s - loss: 0.0385 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 17s - loss: 0.0383 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 17s - loss: 0.0382 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 17s - loss: 0.0381 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 2s - loss: 8.7611e-05 - acc: 1.0000
Epoch 2/15
 - 2s - loss: 4.6916e-05 - acc: 1.0000
Epoch 3/15
 - 2s - loss: 1.4790e-05 - acc: 1.0000
Epoch 4/15
 - 2s - loss: 7.3472e-05 - acc: 1.0000
Epoch 5/15
 - 2s - loss: 1.2931e-06 - acc: 1.0000
Epoch 6/15
 - 2s - loss: 1.1151e-06 - acc: 1.0000
Epoch 7/15
 - 2s - loss: 1.6027e-06 - acc: 1.0000
Epoch 8/15
 - 2s - loss: 1.3704e-04 - acc: 1.0000
Epoch 9/15
 - 2s - loss: 2.3904e-07 - acc: 1.0000
Epoch 10/15
 - 2s - loss: 2.5785e-07 - acc: 1.0000
Epoch 11/15
 - 2s - loss: 2.4577e-07 - acc: 1.0000
Epoch 12/15
 - 2s - loss: 1.5634e-07 - acc: 1.0000
Epoch 13/15
 - 2s - loss: 1.3712e-07 - acc: 1.0000
Epoch 14/15
 - 2s - loss: 1.2448e-07 - acc: 1.0000
Epoch 15/15
 - 2s - loss: 1.2931e-07 - acc: 1.0000
# Training time = 0:05:04.244027
# F-Score(Ordinary) = 0.7, Recall: 0.756, Precision: 0.651
# F-Score(lvc) = 0.549, Recall: 0.66, Precision: 0.47
# F-Score(ireflv) = 0.79, Recall: 0.718, Precision: 0.877
# F-Score(id) = 0.722, Recall: 0.852, Precision: 0.627
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_15 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_16 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_15 (Embedding)        (None, 4, 48)        705264      input_15[0][0]                   
__________________________________________________________________________________________________
embedding_16 (Embedding)        (None, 4, 24)        5640        input_16[0][0]                   
__________________________________________________________________________________________________
flatten_15 (Flatten)            (None, 192)          0           embedding_15[0][0]               
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 96)           0           embedding_16[0][0]               
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 288)          0           flatten_15[0][0]                 
                                                                 flatten_16[0][0]                 
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 24)           6936        concatenate_8[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24)           0           dense_15[0][0]                   
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 8)            200         dropout_8[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 104082), (1.0, 98992), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
(212145,)
(728574,)
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 655716 samples, validate on 72858 samples
Epoch 1/15
 - 17s - loss: 0.0816 - acc: 0.9815 - val_loss: 3.5763e-07 - val_acc: 1.0000
Epoch 2/15
 - 17s - loss: 0.0453 - acc: 0.9905 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 17s - loss: 0.0427 - acc: 0.9912 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 17s - loss: 0.0414 - acc: 0.9914 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 17s - loss: 0.0405 - acc: 0.9916 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 17s - loss: 0.0399 - acc: 0.9917 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 17s - loss: 0.0395 - acc: 0.9919 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 17s - loss: 0.0393 - acc: 0.9920 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 17s - loss: 0.0389 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 17s - loss: 0.0387 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 17s - loss: 0.0385 - acc: 0.9922 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 17s - loss: 0.0384 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 17s - loss: 0.0383 - acc: 0.9922 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 17s - loss: 0.0382 - acc: 0.9922 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 17s - loss: 0.0382 - acc: 0.9922 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 2s - loss: 9.6592e-05 - acc: 1.0000
Epoch 2/15
 - 2s - loss: 4.3591e-05 - acc: 1.0000
Epoch 3/15
 - 2s - loss: 2.3564e-06 - acc: 1.0000
Epoch 4/15
 - 2s - loss: 8.3875e-05 - acc: 1.0000
Epoch 5/15
 - 2s - loss: 3.2047e-06 - acc: 1.0000
Epoch 6/15
 - 2s - loss: 1.4373e-06 - acc: 1.0000
Epoch 7/15
 - 2s - loss: 7.5697e-07 - acc: 1.0000
Epoch 8/15
 - 2s - loss: 1.7053e-07 - acc: 1.0000
Epoch 9/15
 - 2s - loss: 2.1833e-07 - acc: 1.0000
Epoch 10/15
 - 2s - loss: 6.1698e-05 - acc: 1.0000
Epoch 11/15
 - 2s - loss: 9.3467e-07 - acc: 1.0000
Epoch 12/15
 - 2s - loss: 1.5709e-07 - acc: 1.0000
Epoch 13/15
 - 2s - loss: 4.4524e-07 - acc: 1.0000
Epoch 14/15
 - 2s - loss: 1.2820e-07 - acc: 1.0000
Epoch 15/15
 - 2s - loss: 1.3332e-07 - acc: 1.0000
# Training time = 0:05:03.906425
# F-Score(Ordinary) = 0.677, Recall: 0.704, Precision: 0.653
# F-Score(lvc) = 0.593, Recall: 0.805, Precision: 0.47
# F-Score(ireflv) = 0.821, Recall: 0.857, Precision: 0.787
# F-Score(id) = 0.592, Recall: 0.549, Precision: 0.642
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_17 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_18 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_17 (Embedding)        (None, 4, 48)        705264      input_17[0][0]                   
__________________________________________________________________________________________________
embedding_18 (Embedding)        (None, 4, 24)        5640        input_18[0][0]                   
__________________________________________________________________________________________________
flatten_17 (Flatten)            (None, 192)          0           embedding_17[0][0]               
__________________________________________________________________________________________________
flatten_18 (Flatten)            (None, 96)           0           embedding_18[0][0]               
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 288)          0           flatten_17[0][0]                 
                                                                 flatten_18[0][0]                 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 24)           6936        concatenate_9[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24)           0           dense_17[0][0]                   
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 8)            200         dropout_9[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 104082), (1.0, 98992), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
(212145,)
(728574,)
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 655716 samples, validate on 72858 samples
Epoch 1/15
 - 17s - loss: 0.0822 - acc: 0.9821 - val_loss: 5.1856e-06 - val_acc: 1.0000
Epoch 2/15
 - 17s - loss: 0.0457 - acc: 0.9905 - val_loss: 2.3842e-07 - val_acc: 1.0000
Epoch 3/15
 - 17s - loss: 0.0428 - acc: 0.9910 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 17s - loss: 0.0414 - acc: 0.9913 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 17s - loss: 0.0409 - acc: 0.9915 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 17s - loss: 0.0401 - acc: 0.9917 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 17s - loss: 0.0400 - acc: 0.9917 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 17s - loss: 0.0395 - acc: 0.9919 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 17s - loss: 0.0392 - acc: 0.9919 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 17s - loss: 0.0391 - acc: 0.9920 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 17s - loss: 0.0388 - acc: 0.9920 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 17s - loss: 0.0388 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 17s - loss: 0.0386 - acc: 0.9922 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 17s - loss: 0.0384 - acc: 0.9922 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 17s - loss: 0.0383 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 2s - loss: 2.4435e-05 - acc: 1.0000
Epoch 2/15
 - 2s - loss: 9.6271e-06 - acc: 1.0000
Epoch 3/15
 - 2s - loss: 3.9140e-05 - acc: 1.0000
Epoch 4/15
 - 2s - loss: 1.9453e-06 - acc: 1.0000
Epoch 5/15
 - 2s - loss: 2.4847e-07 - acc: 1.0000
Epoch 6/15
 - 2s - loss: 1.7223e-06 - acc: 1.0000
Epoch 7/15
 - 2s - loss: 4.0904e-07 - acc: 1.0000
Epoch 8/15
 - 2s - loss: 1.3778e-06 - acc: 1.0000
Epoch 9/15
 - 2s - loss: 2.4011e-05 - acc: 1.0000
Epoch 10/15
 - 2s - loss: 1.2595e-07 - acc: 1.0000
Epoch 11/15
 - 2s - loss: 1.6276e-07 - acc: 1.0000
Epoch 12/15
 - 2s - loss: 1.2248e-07 - acc: 1.0000
Epoch 13/15
 - 2s - loss: 1.2206e-07 - acc: 1.0000
Epoch 14/15
 - 2s - loss: 1.1981e-07 - acc: 1.0000
Epoch 15/15
 - 2s - loss: 3.4638e-07 - acc: 1.0000
# Training time = 0:05:04.194304
# F-Score(Ordinary) = 0.718, Recall: 0.815, Precision: 0.642
# F-Score(lvc) = 0.555, Recall: 0.753, Precision: 0.439
# F-Score(ireflv) = 0.812, Recall: 0.829, Precision: 0.795
# F-Score(id) = 0.741, Recall: 0.823, Precision: 0.674
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_19 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_20 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_19 (Embedding)        (None, 4, 48)        705264      input_19[0][0]                   
__________________________________________________________________________________________________
embedding_20 (Embedding)        (None, 4, 24)        5640        input_20[0][0]                   
__________________________________________________________________________________________________
flatten_19 (Flatten)            (None, 192)          0           embedding_19[0][0]               
__________________________________________________________________________________________________
flatten_20 (Flatten)            (None, 96)           0           embedding_20[0][0]               
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 288)          0           flatten_19[0][0]                 
                                                                 flatten_20[0][0]                 
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 24)           6936        concatenate_10[0][0]             
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24)           0           dense_19[0][0]                   
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 8)            200         dropout_10[0][0]                 
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
[(0.0, 104082), (1.0, 98992), (2.0, 5090), (4.0, 1191), (5.0, 1593), (6.0, 1196), (7.0, 1)]
(212145,)
(728574,)
class_weight [1. 1. 1. 1. 1. 1. 1.]
Train on 655716 samples, validate on 72858 samples
Epoch 1/15
 - 17s - loss: 0.0803 - acc: 0.9824 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 2/15
 - 17s - loss: 0.0451 - acc: 0.9907 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 3/15
 - 17s - loss: 0.0425 - acc: 0.9912 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 4/15
 - 17s - loss: 0.0411 - acc: 0.9915 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 5/15
 - 17s - loss: 0.0404 - acc: 0.9916 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 6/15
 - 17s - loss: 0.0398 - acc: 0.9918 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 7/15
 - 17s - loss: 0.0394 - acc: 0.9919 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 8/15
 - 17s - loss: 0.0392 - acc: 0.9919 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 9/15
 - 17s - loss: 0.0388 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 10/15
 - 17s - loss: 0.0387 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 11/15
 - 17s - loss: 0.0384 - acc: 0.9922 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 12/15
 - 17s - loss: 0.0385 - acc: 0.9921 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 13/15
 - 17s - loss: 0.0383 - acc: 0.9922 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 14/15
 - 17s - loss: 0.0382 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
Epoch 15/15
 - 17s - loss: 0.0381 - acc: 0.9923 - val_loss: 1.1921e-07 - val_acc: 1.0000
class_weight [1.]
Epoch 1/15
 - 2s - loss: 5.6061e-05 - acc: 1.0000
Epoch 2/15
 - 2s - loss: 1.0654e-05 - acc: 1.0000
Epoch 3/15
 - 2s - loss: 1.0180e-05 - acc: 1.0000
Epoch 4/15
 - 2s - loss: 8.2157e-06 - acc: 1.0000
Epoch 5/15
 - 2s - loss: 8.2500e-07 - acc: 1.0000
Epoch 6/15
 - 2s - loss: 6.3424e-05 - acc: 1.0000
Epoch 7/15
 - 2s - loss: 5.8644e-07 - acc: 1.0000
Epoch 8/15
 - 2s - loss: 2.6743e-07 - acc: 1.0000
Epoch 9/15
 - 2s - loss: 1.8624e-06 - acc: 1.0000
Epoch 10/15
 - 2s - loss: 3.2325e-07 - acc: 1.0000
Epoch 11/15
 - 2s - loss: 1.1901e-04 - acc: 1.0000
Epoch 12/15
 - 2s - loss: 1.6942e-07 - acc: 1.0000
Epoch 13/15
 - 2s - loss: 1.3493e-07 - acc: 1.0000
Epoch 14/15
 - 2s - loss: 1.2812e-07 - acc: 1.0000
Epoch 15/15
 - 2s - loss: 5.8430e-05 - acc: 1.0000
# Training time = 0:05:04.159168
# F-Score(Ordinary) = 0.603, Recall: 0.541, Precision: 0.68
# F-Score(lvc) = 0.403, Recall: 0.352, Precision: 0.47
# F-Score(ireflv) = 0.808, Recall: 0.822, Precision: 0.795
# F-Score(id) = 0.573, Recall: 0.493, Precision: 0.684
********************
