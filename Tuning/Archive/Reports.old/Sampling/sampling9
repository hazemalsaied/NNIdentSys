INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 4, 48)        705264      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 4, 24)        5640        input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 192)          0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 96)           0           embedding_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 288)          0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 24)           6936        concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24)           0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 8)            200         dropout_1[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.8132 - acc: 0.9390 - val_loss: 0.1499 - val_acc: 0.9576
Epoch 2/15
 - 5s - loss: 0.5649 - acc: 0.9629 - val_loss: 0.1002 - val_acc: 0.9616
Epoch 3/15
 - 5s - loss: 0.4286 - acc: 0.9678 - val_loss: 0.1066 - val_acc: 0.9609
Epoch 4/15
 - 5s - loss: 0.2935 - acc: 0.9693 - val_loss: 0.1110 - val_acc: 0.9635
Epoch 5/15
 - 5s - loss: 0.3571 - acc: 0.9715 - val_loss: 0.1094 - val_acc: 0.9648
Epoch 6/15
 - 5s - loss: 0.2660 - acc: 0.9727 - val_loss: 0.1210 - val_acc: 0.9642
Epoch 7/15
 - 5s - loss: 0.3353 - acc: 0.9732 - val_loss: 0.1256 - val_acc: 0.9650
Epoch 8/15
 - 5s - loss: 0.1605 - acc: 0.9740 - val_loss: 0.1362 - val_acc: 0.9624
Epoch 9/15
 - 5s - loss: 0.3605 - acc: 0.9744 - val_loss: 0.1369 - val_acc: 0.9652
Epoch 10/15
 - 5s - loss: 0.1830 - acc: 0.9748 - val_loss: 0.1473 - val_acc: 0.9659
Epoch 11/15
 - 5s - loss: 0.0992 - acc: 0.9751 - val_loss: 0.1325 - val_acc: 0.9639
Epoch 12/15
 - 5s - loss: 0.2816 - acc: 0.9755 - val_loss: 0.1383 - val_acc: 0.9645
Epoch 13/15
 - 5s - loss: 0.0734 - acc: 0.9756 - val_loss: 0.1566 - val_acc: 0.9654
Epoch 14/15
 - 5s - loss: 0.0506 - acc: 0.9761 - val_loss: 0.1441 - val_acc: 0.9644
Epoch 15/15
 - 5s - loss: 0.0445 - acc: 0.9760 - val_loss: 0.1490 - val_acc: 0.9653
Epoch 1/15
 - 0s - loss: 0.1586 - acc: 0.9585
Epoch 2/15
 - 1s - loss: 0.0871 - acc: 0.9677
Epoch 3/15
 - 1s - loss: 0.0702 - acc: 0.9707
Epoch 4/15
 - 1s - loss: 0.0583 - acc: 0.9729
Epoch 5/15
 - 1s - loss: 0.0503 - acc: 0.9740
Epoch 6/15
 - 1s - loss: 0.0490 - acc: 0.9751
Epoch 7/15
 - 1s - loss: 0.0489 - acc: 0.9749
Epoch 8/15
 - 1s - loss: 0.0480 - acc: 0.9763
Epoch 9/15
 - 1s - loss: 0.0467 - acc: 0.9761
Epoch 10/15
 - 1s - loss: 0.0459 - acc: 0.9768
Epoch 11/15
 - 1s - loss: 0.0474 - acc: 0.9770
Epoch 12/15
 - 1s - loss: 0.0459 - acc: 0.9769
Epoch 13/15
 - 1s - loss: 0.0439 - acc: 0.9769
Epoch 14/15
 - 1s - loss: 0.0424 - acc: 0.9782
Epoch 15/15
 - 1s - loss: 0.0422 - acc: 0.9779
# Training time = 0:01:46.119225
# F-Score(Ordinary) = 0.538, Recall: 0.428, Precision: 0.723
# F-Score(lvc) = 0.284, Recall: 0.189, Precision: 0.568
# F-Score(ireflv) = 0.737, Recall: 0.632, Precision: 0.885
# F-Score(id) = 0.679, Recall: 0.69, Precision: 0.668
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 4, 48)        705264      input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 4, 24)        5640        input_4[0][0]                    
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 192)          0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 96)           0           embedding_4[0][0]                
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 288)          0           flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 24)           6936        concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24)           0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 8)            200         dropout_2[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.1468 - acc: 0.9295 - val_loss: 0.1156 - val_acc: 0.9590
Epoch 2/15
 - 5s - loss: 1.6538 - acc: 0.9629 - val_loss: 0.0979 - val_acc: 0.9633
Epoch 3/15
 - 5s - loss: 0.4163 - acc: 0.9669 - val_loss: 0.1025 - val_acc: 0.9625
Epoch 4/15
 - 5s - loss: 0.4994 - acc: 0.9693 - val_loss: 0.1043 - val_acc: 0.9639
Epoch 5/15
 - 5s - loss: 0.2614 - acc: 0.9715 - val_loss: 0.1145 - val_acc: 0.9648
Epoch 6/15
 - 5s - loss: 0.1901 - acc: 0.9730 - val_loss: 0.1176 - val_acc: 0.9636
Epoch 7/15
 - 5s - loss: 0.1318 - acc: 0.9740 - val_loss: 0.1256 - val_acc: 0.9640
Epoch 8/15
 - 5s - loss: 0.0919 - acc: 0.9740 - val_loss: 0.1272 - val_acc: 0.9647
Epoch 9/15
 - 5s - loss: 0.0754 - acc: 0.9745 - val_loss: 0.1303 - val_acc: 0.9635
Epoch 10/15
 - 5s - loss: 0.0466 - acc: 0.9745 - val_loss: 0.1471 - val_acc: 0.9620
Epoch 11/15
 - 5s - loss: 0.0461 - acc: 0.9749 - val_loss: 0.1468 - val_acc: 0.9640
Epoch 12/15
 - 5s - loss: 0.0618 - acc: 0.9748 - val_loss: 0.1482 - val_acc: 0.9640
Epoch 13/15
 - 5s - loss: 0.0436 - acc: 0.9756 - val_loss: 0.1460 - val_acc: 0.9627
Epoch 14/15
 - 5s - loss: 0.0436 - acc: 0.9753 - val_loss: 0.1650 - val_acc: 0.9646
Epoch 15/15
 - 5s - loss: 0.0416 - acc: 0.9759 - val_loss: 0.1649 - val_acc: 0.9631
Epoch 1/15
 - 1s - loss: 0.1451 - acc: 0.9604
Epoch 2/15
 - 1s - loss: 0.0904 - acc: 0.9655
Epoch 3/15
 - 0s - loss: 0.0630 - acc: 0.9706
Epoch 4/15
 - 1s - loss: 0.0533 - acc: 0.9730
Epoch 5/15
 - 1s - loss: 0.0501 - acc: 0.9737
Epoch 6/15
 - 1s - loss: 0.0513 - acc: 0.9747
Epoch 7/15
 - 1s - loss: 0.0469 - acc: 0.9759
Epoch 8/15
 - 1s - loss: 0.0449 - acc: 0.9764
Epoch 9/15
 - 1s - loss: 0.0427 - acc: 0.9770
Epoch 10/15
 - 1s - loss: 0.0434 - acc: 0.9774
Epoch 11/15
 - 1s - loss: 0.0443 - acc: 0.9778
Epoch 12/15
 - 1s - loss: 0.0447 - acc: 0.9774
Epoch 13/15
 - 1s - loss: 0.0433 - acc: 0.9773
Epoch 14/15
 - 1s - loss: 0.0463 - acc: 0.9777
Epoch 15/15
 - 1s - loss: 0.0427 - acc: 0.9777
# Training time = 0:01:36.931778
# F-Score(Ordinary) = 0.557, Recall: 0.451, Precision: 0.727
# F-Score(lvc) = 0.444, Recall: 0.383, Precision: 0.53
# F-Score(ireflv) = 0.747, Recall: 0.634, Precision: 0.91
# F-Score(id) = 0.476, Recall: 0.365, Precision: 0.684
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 4, 48)        705264      input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 4, 24)        5640        input_6[0][0]                    
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 192)          0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 96)           0           embedding_6[0][0]                
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 288)          0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 24)           6936        concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24)           0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 8)            200         dropout_3[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.6780 - acc: 0.9363 - val_loss: 0.1095 - val_acc: 0.9577
Epoch 2/15
 - 5s - loss: 0.8655 - acc: 0.9616 - val_loss: 0.1096 - val_acc: 0.9589
Epoch 3/15
 - 5s - loss: 0.2945 - acc: 0.9670 - val_loss: 0.1184 - val_acc: 0.9637
Epoch 4/15
 - 5s - loss: 0.5085 - acc: 0.9698 - val_loss: 0.1108 - val_acc: 0.9637
Epoch 5/15
 - 5s - loss: 0.2108 - acc: 0.9712 - val_loss: 0.1374 - val_acc: 0.9641
Epoch 6/15
 - 5s - loss: 0.0795 - acc: 0.9721 - val_loss: 0.1314 - val_acc: 0.9664
Epoch 7/15
 - 5s - loss: 0.0534 - acc: 0.9733 - val_loss: 0.1369 - val_acc: 0.9660
Epoch 8/15
 - 5s - loss: 0.0473 - acc: 0.9738 - val_loss: 0.1365 - val_acc: 0.9653
Epoch 9/15
 - 5s - loss: 0.1663 - acc: 0.9739 - val_loss: 0.1683 - val_acc: 0.9649
Epoch 10/15
 - 5s - loss: 0.0955 - acc: 0.9746 - val_loss: 0.1764 - val_acc: 0.9648
Epoch 11/15
 - 5s - loss: 0.0437 - acc: 0.9749 - val_loss: 0.1516 - val_acc: 0.9631
Epoch 12/15
 - 5s - loss: 0.0625 - acc: 0.9751 - val_loss: 0.1786 - val_acc: 0.9625
Epoch 13/15
 - 5s - loss: 0.0421 - acc: 0.9753 - val_loss: 0.2081 - val_acc: 0.9647
Epoch 14/15
 - 5s - loss: 0.0409 - acc: 0.9755 - val_loss: 0.2083 - val_acc: 0.9644
Epoch 15/15
 - 5s - loss: 0.0393 - acc: 0.9760 - val_loss: 0.2108 - val_acc: 0.9634
Epoch 1/15
 - 1s - loss: 0.1866 - acc: 0.9588
Epoch 2/15
 - 1s - loss: 0.0942 - acc: 0.9662
Epoch 3/15
 - 1s - loss: 0.0666 - acc: 0.9711
Epoch 4/15
 - 1s - loss: 0.0599 - acc: 0.9730
Epoch 5/15
 - 1s - loss: 0.0548 - acc: 0.9740
Epoch 6/15
 - 1s - loss: 0.0485 - acc: 0.9756
Epoch 7/15
 - 1s - loss: 0.0450 - acc: 0.9764
Epoch 8/15
 - 1s - loss: 0.0441 - acc: 0.9763
Epoch 9/15
 - 1s - loss: 0.0442 - acc: 0.9766
Epoch 10/15
 - 1s - loss: 0.0434 - acc: 0.9763
Epoch 11/15
 - 1s - loss: 0.0429 - acc: 0.9773
Epoch 12/15
 - 1s - loss: 0.0438 - acc: 0.9773
Epoch 13/15
 - 1s - loss: 0.0417 - acc: 0.9779
Epoch 14/15
 - 1s - loss: 0.0419 - acc: 0.9780
Epoch 15/15
 - 1s - loss: 0.0414 - acc: 0.9785
# Training time = 0:01:37.355221
# F-Score(Ordinary) = 0.498, Recall: 0.377, Precision: 0.732
# F-Score(lvc) = 0.379, Recall: 0.281, Precision: 0.583
# F-Score(ireflv) = 0.721, Recall: 0.611, Precision: 0.877
# F-Score(id) = 0.429, Recall: 0.313, Precision: 0.679
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 4, 48)        705264      input_7[0][0]                    
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 4, 24)        5640        input_8[0][0]                    
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 192)          0           embedding_7[0][0]                
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 96)           0           embedding_8[0][0]                
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 288)          0           flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 24)           6936        concatenate_4[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24)           0           dense_7[0][0]                    
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 8)            200         dropout_4[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 0.6559 - acc: 0.9131 - val_loss: 0.1158 - val_acc: 0.9588
Epoch 2/15
 - 5s - loss: 1.0187 - acc: 0.9623 - val_loss: 0.1023 - val_acc: 0.9643
Epoch 3/15
 - 5s - loss: 0.4712 - acc: 0.9681 - val_loss: 0.1076 - val_acc: 0.9638
Epoch 4/15
 - 5s - loss: 0.6501 - acc: 0.9706 - val_loss: 0.1180 - val_acc: 0.9648
Epoch 5/15
 - 5s - loss: 0.3701 - acc: 0.9720 - val_loss: 0.1110 - val_acc: 0.9638
Epoch 6/15
 - 5s - loss: 0.2442 - acc: 0.9725 - val_loss: 0.1203 - val_acc: 0.9645
Epoch 7/15
 - 5s - loss: 0.0747 - acc: 0.9733 - val_loss: 0.1275 - val_acc: 0.9644
Epoch 8/15
 - 5s - loss: 0.0817 - acc: 0.9737 - val_loss: 0.1363 - val_acc: 0.9646
Epoch 9/15
 - 5s - loss: 0.0476 - acc: 0.9741 - val_loss: 0.1456 - val_acc: 0.9654
Epoch 10/15
 - 5s - loss: 0.0444 - acc: 0.9748 - val_loss: 0.1563 - val_acc: 0.9659
Epoch 11/15
 - 5s - loss: 0.0439 - acc: 0.9750 - val_loss: 0.1517 - val_acc: 0.9654
Epoch 12/15
 - 5s - loss: 0.0419 - acc: 0.9752 - val_loss: 0.1731 - val_acc: 0.9629
Epoch 13/15
 - 5s - loss: 0.0412 - acc: 0.9754 - val_loss: 0.1660 - val_acc: 0.9641
Epoch 14/15
 - 5s - loss: 0.0402 - acc: 0.9755 - val_loss: 0.1792 - val_acc: 0.9656
Epoch 15/15
 - 5s - loss: 0.0400 - acc: 0.9758 - val_loss: 0.1865 - val_acc: 0.9642
Epoch 1/15
 - 1s - loss: 0.1668 - acc: 0.9597
Epoch 2/15
 - 1s - loss: 0.0966 - acc: 0.9654
Epoch 3/15
 - 1s - loss: 0.0740 - acc: 0.9704
Epoch 4/15
 - 1s - loss: 0.0599 - acc: 0.9722
Epoch 5/15
 - 1s - loss: 0.0526 - acc: 0.9733
Epoch 6/15
 - 1s - loss: 0.0476 - acc: 0.9755
Epoch 7/15
 - 1s - loss: 0.0448 - acc: 0.9749
Epoch 8/15
 - 1s - loss: 0.0441 - acc: 0.9761
Epoch 9/15
 - 1s - loss: 0.0452 - acc: 0.9763
Epoch 10/15
 - 1s - loss: 0.0438 - acc: 0.9768
Epoch 11/15
 - 1s - loss: 0.0447 - acc: 0.9778
Epoch 12/15
 - 1s - loss: 0.0440 - acc: 0.9769
Epoch 13/15
 - 1s - loss: 0.0412 - acc: 0.9781
Epoch 14/15
 - 1s - loss: 0.0418 - acc: 0.9774
Epoch 15/15
 - 1s - loss: 0.0432 - acc: 0.9785
# Training time = 0:01:37.519034
# F-Score(Ordinary) = 0.422, Recall: 0.299, Precision: 0.718
# F-Score(lvc) = 0.542, Recall: 0.602, Precision: 0.492
# F-Score(ireflv) = 0.724, Recall: 0.625, Precision: 0.861
# F-Score(id) = 0.274, Recall: 0.17, Precision: 0.705
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_10 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 4, 48)        705264      input_9[0][0]                    
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 4, 24)        5640        input_10[0][0]                   
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 192)          0           embedding_9[0][0]                
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 96)           0           embedding_10[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 288)          0           flatten_9[0][0]                  
                                                                 flatten_10[0][0]                 
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 24)           6936        concatenate_5[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24)           0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 8)            200         dropout_5[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.3774 - acc: 0.9228 - val_loss: 0.1228 - val_acc: 0.9529
Epoch 2/15
 - 5s - loss: 0.5475 - acc: 0.9583 - val_loss: 0.0981 - val_acc: 0.9607
Epoch 3/15
 - 5s - loss: 0.5575 - acc: 0.9639 - val_loss: 0.0982 - val_acc: 0.9635
Epoch 4/15
 - 5s - loss: 0.3312 - acc: 0.9671 - val_loss: 0.1035 - val_acc: 0.9636
Epoch 5/15
 - 5s - loss: 0.1732 - acc: 0.9694 - val_loss: 0.1133 - val_acc: 0.9628
Epoch 6/15
 - 5s - loss: 0.0912 - acc: 0.9708 - val_loss: 0.1173 - val_acc: 0.9654
Epoch 7/15
 - 5s - loss: 0.1255 - acc: 0.9714 - val_loss: 0.1232 - val_acc: 0.9645
Epoch 8/15
 - 5s - loss: 0.0500 - acc: 0.9728 - val_loss: 0.1317 - val_acc: 0.9642
Epoch 9/15
 - 5s - loss: 0.1747 - acc: 0.9735 - val_loss: 0.1278 - val_acc: 0.9622
Epoch 10/15
 - 5s - loss: 0.0445 - acc: 0.9738 - val_loss: 0.1392 - val_acc: 0.9644
Epoch 11/15
 - 5s - loss: 0.0424 - acc: 0.9744 - val_loss: 0.1437 - val_acc: 0.9646
Epoch 12/15
 - 5s - loss: 0.0422 - acc: 0.9746 - val_loss: 0.1394 - val_acc: 0.9644
Epoch 13/15
 - 5s - loss: 0.0428 - acc: 0.9751 - val_loss: 0.1646 - val_acc: 0.9652
Epoch 14/15
 - 5s - loss: 0.0407 - acc: 0.9749 - val_loss: 0.1508 - val_acc: 0.9630
Epoch 15/15
 - 5s - loss: 0.0405 - acc: 0.9752 - val_loss: 0.1701 - val_acc: 0.9652
Epoch 1/15
 - 0s - loss: 0.1483 - acc: 0.9583
Epoch 2/15
 - 0s - loss: 0.0796 - acc: 0.9668
Epoch 3/15
 - 0s - loss: 0.0599 - acc: 0.9712
Epoch 4/15
 - 0s - loss: 0.0526 - acc: 0.9729
Epoch 5/15
 - 0s - loss: 0.0543 - acc: 0.9742
Epoch 6/15
 - 0s - loss: 0.0470 - acc: 0.9746
Epoch 7/15
 - 0s - loss: 0.0449 - acc: 0.9758
Epoch 8/15
 - 0s - loss: 0.0452 - acc: 0.9759
Epoch 9/15
 - 0s - loss: 0.0493 - acc: 0.9758
Epoch 10/15
 - 0s - loss: 0.0425 - acc: 0.9769
Epoch 11/15
 - 0s - loss: 0.0421 - acc: 0.9771
Epoch 12/15
 - 0s - loss: 0.0418 - acc: 0.9773
Epoch 13/15
 - 0s - loss: 0.0424 - acc: 0.9770
Epoch 14/15
 - 0s - loss: 0.0411 - acc: 0.9779
Epoch 15/15
 - 0s - loss: 0.0438 - acc: 0.9782
# Training time = 0:01:37.127536
# F-Score(Ordinary) = 0.629, Recall: 0.562, Precision: 0.714
# F-Score(lvc) = 0.48, Recall: 0.424, Precision: 0.553
# F-Score(ireflv) = 0.754, Recall: 0.667, Precision: 0.869
# F-Score(id) = 0.623, Recall: 0.565, Precision: 0.694
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 4, 48)        705264      input_11[0][0]                   
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 4, 24)        5640        input_12[0][0]                   
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 192)          0           embedding_11[0][0]               
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 96)           0           embedding_12[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 288)          0           flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 24)           6936        concatenate_6[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24)           0           dense_11[0][0]                   
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 8)            200         dropout_6[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.7998 - acc: 0.9227 - val_loss: 0.1115 - val_acc: 0.9578
Epoch 2/15
 - 5s - loss: 0.9473 - acc: 0.9617 - val_loss: 0.1021 - val_acc: 0.9617
Epoch 3/15
 - 5s - loss: 0.3602 - acc: 0.9672 - val_loss: 0.0983 - val_acc: 0.9629
Epoch 4/15
 - 5s - loss: 0.3849 - acc: 0.9689 - val_loss: 0.1023 - val_acc: 0.9620
Epoch 5/15
 - 5s - loss: 0.4103 - acc: 0.9706 - val_loss: 0.1100 - val_acc: 0.9633
Epoch 6/15
 - 5s - loss: 0.3970 - acc: 0.9715 - val_loss: 0.1159 - val_acc: 0.9635
Epoch 7/15
 - 5s - loss: 0.1838 - acc: 0.9730 - val_loss: 0.1157 - val_acc: 0.9639
Epoch 8/15
 - 5s - loss: 0.2489 - acc: 0.9735 - val_loss: 0.1318 - val_acc: 0.9629
Epoch 9/15
 - 5s - loss: 0.0663 - acc: 0.9741 - val_loss: 0.1385 - val_acc: 0.9638
Epoch 10/15
 - 5s - loss: 0.1699 - acc: 0.9747 - val_loss: 0.1702 - val_acc: 0.9645
Epoch 11/15
 - 5s - loss: 0.0479 - acc: 0.9747 - val_loss: 0.1376 - val_acc: 0.9640
Epoch 12/15
 - 5s - loss: 0.1848 - acc: 0.9750 - val_loss: 0.1413 - val_acc: 0.9648
Epoch 13/15
 - 5s - loss: 0.0592 - acc: 0.9752 - val_loss: 0.1590 - val_acc: 0.9657
Epoch 14/15
 - 5s - loss: 0.0461 - acc: 0.9757 - val_loss: 0.1399 - val_acc: 0.9646
Epoch 15/15
 - 5s - loss: 0.0450 - acc: 0.9759 - val_loss: 0.1518 - val_acc: 0.9647
Epoch 1/15
 - 1s - loss: 0.1624 - acc: 0.9607
Epoch 2/15
 - 1s - loss: 0.0913 - acc: 0.9645
Epoch 3/15
 - 1s - loss: 0.0670 - acc: 0.9707
Epoch 4/15
 - 1s - loss: 0.0539 - acc: 0.9720
Epoch 5/15
 - 1s - loss: 0.0494 - acc: 0.9746
Epoch 6/15
 - 1s - loss: 0.0488 - acc: 0.9749
Epoch 7/15
 - 1s - loss: 0.0473 - acc: 0.9756
Epoch 8/15
 - 1s - loss: 0.0451 - acc: 0.9762
Epoch 9/15
 - 1s - loss: 0.0452 - acc: 0.9771
Epoch 10/15
 - 1s - loss: 0.0442 - acc: 0.9770
Epoch 11/15
 - 1s - loss: 0.0438 - acc: 0.9773
Epoch 12/15
 - 1s - loss: 0.0429 - acc: 0.9780
Epoch 13/15
 - 1s - loss: 0.0444 - acc: 0.9776
Epoch 14/15
 - 1s - loss: 0.0437 - acc: 0.9781
Epoch 15/15
 - 1s - loss: 0.0441 - acc: 0.9774
# Training time = 0:01:37.513636
# F-Score(Ordinary) = 0.507, Recall: 0.394, Precision: 0.711
# F-Score(lvc) = 0.306, Recall: 0.211, Precision: 0.561
# F-Score(ireflv) = 0.673, Recall: 0.54, Precision: 0.893
# F-Score(id) = 0.568, Recall: 0.5, Precision: 0.658
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_14 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 4, 48)        705264      input_13[0][0]                   
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 4, 24)        5640        input_14[0][0]                   
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 192)          0           embedding_13[0][0]               
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 96)           0           embedding_14[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 288)          0           flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 24)           6936        concatenate_7[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24)           0           dense_13[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 8)            200         dropout_7[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.6369 - acc: 0.9324 - val_loss: 0.1120 - val_acc: 0.9562
Epoch 2/15
 - 5s - loss: 1.2067 - acc: 0.9630 - val_loss: 0.1014 - val_acc: 0.9602
Epoch 3/15
 - 5s - loss: 0.6781 - acc: 0.9667 - val_loss: 0.1025 - val_acc: 0.9628
Epoch 4/15
 - 5s - loss: 0.4203 - acc: 0.9690 - val_loss: 0.1129 - val_acc: 0.9642
Epoch 5/15
 - 5s - loss: 0.3436 - acc: 0.9708 - val_loss: 0.1088 - val_acc: 0.9655
Epoch 6/15
 - 5s - loss: 0.2790 - acc: 0.9720 - val_loss: 0.1154 - val_acc: 0.9642
Epoch 7/15
 - 5s - loss: 0.3874 - acc: 0.9727 - val_loss: 0.1148 - val_acc: 0.9638
Epoch 8/15
 - 5s - loss: 0.2212 - acc: 0.9733 - val_loss: 0.1387 - val_acc: 0.9640
Epoch 9/15
 - 5s - loss: 0.1128 - acc: 0.9736 - val_loss: 0.1354 - val_acc: 0.9642
Epoch 10/15
 - 5s - loss: 0.0545 - acc: 0.9744 - val_loss: 0.1410 - val_acc: 0.9657
Epoch 11/15
 - 5s - loss: 0.0454 - acc: 0.9744 - val_loss: 0.1324 - val_acc: 0.9647
Epoch 12/15
 - 5s - loss: 0.0769 - acc: 0.9750 - val_loss: 0.1834 - val_acc: 0.9645
Epoch 13/15
 - 5s - loss: 0.0444 - acc: 0.9749 - val_loss: 0.1495 - val_acc: 0.9651
Epoch 14/15
 - 5s - loss: 0.0458 - acc: 0.9749 - val_loss: 0.1490 - val_acc: 0.9651
Epoch 15/15
 - 5s - loss: 0.1498 - acc: 0.9749 - val_loss: 0.1861 - val_acc: 0.9638
Epoch 1/15
 - 0s - loss: 0.1792 - acc: 0.9591
Epoch 2/15
 - 0s - loss: 0.0862 - acc: 0.9671
Epoch 3/15
 - 0s - loss: 0.0788 - acc: 0.9693
Epoch 4/15
 - 0s - loss: 0.0634 - acc: 0.9720
Epoch 5/15
 - 0s - loss: 0.0531 - acc: 0.9722
Epoch 6/15
 - 0s - loss: 0.0522 - acc: 0.9741
Epoch 7/15
 - 0s - loss: 0.0474 - acc: 0.9754
Epoch 8/15
 - 0s - loss: 0.0457 - acc: 0.9759
Epoch 9/15
 - 0s - loss: 0.0463 - acc: 0.9764
Epoch 10/15
 - 0s - loss: 0.0473 - acc: 0.9765
Epoch 11/15
 - 0s - loss: 0.0440 - acc: 0.9766
Epoch 12/15
 - 0s - loss: 0.0461 - acc: 0.9761
Epoch 13/15
 - 0s - loss: 0.0434 - acc: 0.9774
Epoch 14/15
 - 0s - loss: 0.0437 - acc: 0.9773
Epoch 15/15
 - 0s - loss: 0.0435 - acc: 0.9777
# Training time = 0:01:37.049930
# F-Score(Ordinary) = 0.488, Recall: 0.368, Precision: 0.727
# F-Score(lvc) = 0.553, Recall: 0.631, Precision: 0.492
# F-Score(ireflv) = 0.718, Recall: 0.603, Precision: 0.885
# F-Score(id) = 0.35, Recall: 0.231, Precision: 0.72
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_15 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_16 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_15 (Embedding)        (None, 4, 48)        705264      input_15[0][0]                   
__________________________________________________________________________________________________
embedding_16 (Embedding)        (None, 4, 24)        5640        input_16[0][0]                   
__________________________________________________________________________________________________
flatten_15 (Flatten)            (None, 192)          0           embedding_15[0][0]               
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 96)           0           embedding_16[0][0]               
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 288)          0           flatten_15[0][0]                 
                                                                 flatten_16[0][0]                 
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 24)           6936        concatenate_8[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24)           0           dense_15[0][0]                   
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 8)            200         dropout_8[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.6525 - acc: 0.9299 - val_loss: 0.1095 - val_acc: 0.9582
Epoch 2/15
 - 5s - loss: 0.8814 - acc: 0.9623 - val_loss: 0.1052 - val_acc: 0.9617
Epoch 3/15
 - 5s - loss: 0.8121 - acc: 0.9676 - val_loss: 0.1008 - val_acc: 0.9625
Epoch 4/15
 - 5s - loss: 0.4143 - acc: 0.9700 - val_loss: 0.1049 - val_acc: 0.9623
Epoch 5/15
 - 5s - loss: 0.3603 - acc: 0.9717 - val_loss: 0.1083 - val_acc: 0.9647
Epoch 6/15
 - 5s - loss: 0.3541 - acc: 0.9730 - val_loss: 0.1083 - val_acc: 0.9645
Epoch 7/15
 - 5s - loss: 0.3577 - acc: 0.9733 - val_loss: 0.1241 - val_acc: 0.9646
Epoch 8/15
 - 5s - loss: 0.2826 - acc: 0.9738 - val_loss: 0.1381 - val_acc: 0.9662
Epoch 9/15
 - 5s - loss: 0.3912 - acc: 0.9740 - val_loss: 0.1425 - val_acc: 0.9645
Epoch 10/15
 - 5s - loss: 0.1856 - acc: 0.9747 - val_loss: 0.1475 - val_acc: 0.9652
Epoch 11/15
 - 5s - loss: 0.1984 - acc: 0.9752 - val_loss: 0.1461 - val_acc: 0.9647
Epoch 12/15
 - 5s - loss: 0.0883 - acc: 0.9748 - val_loss: 0.1525 - val_acc: 0.9645
Epoch 13/15
 - 5s - loss: 0.1035 - acc: 0.9755 - val_loss: 0.1502 - val_acc: 0.9659
Epoch 14/15
 - 5s - loss: 0.0450 - acc: 0.9756 - val_loss: 0.1541 - val_acc: 0.9653
Epoch 15/15
 - 5s - loss: 0.1626 - acc: 0.9762 - val_loss: 0.1887 - val_acc: 0.9659
Epoch 1/15
 - 0s - loss: 0.2012 - acc: 0.9604
Epoch 2/15
 - 1s - loss: 0.1038 - acc: 0.9678
Epoch 3/15
 - 0s - loss: 0.0781 - acc: 0.9709
Epoch 4/15
 - 1s - loss: 0.0638 - acc: 0.9712
Epoch 5/15
 - 0s - loss: 0.0490 - acc: 0.9739
Epoch 6/15
 - 1s - loss: 0.0474 - acc: 0.9743
Epoch 7/15
 - 0s - loss: 0.0481 - acc: 0.9755
Epoch 8/15
 - 0s - loss: 0.0440 - acc: 0.9763
Epoch 9/15
 - 0s - loss: 0.0461 - acc: 0.9764
Epoch 10/15
 - 1s - loss: 0.0439 - acc: 0.9771
Epoch 11/15
 - 0s - loss: 0.0429 - acc: 0.9773
Epoch 12/15
 - 1s - loss: 0.0439 - acc: 0.9770
Epoch 13/15
 - 1s - loss: 0.0427 - acc: 0.9779
Epoch 14/15
 - 1s - loss: 0.0415 - acc: 0.9780
Epoch 15/15
 - 1s - loss: 0.0419 - acc: 0.9777
# Training time = 0:01:37.335204
# F-Score(Ordinary) = 0.477, Recall: 0.354, Precision: 0.729
# F-Score(lvc) = 0.356, Recall: 0.255, Precision: 0.591
# F-Score(ireflv) = 0.734, Recall: 0.635, Precision: 0.869
# F-Score(id) = 0.406, Recall: 0.291, Precision: 0.674
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_17 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_18 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_17 (Embedding)        (None, 4, 48)        705264      input_17[0][0]                   
__________________________________________________________________________________________________
embedding_18 (Embedding)        (None, 4, 24)        5640        input_18[0][0]                   
__________________________________________________________________________________________________
flatten_17 (Flatten)            (None, 192)          0           embedding_17[0][0]               
__________________________________________________________________________________________________
flatten_18 (Flatten)            (None, 96)           0           embedding_18[0][0]               
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 288)          0           flatten_17[0][0]                 
                                                                 flatten_18[0][0]                 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 24)           6936        concatenate_9[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24)           0           dense_17[0][0]                   
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 8)            200         dropout_9[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.3992 - acc: 0.9221 - val_loss: 0.1178 - val_acc: 0.9569
Epoch 2/15
 - 5s - loss: 0.8941 - acc: 0.9635 - val_loss: 0.1052 - val_acc: 0.9612
Epoch 3/15
 - 5s - loss: 0.7849 - acc: 0.9681 - val_loss: 0.1103 - val_acc: 0.9632
Epoch 4/15
 - 5s - loss: 0.4138 - acc: 0.9700 - val_loss: 0.1142 - val_acc: 0.9640
Epoch 5/15
 - 5s - loss: 0.2710 - acc: 0.9705 - val_loss: 0.1268 - val_acc: 0.9644
Epoch 6/15
 - 5s - loss: 0.3243 - acc: 0.9714 - val_loss: 0.1180 - val_acc: 0.9622
Epoch 7/15
 - 5s - loss: 0.2895 - acc: 0.9727 - val_loss: 0.1369 - val_acc: 0.9643
Epoch 8/15
 - 5s - loss: 0.3424 - acc: 0.9734 - val_loss: 0.1363 - val_acc: 0.9629
Epoch 9/15
 - 5s - loss: 0.1388 - acc: 0.9737 - val_loss: 0.1549 - val_acc: 0.9639
Epoch 10/15
 - 5s - loss: 0.0971 - acc: 0.9741 - val_loss: 0.1441 - val_acc: 0.9640
Epoch 11/15
 - 5s - loss: 0.0615 - acc: 0.9747 - val_loss: 0.1585 - val_acc: 0.9649
Epoch 12/15
 - 5s - loss: 0.3310 - acc: 0.9745 - val_loss: 0.1587 - val_acc: 0.9641
Epoch 13/15
 - 5s - loss: 0.0488 - acc: 0.9749 - val_loss: 0.1766 - val_acc: 0.9641
Epoch 14/15
 - 5s - loss: 0.1224 - acc: 0.9751 - val_loss: 0.1631 - val_acc: 0.9643
Epoch 15/15
 - 5s - loss: 0.0429 - acc: 0.9755 - val_loss: 0.1698 - val_acc: 0.9644
Epoch 1/15
 - 1s - loss: 0.1828 - acc: 0.9576
Epoch 2/15
 - 1s - loss: 0.0790 - acc: 0.9651
Epoch 3/15
 - 1s - loss: 0.0687 - acc: 0.9691
Epoch 4/15
 - 1s - loss: 0.0628 - acc: 0.9721
Epoch 5/15
 - 1s - loss: 0.0542 - acc: 0.9733
Epoch 6/15
 - 1s - loss: 0.0512 - acc: 0.9741
Epoch 7/15
 - 1s - loss: 0.0514 - acc: 0.9752
Epoch 8/15
 - 1s - loss: 0.0465 - acc: 0.9761
Epoch 9/15
 - 1s - loss: 0.0466 - acc: 0.9762
Epoch 10/15
 - 1s - loss: 0.0459 - acc: 0.9768
Epoch 11/15
 - 1s - loss: 0.0461 - acc: 0.9763
Epoch 12/15
 - 1s - loss: 0.0458 - acc: 0.9778
Epoch 13/15
 - 1s - loss: 0.0438 - acc: 0.9774
Epoch 14/15
 - 1s - loss: 0.0431 - acc: 0.9776
Epoch 15/15
 - 1s - loss: 0.0472 - acc: 0.9771
# Training time = 0:01:37.901716
# F-Score(Ordinary) = 0.548, Recall: 0.441, Precision: 0.725
# F-Score(lvc) = 0.522, Recall: 0.515, Precision: 0.53
# F-Score(ireflv) = 0.675, Recall: 0.539, Precision: 0.902
# F-Score(id) = 0.463, Recall: 0.344, Precision: 0.705
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_19 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_20 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_19 (Embedding)        (None, 4, 48)        705264      input_19[0][0]                   
__________________________________________________________________________________________________
embedding_20 (Embedding)        (None, 4, 24)        5640        input_20[0][0]                   
__________________________________________________________________________________________________
flatten_19 (Flatten)            (None, 192)          0           embedding_19[0][0]               
__________________________________________________________________________________________________
flatten_20 (Flatten)            (None, 96)           0           embedding_20[0][0]               
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 288)          0           flatten_19[0][0]                 
                                                                 flatten_20[0][0]                 
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 24)           6936        concatenate_10[0][0]             
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24)           0           dense_19[0][0]                   
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 8)            200         dropout_10[0][0]                 
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/15
 - 5s - loss: 1.2900 - acc: 0.9156 - val_loss: 0.1124 - val_acc: 0.9589
Epoch 2/15
 - 5s - loss: 1.1785 - acc: 0.9624 - val_loss: 0.1048 - val_acc: 0.9620
Epoch 3/15
 - 5s - loss: 0.6144 - acc: 0.9658 - val_loss: 0.1064 - val_acc: 0.9621
Epoch 4/15
 - 5s - loss: 0.3032 - acc: 0.9686 - val_loss: 0.1117 - val_acc: 0.9622
Epoch 5/15
 - 5s - loss: 0.5605 - acc: 0.9705 - val_loss: 0.1208 - val_acc: 0.9634
Epoch 6/15
 - 5s - loss: 0.3775 - acc: 0.9716 - val_loss: 0.1246 - val_acc: 0.9642
Epoch 7/15
 - 5s - loss: 0.1164 - acc: 0.9722 - val_loss: 0.1372 - val_acc: 0.9638
Epoch 8/15
 - 5s - loss: 0.0802 - acc: 0.9735 - val_loss: 0.1430 - val_acc: 0.9645
Epoch 9/15
 - 5s - loss: 0.0504 - acc: 0.9735 - val_loss: 0.1445 - val_acc: 0.9644
Epoch 10/15
 - 5s - loss: 0.0475 - acc: 0.9740 - val_loss: 0.1590 - val_acc: 0.9641
Epoch 11/15
 - 5s - loss: 0.0465 - acc: 0.9745 - val_loss: 0.1891 - val_acc: 0.9654
Epoch 12/15
 - 5s - loss: 0.0451 - acc: 0.9747 - val_loss: 0.1743 - val_acc: 0.9645
Epoch 13/15
 - 5s - loss: 0.0440 - acc: 0.9751 - val_loss: 0.1682 - val_acc: 0.9648
Epoch 14/15
 - 5s - loss: 0.0519 - acc: 0.9751 - val_loss: 0.1837 - val_acc: 0.9646
Epoch 15/15
 - 5s - loss: 0.0515 - acc: 0.9756 - val_loss: 0.1980 - val_acc: 0.9649
Epoch 1/15
 - 1s - loss: 0.1949 - acc: 0.9583
Epoch 2/15
 - 1s - loss: 0.1004 - acc: 0.9657
Epoch 3/15
 - 1s - loss: 0.0619 - acc: 0.9685
Epoch 4/15
 - 1s - loss: 0.0557 - acc: 0.9729
Epoch 5/15
 - 1s - loss: 0.0522 - acc: 0.9733
Epoch 6/15
 - 1s - loss: 0.0521 - acc: 0.9745
Epoch 7/15
 - 1s - loss: 0.0467 - acc: 0.9751
Epoch 8/15
 - 1s - loss: 0.0445 - acc: 0.9768
Epoch 9/15
 - 1s - loss: 0.0473 - acc: 0.9762
Epoch 10/15
 - 1s - loss: 0.0442 - acc: 0.9766
Epoch 11/15
 - 1s - loss: 0.0442 - acc: 0.9771
Epoch 12/15
 - 1s - loss: 0.0464 - acc: 0.9773
Epoch 13/15
 - 1s - loss: 0.0439 - acc: 0.9777
Epoch 14/15
 - 1s - loss: 0.0416 - acc: 0.9779
Epoch 15/15
 - 1s - loss: 0.0415 - acc: 0.9782
# Training time = 0:01:37.663130
# F-Score(Ordinary) = 0.495, Recall: 0.379, Precision: 0.714
# F-Score(lvc) = 0.278, Recall: 0.184, Precision: 0.576
# F-Score(ireflv) = 0.719, Recall: 0.613, Precision: 0.869
# F-Score(id) = 0.567, Recall: 0.498, Precision: 0.658
********************
