INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 4, 48)        705264      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 4, 24)        5640        input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 192)          0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 96)           0           embedding_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 288)          0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 24)           6936        concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24)           0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 8)            200         dropout_1[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/25
 - 8s - loss: 1.8132 - acc: 0.9390 - val_loss: 0.1499 - val_acc: 0.9576
Epoch 2/25
 - 8s - loss: 0.5649 - acc: 0.9629 - val_loss: 0.1002 - val_acc: 0.9616
Epoch 3/25
 - 7s - loss: 0.4286 - acc: 0.9678 - val_loss: 0.1066 - val_acc: 0.9609
Epoch 4/25
 - 7s - loss: 0.2935 - acc: 0.9693 - val_loss: 0.1110 - val_acc: 0.9635
Epoch 5/25
 - 8s - loss: 0.3571 - acc: 0.9715 - val_loss: 0.1094 - val_acc: 0.9648
Epoch 6/25
 - 8s - loss: 0.2660 - acc: 0.9727 - val_loss: 0.1210 - val_acc: 0.9642
Epoch 7/25
 - 8s - loss: 0.3353 - acc: 0.9732 - val_loss: 0.1256 - val_acc: 0.9650
Epoch 8/25
 - 8s - loss: 0.1605 - acc: 0.9740 - val_loss: 0.1362 - val_acc: 0.9624
Epoch 9/25
 - 8s - loss: 0.3605 - acc: 0.9744 - val_loss: 0.1369 - val_acc: 0.9652
Epoch 10/25
 - 8s - loss: 0.1830 - acc: 0.9748 - val_loss: 0.1471 - val_acc: 0.9658
Epoch 11/25
 - 8s - loss: 0.0994 - acc: 0.9751 - val_loss: 0.1327 - val_acc: 0.9640
Epoch 12/25
 - 7s - loss: 0.2816 - acc: 0.9755 - val_loss: 0.1402 - val_acc: 0.9656
Epoch 13/25
 - 7s - loss: 0.0734 - acc: 0.9758 - val_loss: 0.1511 - val_acc: 0.9636
Epoch 14/25
 - 8s - loss: 0.0503 - acc: 0.9761 - val_loss: 0.1426 - val_acc: 0.9649
Epoch 15/25
 - 8s - loss: 0.0438 - acc: 0.9758 - val_loss: 0.1566 - val_acc: 0.9663
Epoch 16/25
 - 8s - loss: 0.3882 - acc: 0.9760 - val_loss: 0.1503 - val_acc: 0.9661
Epoch 17/25
 - 8s - loss: 0.0406 - acc: 0.9762 - val_loss: 0.1588 - val_acc: 0.9658
Epoch 18/25
 - 8s - loss: 0.0403 - acc: 0.9762 - val_loss: 0.1811 - val_acc: 0.9652
Epoch 19/25
 - 7s - loss: 0.0401 - acc: 0.9767 - val_loss: 0.1565 - val_acc: 0.9665
Epoch 20/25
 - 8s - loss: 0.0411 - acc: 0.9763 - val_loss: 0.1587 - val_acc: 0.9648
Epoch 21/25
 - 8s - loss: 0.0395 - acc: 0.9768 - val_loss: 0.1443 - val_acc: 0.9661
Epoch 22/25
 - 8s - loss: 0.0380 - acc: 0.9770 - val_loss: 0.1606 - val_acc: 0.9660
Epoch 23/25
 - 8s - loss: 0.0381 - acc: 0.9768 - val_loss: 0.1775 - val_acc: 0.9652
Epoch 24/25
 - 8s - loss: 0.0394 - acc: 0.9769 - val_loss: 0.1665 - val_acc: 0.9655
Epoch 25/25
 - 8s - loss: 0.0385 - acc: 0.9770 - val_loss: 0.1723 - val_acc: 0.9657
Epoch 1/25
 - 1s - loss: 0.1661 - acc: 0.9612
Epoch 2/25
 - 1s - loss: 0.1078 - acc: 0.9652
Epoch 3/25
 - 1s - loss: 0.0797 - acc: 0.9697
Epoch 4/25
 - 1s - loss: 0.0751 - acc: 0.9704
Epoch 5/25
 - 1s - loss: 0.0721 - acc: 0.9727
Epoch 6/25
 - 1s - loss: 0.0676 - acc: 0.9741
Epoch 7/25
 - 1s - loss: 0.0653 - acc: 0.9740
Epoch 8/25
 - 1s - loss: 0.0629 - acc: 0.9751
Epoch 9/25
 - 1s - loss: 0.0631 - acc: 0.9744
Epoch 10/25
 - 1s - loss: 0.0565 - acc: 0.9755
Epoch 11/25
 - 1s - loss: 0.0567 - acc: 0.9752
Epoch 12/25
 - 1s - loss: 0.0525 - acc: 0.9765
Epoch 13/25
 - 1s - loss: 0.0485 - acc: 0.9767
Epoch 14/25
 - 1s - loss: 0.0497 - acc: 0.9770
Epoch 15/25
 - 1s - loss: 0.0480 - acc: 0.9772
Epoch 16/25
 - 1s - loss: 0.0484 - acc: 0.9770
Epoch 17/25
 - 1s - loss: 0.0440 - acc: 0.9777
Epoch 18/25
 - 1s - loss: 0.0444 - acc: 0.9780
Epoch 19/25
 - 1s - loss: 0.0460 - acc: 0.9777
Epoch 20/25
 - 1s - loss: 0.0495 - acc: 0.9771
Epoch 21/25
 - 1s - loss: 0.0434 - acc: 0.9783
Epoch 22/25
 - 1s - loss: 0.0418 - acc: 0.9786
Epoch 23/25
 - 1s - loss: 0.0618 - acc: 0.9779
Epoch 24/25
 - 1s - loss: 0.0433 - acc: 0.9780
Epoch 25/25
 - 1s - loss: 0.0427 - acc: 0.9780
# Training time = 0:04:13.820289
# F-Score(Ordinary) = 0.46, Recall: 0.333, Precision: 0.743
# F-Score(lvc) = 0.412, Recall: 0.302, Precision: 0.644
# F-Score(ireflv) = 0.775, Recall: 0.679, Precision: 0.902
# F-Score(id) = 0.337, Recall: 0.227, Precision: 0.653
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 4, 48)        705264      input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 4, 24)        5640        input_4[0][0]                    
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 192)          0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 96)           0           embedding_4[0][0]                
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 288)          0           flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 24)           6936        concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24)           0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 8)            200         dropout_2[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/25
 - 8s - loss: 1.1468 - acc: 0.9295 - val_loss: 0.1156 - val_acc: 0.9590
Epoch 2/25
 - 8s - loss: 1.6538 - acc: 0.9629 - val_loss: 0.0979 - val_acc: 0.9633
Epoch 3/25
 - 8s - loss: 0.4163 - acc: 0.9669 - val_loss: 0.1025 - val_acc: 0.9625
Epoch 4/25
 - 8s - loss: 0.4994 - acc: 0.9693 - val_loss: 0.1044 - val_acc: 0.9638
Epoch 5/25
 - 8s - loss: 0.2614 - acc: 0.9716 - val_loss: 0.1144 - val_acc: 0.9646
Epoch 6/25
 - 8s - loss: 0.1902 - acc: 0.9729 - val_loss: 0.1188 - val_acc: 0.9637
Epoch 7/25
 - 8s - loss: 0.1316 - acc: 0.9738 - val_loss: 0.1219 - val_acc: 0.9632
Epoch 8/25
 - 8s - loss: 0.0755 - acc: 0.9745 - val_loss: 0.1298 - val_acc: 0.9647
Epoch 9/25
 - 8s - loss: 0.0525 - acc: 0.9746 - val_loss: 0.1356 - val_acc: 0.9641
Epoch 10/25
 - 8s - loss: 0.0458 - acc: 0.9748 - val_loss: 0.1585 - val_acc: 0.9630
Epoch 11/25
 - 8s - loss: 0.0469 - acc: 0.9748 - val_loss: 0.1431 - val_acc: 0.9636
Epoch 12/25
 - 8s - loss: 0.0460 - acc: 0.9754 - val_loss: 0.1508 - val_acc: 0.9647
Epoch 13/25
 - 8s - loss: 0.0434 - acc: 0.9752 - val_loss: 0.1435 - val_acc: 0.9636
Epoch 14/25
 - 8s - loss: 0.0426 - acc: 0.9754 - val_loss: 0.1655 - val_acc: 0.9654
Epoch 15/25
 - 8s - loss: 0.0409 - acc: 0.9761 - val_loss: 0.1635 - val_acc: 0.9647
Epoch 16/25
 - 8s - loss: 0.3335 - acc: 0.9758 - val_loss: 0.1605 - val_acc: 0.9647
Epoch 17/25
 - 8s - loss: 0.0388 - acc: 0.9761 - val_loss: 0.1730 - val_acc: 0.9638
Epoch 18/25
 - 8s - loss: 0.0382 - acc: 0.9764 - val_loss: 0.1870 - val_acc: 0.9648
Epoch 19/25
 - 8s - loss: 0.0391 - acc: 0.9764 - val_loss: 0.1657 - val_acc: 0.9641
Epoch 20/25
 - 8s - loss: 0.0400 - acc: 0.9766 - val_loss: 0.1896 - val_acc: 0.9641
Epoch 21/25
 - 8s - loss: 0.0380 - acc: 0.9766 - val_loss: 0.1850 - val_acc: 0.9638
Epoch 22/25
 - 8s - loss: 0.1626 - acc: 0.9766 - val_loss: 0.1939 - val_acc: 0.9640
Epoch 23/25
 - 8s - loss: 0.0380 - acc: 0.9770 - val_loss: 0.1905 - val_acc: 0.9633
Epoch 24/25
 - 8s - loss: 0.3344 - acc: 0.9768 - val_loss: 0.1917 - val_acc: 0.9635
Epoch 25/25
 - 8s - loss: 0.0379 - acc: 0.9771 - val_loss: 0.2073 - val_acc: 0.9646
Epoch 1/25
 - 1s - loss: 0.1801 - acc: 0.9591
Epoch 2/25
 - 1s - loss: 0.0929 - acc: 0.9638
Epoch 3/25
 - 1s - loss: 0.0704 - acc: 0.9696
Epoch 4/25
 - 1s - loss: 0.0631 - acc: 0.9710
Epoch 5/25
 - 1s - loss: 0.0567 - acc: 0.9727
Epoch 6/25
 - 1s - loss: 0.0524 - acc: 0.9740
Epoch 7/25
 - 1s - loss: 0.0534 - acc: 0.9744
Epoch 8/25
 - 1s - loss: 0.0482 - acc: 0.9755
Epoch 9/25
 - 1s - loss: 0.0452 - acc: 0.9760
Epoch 10/25
 - 1s - loss: 0.0479 - acc: 0.9767
Epoch 11/25
 - 1s - loss: 0.0433 - acc: 0.9768
Epoch 12/25
 - 1s - loss: 0.0463 - acc: 0.9768
Epoch 13/25
 - 1s - loss: 0.0440 - acc: 0.9771
Epoch 14/25
 - 1s - loss: 0.0450 - acc: 0.9774
Epoch 15/25
 - 1s - loss: 0.0424 - acc: 0.9774
Epoch 16/25
 - 1s - loss: 0.0424 - acc: 0.9778
Epoch 17/25
 - 1s - loss: 0.0440 - acc: 0.9781
Epoch 18/25
 - 1s - loss: 0.0429 - acc: 0.9783
Epoch 19/25
 - 1s - loss: 0.0431 - acc: 0.9781
Epoch 20/25
 - 1s - loss: 0.0450 - acc: 0.9779
Epoch 21/25
 - 1s - loss: 0.0425 - acc: 0.9783
Epoch 22/25
 - 1s - loss: 0.0430 - acc: 0.9784
Epoch 23/25
 - 1s - loss: 0.0479 - acc: 0.9784
Epoch 24/25
 - 1s - loss: 0.0416 - acc: 0.9781
Epoch 25/25
 - 1s - loss: 0.0438 - acc: 0.9782
# Training time = 0:04:01.177681
# F-Score(Ordinary) = 0.471, Recall: 0.345, Precision: 0.74
# F-Score(lvc) = 0.374, Recall: 0.277, Precision: 0.576
# F-Score(ireflv) = 0.704, Recall: 0.588, Precision: 0.877
# F-Score(id) = 0.39, Recall: 0.27, Precision: 0.705
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 4, 48)        705264      input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 4, 24)        5640        input_6[0][0]                    
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 192)          0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 96)           0           embedding_6[0][0]                
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 288)          0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 24)           6936        concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24)           0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 8)            200         dropout_3[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/25
 - 8s - loss: 1.6780 - acc: 0.9363 - val_loss: 0.1095 - val_acc: 0.9577
Epoch 2/25
 - 8s - loss: 0.8655 - acc: 0.9616 - val_loss: 0.1096 - val_acc: 0.9589
Epoch 3/25
 - 8s - loss: 0.2945 - acc: 0.9670 - val_loss: 0.1184 - val_acc: 0.9637
Epoch 4/25
 - 8s - loss: 0.5085 - acc: 0.9698 - val_loss: 0.1108 - val_acc: 0.9637
Epoch 5/25
 - 8s - loss: 0.2108 - acc: 0.9712 - val_loss: 0.1374 - val_acc: 0.9641
Epoch 6/25
 - 8s - loss: 0.0795 - acc: 0.9721 - val_loss: 0.1314 - val_acc: 0.9664
Epoch 7/25
 - 8s - loss: 0.0534 - acc: 0.9733 - val_loss: 0.1369 - val_acc: 0.9660
Epoch 8/25
 - 8s - loss: 0.0473 - acc: 0.9738 - val_loss: 0.1365 - val_acc: 0.9653
Epoch 9/25
 - 8s - loss: 0.1663 - acc: 0.9740 - val_loss: 0.1687 - val_acc: 0.9651
Epoch 10/25
 - 8s - loss: 0.0976 - acc: 0.9745 - val_loss: 0.1801 - val_acc: 0.9641
Epoch 11/25
 - 8s - loss: 0.0437 - acc: 0.9749 - val_loss: 0.1665 - val_acc: 0.9628
Epoch 12/25
 - 8s - loss: 0.0632 - acc: 0.9752 - val_loss: 0.1773 - val_acc: 0.9639
Epoch 13/25
 - 8s - loss: 0.0408 - acc: 0.9756 - val_loss: 0.2075 - val_acc: 0.9642
Epoch 14/25
 - 8s - loss: 0.0413 - acc: 0.9757 - val_loss: 0.1831 - val_acc: 0.9633
Epoch 15/25
 - 8s - loss: 0.0400 - acc: 0.9754 - val_loss: 0.2007 - val_acc: 0.9635
Epoch 16/25
 - 8s - loss: 0.0383 - acc: 0.9761 - val_loss: 0.2440 - val_acc: 0.9652
Epoch 17/25
 - 8s - loss: 0.0520 - acc: 0.9762 - val_loss: 0.1867 - val_acc: 0.9654
Epoch 18/25
 - 8s - loss: 0.0381 - acc: 0.9762 - val_loss: 0.2410 - val_acc: 0.9642
Epoch 19/25
 - 8s - loss: 0.0428 - acc: 0.9765 - val_loss: 0.2243 - val_acc: 0.9642
Epoch 20/25
 - 8s - loss: 0.5790 - acc: 0.9765 - val_loss: 0.2125 - val_acc: 0.9638
Epoch 21/25
 - 8s - loss: 0.0698 - acc: 0.9767 - val_loss: 0.2088 - val_acc: 0.9644
Epoch 22/25
 - 8s - loss: 0.0379 - acc: 0.9767 - val_loss: 0.2152 - val_acc: 0.9646
Epoch 23/25
 - 8s - loss: 0.0369 - acc: 0.9769 - val_loss: 0.2191 - val_acc: 0.9648
Epoch 24/25
 - 8s - loss: 0.0372 - acc: 0.9773 - val_loss: 0.2333 - val_acc: 0.9653
Epoch 25/25
 - 8s - loss: 0.0366 - acc: 0.9772 - val_loss: 0.2465 - val_acc: 0.9641
Epoch 1/25
 - 1s - loss: 0.2205 - acc: 0.9583
Epoch 2/25
 - 1s - loss: 0.1168 - acc: 0.9650
Epoch 3/25
 - 1s - loss: 0.0802 - acc: 0.9687
Epoch 4/25
 - 1s - loss: 0.0634 - acc: 0.9709
Epoch 5/25
 - 1s - loss: 0.0535 - acc: 0.9733
Epoch 6/25
 - 1s - loss: 0.0531 - acc: 0.9741
Epoch 7/25
 - 1s - loss: 0.0471 - acc: 0.9753
Epoch 8/25
 - 1s - loss: 0.0460 - acc: 0.9760
Epoch 9/25
 - 1s - loss: 0.0446 - acc: 0.9761
Epoch 10/25
 - 1s - loss: 0.0441 - acc: 0.9762
Epoch 11/25
 - 1s - loss: 0.0440 - acc: 0.9765
Epoch 12/25
 - 1s - loss: 0.0452 - acc: 0.9766
Epoch 13/25
 - 1s - loss: 0.0440 - acc: 0.9768
Epoch 14/25
 - 1s - loss: 0.0424 - acc: 0.9774
Epoch 15/25
 - 1s - loss: 0.0422 - acc: 0.9775
Epoch 16/25
 - 1s - loss: 0.0417 - acc: 0.9778
Epoch 17/25
 - 1s - loss: 0.0429 - acc: 0.9781
Epoch 18/25
 - 1s - loss: 0.0416 - acc: 0.9779
Epoch 19/25
 - 1s - loss: 0.0466 - acc: 0.9777
Epoch 20/25
 - 1s - loss: 0.0443 - acc: 0.9780
Epoch 21/25
 - 1s - loss: 0.0439 - acc: 0.9781
Epoch 22/25
 - 1s - loss: 0.0419 - acc: 0.9784
Epoch 23/25
 - 1s - loss: 0.0432 - acc: 0.9783
Epoch 24/25
 - 1s - loss: 0.0406 - acc: 0.9781
Epoch 25/25
 - 1s - loss: 0.0404 - acc: 0.9790
# Training time = 0:04:01.643974
# F-Score(Ordinary) = 0.519, Recall: 0.424, Precision: 0.669
# F-Score(lvc) = 0.39, Recall: 0.323, Precision: 0.492
# F-Score(ireflv) = 0.747, Recall: 0.66, Precision: 0.861
# F-Score(id) = 0.461, Recall: 0.359, Precision: 0.642
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 4, 48)        705264      input_7[0][0]                    
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 4, 24)        5640        input_8[0][0]                    
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 192)          0           embedding_7[0][0]                
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 96)           0           embedding_8[0][0]                
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 288)          0           flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 24)           6936        concatenate_4[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24)           0           dense_7[0][0]                    
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 8)            200         dropout_4[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/25
 - 8s - loss: 0.6559 - acc: 0.9131 - val_loss: 0.1158 - val_acc: 0.9588
Epoch 2/25
 - 8s - loss: 1.0186 - acc: 0.9624 - val_loss: 0.1023 - val_acc: 0.9643
Epoch 3/25
 - 8s - loss: 0.4727 - acc: 0.9682 - val_loss: 0.1075 - val_acc: 0.9638
Epoch 4/25
 - 8s - loss: 0.6471 - acc: 0.9705 - val_loss: 0.1182 - val_acc: 0.9648
Epoch 5/25
 - 8s - loss: 0.3076 - acc: 0.9719 - val_loss: 0.1127 - val_acc: 0.9635
Epoch 6/25
 - 8s - loss: 0.2603 - acc: 0.9723 - val_loss: 0.1192 - val_acc: 0.9635
Epoch 7/25
 - 8s - loss: 0.0657 - acc: 0.9732 - val_loss: 0.1285 - val_acc: 0.9644
Epoch 8/25
 - 8s - loss: 0.0741 - acc: 0.9739 - val_loss: 0.1265 - val_acc: 0.9656
Epoch 9/25
 - 8s - loss: 0.0472 - acc: 0.9743 - val_loss: 0.1414 - val_acc: 0.9654
Epoch 10/25
 - 8s - loss: 0.0438 - acc: 0.9748 - val_loss: 0.1602 - val_acc: 0.9659
Epoch 11/25
 - 8s - loss: 0.0438 - acc: 0.9752 - val_loss: 0.1538 - val_acc: 0.9655
Epoch 12/25
 - 8s - loss: 0.0423 - acc: 0.9751 - val_loss: 0.1691 - val_acc: 0.9632
Epoch 13/25
 - 8s - loss: 0.0411 - acc: 0.9753 - val_loss: 0.1628 - val_acc: 0.9649
Epoch 14/25
 - 8s - loss: 0.0404 - acc: 0.9757 - val_loss: 0.1623 - val_acc: 0.9649
Epoch 15/25
 - 8s - loss: 0.0401 - acc: 0.9757 - val_loss: 0.1920 - val_acc: 0.9642
Epoch 16/25
 - 8s - loss: 0.3471 - acc: 0.9758 - val_loss: 0.1764 - val_acc: 0.9644
Epoch 17/25
 - 8s - loss: 0.0392 - acc: 0.9760 - val_loss: 0.1615 - val_acc: 0.9638
Epoch 18/25
 - 8s - loss: 0.0383 - acc: 0.9766 - val_loss: 0.1976 - val_acc: 0.9648
Epoch 19/25
 - 8s - loss: 0.0421 - acc: 0.9763 - val_loss: 0.2035 - val_acc: 0.9640
Epoch 20/25
 - 8s - loss: 0.0377 - acc: 0.9767 - val_loss: 0.1930 - val_acc: 0.9645
Epoch 21/25
 - 8s - loss: 0.0377 - acc: 0.9765 - val_loss: 0.1876 - val_acc: 0.9634
Epoch 22/25
 - 8s - loss: 0.0375 - acc: 0.9769 - val_loss: 0.1902 - val_acc: 0.9649
Epoch 23/25
 - 8s - loss: 0.0369 - acc: 0.9768 - val_loss: 0.2519 - val_acc: 0.9641
Epoch 24/25
 - 8s - loss: 0.0365 - acc: 0.9771 - val_loss: 0.2477 - val_acc: 0.9648
Epoch 25/25
 - 8s - loss: 0.0367 - acc: 0.9768 - val_loss: 0.2094 - val_acc: 0.9652
Epoch 1/25
 - 1s - loss: 0.2072 - acc: 0.9581
Epoch 2/25
 - 1s - loss: 0.0996 - acc: 0.9631
Epoch 3/25
 - 1s - loss: 0.0838 - acc: 0.9675
Epoch 4/25
 - 1s - loss: 0.0756 - acc: 0.9703
Epoch 5/25
 - 1s - loss: 0.0693 - acc: 0.9717
Epoch 6/25
 - 1s - loss: 0.0636 - acc: 0.9735
Epoch 7/25
 - 1s - loss: 0.0617 - acc: 0.9746
Epoch 8/25
 - 1s - loss: 0.0607 - acc: 0.9747
Epoch 9/25
 - 1s - loss: 0.0601 - acc: 0.9751
Epoch 10/25
 - 1s - loss: 0.0576 - acc: 0.9755
Epoch 11/25
 - 1s - loss: 0.0559 - acc: 0.9762
Epoch 12/25
 - 1s - loss: 0.0484 - acc: 0.9768
Epoch 13/25
 - 1s - loss: 0.0467 - acc: 0.9769
Epoch 14/25
 - 1s - loss: 0.0480 - acc: 0.9770
Epoch 15/25
 - 1s - loss: 0.0439 - acc: 0.9772
Epoch 16/25
 - 1s - loss: 0.0427 - acc: 0.9773
Epoch 17/25
 - 1s - loss: 0.0429 - acc: 0.9773
Epoch 18/25
 - 1s - loss: 0.0435 - acc: 0.9775
Epoch 19/25
 - 1s - loss: 0.0412 - acc: 0.9779
Epoch 20/25
 - 1s - loss: 0.0430 - acc: 0.9778
Epoch 21/25
 - 1s - loss: 0.0415 - acc: 0.9785
Epoch 22/25
 - 1s - loss: 0.0408 - acc: 0.9783
Epoch 23/25
 - 1s - loss: 0.0419 - acc: 0.9790
Epoch 24/25
 - 1s - loss: 0.0435 - acc: 0.9783
Epoch 25/25
 - 1s - loss: 0.0414 - acc: 0.9783
# Training time = 0:04:05.595648
# F-Score(Ordinary) = 0.491, Recall: 0.378, Precision: 0.702
# F-Score(lvc) = 0.495, Recall: 0.476, Precision: 0.515
# F-Score(ireflv) = 0.734, Recall: 0.623, Precision: 0.893
# F-Score(id) = 0.357, Recall: 0.246, Precision: 0.653
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_10 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 4, 48)        705264      input_9[0][0]                    
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 4, 24)        5640        input_10[0][0]                   
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 192)          0           embedding_9[0][0]                
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 96)           0           embedding_10[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 288)          0           flatten_9[0][0]                  
                                                                 flatten_10[0][0]                 
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 24)           6936        concatenate_5[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24)           0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 8)            200         dropout_5[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/25
 - 8s - loss: 1.3774 - acc: 0.9228 - val_loss: 0.1228 - val_acc: 0.9529
Epoch 2/25
 - 8s - loss: 0.5475 - acc: 0.9583 - val_loss: 0.0981 - val_acc: 0.9607
Epoch 3/25
 - 8s - loss: 0.5575 - acc: 0.9639 - val_loss: 0.0982 - val_acc: 0.9635
Epoch 4/25
 - 8s - loss: 0.3312 - acc: 0.9671 - val_loss: 0.1035 - val_acc: 0.9636
Epoch 5/25
 - 8s - loss: 0.1732 - acc: 0.9694 - val_loss: 0.1133 - val_acc: 0.9628
Epoch 6/25
 - 8s - loss: 0.0912 - acc: 0.9708 - val_loss: 0.1173 - val_acc: 0.9654
Epoch 7/25
 - 8s - loss: 0.1255 - acc: 0.9714 - val_loss: 0.1232 - val_acc: 0.9645
Epoch 8/25
 - 8s - loss: 0.0500 - acc: 0.9728 - val_loss: 0.1317 - val_acc: 0.9642
Epoch 9/25
 - 8s - loss: 0.1747 - acc: 0.9735 - val_loss: 0.1278 - val_acc: 0.9622
Epoch 10/25
 - 8s - loss: 0.0445 - acc: 0.9738 - val_loss: 0.1392 - val_acc: 0.9644
Epoch 11/25
 - 8s - loss: 0.0424 - acc: 0.9744 - val_loss: 0.1437 - val_acc: 0.9646
Epoch 12/25
 - 8s - loss: 0.0422 - acc: 0.9746 - val_loss: 0.1394 - val_acc: 0.9644
Epoch 13/25
 - 8s - loss: 0.0428 - acc: 0.9751 - val_loss: 0.1646 - val_acc: 0.9652
Epoch 14/25
 - 8s - loss: 0.0407 - acc: 0.9749 - val_loss: 0.1508 - val_acc: 0.9630
Epoch 15/25
 - 8s - loss: 0.0405 - acc: 0.9752 - val_loss: 0.1701 - val_acc: 0.9652
Epoch 16/25
 - 8s - loss: 0.0386 - acc: 0.9755 - val_loss: 0.1731 - val_acc: 0.9656
Epoch 17/25
 - 8s - loss: 0.0404 - acc: 0.9757 - val_loss: 0.1571 - val_acc: 0.9647
Epoch 18/25
 - 8s - loss: 0.0381 - acc: 0.9760 - val_loss: 0.1674 - val_acc: 0.9647
Epoch 19/25
 - 8s - loss: 0.8803 - acc: 0.9761 - val_loss: 0.1902 - val_acc: 0.9644
Epoch 20/25
 - 8s - loss: 0.6000 - acc: 0.9761 - val_loss: 0.1806 - val_acc: 0.9648
Epoch 21/25
 - 8s - loss: 0.0386 - acc: 0.9764 - val_loss: 0.1823 - val_acc: 0.9641
Epoch 22/25
 - 8s - loss: 0.0384 - acc: 0.9765 - val_loss: 0.1792 - val_acc: 0.9646
Epoch 23/25
 - 8s - loss: 0.0370 - acc: 0.9768 - val_loss: 0.1847 - val_acc: 0.9654
Epoch 24/25
 - 8s - loss: 0.0398 - acc: 0.9769 - val_loss: 0.1933 - val_acc: 0.9657
Epoch 25/25
 - 8s - loss: 0.0367 - acc: 0.9769 - val_loss: 0.2098 - val_acc: 0.9656
Epoch 1/25
 - 1s - loss: 0.1884 - acc: 0.9590
Epoch 2/25
 - 1s - loss: 0.1175 - acc: 0.9654
Epoch 3/25
 - 1s - loss: 0.0961 - acc: 0.9689
Epoch 4/25
 - 1s - loss: 0.0761 - acc: 0.9708
Epoch 5/25
 - 1s - loss: 0.0780 - acc: 0.9720
Epoch 6/25
 - 1s - loss: 0.0624 - acc: 0.9737
Epoch 7/25
 - 1s - loss: 0.0537 - acc: 0.9745
Epoch 8/25
 - 1s - loss: 0.0475 - acc: 0.9745
Epoch 9/25
 - 1s - loss: 0.0474 - acc: 0.9758
Epoch 10/25
 - 1s - loss: 0.0450 - acc: 0.9756
Epoch 11/25
 - 1s - loss: 0.0429 - acc: 0.9767
Epoch 12/25
 - 1s - loss: 0.0437 - acc: 0.9772
Epoch 13/25
 - 1s - loss: 0.0438 - acc: 0.9767
Epoch 14/25
 - 1s - loss: 0.0435 - acc: 0.9771
Epoch 15/25
 - 1s - loss: 0.0422 - acc: 0.9771
Epoch 16/25
 - 1s - loss: 0.0407 - acc: 0.9778
Epoch 17/25
 - 1s - loss: 0.0410 - acc: 0.9781
Epoch 18/25
 - 1s - loss: 0.0416 - acc: 0.9779
Epoch 19/25
 - 1s - loss: 0.0420 - acc: 0.9782
Epoch 20/25
 - 1s - loss: 0.0417 - acc: 0.9781
Epoch 21/25
 - 1s - loss: 0.0403 - acc: 0.9780
Epoch 22/25
 - 1s - loss: 0.0420 - acc: 0.9774
Epoch 23/25
 - 1s - loss: 0.0397 - acc: 0.9784
Epoch 24/25
 - 1s - loss: 0.0424 - acc: 0.9787
Epoch 25/25
 - 1s - loss: 0.0403 - acc: 0.9783
# Training time = 0:04:00.687313
# F-Score(Ordinary) = 0.588, Recall: 0.512, Precision: 0.689
# F-Score(lvc) = 0.485, Recall: 0.441, Precision: 0.538
# F-Score(ireflv) = 0.713, Recall: 0.617, Precision: 0.844
# F-Score(id) = 0.554, Recall: 0.473, Precision: 0.668
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 4, 48)        705264      input_11[0][0]                   
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 4, 24)        5640        input_12[0][0]                   
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 192)          0           embedding_11[0][0]               
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 96)           0           embedding_12[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 288)          0           flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 24)           6936        concatenate_6[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24)           0           dense_11[0][0]                   
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 8)            200         dropout_6[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/25
 - 8s - loss: 1.7998 - acc: 0.9227 - val_loss: 0.1115 - val_acc: 0.9578
Epoch 2/25
 - 8s - loss: 0.9473 - acc: 0.9617 - val_loss: 0.1021 - val_acc: 0.9617
Epoch 3/25
 - 8s - loss: 0.3602 - acc: 0.9672 - val_loss: 0.0983 - val_acc: 0.9629
Epoch 4/25
 - 8s - loss: 0.3849 - acc: 0.9689 - val_loss: 0.1023 - val_acc: 0.9620
Epoch 5/25
 - 8s - loss: 0.4103 - acc: 0.9706 - val_loss: 0.1100 - val_acc: 0.9633
Epoch 6/25
 - 8s - loss: 0.3970 - acc: 0.9715 - val_loss: 0.1159 - val_acc: 0.9635
Epoch 7/25
 - 8s - loss: 0.1838 - acc: 0.9730 - val_loss: 0.1157 - val_acc: 0.9639
Epoch 8/25
 - 8s - loss: 0.2489 - acc: 0.9735 - val_loss: 0.1318 - val_acc: 0.9629
Epoch 9/25
 - 8s - loss: 0.0662 - acc: 0.9742 - val_loss: 0.1384 - val_acc: 0.9639
Epoch 10/25
 - 8s - loss: 0.1699 - acc: 0.9746 - val_loss: 0.1577 - val_acc: 0.9645
Epoch 11/25
 - 8s - loss: 0.0472 - acc: 0.9748 - val_loss: 0.1349 - val_acc: 0.9642
Epoch 12/25
 - 8s - loss: 0.1727 - acc: 0.9751 - val_loss: 0.1351 - val_acc: 0.9646
Epoch 13/25
 - 8s - loss: 0.0567 - acc: 0.9752 - val_loss: 0.1519 - val_acc: 0.9650
Epoch 14/25
 - 8s - loss: 0.0453 - acc: 0.9756 - val_loss: 0.1422 - val_acc: 0.9642
Epoch 15/25
 - 8s - loss: 0.0436 - acc: 0.9757 - val_loss: 0.1538 - val_acc: 0.9655
Epoch 16/25
 - 8s - loss: 0.0413 - acc: 0.9759 - val_loss: 0.1514 - val_acc: 0.9641
Epoch 17/25
 - 8s - loss: 0.0445 - acc: 0.9753 - val_loss: 0.1663 - val_acc: 0.9640
Epoch 18/25
 - 8s - loss: 0.0389 - acc: 0.9762 - val_loss: 0.1658 - val_acc: 0.9655
Epoch 19/25
 - 8s - loss: 0.0406 - acc: 0.9763 - val_loss: 0.1756 - val_acc: 0.9658
Epoch 20/25
 - 8s - loss: 0.0387 - acc: 0.9761 - val_loss: 0.1646 - val_acc: 0.9632
Epoch 21/25
 - 8s - loss: 0.0400 - acc: 0.9765 - val_loss: 0.1859 - val_acc: 0.9659
Epoch 22/25
 - 8s - loss: 0.0655 - acc: 0.9767 - val_loss: 0.1713 - val_acc: 0.9652
Epoch 23/25
 - 8s - loss: 0.0421 - acc: 0.9764 - val_loss: 0.1484 - val_acc: 0.9645
Epoch 24/25
 - 8s - loss: 0.0421 - acc: 0.9771 - val_loss: 0.1564 - val_acc: 0.9660
Epoch 25/25
 - 8s - loss: 0.0387 - acc: 0.9766 - val_loss: 0.1673 - val_acc: 0.9650
Epoch 1/25
 - 1s - loss: 0.1464 - acc: 0.9592
Epoch 2/25
 - 1s - loss: 0.1123 - acc: 0.9650
Epoch 3/25
 - 1s - loss: 0.0736 - acc: 0.9700
Epoch 4/25
 - 1s - loss: 0.0623 - acc: 0.9720
Epoch 5/25
 - 1s - loss: 0.0527 - acc: 0.9730
Epoch 6/25
 - 1s - loss: 0.0484 - acc: 0.9743
Epoch 7/25
 - 1s - loss: 0.0458 - acc: 0.9752
Epoch 8/25
 - 1s - loss: 0.0451 - acc: 0.9756
Epoch 9/25
 - 1s - loss: 0.0458 - acc: 0.9765
Epoch 10/25
 - 1s - loss: 0.0456 - acc: 0.9769
Epoch 11/25
 - 1s - loss: 0.0437 - acc: 0.9767
Epoch 12/25
 - 1s - loss: 0.0452 - acc: 0.9764
Epoch 13/25
 - 1s - loss: 0.0420 - acc: 0.9771
Epoch 14/25
 - 1s - loss: 0.0417 - acc: 0.9779
Epoch 15/25
 - 1s - loss: 0.0414 - acc: 0.9776
Epoch 16/25
 - 1s - loss: 0.0412 - acc: 0.9777
Epoch 17/25
 - 1s - loss: 0.0460 - acc: 0.9780
Epoch 18/25
 - 1s - loss: 0.0420 - acc: 0.9778
Epoch 19/25
 - 1s - loss: 0.0406 - acc: 0.9783
Epoch 20/25
 - 1s - loss: 0.0422 - acc: 0.9781
Epoch 21/25
 - 1s - loss: 0.0436 - acc: 0.9783
Epoch 22/25
 - 1s - loss: 0.0412 - acc: 0.9786
Epoch 23/25
 - 1s - loss: 0.0434 - acc: 0.9778
Epoch 24/25
 - 1s - loss: 0.0412 - acc: 0.9783
Epoch 25/25
 - 1s - loss: 0.0400 - acc: 0.9790
# Training time = 0:04:01.364875
# F-Score(Ordinary) = 0.55, Recall: 0.445, Precision: 0.718
# F-Score(lvc) = 0.352, Recall: 0.258, Precision: 0.553
# F-Score(ireflv) = 0.677, Recall: 0.555, Precision: 0.869
# F-Score(id) = 0.605, Recall: 0.538, Precision: 0.689
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_14 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 4, 48)        705264      input_13[0][0]                   
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 4, 24)        5640        input_14[0][0]                   
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 192)          0           embedding_13[0][0]               
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 96)           0           embedding_14[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 288)          0           flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 24)           6936        concatenate_7[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24)           0           dense_13[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 8)            200         dropout_7[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/25
 - 8s - loss: 1.6369 - acc: 0.9324 - val_loss: 0.1120 - val_acc: 0.9562
Epoch 2/25
 - 8s - loss: 1.2067 - acc: 0.9630 - val_loss: 0.1014 - val_acc: 0.9602
Epoch 3/25
 - 8s - loss: 0.6781 - acc: 0.9667 - val_loss: 0.1025 - val_acc: 0.9628
Epoch 4/25
 - 8s - loss: 0.4203 - acc: 0.9690 - val_loss: 0.1129 - val_acc: 0.9642
Epoch 5/25
 - 8s - loss: 0.3436 - acc: 0.9708 - val_loss: 0.1088 - val_acc: 0.9655
Epoch 6/25
 - 8s - loss: 0.2790 - acc: 0.9720 - val_loss: 0.1154 - val_acc: 0.9642
Epoch 7/25
 - 8s - loss: 0.3874 - acc: 0.9727 - val_loss: 0.1148 - val_acc: 0.9638
Epoch 8/25
 - 8s - loss: 0.2212 - acc: 0.9733 - val_loss: 0.1387 - val_acc: 0.9640
Epoch 9/25
 - 8s - loss: 0.1128 - acc: 0.9736 - val_loss: 0.1354 - val_acc: 0.9642
Epoch 10/25
 - 8s - loss: 0.0545 - acc: 0.9744 - val_loss: 0.1410 - val_acc: 0.9657
Epoch 11/25
 - 8s - loss: 0.0454 - acc: 0.9744 - val_loss: 0.1324 - val_acc: 0.9647
Epoch 12/25
 - 8s - loss: 0.0769 - acc: 0.9750 - val_loss: 0.1816 - val_acc: 0.9645
Epoch 13/25
 - 8s - loss: 0.0444 - acc: 0.9749 - val_loss: 0.1438 - val_acc: 0.9651
Epoch 14/25
 - 8s - loss: 0.0455 - acc: 0.9750 - val_loss: 0.1529 - val_acc: 0.9651
Epoch 15/25
 - 8s - loss: 0.1385 - acc: 0.9750 - val_loss: 0.1649 - val_acc: 0.9634
Epoch 16/25
 - 8s - loss: 0.3057 - acc: 0.9759 - val_loss: 0.1635 - val_acc: 0.9649
Epoch 17/25
 - 8s - loss: 0.0413 - acc: 0.9754 - val_loss: 0.1571 - val_acc: 0.9652
Epoch 18/25
 - 8s - loss: 0.0391 - acc: 0.9761 - val_loss: 0.1587 - val_acc: 0.9645
Epoch 19/25
 - 8s - loss: 0.0401 - acc: 0.9762 - val_loss: 0.1656 - val_acc: 0.9645
Epoch 20/25
 - 8s - loss: 0.0406 - acc: 0.9759 - val_loss: 0.1817 - val_acc: 0.9647
Epoch 21/25
 - 8s - loss: 0.0396 - acc: 0.9764 - val_loss: 0.1741 - val_acc: 0.9641
Epoch 22/25
 - 8s - loss: 0.0381 - acc: 0.9764 - val_loss: 0.1821 - val_acc: 0.9643
Epoch 23/25
 - 8s - loss: 0.0383 - acc: 0.9767 - val_loss: 0.1703 - val_acc: 0.9638
Epoch 24/25
 - 8s - loss: 0.2514 - acc: 0.9764 - val_loss: 0.1638 - val_acc: 0.9649
Epoch 25/25
 - 8s - loss: 0.0373 - acc: 0.9771 - val_loss: 0.1797 - val_acc: 0.9659
Epoch 1/25
 - 1s - loss: 0.1901 - acc: 0.9612
Epoch 2/25
 - 1s - loss: 0.1314 - acc: 0.9640
Epoch 3/25
 - 1s - loss: 0.0855 - acc: 0.9687
Epoch 4/25
 - 1s - loss: 0.0738 - acc: 0.9716
Epoch 5/25
 - 1s - loss: 0.0672 - acc: 0.9732
Epoch 6/25
 - 1s - loss: 0.0652 - acc: 0.9738
Epoch 7/25
 - 1s - loss: 0.0639 - acc: 0.9745
Epoch 8/25
 - 1s - loss: 0.0497 - acc: 0.9755
Epoch 9/25
 - 1s - loss: 0.0617 - acc: 0.9763
Epoch 10/25
 - 1s - loss: 0.0627 - acc: 0.9761
Epoch 11/25
 - 1s - loss: 0.0619 - acc: 0.9754
Epoch 12/25
 - 1s - loss: 0.0474 - acc: 0.9765
Epoch 13/25
 - 1s - loss: 0.0441 - acc: 0.9766
Epoch 14/25
 - 1s - loss: 0.0429 - acc: 0.9770
Epoch 15/25
 - 1s - loss: 0.0427 - acc: 0.9773
Epoch 16/25
 - 1s - loss: 0.0449 - acc: 0.9769
Epoch 17/25
 - 1s - loss: 0.0430 - acc: 0.9766
Epoch 18/25
 - 1s - loss: 0.0433 - acc: 0.9778
Epoch 19/25
 - 1s - loss: 0.0427 - acc: 0.9778
Epoch 20/25
 - 1s - loss: 0.0415 - acc: 0.9781
Epoch 21/25
 - 1s - loss: 0.0414 - acc: 0.9782
Epoch 22/25
 - 1s - loss: 0.0407 - acc: 0.9784
Epoch 23/25
 - 1s - loss: 0.0409 - acc: 0.9785
Epoch 24/25
 - 1s - loss: 0.0415 - acc: 0.9787
Epoch 25/25
 - 1s - loss: 0.0402 - acc: 0.9788
# Training time = 0:04:01.093732
# F-Score(Ordinary) = 0.508, Recall: 0.398, Precision: 0.7
# F-Score(lvc) = 0.571, Recall: 0.729, Precision: 0.47
# F-Score(ireflv) = 0.764, Recall: 0.677, Precision: 0.877
# F-Score(id) = 0.359, Recall: 0.243, Precision: 0.684
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_15 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_16 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_15 (Embedding)        (None, 4, 48)        705264      input_15[0][0]                   
__________________________________________________________________________________________________
embedding_16 (Embedding)        (None, 4, 24)        5640        input_16[0][0]                   
__________________________________________________________________________________________________
flatten_15 (Flatten)            (None, 192)          0           embedding_15[0][0]               
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 96)           0           embedding_16[0][0]               
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 288)          0           flatten_15[0][0]                 
                                                                 flatten_16[0][0]                 
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 24)           6936        concatenate_8[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24)           0           dense_15[0][0]                   
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 8)            200         dropout_8[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/25
 - 8s - loss: 1.6525 - acc: 0.9299 - val_loss: 0.1095 - val_acc: 0.9582
Epoch 2/25
 - 8s - loss: 0.8814 - acc: 0.9623 - val_loss: 0.1052 - val_acc: 0.9617
Epoch 3/25
 - 8s - loss: 0.8121 - acc: 0.9676 - val_loss: 0.1008 - val_acc: 0.9625
Epoch 4/25
 - 8s - loss: 0.4143 - acc: 0.9700 - val_loss: 0.1049 - val_acc: 0.9623
Epoch 5/25
 - 8s - loss: 0.3603 - acc: 0.9717 - val_loss: 0.1083 - val_acc: 0.9647
Epoch 6/25
 - 8s - loss: 0.3541 - acc: 0.9730 - val_loss: 0.1083 - val_acc: 0.9645
Epoch 7/25
 - 8s - loss: 0.3577 - acc: 0.9733 - val_loss: 0.1241 - val_acc: 0.9646
Epoch 8/25
 - 8s - loss: 0.2826 - acc: 0.9738 - val_loss: 0.1381 - val_acc: 0.9662
Epoch 9/25
 - 8s - loss: 0.3912 - acc: 0.9740 - val_loss: 0.1424 - val_acc: 0.9643
Epoch 10/25
 - 8s - loss: 0.1834 - acc: 0.9747 - val_loss: 0.1502 - val_acc: 0.9654
Epoch 11/25
 - 8s - loss: 0.1966 - acc: 0.9752 - val_loss: 0.1460 - val_acc: 0.9649
Epoch 12/25
 - 8s - loss: 0.0990 - acc: 0.9747 - val_loss: 0.1523 - val_acc: 0.9649
Epoch 13/25
 - 8s - loss: 0.1230 - acc: 0.9756 - val_loss: 0.1441 - val_acc: 0.9651
Epoch 14/25
 - 8s - loss: 0.0501 - acc: 0.9757 - val_loss: 0.1583 - val_acc: 0.9652
Epoch 15/25
 - 8s - loss: 0.1689 - acc: 0.9761 - val_loss: 0.1671 - val_acc: 0.9649
Epoch 16/25
 - 8s - loss: 0.0408 - acc: 0.9761 - val_loss: 0.1965 - val_acc: 0.9651
Epoch 17/25
 - 8s - loss: 0.0392 - acc: 0.9763 - val_loss: 0.1568 - val_acc: 0.9652
Epoch 18/25
 - 8s - loss: 0.0489 - acc: 0.9763 - val_loss: 0.1837 - val_acc: 0.9654
Epoch 19/25
 - 8s - loss: 0.1105 - acc: 0.9767 - val_loss: 0.1691 - val_acc: 0.9657
Epoch 20/25
 - 8s - loss: 0.0624 - acc: 0.9765 - val_loss: 0.1785 - val_acc: 0.9640
Epoch 21/25
 - 8s - loss: 0.0429 - acc: 0.9765 - val_loss: 0.2056 - val_acc: 0.9641
Epoch 22/25
 - 8s - loss: 0.0374 - acc: 0.9770 - val_loss: 0.1864 - val_acc: 0.9650
Epoch 23/25
 - 8s - loss: 0.1037 - acc: 0.9769 - val_loss: 0.2454 - val_acc: 0.9652
Epoch 24/25
 - 8s - loss: 0.0386 - acc: 0.9769 - val_loss: 0.2059 - val_acc: 0.9636
Epoch 25/25
 - 8s - loss: 0.0385 - acc: 0.9773 - val_loss: 0.1840 - val_acc: 0.9654
Epoch 1/25
 - 1s - loss: 0.2058 - acc: 0.9600
Epoch 2/25
 - 1s - loss: 0.1400 - acc: 0.9636
Epoch 3/25
 - 1s - loss: 0.0898 - acc: 0.9679
Epoch 4/25
 - 1s - loss: 0.0667 - acc: 0.9706
Epoch 5/25
 - 1s - loss: 0.0601 - acc: 0.9713
Epoch 6/25
 - 1s - loss: 0.0520 - acc: 0.9735
Epoch 7/25
 - 1s - loss: 0.0511 - acc: 0.9750
Epoch 8/25
 - 1s - loss: 0.0465 - acc: 0.9755
Epoch 9/25
 - 1s - loss: 0.0458 - acc: 0.9759
Epoch 10/25
 - 1s - loss: 0.0490 - acc: 0.9760
Epoch 11/25
 - 1s - loss: 0.0449 - acc: 0.9763
Epoch 12/25
 - 1s - loss: 0.0445 - acc: 0.9772
Epoch 13/25
 - 1s - loss: 0.0439 - acc: 0.9772
Epoch 14/25
 - 1s - loss: 0.0436 - acc: 0.9774
Epoch 15/25
 - 1s - loss: 0.0422 - acc: 0.9773
Epoch 16/25
 - 1s - loss: 0.0417 - acc: 0.9780
Epoch 17/25
 - 1s - loss: 0.0411 - acc: 0.9780
Epoch 18/25
 - 1s - loss: 0.0408 - acc: 0.9784
Epoch 19/25
 - 1s - loss: 0.0408 - acc: 0.9786
Epoch 20/25
 - 1s - loss: 0.0421 - acc: 0.9782
Epoch 21/25
 - 1s - loss: 0.0400 - acc: 0.9790
Epoch 22/25
 - 1s - loss: 0.0431 - acc: 0.9789
Epoch 23/25
 - 1s - loss: 0.0402 - acc: 0.9788
Epoch 24/25
 - 1s - loss: 0.0392 - acc: 0.9789
Epoch 25/25
 - 1s - loss: 0.0409 - acc: 0.9791
# Training time = 0:04:01.656452
# F-Score(Ordinary) = 0.473, Recall: 0.36, Precision: 0.691
# F-Score(lvc) = 0.375, Recall: 0.287, Precision: 0.538
# F-Score(ireflv) = 0.742, Recall: 0.652, Precision: 0.861
# F-Score(id) = 0.379, Recall: 0.271, Precision: 0.632
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_17 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_18 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_17 (Embedding)        (None, 4, 48)        705264      input_17[0][0]                   
__________________________________________________________________________________________________
embedding_18 (Embedding)        (None, 4, 24)        5640        input_18[0][0]                   
__________________________________________________________________________________________________
flatten_17 (Flatten)            (None, 192)          0           embedding_17[0][0]               
__________________________________________________________________________________________________
flatten_18 (Flatten)            (None, 96)           0           embedding_18[0][0]               
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 288)          0           flatten_17[0][0]                 
                                                                 flatten_18[0][0]                 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 24)           6936        concatenate_9[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24)           0           dense_17[0][0]                   
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 8)            200         dropout_9[0][0]                  
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/25
 - 8s - loss: 1.3992 - acc: 0.9221 - val_loss: 0.1178 - val_acc: 0.9569
Epoch 2/25
 - 8s - loss: 0.8941 - acc: 0.9635 - val_loss: 0.1052 - val_acc: 0.9612
Epoch 3/25
 - 8s - loss: 0.7849 - acc: 0.9681 - val_loss: 0.1103 - val_acc: 0.9632
Epoch 4/25
 - 8s - loss: 0.4138 - acc: 0.9700 - val_loss: 0.1142 - val_acc: 0.9640
Epoch 5/25
 - 8s - loss: 0.2710 - acc: 0.9705 - val_loss: 0.1268 - val_acc: 0.9644
Epoch 6/25
 - 8s - loss: 0.3243 - acc: 0.9714 - val_loss: 0.1180 - val_acc: 0.9622
Epoch 7/25
 - 8s - loss: 0.2894 - acc: 0.9727 - val_loss: 0.1370 - val_acc: 0.9640
Epoch 8/25
 - 8s - loss: 0.3424 - acc: 0.9732 - val_loss: 0.1359 - val_acc: 0.9634
Epoch 9/25
 - 8s - loss: 0.1361 - acc: 0.9738 - val_loss: 0.1558 - val_acc: 0.9646
Epoch 10/25
 - 8s - loss: 0.0904 - acc: 0.9741 - val_loss: 0.1502 - val_acc: 0.9649
Epoch 11/25
 - 8s - loss: 0.0608 - acc: 0.9745 - val_loss: 0.1576 - val_acc: 0.9649
Epoch 12/25
 - 8s - loss: 0.3204 - acc: 0.9746 - val_loss: 0.1592 - val_acc: 0.9631
Epoch 13/25
 - 8s - loss: 0.0505 - acc: 0.9751 - val_loss: 0.1866 - val_acc: 0.9638
Epoch 14/25
 - 8s - loss: 0.1066 - acc: 0.9751 - val_loss: 0.1584 - val_acc: 0.9628
Epoch 15/25
 - 8s - loss: 0.0422 - acc: 0.9756 - val_loss: 0.1684 - val_acc: 0.9643
Epoch 16/25
 - 8s - loss: 0.0419 - acc: 0.9756 - val_loss: 0.1763 - val_acc: 0.9635
Epoch 17/25
 - 8s - loss: 0.0415 - acc: 0.9755 - val_loss: 0.1799 - val_acc: 0.9619
Epoch 18/25
 - 8s - loss: 0.0435 - acc: 0.9756 - val_loss: 0.1989 - val_acc: 0.9646
Epoch 19/25
 - 8s - loss: 0.0409 - acc: 0.9761 - val_loss: 0.1879 - val_acc: 0.9641
Epoch 20/25
 - 8s - loss: 0.0401 - acc: 0.9759 - val_loss: 0.1989 - val_acc: 0.9639
Epoch 21/25
 - 8s - loss: 0.0402 - acc: 0.9759 - val_loss: 0.2254 - val_acc: 0.9644
Epoch 22/25
 - 8s - loss: 0.0379 - acc: 0.9763 - val_loss: 0.2199 - val_acc: 0.9650
Epoch 23/25
 - 8s - loss: 0.0392 - acc: 0.9762 - val_loss: 0.1906 - val_acc: 0.9641
Epoch 24/25
 - 8s - loss: 0.0409 - acc: 0.9765 - val_loss: 0.2211 - val_acc: 0.9636
Epoch 25/25
 - 8s - loss: 0.0375 - acc: 0.9767 - val_loss: 0.2102 - val_acc: 0.9646
Epoch 1/25
 - 1s - loss: 0.2077 - acc: 0.9592
Epoch 2/25
 - 1s - loss: 0.1165 - acc: 0.9630
Epoch 3/25
 - 1s - loss: 0.0761 - acc: 0.9688
Epoch 4/25
 - 1s - loss: 0.0701 - acc: 0.9722
Epoch 5/25
 - 1s - loss: 0.0635 - acc: 0.9725
Epoch 6/25
 - 1s - loss: 0.0525 - acc: 0.9738
Epoch 7/25
 - 1s - loss: 0.0481 - acc: 0.9746
Epoch 8/25
 - 1s - loss: 0.0479 - acc: 0.9756
Epoch 9/25
 - 1s - loss: 0.0482 - acc: 0.9759
Epoch 10/25
 - 1s - loss: 0.0443 - acc: 0.9764
Epoch 11/25
 - 1s - loss: 0.0448 - acc: 0.9769
Epoch 12/25
 - 1s - loss: 0.0434 - acc: 0.9778
Epoch 13/25
 - 1s - loss: 0.0438 - acc: 0.9765
Epoch 14/25
 - 1s - loss: 0.0455 - acc: 0.9768
Epoch 15/25
 - 1s - loss: 0.0429 - acc: 0.9777
Epoch 16/25
 - 1s - loss: 0.0423 - acc: 0.9773
Epoch 17/25
 - 1s - loss: 0.0425 - acc: 0.9783
Epoch 18/25
 - 1s - loss: 0.0414 - acc: 0.9783
Epoch 19/25
 - 1s - loss: 0.0420 - acc: 0.9783
Epoch 20/25
 - 1s - loss: 0.0422 - acc: 0.9782
Epoch 21/25
 - 1s - loss: 0.0412 - acc: 0.9787
Epoch 22/25
 - 1s - loss: 0.0449 - acc: 0.9785
Epoch 23/25
 - 1s - loss: 0.0419 - acc: 0.9781
Epoch 24/25
 - 1s - loss: 0.0412 - acc: 0.9786
Epoch 25/25
 - 1s - loss: 0.0426 - acc: 0.9784
# Training time = 0:04:02.067046
# F-Score(Ordinary) = 0.593, Recall: 0.512, Precision: 0.705
# F-Score(lvc) = 0.451, Recall: 0.41, Precision: 0.5
# F-Score(ireflv) = 0.723, Recall: 0.6, Precision: 0.91
# F-Score(id) = 0.567, Recall: 0.487, Precision: 0.679
********************
********************
# XP = FR: 
********************
********************
Deep model(No padding)
# Language = FR
# Train file = train.conllu.autoPOS.autoDep
# Test file = test.conllu.autoPOS.autoDep
FRidxDic
# Train = 16091
# Test = 1788
# Tokens vocabulary = 14693
# POSs vocabulary = 235
# embedding: dataFR.profiles.min
# token vocabulary = 14693
# POS vocabulary = 235
# Padding = False
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 48
# POS = True
# POS emb = 24
# Features = False
# Parameters = 718040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_19 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_20 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_19 (Embedding)        (None, 4, 48)        705264      input_19[0][0]                   
__________________________________________________________________________________________________
embedding_20 (Embedding)        (None, 4, 24)        5640        input_20[0][0]                   
__________________________________________________________________________________________________
flatten_19 (Flatten)            (None, 192)          0           embedding_19[0][0]               
__________________________________________________________________________________________________
flatten_20 (Flatten)            (None, 96)           0           embedding_20[0][0]               
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 288)          0           flatten_19[0][0]                 
                                                                 flatten_20[0][0]                 
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 24)           6936        concatenate_10[0][0]             
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24)           0           dense_19[0][0]                   
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 8)            200         dropout_10[0][0]                 
==================================================================================================
Total params: 718,040
Trainable params: 718,040
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 190930 samples, validate on 21215 samples
Epoch 1/25
 - 7s - loss: 1.2900 - acc: 0.9156 - val_loss: 0.1124 - val_acc: 0.9589
Epoch 2/25
 - 7s - loss: 1.1785 - acc: 0.9624 - val_loss: 0.1048 - val_acc: 0.9620
Epoch 3/25
 - 7s - loss: 0.6144 - acc: 0.9658 - val_loss: 0.1064 - val_acc: 0.9621
Epoch 4/25
 - 7s - loss: 0.3032 - acc: 0.9686 - val_loss: 0.1117 - val_acc: 0.9622
Epoch 5/25
 - 7s - loss: 0.5605 - acc: 0.9705 - val_loss: 0.1208 - val_acc: 0.9634
Epoch 6/25
 - 7s - loss: 0.3775 - acc: 0.9716 - val_loss: 0.1246 - val_acc: 0.9642
Epoch 7/25
 - 7s - loss: 0.1164 - acc: 0.9722 - val_loss: 0.1372 - val_acc: 0.9638
Epoch 8/25
 - 7s - loss: 0.0801 - acc: 0.9735 - val_loss: 0.1429 - val_acc: 0.9646
Epoch 9/25
 - 7s - loss: 0.0504 - acc: 0.9736 - val_loss: 0.1449 - val_acc: 0.9643
Epoch 10/25
 - 7s - loss: 0.0480 - acc: 0.9740 - val_loss: 0.1644 - val_acc: 0.9638
Epoch 11/25
 - 7s - loss: 0.0459 - acc: 0.9745 - val_loss: 0.1728 - val_acc: 0.9656
Epoch 12/25
 - 7s - loss: 0.0453 - acc: 0.9749 - val_loss: 0.1741 - val_acc: 0.9638
Epoch 13/25
 - 7s - loss: 0.0424 - acc: 0.9752 - val_loss: 0.1736 - val_acc: 0.9649
Epoch 14/25
 - 7s - loss: 0.0518 - acc: 0.9753 - val_loss: 0.1776 - val_acc: 0.9637
Epoch 15/25
 - 7s - loss: 0.0428 - acc: 0.9757 - val_loss: 0.1756 - val_acc: 0.9644
Epoch 16/25
 - 7s - loss: 0.0398 - acc: 0.9757 - val_loss: 0.1685 - val_acc: 0.9638
Epoch 17/25
 - 7s - loss: 0.0403 - acc: 0.9759 - val_loss: 0.1834 - val_acc: 0.9649
Epoch 18/25
 - 7s - loss: 0.0395 - acc: 0.9759 - val_loss: 0.1768 - val_acc: 0.9650
Epoch 19/25
 - 7s - loss: 0.0380 - acc: 0.9764 - val_loss: 0.1898 - val_acc: 0.9643
Epoch 20/25
 - 7s - loss: 0.0376 - acc: 0.9765 - val_loss: 0.1992 - val_acc: 0.9647
Epoch 21/25
 - 7s - loss: 0.0438 - acc: 0.9765 - val_loss: 0.2014 - val_acc: 0.9641
Epoch 22/25
 - 7s - loss: 0.0388 - acc: 0.9766 - val_loss: 0.1863 - val_acc: 0.9641
Epoch 23/25
 - 7s - loss: 0.3115 - acc: 0.9769 - val_loss: 0.2161 - val_acc: 0.9654
Epoch 24/25
 - 7s - loss: 0.0376 - acc: 0.9770 - val_loss: 0.1989 - val_acc: 0.9640
Epoch 25/25
 - 7s - loss: 0.0367 - acc: 0.9769 - val_loss: 0.2630 - val_acc: 0.9655
Epoch 1/25
 - 1s - loss: 0.2337 - acc: 0.9604
Epoch 2/25
 - 1s - loss: 0.1133 - acc: 0.9630
Epoch 3/25
 - 1s - loss: 0.0865 - acc: 0.9672
Epoch 4/25
 - 1s - loss: 0.0718 - acc: 0.9702
Epoch 5/25
 - 1s - loss: 0.0597 - acc: 0.9717
Epoch 6/25
 - 1s - loss: 0.0558 - acc: 0.9735
Epoch 7/25
 - 1s - loss: 0.0504 - acc: 0.9750
Epoch 8/25
 - 1s - loss: 0.0507 - acc: 0.9747
Epoch 9/25
 - 1s - loss: 0.0483 - acc: 0.9751
Epoch 10/25
 - 1s - loss: 0.0451 - acc: 0.9761
Epoch 11/25
 - 1s - loss: 0.0439 - acc: 0.9763
Epoch 12/25
 - 1s - loss: 0.0441 - acc: 0.9770
Epoch 13/25
 - 1s - loss: 0.0431 - acc: 0.9773
Epoch 14/25
 - 1s - loss: 0.0424 - acc: 0.9770
Epoch 15/25
 - 1s - loss: 0.0430 - acc: 0.9777
Epoch 16/25
 - 1s - loss: 0.0436 - acc: 0.9778
Epoch 17/25
 - 1s - loss: 0.0454 - acc: 0.9773
Epoch 18/25
 - 1s - loss: 0.0423 - acc: 0.9780
Epoch 19/25
 - 1s - loss: 0.0405 - acc: 0.9781
Epoch 20/25
 - 1s - loss: 0.0406 - acc: 0.9785
Epoch 21/25
 - 1s - loss: 0.0398 - acc: 0.9781
Epoch 22/25
 - 1s - loss: 0.0396 - acc: 0.9788
Epoch 23/25
 - 1s - loss: 0.0405 - acc: 0.9793
Epoch 24/25
 - 1s - loss: 0.0405 - acc: 0.9790
Epoch 25/25
 - 1s - loss: 0.0393 - acc: 0.9792
# Training time = 0:04:02.843070
# F-Score(Ordinary) = 0.574, Recall: 0.478, Precision: 0.72
# F-Score(lvc) = 0.342, Recall: 0.243, Precision: 0.576
# F-Score(ireflv) = 0.765, Recall: 0.684, Precision: 0.869
# F-Score(id) = 0.642, Recall: 0.621, Precision: 0.663
********************
