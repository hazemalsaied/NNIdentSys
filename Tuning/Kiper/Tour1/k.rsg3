INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
/home/halsaied/miniconda2/lib/python2.7/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.19 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
KIPER CONF: word = 109 - pos 28 - lstmLayers 1 - lstmUnits 60 - lstmDrop 0.19 - denseUnits 32 - dnenseActiv tanh - optim adagrad lr 0.018 compactVocab True Lemma False 

==================================================================================================
	Fixed Size Mode
==================================================================================================
	Language : FR
==================================================================================================
	Dataset : Sharedtask 1.1
	Training (Important) : 2495, Test : 2236
	MWEs in tain : 1876, occurrences : 2876
	Impotant words in tain : 1677
	MWE length mean : 2.29
	Seen MWEs : 312 (49 %)
	New MWEs : 317 (50 %)
==================================================================================================
# Network optimizer = adagrad, learning rate = 0.018

==================================================================================================
	Training time : 1:52:33.992563
==================================================================================================
/home/halsaied/miniconda2/lib/python2.7/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
	Randomly Selected Transitions: 0
	Identification : 0.544
	Test analysis
==================================================================================================
	Correctly identified MWEs
==================================================================================================
	0 : 161
	25 : 2
	50 : 3
	5 : 25

__________________________________________________________________________________________________
	Non Identified MWEs
==================================================================================================
	0 : 295
	25 : 1
	50 : 3
	5 : 12

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
KIPER CONF: word = 37 - pos 6 - lstmLayers 1 - lstmUnits 56 - lstmDrop 0.3 - denseUnits 16 - dnenseActiv tanh - optim adagrad lr 0.014 compactVocab False Lemma False 

==================================================================================================
	Fixed Size Mode
==================================================================================================
	Language : FR
==================================================================================================
	Dataset : Sharedtask 1.1
	Training (Important) : 2495, Test : 2236
	MWEs in tain : 1876, occurrences : 2876
	Impotant words in tain : 1677
	MWE length mean : 2.29
	Seen MWEs : 312 (49 %)
	New MWEs : 317 (50 %)
==================================================================================================
# Network optimizer = adagrad, learning rate = 0.014

==================================================================================================
	Training time : 1:53:15.830099
==================================================================================================
	Randomly Selected Transitions: 0
	Identification : 0.223
	Test analysis
==================================================================================================
	Correctly identified MWEs
==================================================================================================
	0 : 85
	25 : 2
	50 : 3
	5 : 10

__________________________________________________________________________________________________
	Non Identified MWEs
==================================================================================================
	0 : 370
	25 : 2
	50 : 3
	5 : 24

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
KIPER CONF: word = 114 - pos 37 - lstmLayers 2 - lstmUnits 62 - lstmDrop 0.23 - denseUnits 18 - dnenseActiv tanh - optim adagrad lr 0.03 compactVocab True Lemma True 

==================================================================================================
	Fixed Size Mode
==================================================================================================
	Language : FR
==================================================================================================
	Dataset : Sharedtask 1.1
	Training (Important) : 2495, Test : 2236
	MWEs in tain : 1195, occurrences : 2876
	Impotant words in tain : 1000
	MWE length mean : 2.29
	Seen MWEs : 444 (70 %)
	New MWEs : 185 (29 %)
==================================================================================================
# Network optimizer = adagrad, learning rate = 0.03

==================================================================================================
	Training time : 2:17:33.752490
==================================================================================================
	Randomly Selected Transitions: 0
	Identification : 0.221
	Test analysis
==================================================================================================
	Correctly identified MWEs
==================================================================================================
	0 : 44
	50 : 3
	100 : 1
	5 : 19

__________________________________________________________________________________________________
	Non Identified MWEs
==================================================================================================
	0 : 284
	25 : 2
	50 : 5
	100 : 1
	5 : 63

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
KIPER CONF: word = 24 - pos 27 - lstmLayers 2 - lstmUnits 20 - lstmDrop 0.29 - denseUnits 10 - dnenseActiv relu - optim adagrad lr 0.055 compactVocab True Lemma False 

==================================================================================================
	Fixed Size Mode
==================================================================================================
	Language : FR
==================================================================================================
	Dataset : Sharedtask 1.1
	Training (Important) : 2495, Test : 2236
	MWEs in tain : 1876, occurrences : 2876
	Impotant words in tain : 1677
	MWE length mean : 2.29
	Seen MWEs : 312 (49 %)
	New MWEs : 317 (50 %)
==================================================================================================
# Network optimizer = adagrad, learning rate = 0.055

==================================================================================================
	Training time : 2:09:01.749769
==================================================================================================
## OAR [2018-09-10 15:41:25] Job 1676948 KILLED ##
